# Comparing `tmp/google-cloud-dataplex-1.9.0.tar.gz` & `tmp/google-cloud-dataplex-2.0.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "google-cloud-dataplex-1.9.0.tar", last modified: Wed Nov 29 18:55:34 2023, max compression
+gzip compressed data, was "google-cloud-dataplex-2.0.0.tar", last modified: Thu May 16 17:15:10 2024, max compression
```

## Comparing `google-cloud-dataplex-1.9.0.tar` & `google-cloud-dataplex-2.0.0.tar`

### file list

```diff
@@ -1,106 +1,117 @@
-drwxr-sr-x   0 root         (0)     1003        0 2023-11-29 18:55:34.313031 google-cloud-dataplex-1.9.0/
--rw-rw-r--   0 root         (0)     1003    11358 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/LICENSE
--rw-rw-r--   0 root         (0)     1003      860 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/MANIFEST.in
--rw-r--r--   0 root         (0)     1003     5226 2023-11-29 18:55:34.313031 google-cloud-dataplex-1.9.0/PKG-INFO
--rw-rw-r--   0 root         (0)     1003     3879 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/README.rst
-drwxr-sr-x   0 root         (0)     1003        0 2023-11-29 18:55:34.177018 google-cloud-dataplex-1.9.0/google/
-drwxr-sr-x   0 root         (0)     1003        0 2023-11-29 18:55:34.181018 google-cloud-dataplex-1.9.0/google/cloud/
-drwxr-sr-x   0 root         (0)     1003        0 2023-11-29 18:55:34.185018 google-cloud-dataplex-1.9.0/google/cloud/dataplex/
--rw-rw-r--   0 root         (0)     1003     9275 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex/__init__.py
--rw-rw-r--   0 root         (0)     1003      652 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex/gapic_version.py
--rw-rw-r--   0 root         (0)     1003       82 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex/py.typed
-drwxr-sr-x   0 root         (0)     1003        0 2023-11-29 18:55:34.189019 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/
--rw-rw-r--   0 root         (0)     1003     8325 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/__init__.py
--rw-rw-r--   0 root         (0)     1003    19755 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/gapic_metadata.json
--rw-rw-r--   0 root         (0)     1003      652 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/gapic_version.py
--rw-rw-r--   0 root         (0)     1003       82 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/py.typed
-drwxr-sr-x   0 root         (0)     1003        0 2023-11-29 18:55:34.189019 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/
--rw-rw-r--   0 root         (0)     1003      600 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/__init__.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-11-29 18:55:34.193019 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/content_service/
--rw-rw-r--   0 root         (0)     1003      769 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/content_service/__init__.py
--rw-rw-r--   0 root         (0)     1003    62131 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/content_service/async_client.py
--rw-rw-r--   0 root         (0)     1003    70882 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/content_service/client.py
--rw-rw-r--   0 root         (0)     1003     5658 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/content_service/pagers.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-11-29 18:55:34.197019 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/content_service/transports/
--rw-rw-r--   0 root         (0)     1003     1193 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/content_service/transports/__init__.py
--rw-rw-r--   0 root         (0)     1003    12134 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/content_service/transports/base.py
--rw-rw-r--   0 root         (0)     1003    25634 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/content_service/transports/grpc.py
--rw-rw-r--   0 root         (0)     1003    26008 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/content_service/transports/grpc_asyncio.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-11-29 18:55:34.209021 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_scan_service/
--rw-rw-r--   0 root         (0)     1003      773 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_scan_service/__init__.py
--rw-rw-r--   0 root         (0)     1003    62437 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_scan_service/async_client.py
--rw-rw-r--   0 root         (0)     1003    73573 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_scan_service/client.py
--rw-rw-r--   0 root         (0)     1003    10807 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_scan_service/pagers.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-11-29 18:55:34.213021 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_scan_service/transports/
--rw-rw-r--   0 root         (0)     1003     1202 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_scan_service/transports/__init__.py
--rw-rw-r--   0 root         (0)     1003    10921 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_scan_service/transports/base.py
--rw-rw-r--   0 root         (0)     1003    25499 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_scan_service/transports/grpc.py
--rw-rw-r--   0 root         (0)     1003    25983 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_scan_service/transports/grpc_asyncio.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-11-29 18:55:34.225022 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_taxonomy_service/
--rw-rw-r--   0 root         (0)     1003      789 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_taxonomy_service/__init__.py
--rw-rw-r--   0 root         (0)     1003   100480 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_taxonomy_service/async_client.py
--rw-rw-r--   0 root         (0)     1003   112968 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_taxonomy_service/client.py
--rw-rw-r--   0 root         (0)     1003    16556 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_taxonomy_service/pagers.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-11-29 18:55:34.233023 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_taxonomy_service/transports/
--rw-rw-r--   0 root         (0)     1003     1246 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_taxonomy_service/transports/__init__.py
--rw-rw-r--   0 root         (0)     1003    14730 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_taxonomy_service/transports/base.py
--rw-rw-r--   0 root         (0)     1003    35102 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_taxonomy_service/transports/grpc.py
--rw-rw-r--   0 root         (0)     1003    35794 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_taxonomy_service/transports/grpc_asyncio.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-11-29 18:55:34.245024 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/dataplex_service/
--rw-rw-r--   0 root         (0)     1003      773 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/dataplex_service/__init__.py
--rw-rw-r--   0 root         (0)     1003   186298 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/dataplex_service/async_client.py
--rw-rw-r--   0 root         (0)     1003   199328 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/dataplex_service/client.py
--rw-rw-r--   0 root         (0)     1003    49482 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/dataplex_service/pagers.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-11-29 18:55:34.249025 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/dataplex_service/transports/
--rw-rw-r--   0 root         (0)     1003     1202 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/dataplex_service/transports/__init__.py
--rw-rw-r--   0 root         (0)     1003    26223 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/dataplex_service/transports/base.py
--rw-rw-r--   0 root         (0)     1003    52208 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/dataplex_service/transports/grpc.py
--rw-rw-r--   0 root         (0)     1003    53320 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/dataplex_service/transports/grpc_asyncio.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-11-29 18:55:34.257025 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/metadata_service/
--rw-rw-r--   0 root         (0)     1003      773 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/metadata_service/__init__.py
--rw-rw-r--   0 root         (0)     1003    61647 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/metadata_service/async_client.py
--rw-rw-r--   0 root         (0)     1003    72101 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/metadata_service/client.py
--rw-rw-r--   0 root         (0)     1003    10685 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/metadata_service/pagers.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-11-29 18:55:34.261026 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/metadata_service/transports/
--rw-rw-r--   0 root         (0)     1003     1202 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/metadata_service/transports/__init__.py
--rw-rw-r--   0 root         (0)     1003    12435 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/metadata_service/transports/base.py
--rw-rw-r--   0 root         (0)     1003    25630 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/metadata_service/transports/grpc.py
--rw-rw-r--   0 root         (0)     1003    26055 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/metadata_service/transports/grpc_asyncio.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-11-29 18:55:34.293029 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/types/
--rw-rw-r--   0 root         (0)     1003     7329 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/types/__init__.py
--rw-rw-r--   0 root         (0)     1003    16335 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/types/analyze.py
--rw-rw-r--   0 root         (0)     1003     6555 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/types/content.py
--rw-rw-r--   0 root         (0)     1003    22501 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/types/data_profile.py
--rw-rw-r--   0 root         (0)     1003    23336 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/types/data_quality.py
--rw-rw-r--   0 root         (0)     1003    31052 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/types/data_taxonomy.py
--rw-rw-r--   0 root         (0)     1003    25543 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/types/datascans.py
--rw-rw-r--   0 root         (0)     1003    40511 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/types/logs.py
--rw-rw-r--   0 root         (0)     1003    38145 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/types/metadata_.py
--rw-rw-r--   0 root         (0)     1003     5857 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/types/processing.py
--rw-rw-r--   0 root         (0)     1003    50791 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/types/resources.py
--rw-rw-r--   0 root         (0)     1003     2922 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/types/security.py
--rw-rw-r--   0 root         (0)     1003    40691 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/types/service.py
--rw-rw-r--   0 root         (0)     1003    27261 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/types/tasks.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-11-29 18:55:34.293029 google-cloud-dataplex-1.9.0/google_cloud_dataplex.egg-info/
--rw-r--r--   0 root         (0)     1003     5226 2023-11-29 18:55:34.000000 google-cloud-dataplex-1.9.0/google_cloud_dataplex.egg-info/PKG-INFO
--rw-r--r--   0 root         (0)     1003     4435 2023-11-29 18:55:34.000000 google-cloud-dataplex-1.9.0/google_cloud_dataplex.egg-info/SOURCES.txt
--rw-r--r--   0 root         (0)     1003        1 2023-11-29 18:55:34.000000 google-cloud-dataplex-1.9.0/google_cloud_dataplex.egg-info/dependency_links.txt
--rw-r--r--   0 root         (0)     1003       20 2023-11-29 18:55:34.000000 google-cloud-dataplex-1.9.0/google_cloud_dataplex.egg-info/namespace_packages.txt
--rw-r--r--   0 root         (0)     1003        1 2023-11-29 18:55:34.000000 google-cloud-dataplex-1.9.0/google_cloud_dataplex.egg-info/not-zip-safe
--rw-r--r--   0 root         (0)     1003      352 2023-11-29 18:55:34.000000 google-cloud-dataplex-1.9.0/google_cloud_dataplex.egg-info/requires.txt
--rw-r--r--   0 root         (0)     1003        7 2023-11-29 18:55:34.000000 google-cloud-dataplex-1.9.0/google_cloud_dataplex.egg-info/top_level.txt
--rw-rw-r--   0 root         (0)     1003       67 2023-11-29 18:55:34.313031 google-cloud-dataplex-1.9.0/setup.cfg
--rw-rw-r--   0 root         (0)     1003     2976 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/setup.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-11-29 18:55:34.293029 google-cloud-dataplex-1.9.0/tests/
--rw-rw-r--   0 root         (0)     1003      600 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/tests/__init__.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-11-29 18:55:34.293029 google-cloud-dataplex-1.9.0/tests/unit/
--rw-rw-r--   0 root         (0)     1003      600 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/tests/unit/__init__.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-11-29 18:55:34.297029 google-cloud-dataplex-1.9.0/tests/unit/gapic/
--rw-rw-r--   0 root         (0)     1003      600 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/tests/unit/gapic/__init__.py
-drwxr-sr-x   0 root         (0)     1003        0 2023-11-29 18:55:34.313031 google-cloud-dataplex-1.9.0/tests/unit/gapic/dataplex_v1/
--rw-rw-r--   0 root         (0)     1003      600 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/tests/unit/gapic/dataplex_v1/__init__.py
--rw-rw-r--   0 root         (0)     1003   154388 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/tests/unit/gapic/dataplex_v1/test_content_service.py
--rw-rw-r--   0 root         (0)     1003   169274 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/tests/unit/gapic/dataplex_v1/test_data_scan_service.py
--rw-rw-r--   0 root         (0)     1003   249604 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/tests/unit/gapic/dataplex_v1/test_data_taxonomy_service.py
--rw-rw-r--   0 root         (0)     1003   431970 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/tests/unit/gapic/dataplex_v1/test_dataplex_service.py
--rw-rw-r--   0 root         (0)     1003   175825 2023-11-29 18:51:45.000000 google-cloud-dataplex-1.9.0/tests/unit/gapic/dataplex_v1/test_metadata_service.py
+drwxr-sr-x   0 root         (0)     1003        0 2024-05-16 17:15:10.549616 google-cloud-dataplex-2.0.0/
+-rw-rw-r--   0 root         (0)     1003    11358 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/LICENSE
+-rw-rw-r--   0 root         (0)     1003      860 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/MANIFEST.in
+-rw-r--r--   0 root         (0)     1003     5311 2024-05-16 17:15:10.549616 google-cloud-dataplex-2.0.0/PKG-INFO
+-rw-rw-r--   0 root         (0)     1003     3879 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/README.rst
+drwxr-sr-x   0 root         (0)     1003        0 2024-05-16 17:15:10.521615 google-cloud-dataplex-2.0.0/google/
+drwxr-sr-x   0 root         (0)     1003        0 2024-05-16 17:15:10.521615 google-cloud-dataplex-2.0.0/google/cloud/
+drwxr-sr-x   0 root         (0)     1003        0 2024-05-16 17:15:10.525615 google-cloud-dataplex-2.0.0/google/cloud/dataplex/
+-rw-rw-r--   0 root         (0)     1003    11664 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex/__init__.py
+-rw-rw-r--   0 root         (0)     1003      652 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex/gapic_version.py
+-rw-rw-r--   0 root         (0)     1003       82 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex/py.typed
+drwxr-sr-x   0 root         (0)     1003        0 2024-05-16 17:15:10.525615 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/
+-rw-rw-r--   0 root         (0)     1003    10567 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/__init__.py
+-rw-rw-r--   0 root         (0)     1003    25787 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/gapic_metadata.json
+-rw-rw-r--   0 root         (0)     1003      652 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/gapic_version.py
+-rw-rw-r--   0 root         (0)     1003       82 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/py.typed
+drwxr-sr-x   0 root         (0)     1003        0 2024-05-16 17:15:10.525615 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/
+-rw-rw-r--   0 root         (0)     1003      600 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/__init__.py
+drwxr-sr-x   0 root         (0)     1003        0 2024-05-16 17:15:10.529615 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/catalog_service/
+-rw-rw-r--   0 root         (0)     1003      769 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/catalog_service/__init__.py
+-rw-rw-r--   0 root         (0)     1003   134347 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/catalog_service/async_client.py
+-rw-rw-r--   0 root         (0)     1003   150223 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/catalog_service/client.py
+-rw-rw-r--   0 root         (0)     1003    25543 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/catalog_service/pagers.py
+drwxr-sr-x   0 root         (0)     1003        0 2024-05-16 17:15:10.529615 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/catalog_service/transports/
+-rw-rw-r--   0 root         (0)     1003     1193 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/catalog_service/transports/__init__.py
+-rw-rw-r--   0 root         (0)     1003    21274 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/catalog_service/transports/base.py
+-rw-rw-r--   0 root         (0)     1003    41213 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/catalog_service/transports/grpc.py
+-rw-rw-r--   0 root         (0)     1003    51306 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/catalog_service/transports/grpc_asyncio.py
+drwxr-sr-x   0 root         (0)     1003        0 2024-05-16 17:15:10.529615 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/content_service/
+-rw-rw-r--   0 root         (0)     1003      769 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/content_service/__init__.py
+-rw-rw-r--   0 root         (0)     1003    65005 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/content_service/async_client.py
+-rw-rw-r--   0 root         (0)     1003    81453 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/content_service/client.py
+-rw-rw-r--   0 root         (0)     1003     5658 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/content_service/pagers.py
+drwxr-sr-x   0 root         (0)     1003        0 2024-05-16 17:15:10.529615 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/content_service/transports/
+-rw-rw-r--   0 root         (0)     1003     1193 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/content_service/transports/__init__.py
+-rw-rw-r--   0 root         (0)     1003    12232 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/content_service/transports/base.py
+-rw-rw-r--   0 root         (0)     1003    26218 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/content_service/transports/grpc.py
+-rw-rw-r--   0 root         (0)     1003    29798 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/content_service/transports/grpc_asyncio.py
+drwxr-sr-x   0 root         (0)     1003        0 2024-05-16 17:15:10.533615 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_scan_service/
+-rw-rw-r--   0 root         (0)     1003      773 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_scan_service/__init__.py
+-rw-rw-r--   0 root         (0)     1003    71652 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_scan_service/async_client.py
+-rw-rw-r--   0 root         (0)     1003    88412 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_scan_service/client.py
+-rw-rw-r--   0 root         (0)     1003    10807 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_scan_service/pagers.py
+drwxr-sr-x   0 root         (0)     1003        0 2024-05-16 17:15:10.533615 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_scan_service/transports/
+-rw-rw-r--   0 root         (0)     1003     1202 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_scan_service/transports/__init__.py
+-rw-rw-r--   0 root         (0)     1003    11568 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_scan_service/transports/base.py
+-rw-rw-r--   0 root         (0)     1003    27406 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_scan_service/transports/grpc.py
+-rw-rw-r--   0 root         (0)     1003    29979 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_scan_service/transports/grpc_asyncio.py
+drwxr-sr-x   0 root         (0)     1003        0 2024-05-16 17:15:10.533615 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_taxonomy_service/
+-rw-rw-r--   0 root         (0)     1003      789 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_taxonomy_service/__init__.py
+-rw-rw-r--   0 root         (0)     1003   107135 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_taxonomy_service/async_client.py
+-rw-rw-r--   0 root         (0)     1003   123268 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_taxonomy_service/client.py
+-rw-rw-r--   0 root         (0)     1003    16556 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_taxonomy_service/pagers.py
+drwxr-sr-x   0 root         (0)     1003        0 2024-05-16 17:15:10.533615 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_taxonomy_service/transports/
+-rw-rw-r--   0 root         (0)     1003     1246 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_taxonomy_service/transports/__init__.py
+-rw-rw-r--   0 root         (0)     1003    14828 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_taxonomy_service/transports/base.py
+-rw-rw-r--   0 root         (0)     1003    35686 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_taxonomy_service/transports/grpc.py
+-rw-rw-r--   0 root         (0)     1003    39845 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_taxonomy_service/transports/grpc_asyncio.py
+drwxr-sr-x   0 root         (0)     1003        0 2024-05-16 17:15:10.537616 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/dataplex_service/
+-rw-rw-r--   0 root         (0)     1003      773 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/dataplex_service/__init__.py
+-rw-rw-r--   0 root         (0)     1003   192440 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/dataplex_service/async_client.py
+-rw-rw-r--   0 root         (0)     1003   209842 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/dataplex_service/client.py
+-rw-rw-r--   0 root         (0)     1003    49482 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/dataplex_service/pagers.py
+drwxr-sr-x   0 root         (0)     1003        0 2024-05-16 17:15:10.537616 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/dataplex_service/transports/
+-rw-rw-r--   0 root         (0)     1003     1202 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/dataplex_service/transports/__init__.py
+-rw-rw-r--   0 root         (0)     1003    26321 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/dataplex_service/transports/base.py
+-rw-rw-r--   0 root         (0)     1003    52792 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/dataplex_service/transports/grpc.py
+-rw-rw-r--   0 root         (0)     1003    65764 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/dataplex_service/transports/grpc_asyncio.py
+drwxr-sr-x   0 root         (0)     1003        0 2024-05-16 17:15:10.537616 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/metadata_service/
+-rw-rw-r--   0 root         (0)     1003      773 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/metadata_service/__init__.py
+-rw-rw-r--   0 root         (0)     1003    65322 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/metadata_service/async_client.py
+-rw-rw-r--   0 root         (0)     1003    82454 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/metadata_service/client.py
+-rw-rw-r--   0 root         (0)     1003    10685 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/metadata_service/pagers.py
+drwxr-sr-x   0 root         (0)     1003        0 2024-05-16 17:15:10.537616 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/metadata_service/transports/
+-rw-rw-r--   0 root         (0)     1003     1202 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/metadata_service/transports/__init__.py
+-rw-rw-r--   0 root         (0)     1003    12533 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/metadata_service/transports/base.py
+-rw-rw-r--   0 root         (0)     1003    26214 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/metadata_service/transports/grpc.py
+-rw-rw-r--   0 root         (0)     1003    30034 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/metadata_service/transports/grpc_asyncio.py
+drwxr-sr-x   0 root         (0)     1003        0 2024-05-16 17:15:10.541616 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/types/
+-rw-rw-r--   0 root         (0)     1003     9418 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/types/__init__.py
+-rw-rw-r--   0 root         (0)     1003    16335 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/types/analyze.py
+-rw-rw-r--   0 root         (0)     1003    60248 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/types/catalog.py
+-rw-rw-r--   0 root         (0)     1003     6555 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/types/content.py
+-rw-rw-r--   0 root         (0)     1003    22501 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/types/data_profile.py
+-rw-rw-r--   0 root         (0)     1003    31228 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/types/data_quality.py
+-rw-rw-r--   0 root         (0)     1003    31052 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/types/data_taxonomy.py
+-rw-rw-r--   0 root         (0)     1003    26583 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/types/datascans.py
+-rw-rw-r--   0 root         (0)     1003    41118 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/types/logs.py
+-rw-rw-r--   0 root         (0)     1003    38145 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/types/metadata_.py
+-rw-rw-r--   0 root         (0)     1003     5857 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/types/processing.py
+-rw-rw-r--   0 root         (0)     1003    50791 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/types/resources.py
+-rw-rw-r--   0 root         (0)     1003     2922 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/types/security.py
+-rw-rw-r--   0 root         (0)     1003    40691 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/types/service.py
+-rw-rw-r--   0 root         (0)     1003    27261 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/types/tasks.py
+drwxr-sr-x   0 root         (0)     1003        0 2024-05-16 17:15:10.545616 google-cloud-dataplex-2.0.0/google_cloud_dataplex.egg-info/
+-rw-r--r--   0 root         (0)     1003     5311 2024-05-16 17:15:10.000000 google-cloud-dataplex-2.0.0/google_cloud_dataplex.egg-info/PKG-INFO
+-rw-r--r--   0 root         (0)     1003     5012 2024-05-16 17:15:10.000000 google-cloud-dataplex-2.0.0/google_cloud_dataplex.egg-info/SOURCES.txt
+-rw-r--r--   0 root         (0)     1003        1 2024-05-16 17:15:10.000000 google-cloud-dataplex-2.0.0/google_cloud_dataplex.egg-info/dependency_links.txt
+-rw-r--r--   0 root         (0)     1003        1 2024-05-16 17:15:10.000000 google-cloud-dataplex-2.0.0/google_cloud_dataplex.egg-info/not-zip-safe
+-rw-r--r--   0 root         (0)     1003      342 2024-05-16 17:15:10.000000 google-cloud-dataplex-2.0.0/google_cloud_dataplex.egg-info/requires.txt
+-rw-r--r--   0 root         (0)     1003        7 2024-05-16 17:15:10.000000 google-cloud-dataplex-2.0.0/google_cloud_dataplex.egg-info/top_level.txt
+-rw-rw-r--   0 root         (0)     1003       67 2024-05-16 17:15:10.549616 google-cloud-dataplex-2.0.0/setup.cfg
+-rw-rw-r--   0 root         (0)     1003     3214 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/setup.py
+drwxr-sr-x   0 root         (0)     1003        0 2024-05-16 17:15:10.545616 google-cloud-dataplex-2.0.0/tests/
+-rw-rw-r--   0 root         (0)     1003      600 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/tests/__init__.py
+drwxr-sr-x   0 root         (0)     1003        0 2024-05-16 17:15:10.545616 google-cloud-dataplex-2.0.0/tests/unit/
+-rw-rw-r--   0 root         (0)     1003      600 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/tests/unit/__init__.py
+drwxr-sr-x   0 root         (0)     1003        0 2024-05-16 17:15:10.545616 google-cloud-dataplex-2.0.0/tests/unit/gapic/
+-rw-rw-r--   0 root         (0)     1003      600 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/tests/unit/gapic/__init__.py
+drwxr-sr-x   0 root         (0)     1003        0 2024-05-16 17:15:10.549616 google-cloud-dataplex-2.0.0/tests/unit/gapic/dataplex_v1/
+-rw-rw-r--   0 root         (0)     1003      600 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/tests/unit/gapic/dataplex_v1/__init__.py
+-rw-rw-r--   0 root         (0)     1003   447142 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/tests/unit/gapic/dataplex_v1/test_catalog_service.py
+-rw-rw-r--   0 root         (0)     1003   212548 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/tests/unit/gapic/dataplex_v1/test_content_service.py
+-rw-rw-r--   0 root         (0)     1003   243165 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/tests/unit/gapic/dataplex_v1/test_data_scan_service.py
+-rw-rw-r--   0 root         (0)     1003   352046 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/tests/unit/gapic/dataplex_v1/test_data_taxonomy_service.py
+-rw-rw-r--   0 root         (0)     1003   623533 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/tests/unit/gapic/dataplex_v1/test_dataplex_service.py
+-rw-rw-r--   0 root         (0)     1003   240507 2024-05-16 17:11:28.000000 google-cloud-dataplex-2.0.0/tests/unit/gapic/dataplex_v1/test_metadata_service.py
```

### Comparing `google-cloud-dataplex-1.9.0/LICENSE` & `google-cloud-dataplex-2.0.0/LICENSE`

 * *Files identical despite different names*

### Comparing `google-cloud-dataplex-1.9.0/MANIFEST.in` & `google-cloud-dataplex-2.0.0/MANIFEST.in`

 * *Files identical despite different names*

### Comparing `google-cloud-dataplex-1.9.0/PKG-INFO` & `google-cloud-dataplex-2.0.0/PKG-INFO`

 * *Files 3% similar despite different names*

```diff
@@ -1,33 +1,34 @@
 Metadata-Version: 2.1
 Name: google-cloud-dataplex
-Version: 1.9.0
+Version: 2.0.0
 Summary: Google Cloud Dataplex API client library
-Home-page: https://github.com/googleapis/google-cloud-python
+Home-page: https://github.com/googleapis/google-cloud-python/tree/main/packages/google-cloud-dataplex
 Author: Google LLC
 Author-email: googleapis-packages@google.com
 License: Apache 2.0
 Platform: Posix; MacOS X; Windows
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Intended Audience :: Developers
 Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Programming Language :: Python
 Classifier: Programming Language :: Python :: 3
 Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11
+Classifier: Programming Language :: Python :: 3.12
 Classifier: Operating System :: OS Independent
 Classifier: Topic :: Internet
 Requires-Python: >=3.7
 License-File: LICENSE
-Requires-Dist: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0
-Requires-Dist: proto-plus<2.0.0dev,>=1.22.0
-Requires-Dist: proto-plus<2.0.0dev,>=1.22.2; python_version >= "3.11"
+Requires-Dist: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1
+Requires-Dist: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1
+Requires-Dist: proto-plus<2.0.0dev,>=1.22.3
 Requires-Dist: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5
 Requires-Dist: grpc-google-iam-v1<1.0.0dev,>=0.12.4
 
 Python Client for Cloud Dataplex
 ================================
 
 |stable| |pypi| |versions|
```

### Comparing `google-cloud-dataplex-1.9.0/README.rst` & `google-cloud-dataplex-2.0.0/README.rst`

 * *Files identical despite different names*

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex/__init__.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/__init__.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,79 +1,98 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
-from google.cloud.dataplex import gapic_version as package_version
+from google.cloud.dataplex_v1 import gapic_version as package_version
 
 __version__ = package_version.__version__
 
 
-from google.cloud.dataplex_v1.services.content_service.async_client import (
-    ContentServiceAsyncClient,
-)
-from google.cloud.dataplex_v1.services.content_service.client import (
-    ContentServiceClient,
-)
-from google.cloud.dataplex_v1.services.data_scan_service.async_client import (
+from .services.catalog_service import CatalogServiceAsyncClient, CatalogServiceClient
+from .services.content_service import ContentServiceAsyncClient, ContentServiceClient
+from .services.data_scan_service import (
     DataScanServiceAsyncClient,
-)
-from google.cloud.dataplex_v1.services.data_scan_service.client import (
     DataScanServiceClient,
 )
-from google.cloud.dataplex_v1.services.data_taxonomy_service.async_client import (
+from .services.data_taxonomy_service import (
     DataTaxonomyServiceAsyncClient,
-)
-from google.cloud.dataplex_v1.services.data_taxonomy_service.client import (
     DataTaxonomyServiceClient,
 )
-from google.cloud.dataplex_v1.services.dataplex_service.async_client import (
-    DataplexServiceAsyncClient,
-)
-from google.cloud.dataplex_v1.services.dataplex_service.client import (
-    DataplexServiceClient,
-)
-from google.cloud.dataplex_v1.services.metadata_service.async_client import (
-    MetadataServiceAsyncClient,
+from .services.dataplex_service import DataplexServiceAsyncClient, DataplexServiceClient
+from .services.metadata_service import MetadataServiceAsyncClient, MetadataServiceClient
+from .types.analyze import Content, Environment, Session
+from .types.catalog import (
+    Aspect,
+    AspectSource,
+    AspectType,
+    CreateAspectTypeRequest,
+    CreateEntryGroupRequest,
+    CreateEntryRequest,
+    CreateEntryTypeRequest,
+    DeleteAspectTypeRequest,
+    DeleteEntryGroupRequest,
+    DeleteEntryRequest,
+    DeleteEntryTypeRequest,
+    Entry,
+    EntryGroup,
+    EntrySource,
+    EntryType,
+    EntryView,
+    GetAspectTypeRequest,
+    GetEntryGroupRequest,
+    GetEntryRequest,
+    GetEntryTypeRequest,
+    ListAspectTypesRequest,
+    ListAspectTypesResponse,
+    ListEntriesRequest,
+    ListEntriesResponse,
+    ListEntryGroupsRequest,
+    ListEntryGroupsResponse,
+    ListEntryTypesRequest,
+    ListEntryTypesResponse,
+    LookupEntryRequest,
+    SearchEntriesRequest,
+    SearchEntriesResponse,
+    SearchEntriesResult,
+    TransferStatus,
+    UpdateAspectTypeRequest,
+    UpdateEntryGroupRequest,
+    UpdateEntryRequest,
+    UpdateEntryTypeRequest,
 )
-from google.cloud.dataplex_v1.services.metadata_service.client import (
-    MetadataServiceClient,
-)
-from google.cloud.dataplex_v1.types.analyze import Content, Environment, Session
-from google.cloud.dataplex_v1.types.content import (
+from .types.content import (
     CreateContentRequest,
     DeleteContentRequest,
     GetContentRequest,
     ListContentRequest,
     ListContentResponse,
     UpdateContentRequest,
 )
-from google.cloud.dataplex_v1.types.data_profile import (
-    DataProfileResult,
-    DataProfileSpec,
-)
-from google.cloud.dataplex_v1.types.data_quality import (
+from .types.data_profile import DataProfileResult, DataProfileSpec
+from .types.data_quality import (
+    DataQualityColumnResult,
     DataQualityDimension,
     DataQualityDimensionResult,
     DataQualityResult,
     DataQualityRule,
     DataQualityRuleResult,
     DataQualitySpec,
 )
-from google.cloud.dataplex_v1.types.data_taxonomy import (
+from .types.data_taxonomy import (
     CreateDataAttributeBindingRequest,
     CreateDataAttributeRequest,
     CreateDataTaxonomyRequest,
     DataAttribute,
     DataAttributeBinding,
     DataTaxonomy,
     DeleteDataAttributeBindingRequest,
@@ -88,39 +107,41 @@
     ListDataAttributesResponse,
     ListDataTaxonomiesRequest,
     ListDataTaxonomiesResponse,
     UpdateDataAttributeBindingRequest,
     UpdateDataAttributeRequest,
     UpdateDataTaxonomyRequest,
 )
-from google.cloud.dataplex_v1.types.datascans import (
+from .types.datascans import (
     CreateDataScanRequest,
     DataScan,
     DataScanJob,
     DataScanType,
     DeleteDataScanRequest,
+    GenerateDataQualityRulesRequest,
+    GenerateDataQualityRulesResponse,
     GetDataScanJobRequest,
     GetDataScanRequest,
     ListDataScanJobsRequest,
     ListDataScanJobsResponse,
     ListDataScansRequest,
     ListDataScansResponse,
     RunDataScanRequest,
     RunDataScanResponse,
     UpdateDataScanRequest,
 )
-from google.cloud.dataplex_v1.types.logs import (
+from .types.logs import (
     DataQualityScanRuleResult,
     DataScanEvent,
     DiscoveryEvent,
     GovernanceEvent,
     JobEvent,
     SessionEvent,
 )
-from google.cloud.dataplex_v1.types.metadata_ import (
+from .types.metadata_ import (
     CreateEntityRequest,
     CreatePartitionRequest,
     DeleteEntityRequest,
     DeletePartitionRequest,
     Entity,
     GetEntityRequest,
     GetPartitionRequest,
@@ -131,25 +152,18 @@
     Partition,
     Schema,
     StorageAccess,
     StorageFormat,
     StorageSystem,
     UpdateEntityRequest,
 )
-from google.cloud.dataplex_v1.types.processing import DataSource, ScannedData, Trigger
-from google.cloud.dataplex_v1.types.resources import (
-    Action,
-    Asset,
-    AssetStatus,
-    Lake,
-    State,
-    Zone,
-)
-from google.cloud.dataplex_v1.types.security import DataAccessSpec, ResourceAccessSpec
-from google.cloud.dataplex_v1.types.service import (
+from .types.processing import DataSource, ScannedData, Trigger
+from .types.resources import Action, Asset, AssetStatus, Lake, State, Zone
+from .types.security import DataAccessSpec, ResourceAccessSpec
+from .types.service import (
     CancelJobRequest,
     CreateAssetRequest,
     CreateEnvironmentRequest,
     CreateLakeRequest,
     CreateTaskRequest,
     CreateZoneRequest,
     DeleteAssetRequest,
@@ -186,152 +200,194 @@
     RunTaskResponse,
     UpdateAssetRequest,
     UpdateEnvironmentRequest,
     UpdateLakeRequest,
     UpdateTaskRequest,
     UpdateZoneRequest,
 )
-from google.cloud.dataplex_v1.types.tasks import Job, Task
+from .types.tasks import Job, Task
 
 __all__ = (
-    "ContentServiceClient",
+    "CatalogServiceAsyncClient",
     "ContentServiceAsyncClient",
-    "DataplexServiceClient",
-    "DataplexServiceAsyncClient",
-    "DataScanServiceClient",
     "DataScanServiceAsyncClient",
-    "DataTaxonomyServiceClient",
     "DataTaxonomyServiceAsyncClient",
-    "MetadataServiceClient",
+    "DataplexServiceAsyncClient",
     "MetadataServiceAsyncClient",
+    "Action",
+    "Aspect",
+    "AspectSource",
+    "AspectType",
+    "Asset",
+    "AssetStatus",
+    "CancelJobRequest",
+    "CatalogServiceClient",
     "Content",
-    "Environment",
-    "Session",
+    "ContentServiceClient",
+    "CreateAspectTypeRequest",
+    "CreateAssetRequest",
     "CreateContentRequest",
-    "DeleteContentRequest",
-    "GetContentRequest",
-    "ListContentRequest",
-    "ListContentResponse",
-    "UpdateContentRequest",
+    "CreateDataAttributeBindingRequest",
+    "CreateDataAttributeRequest",
+    "CreateDataScanRequest",
+    "CreateDataTaxonomyRequest",
+    "CreateEntityRequest",
+    "CreateEntryGroupRequest",
+    "CreateEntryRequest",
+    "CreateEntryTypeRequest",
+    "CreateEnvironmentRequest",
+    "CreateLakeRequest",
+    "CreatePartitionRequest",
+    "CreateTaskRequest",
+    "CreateZoneRequest",
+    "DataAccessSpec",
+    "DataAttribute",
+    "DataAttributeBinding",
     "DataProfileResult",
     "DataProfileSpec",
+    "DataQualityColumnResult",
     "DataQualityDimension",
     "DataQualityDimensionResult",
     "DataQualityResult",
     "DataQualityRule",
     "DataQualityRuleResult",
+    "DataQualityScanRuleResult",
     "DataQualitySpec",
-    "CreateDataAttributeBindingRequest",
-    "CreateDataAttributeRequest",
-    "CreateDataTaxonomyRequest",
-    "DataAttribute",
-    "DataAttributeBinding",
-    "DataTaxonomy",
-    "DeleteDataAttributeBindingRequest",
-    "DeleteDataAttributeRequest",
-    "DeleteDataTaxonomyRequest",
-    "GetDataAttributeBindingRequest",
-    "GetDataAttributeRequest",
-    "GetDataTaxonomyRequest",
-    "ListDataAttributeBindingsRequest",
-    "ListDataAttributeBindingsResponse",
-    "ListDataAttributesRequest",
-    "ListDataAttributesResponse",
-    "ListDataTaxonomiesRequest",
-    "ListDataTaxonomiesResponse",
-    "UpdateDataAttributeBindingRequest",
-    "UpdateDataAttributeRequest",
-    "UpdateDataTaxonomyRequest",
-    "CreateDataScanRequest",
     "DataScan",
+    "DataScanEvent",
     "DataScanJob",
-    "DeleteDataScanRequest",
-    "GetDataScanJobRequest",
-    "GetDataScanRequest",
-    "ListDataScanJobsRequest",
-    "ListDataScanJobsResponse",
-    "ListDataScansRequest",
-    "ListDataScansResponse",
-    "RunDataScanRequest",
-    "RunDataScanResponse",
-    "UpdateDataScanRequest",
+    "DataScanServiceClient",
     "DataScanType",
-    "DataQualityScanRuleResult",
-    "DataScanEvent",
-    "DiscoveryEvent",
-    "GovernanceEvent",
-    "JobEvent",
-    "SessionEvent",
-    "CreateEntityRequest",
-    "CreatePartitionRequest",
-    "DeleteEntityRequest",
-    "DeletePartitionRequest",
-    "Entity",
-    "GetEntityRequest",
-    "GetPartitionRequest",
-    "ListEntitiesRequest",
-    "ListEntitiesResponse",
-    "ListPartitionsRequest",
-    "ListPartitionsResponse",
-    "Partition",
-    "Schema",
-    "StorageAccess",
-    "StorageFormat",
-    "UpdateEntityRequest",
-    "StorageSystem",
     "DataSource",
-    "ScannedData",
-    "Trigger",
-    "Action",
-    "Asset",
-    "AssetStatus",
-    "Lake",
-    "Zone",
-    "State",
-    "DataAccessSpec",
-    "ResourceAccessSpec",
-    "CancelJobRequest",
-    "CreateAssetRequest",
-    "CreateEnvironmentRequest",
-    "CreateLakeRequest",
-    "CreateTaskRequest",
-    "CreateZoneRequest",
+    "DataTaxonomy",
+    "DataTaxonomyServiceClient",
+    "DataplexServiceClient",
+    "DeleteAspectTypeRequest",
     "DeleteAssetRequest",
+    "DeleteContentRequest",
+    "DeleteDataAttributeBindingRequest",
+    "DeleteDataAttributeRequest",
+    "DeleteDataScanRequest",
+    "DeleteDataTaxonomyRequest",
+    "DeleteEntityRequest",
+    "DeleteEntryGroupRequest",
+    "DeleteEntryRequest",
+    "DeleteEntryTypeRequest",
     "DeleteEnvironmentRequest",
     "DeleteLakeRequest",
+    "DeletePartitionRequest",
     "DeleteTaskRequest",
     "DeleteZoneRequest",
+    "DiscoveryEvent",
+    "Entity",
+    "Entry",
+    "EntryGroup",
+    "EntrySource",
+    "EntryType",
+    "EntryView",
+    "Environment",
+    "GenerateDataQualityRulesRequest",
+    "GenerateDataQualityRulesResponse",
+    "GetAspectTypeRequest",
     "GetAssetRequest",
+    "GetContentRequest",
+    "GetDataAttributeBindingRequest",
+    "GetDataAttributeRequest",
+    "GetDataScanJobRequest",
+    "GetDataScanRequest",
+    "GetDataTaxonomyRequest",
+    "GetEntityRequest",
+    "GetEntryGroupRequest",
+    "GetEntryRequest",
+    "GetEntryTypeRequest",
     "GetEnvironmentRequest",
     "GetJobRequest",
     "GetLakeRequest",
+    "GetPartitionRequest",
     "GetTaskRequest",
     "GetZoneRequest",
+    "GovernanceEvent",
+    "Job",
+    "JobEvent",
+    "Lake",
     "ListActionsResponse",
+    "ListAspectTypesRequest",
+    "ListAspectTypesResponse",
     "ListAssetActionsRequest",
     "ListAssetsRequest",
     "ListAssetsResponse",
+    "ListContentRequest",
+    "ListContentResponse",
+    "ListDataAttributeBindingsRequest",
+    "ListDataAttributeBindingsResponse",
+    "ListDataAttributesRequest",
+    "ListDataAttributesResponse",
+    "ListDataScanJobsRequest",
+    "ListDataScanJobsResponse",
+    "ListDataScansRequest",
+    "ListDataScansResponse",
+    "ListDataTaxonomiesRequest",
+    "ListDataTaxonomiesResponse",
+    "ListEntitiesRequest",
+    "ListEntitiesResponse",
+    "ListEntriesRequest",
+    "ListEntriesResponse",
+    "ListEntryGroupsRequest",
+    "ListEntryGroupsResponse",
+    "ListEntryTypesRequest",
+    "ListEntryTypesResponse",
     "ListEnvironmentsRequest",
     "ListEnvironmentsResponse",
     "ListJobsRequest",
     "ListJobsResponse",
     "ListLakeActionsRequest",
     "ListLakesRequest",
     "ListLakesResponse",
+    "ListPartitionsRequest",
+    "ListPartitionsResponse",
     "ListSessionsRequest",
     "ListSessionsResponse",
     "ListTasksRequest",
     "ListTasksResponse",
     "ListZoneActionsRequest",
     "ListZonesRequest",
     "ListZonesResponse",
+    "LookupEntryRequest",
+    "MetadataServiceClient",
     "OperationMetadata",
+    "Partition",
+    "ResourceAccessSpec",
+    "RunDataScanRequest",
+    "RunDataScanResponse",
     "RunTaskRequest",
     "RunTaskResponse",
+    "ScannedData",
+    "Schema",
+    "SearchEntriesRequest",
+    "SearchEntriesResponse",
+    "SearchEntriesResult",
+    "Session",
+    "SessionEvent",
+    "State",
+    "StorageAccess",
+    "StorageFormat",
+    "StorageSystem",
+    "Task",
+    "TransferStatus",
+    "Trigger",
+    "UpdateAspectTypeRequest",
     "UpdateAssetRequest",
+    "UpdateContentRequest",
+    "UpdateDataAttributeBindingRequest",
+    "UpdateDataAttributeRequest",
+    "UpdateDataScanRequest",
+    "UpdateDataTaxonomyRequest",
+    "UpdateEntityRequest",
+    "UpdateEntryGroupRequest",
+    "UpdateEntryRequest",
+    "UpdateEntryTypeRequest",
     "UpdateEnvironmentRequest",
     "UpdateLakeRequest",
     "UpdateTaskRequest",
     "UpdateZoneRequest",
-    "Job",
-    "Task",
+    "Zone",
 )
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex/gapic_version.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex/gapic_version.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
-__version__ = "1.9.0"  # {x-release-please-version}
+__version__ = "2.0.0"  # {x-release-please-version}
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/__init__.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/types/__init__.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,57 +1,81 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
-from google.cloud.dataplex_v1 import gapic_version as package_version
-
-__version__ = package_version.__version__
-
-
-from .services.content_service import ContentServiceAsyncClient, ContentServiceClient
-from .services.data_scan_service import (
-    DataScanServiceAsyncClient,
-    DataScanServiceClient,
+from .analyze import Content, Environment, Session
+from .catalog import (
+    Aspect,
+    AspectSource,
+    AspectType,
+    CreateAspectTypeRequest,
+    CreateEntryGroupRequest,
+    CreateEntryRequest,
+    CreateEntryTypeRequest,
+    DeleteAspectTypeRequest,
+    DeleteEntryGroupRequest,
+    DeleteEntryRequest,
+    DeleteEntryTypeRequest,
+    Entry,
+    EntryGroup,
+    EntrySource,
+    EntryType,
+    EntryView,
+    GetAspectTypeRequest,
+    GetEntryGroupRequest,
+    GetEntryRequest,
+    GetEntryTypeRequest,
+    ListAspectTypesRequest,
+    ListAspectTypesResponse,
+    ListEntriesRequest,
+    ListEntriesResponse,
+    ListEntryGroupsRequest,
+    ListEntryGroupsResponse,
+    ListEntryTypesRequest,
+    ListEntryTypesResponse,
+    LookupEntryRequest,
+    SearchEntriesRequest,
+    SearchEntriesResponse,
+    SearchEntriesResult,
+    TransferStatus,
+    UpdateAspectTypeRequest,
+    UpdateEntryGroupRequest,
+    UpdateEntryRequest,
+    UpdateEntryTypeRequest,
 )
-from .services.data_taxonomy_service import (
-    DataTaxonomyServiceAsyncClient,
-    DataTaxonomyServiceClient,
-)
-from .services.dataplex_service import DataplexServiceAsyncClient, DataplexServiceClient
-from .services.metadata_service import MetadataServiceAsyncClient, MetadataServiceClient
-from .types.analyze import Content, Environment, Session
-from .types.content import (
+from .content import (
     CreateContentRequest,
     DeleteContentRequest,
     GetContentRequest,
     ListContentRequest,
     ListContentResponse,
     UpdateContentRequest,
 )
-from .types.data_profile import DataProfileResult, DataProfileSpec
-from .types.data_quality import (
+from .data_profile import DataProfileResult, DataProfileSpec
+from .data_quality import (
+    DataQualityColumnResult,
     DataQualityDimension,
     DataQualityDimensionResult,
     DataQualityResult,
     DataQualityRule,
     DataQualityRuleResult,
     DataQualitySpec,
 )
-from .types.data_taxonomy import (
+from .data_taxonomy import (
     CreateDataAttributeBindingRequest,
     CreateDataAttributeRequest,
     CreateDataTaxonomyRequest,
     DataAttribute,
     DataAttributeBinding,
     DataTaxonomy,
     DeleteDataAttributeBindingRequest,
@@ -66,39 +90,41 @@
     ListDataAttributesResponse,
     ListDataTaxonomiesRequest,
     ListDataTaxonomiesResponse,
     UpdateDataAttributeBindingRequest,
     UpdateDataAttributeRequest,
     UpdateDataTaxonomyRequest,
 )
-from .types.datascans import (
+from .datascans import (
     CreateDataScanRequest,
     DataScan,
     DataScanJob,
     DataScanType,
     DeleteDataScanRequest,
+    GenerateDataQualityRulesRequest,
+    GenerateDataQualityRulesResponse,
     GetDataScanJobRequest,
     GetDataScanRequest,
     ListDataScanJobsRequest,
     ListDataScanJobsResponse,
     ListDataScansRequest,
     ListDataScansResponse,
     RunDataScanRequest,
     RunDataScanResponse,
     UpdateDataScanRequest,
 )
-from .types.logs import (
+from .logs import (
     DataQualityScanRuleResult,
     DataScanEvent,
     DiscoveryEvent,
     GovernanceEvent,
     JobEvent,
     SessionEvent,
 )
-from .types.metadata_ import (
+from .metadata_ import (
     CreateEntityRequest,
     CreatePartitionRequest,
     DeleteEntityRequest,
     DeletePartitionRequest,
     Entity,
     GetEntityRequest,
     GetPartitionRequest,
@@ -109,18 +135,18 @@
     Partition,
     Schema,
     StorageAccess,
     StorageFormat,
     StorageSystem,
     UpdateEntityRequest,
 )
-from .types.processing import DataSource, ScannedData, Trigger
-from .types.resources import Action, Asset, AssetStatus, Lake, State, Zone
-from .types.security import DataAccessSpec, ResourceAccessSpec
-from .types.service import (
+from .processing import DataSource, ScannedData, Trigger
+from .resources import Action, Asset, AssetStatus, Lake, State, Zone
+from .security import DataAccessSpec, ResourceAccessSpec
+from .service import (
     CancelJobRequest,
     CreateAssetRequest,
     CreateEnvironmentRequest,
     CreateLakeRequest,
     CreateTaskRequest,
     CreateZoneRequest,
     DeleteAssetRequest,
@@ -157,152 +183,182 @@
     RunTaskResponse,
     UpdateAssetRequest,
     UpdateEnvironmentRequest,
     UpdateLakeRequest,
     UpdateTaskRequest,
     UpdateZoneRequest,
 )
-from .types.tasks import Job, Task
+from .tasks import Job, Task
 
 __all__ = (
-    "ContentServiceAsyncClient",
-    "DataScanServiceAsyncClient",
-    "DataTaxonomyServiceAsyncClient",
-    "DataplexServiceAsyncClient",
-    "MetadataServiceAsyncClient",
-    "Action",
-    "Asset",
-    "AssetStatus",
-    "CancelJobRequest",
     "Content",
-    "ContentServiceClient",
-    "CreateAssetRequest",
+    "Environment",
+    "Session",
+    "Aspect",
+    "AspectSource",
+    "AspectType",
+    "CreateAspectTypeRequest",
+    "CreateEntryGroupRequest",
+    "CreateEntryRequest",
+    "CreateEntryTypeRequest",
+    "DeleteAspectTypeRequest",
+    "DeleteEntryGroupRequest",
+    "DeleteEntryRequest",
+    "DeleteEntryTypeRequest",
+    "Entry",
+    "EntryGroup",
+    "EntrySource",
+    "EntryType",
+    "GetAspectTypeRequest",
+    "GetEntryGroupRequest",
+    "GetEntryRequest",
+    "GetEntryTypeRequest",
+    "ListAspectTypesRequest",
+    "ListAspectTypesResponse",
+    "ListEntriesRequest",
+    "ListEntriesResponse",
+    "ListEntryGroupsRequest",
+    "ListEntryGroupsResponse",
+    "ListEntryTypesRequest",
+    "ListEntryTypesResponse",
+    "LookupEntryRequest",
+    "SearchEntriesRequest",
+    "SearchEntriesResponse",
+    "SearchEntriesResult",
+    "UpdateAspectTypeRequest",
+    "UpdateEntryGroupRequest",
+    "UpdateEntryRequest",
+    "UpdateEntryTypeRequest",
+    "EntryView",
+    "TransferStatus",
     "CreateContentRequest",
-    "CreateDataAttributeBindingRequest",
-    "CreateDataAttributeRequest",
-    "CreateDataScanRequest",
-    "CreateDataTaxonomyRequest",
-    "CreateEntityRequest",
-    "CreateEnvironmentRequest",
-    "CreateLakeRequest",
-    "CreatePartitionRequest",
-    "CreateTaskRequest",
-    "CreateZoneRequest",
-    "DataAccessSpec",
-    "DataAttribute",
-    "DataAttributeBinding",
+    "DeleteContentRequest",
+    "GetContentRequest",
+    "ListContentRequest",
+    "ListContentResponse",
+    "UpdateContentRequest",
     "DataProfileResult",
     "DataProfileSpec",
+    "DataQualityColumnResult",
     "DataQualityDimension",
     "DataQualityDimensionResult",
     "DataQualityResult",
     "DataQualityRule",
     "DataQualityRuleResult",
-    "DataQualityScanRuleResult",
     "DataQualitySpec",
-    "DataScan",
-    "DataScanEvent",
-    "DataScanJob",
-    "DataScanServiceClient",
-    "DataScanType",
-    "DataSource",
+    "CreateDataAttributeBindingRequest",
+    "CreateDataAttributeRequest",
+    "CreateDataTaxonomyRequest",
+    "DataAttribute",
+    "DataAttributeBinding",
     "DataTaxonomy",
-    "DataTaxonomyServiceClient",
-    "DataplexServiceClient",
-    "DeleteAssetRequest",
-    "DeleteContentRequest",
     "DeleteDataAttributeBindingRequest",
     "DeleteDataAttributeRequest",
-    "DeleteDataScanRequest",
     "DeleteDataTaxonomyRequest",
+    "GetDataAttributeBindingRequest",
+    "GetDataAttributeRequest",
+    "GetDataTaxonomyRequest",
+    "ListDataAttributeBindingsRequest",
+    "ListDataAttributeBindingsResponse",
+    "ListDataAttributesRequest",
+    "ListDataAttributesResponse",
+    "ListDataTaxonomiesRequest",
+    "ListDataTaxonomiesResponse",
+    "UpdateDataAttributeBindingRequest",
+    "UpdateDataAttributeRequest",
+    "UpdateDataTaxonomyRequest",
+    "CreateDataScanRequest",
+    "DataScan",
+    "DataScanJob",
+    "DeleteDataScanRequest",
+    "GenerateDataQualityRulesRequest",
+    "GenerateDataQualityRulesResponse",
+    "GetDataScanJobRequest",
+    "GetDataScanRequest",
+    "ListDataScanJobsRequest",
+    "ListDataScanJobsResponse",
+    "ListDataScansRequest",
+    "ListDataScansResponse",
+    "RunDataScanRequest",
+    "RunDataScanResponse",
+    "UpdateDataScanRequest",
+    "DataScanType",
+    "DataQualityScanRuleResult",
+    "DataScanEvent",
+    "DiscoveryEvent",
+    "GovernanceEvent",
+    "JobEvent",
+    "SessionEvent",
+    "CreateEntityRequest",
+    "CreatePartitionRequest",
     "DeleteEntityRequest",
+    "DeletePartitionRequest",
+    "Entity",
+    "GetEntityRequest",
+    "GetPartitionRequest",
+    "ListEntitiesRequest",
+    "ListEntitiesResponse",
+    "ListPartitionsRequest",
+    "ListPartitionsResponse",
+    "Partition",
+    "Schema",
+    "StorageAccess",
+    "StorageFormat",
+    "UpdateEntityRequest",
+    "StorageSystem",
+    "DataSource",
+    "ScannedData",
+    "Trigger",
+    "Action",
+    "Asset",
+    "AssetStatus",
+    "Lake",
+    "Zone",
+    "State",
+    "DataAccessSpec",
+    "ResourceAccessSpec",
+    "CancelJobRequest",
+    "CreateAssetRequest",
+    "CreateEnvironmentRequest",
+    "CreateLakeRequest",
+    "CreateTaskRequest",
+    "CreateZoneRequest",
+    "DeleteAssetRequest",
     "DeleteEnvironmentRequest",
     "DeleteLakeRequest",
-    "DeletePartitionRequest",
     "DeleteTaskRequest",
     "DeleteZoneRequest",
-    "DiscoveryEvent",
-    "Entity",
-    "Environment",
     "GetAssetRequest",
-    "GetContentRequest",
-    "GetDataAttributeBindingRequest",
-    "GetDataAttributeRequest",
-    "GetDataScanJobRequest",
-    "GetDataScanRequest",
-    "GetDataTaxonomyRequest",
-    "GetEntityRequest",
     "GetEnvironmentRequest",
     "GetJobRequest",
     "GetLakeRequest",
-    "GetPartitionRequest",
     "GetTaskRequest",
     "GetZoneRequest",
-    "GovernanceEvent",
-    "Job",
-    "JobEvent",
-    "Lake",
     "ListActionsResponse",
     "ListAssetActionsRequest",
     "ListAssetsRequest",
     "ListAssetsResponse",
-    "ListContentRequest",
-    "ListContentResponse",
-    "ListDataAttributeBindingsRequest",
-    "ListDataAttributeBindingsResponse",
-    "ListDataAttributesRequest",
-    "ListDataAttributesResponse",
-    "ListDataScanJobsRequest",
-    "ListDataScanJobsResponse",
-    "ListDataScansRequest",
-    "ListDataScansResponse",
-    "ListDataTaxonomiesRequest",
-    "ListDataTaxonomiesResponse",
-    "ListEntitiesRequest",
-    "ListEntitiesResponse",
     "ListEnvironmentsRequest",
     "ListEnvironmentsResponse",
     "ListJobsRequest",
     "ListJobsResponse",
     "ListLakeActionsRequest",
     "ListLakesRequest",
     "ListLakesResponse",
-    "ListPartitionsRequest",
-    "ListPartitionsResponse",
     "ListSessionsRequest",
     "ListSessionsResponse",
     "ListTasksRequest",
     "ListTasksResponse",
     "ListZoneActionsRequest",
     "ListZonesRequest",
     "ListZonesResponse",
-    "MetadataServiceClient",
     "OperationMetadata",
-    "Partition",
-    "ResourceAccessSpec",
-    "RunDataScanRequest",
-    "RunDataScanResponse",
     "RunTaskRequest",
     "RunTaskResponse",
-    "ScannedData",
-    "Schema",
-    "Session",
-    "SessionEvent",
-    "State",
-    "StorageAccess",
-    "StorageFormat",
-    "StorageSystem",
-    "Task",
-    "Trigger",
     "UpdateAssetRequest",
-    "UpdateContentRequest",
-    "UpdateDataAttributeBindingRequest",
-    "UpdateDataAttributeRequest",
-    "UpdateDataScanRequest",
-    "UpdateDataTaxonomyRequest",
-    "UpdateEntityRequest",
     "UpdateEnvironmentRequest",
     "UpdateLakeRequest",
     "UpdateTaskRequest",
     "UpdateZoneRequest",
-    "Zone",
+    "Job",
+    "Task",
 )
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/gapic_metadata.json` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/gapic_metadata.json`

 * *Files 15% similar despite different names*

#### Pretty-printed

 * *Similarity: 0.9860628858024691%*

 * *Differences: {"'services'": "{'DataScanService': {'clients': {'grpc': {'rpcs': {'GenerateDataQualityRules': "*

 * *               "OrderedDict([('methods', ['generate_data_quality_rules'])])}}, 'grpc-async': "*

 * *               "{'rpcs': {'GenerateDataQualityRules': OrderedDict([('methods', "*

 * *               "['generate_data_quality_rules'])])}}}}, 'CatalogService': OrderedDict([('clients', "*

 * *               "OrderedDict([('grpc', OrderedDict([('libraryClient', 'CatalogServiceClient'), "*

 * *               "('rpcs', OrderedDict([('Cr []*

```diff
@@ -1,14 +1,248 @@
 {
     "comment": "This file maps proto services/RPCs to the corresponding library clients/methods",
     "language": "python",
     "libraryPackage": "google.cloud.dataplex_v1",
     "protoPackage": "google.cloud.dataplex.v1",
     "schema": "1.0",
     "services": {
+        "CatalogService": {
+            "clients": {
+                "grpc": {
+                    "libraryClient": "CatalogServiceClient",
+                    "rpcs": {
+                        "CreateAspectType": {
+                            "methods": [
+                                "create_aspect_type"
+                            ]
+                        },
+                        "CreateEntry": {
+                            "methods": [
+                                "create_entry"
+                            ]
+                        },
+                        "CreateEntryGroup": {
+                            "methods": [
+                                "create_entry_group"
+                            ]
+                        },
+                        "CreateEntryType": {
+                            "methods": [
+                                "create_entry_type"
+                            ]
+                        },
+                        "DeleteAspectType": {
+                            "methods": [
+                                "delete_aspect_type"
+                            ]
+                        },
+                        "DeleteEntry": {
+                            "methods": [
+                                "delete_entry"
+                            ]
+                        },
+                        "DeleteEntryGroup": {
+                            "methods": [
+                                "delete_entry_group"
+                            ]
+                        },
+                        "DeleteEntryType": {
+                            "methods": [
+                                "delete_entry_type"
+                            ]
+                        },
+                        "GetAspectType": {
+                            "methods": [
+                                "get_aspect_type"
+                            ]
+                        },
+                        "GetEntry": {
+                            "methods": [
+                                "get_entry"
+                            ]
+                        },
+                        "GetEntryGroup": {
+                            "methods": [
+                                "get_entry_group"
+                            ]
+                        },
+                        "GetEntryType": {
+                            "methods": [
+                                "get_entry_type"
+                            ]
+                        },
+                        "ListAspectTypes": {
+                            "methods": [
+                                "list_aspect_types"
+                            ]
+                        },
+                        "ListEntries": {
+                            "methods": [
+                                "list_entries"
+                            ]
+                        },
+                        "ListEntryGroups": {
+                            "methods": [
+                                "list_entry_groups"
+                            ]
+                        },
+                        "ListEntryTypes": {
+                            "methods": [
+                                "list_entry_types"
+                            ]
+                        },
+                        "LookupEntry": {
+                            "methods": [
+                                "lookup_entry"
+                            ]
+                        },
+                        "SearchEntries": {
+                            "methods": [
+                                "search_entries"
+                            ]
+                        },
+                        "UpdateAspectType": {
+                            "methods": [
+                                "update_aspect_type"
+                            ]
+                        },
+                        "UpdateEntry": {
+                            "methods": [
+                                "update_entry"
+                            ]
+                        },
+                        "UpdateEntryGroup": {
+                            "methods": [
+                                "update_entry_group"
+                            ]
+                        },
+                        "UpdateEntryType": {
+                            "methods": [
+                                "update_entry_type"
+                            ]
+                        }
+                    }
+                },
+                "grpc-async": {
+                    "libraryClient": "CatalogServiceAsyncClient",
+                    "rpcs": {
+                        "CreateAspectType": {
+                            "methods": [
+                                "create_aspect_type"
+                            ]
+                        },
+                        "CreateEntry": {
+                            "methods": [
+                                "create_entry"
+                            ]
+                        },
+                        "CreateEntryGroup": {
+                            "methods": [
+                                "create_entry_group"
+                            ]
+                        },
+                        "CreateEntryType": {
+                            "methods": [
+                                "create_entry_type"
+                            ]
+                        },
+                        "DeleteAspectType": {
+                            "methods": [
+                                "delete_aspect_type"
+                            ]
+                        },
+                        "DeleteEntry": {
+                            "methods": [
+                                "delete_entry"
+                            ]
+                        },
+                        "DeleteEntryGroup": {
+                            "methods": [
+                                "delete_entry_group"
+                            ]
+                        },
+                        "DeleteEntryType": {
+                            "methods": [
+                                "delete_entry_type"
+                            ]
+                        },
+                        "GetAspectType": {
+                            "methods": [
+                                "get_aspect_type"
+                            ]
+                        },
+                        "GetEntry": {
+                            "methods": [
+                                "get_entry"
+                            ]
+                        },
+                        "GetEntryGroup": {
+                            "methods": [
+                                "get_entry_group"
+                            ]
+                        },
+                        "GetEntryType": {
+                            "methods": [
+                                "get_entry_type"
+                            ]
+                        },
+                        "ListAspectTypes": {
+                            "methods": [
+                                "list_aspect_types"
+                            ]
+                        },
+                        "ListEntries": {
+                            "methods": [
+                                "list_entries"
+                            ]
+                        },
+                        "ListEntryGroups": {
+                            "methods": [
+                                "list_entry_groups"
+                            ]
+                        },
+                        "ListEntryTypes": {
+                            "methods": [
+                                "list_entry_types"
+                            ]
+                        },
+                        "LookupEntry": {
+                            "methods": [
+                                "lookup_entry"
+                            ]
+                        },
+                        "SearchEntries": {
+                            "methods": [
+                                "search_entries"
+                            ]
+                        },
+                        "UpdateAspectType": {
+                            "methods": [
+                                "update_aspect_type"
+                            ]
+                        },
+                        "UpdateEntry": {
+                            "methods": [
+                                "update_entry"
+                            ]
+                        },
+                        "UpdateEntryGroup": {
+                            "methods": [
+                                "update_entry_group"
+                            ]
+                        },
+                        "UpdateEntryType": {
+                            "methods": [
+                                "update_entry_type"
+                            ]
+                        }
+                    }
+                }
+            }
+        },
         "ContentService": {
             "clients": {
                 "grpc": {
                     "libraryClient": "ContentServiceClient",
                     "rpcs": {
                         "CreateContent": {
                             "methods": [
@@ -110,14 +344,19 @@
                             ]
                         },
                         "DeleteDataScan": {
                             "methods": [
                                 "delete_data_scan"
                             ]
                         },
+                        "GenerateDataQualityRules": {
+                            "methods": [
+                                "generate_data_quality_rules"
+                            ]
+                        },
                         "GetDataScan": {
                             "methods": [
                                 "get_data_scan"
                             ]
                         },
                         "GetDataScanJob": {
                             "methods": [
@@ -155,14 +394,19 @@
                             ]
                         },
                         "DeleteDataScan": {
                             "methods": [
                                 "delete_data_scan"
                             ]
                         },
+                        "GenerateDataQualityRules": {
+                            "methods": [
+                                "generate_data_quality_rules"
+                            ]
+                        },
                         "GetDataScan": {
                             "methods": [
                                 "get_data_scan"
                             ]
                         },
                         "GetDataScanJob": {
                             "methods": [
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/gapic_version.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/gapic_version.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
-__version__ = "1.9.0"  # {x-release-please-version}
+__version__ = "2.0.0"  # {x-release-please-version}
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/__init__.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/content_service/__init__.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/content_service/__init__.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/content_service/async_client.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/content_service/async_client.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,38 +13,39 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 from collections import OrderedDict
 import functools
 import re
 from typing import (
+    Callable,
     Dict,
     Mapping,
     MutableMapping,
     MutableSequence,
     Optional,
     Sequence,
     Tuple,
     Type,
     Union,
 )
 
 from google.api_core import exceptions as core_exceptions
 from google.api_core import gapic_v1
-from google.api_core import retry as retries
+from google.api_core import retry_async as retries
 from google.api_core.client_options import ClientOptions
 from google.auth import credentials as ga_credentials  # type: ignore
 from google.oauth2 import service_account  # type: ignore
 
 from google.cloud.dataplex_v1 import gapic_version as package_version
 
 try:
-    OptionalRetry = Union[retries.Retry, gapic_v1.method._MethodDefault]
+    OptionalRetry = Union[retries.AsyncRetry, gapic_v1.method._MethodDefault, None]
 except AttributeError:  # pragma: NO COVER
-    OptionalRetry = Union[retries.Retry, object]  # type: ignore
+    OptionalRetry = Union[retries.AsyncRetry, object, None]  # type: ignore
 
 from google.cloud.location import locations_pb2  # type: ignore
 from google.iam.v1 import iam_policy_pb2  # type: ignore
 from google.iam.v1 import policy_pb2  # type: ignore
 from google.longrunning import operations_pb2  # type: ignore
 from google.protobuf import field_mask_pb2  # type: ignore
 from google.protobuf import timestamp_pb2  # type: ignore
@@ -60,16 +61,20 @@
 
 
 class ContentServiceAsyncClient:
     """ContentService manages Notebook and SQL Scripts for Dataplex."""
 
     _client: ContentServiceClient
 
+    # Copy defaults from the synchronous client for use here.
+    # Note: DEFAULT_ENDPOINT is deprecated. Use _DEFAULT_ENDPOINT_TEMPLATE instead.
     DEFAULT_ENDPOINT = ContentServiceClient.DEFAULT_ENDPOINT
     DEFAULT_MTLS_ENDPOINT = ContentServiceClient.DEFAULT_MTLS_ENDPOINT
+    _DEFAULT_ENDPOINT_TEMPLATE = ContentServiceClient._DEFAULT_ENDPOINT_TEMPLATE
+    _DEFAULT_UNIVERSE = ContentServiceClient._DEFAULT_UNIVERSE
 
     content_path = staticmethod(ContentServiceClient.content_path)
     parse_content_path = staticmethod(ContentServiceClient.parse_content_path)
     lake_path = staticmethod(ContentServiceClient.lake_path)
     parse_lake_path = staticmethod(ContentServiceClient.parse_lake_path)
     common_billing_account_path = staticmethod(
         ContentServiceClient.common_billing_account_path
@@ -170,54 +175,92 @@
         """Returns the transport used by the client instance.
 
         Returns:
             ContentServiceTransport: The transport used by the client instance.
         """
         return self._client.transport
 
+    @property
+    def api_endpoint(self):
+        """Return the API endpoint used by the client instance.
+
+        Returns:
+            str: The API endpoint used by the client instance.
+        """
+        return self._client._api_endpoint
+
+    @property
+    def universe_domain(self) -> str:
+        """Return the universe domain used by the client instance.
+
+        Returns:
+            str: The universe domain used
+                by the client instance.
+        """
+        return self._client._universe_domain
+
     get_transport_class = functools.partial(
         type(ContentServiceClient).get_transport_class, type(ContentServiceClient)
     )
 
     def __init__(
         self,
         *,
         credentials: Optional[ga_credentials.Credentials] = None,
-        transport: Union[str, ContentServiceTransport] = "grpc_asyncio",
+        transport: Optional[
+            Union[str, ContentServiceTransport, Callable[..., ContentServiceTransport]]
+        ] = "grpc_asyncio",
         client_options: Optional[ClientOptions] = None,
         client_info: gapic_v1.client_info.ClientInfo = DEFAULT_CLIENT_INFO,
     ) -> None:
-        """Instantiates the content service client.
+        """Instantiates the content service async client.
 
         Args:
             credentials (Optional[google.auth.credentials.Credentials]): The
                 authorization credentials to attach to requests. These
                 credentials identify the application to the service; if none
                 are specified, the client will attempt to ascertain the
                 credentials from the environment.
-            transport (Union[str, ~.ContentServiceTransport]): The
-                transport to use. If set to None, a transport is chosen
-                automatically.
-            client_options (ClientOptions): Custom options for the client. It
-                won't take effect if a ``transport`` instance is provided.
-                (1) The ``api_endpoint`` property can be used to override the
-                default endpoint provided by the client. GOOGLE_API_USE_MTLS_ENDPOINT
-                environment variable can also be used to override the endpoint:
+            transport (Optional[Union[str,ContentServiceTransport,Callable[..., ContentServiceTransport]]]):
+                The transport to use, or a Callable that constructs and returns a new transport to use.
+                If a Callable is given, it will be called with the same set of initialization
+                arguments as used in the ContentServiceTransport constructor.
+                If set to None, a transport is chosen automatically.
+            client_options (Optional[Union[google.api_core.client_options.ClientOptions, dict]]):
+                Custom options for the client.
+
+                1. The ``api_endpoint`` property can be used to override the
+                default endpoint provided by the client when ``transport`` is
+                not explicitly provided. Only if this property is not set and
+                ``transport`` was not explicitly provided, the endpoint is
+                determined by the GOOGLE_API_USE_MTLS_ENDPOINT environment
+                variable, which have one of the following values:
                 "always" (always use the default mTLS endpoint), "never" (always
-                use the default regular endpoint) and "auto" (auto switch to the
-                default mTLS endpoint if client certificate is present, this is
-                the default value). However, the ``api_endpoint`` property takes
-                precedence if provided.
-                (2) If GOOGLE_API_USE_CLIENT_CERTIFICATE environment variable
+                use the default regular endpoint) and "auto" (auto-switch to the
+                default mTLS endpoint if client certificate is present; this is
+                the default value).
+
+                2. If the GOOGLE_API_USE_CLIENT_CERTIFICATE environment variable
                 is "true", then the ``client_cert_source`` property can be used
-                to provide client certificate for mutual TLS transport. If
+                to provide a client certificate for mTLS transport. If
                 not provided, the default SSL client certificate will be used if
                 present. If GOOGLE_API_USE_CLIENT_CERTIFICATE is "false" or not
                 set, no client certificate will be used.
 
+                3. The ``universe_domain`` property can be used to override the
+                default "googleapis.com" universe. Note that ``api_endpoint``
+                property still takes precedence; and ``universe_domain`` is
+                currently not supported for mTLS.
+
+            client_info (google.api_core.gapic_v1.client_info.ClientInfo):
+                The client info used to send a user-agent string along with
+                API requests. If ``None``, then default info will be used.
+                Generally, you only need to set this if you're developing
+                your own client library.
+
         Raises:
             google.auth.exceptions.MutualTlsChannelError: If mutual TLS transport
                 creation failed for any reason.
         """
         self._client = ContentServiceClient(
             credentials=credentials,
             transport=transport,
@@ -280,59 +323,63 @@
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             content (:class:`google.cloud.dataplex_v1.types.Content`):
                 Required. Content resource.
                 This corresponds to the ``content`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.types.Content:
                 Content represents a user-visible
                 notebook or a sql script
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent, content])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = gcd_content.CreateContentRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, gcd_content.CreateContentRequest):
+            request = gcd_content.CreateContentRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if parent is not None:
             request.parent = parent
         if content is not None:
             request.content = content
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.create_content,
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.create_content
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -394,61 +441,65 @@
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             update_mask (:class:`google.protobuf.field_mask_pb2.FieldMask`):
                 Required. Mask of fields to update.
                 This corresponds to the ``update_mask`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.types.Content:
                 Content represents a user-visible
                 notebook or a sql script
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([content, update_mask])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = gcd_content.UpdateContentRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, gcd_content.UpdateContentRequest):
+            request = gcd_content.UpdateContentRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if content is not None:
             request.content = content
         if update_mask is not None:
             request.update_mask = update_mask
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.update_content,
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.update_content
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata(
                 (("content.name", request.content.name),)
             ),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -496,51 +547,55 @@
             name (:class:`str`):
                 Required. The resource name of the content:
                 projects/{project_id}/locations/{location_id}/lakes/{lake_id}/content/{content_id}
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = content.DeleteContentRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, content.DeleteContentRequest):
+            request = content.DeleteContentRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if name is not None:
             request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.delete_content,
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.delete_content
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -588,66 +643,61 @@
             name (:class:`str`):
                 Required. The resource name of the content:
                 projects/{project_id}/locations/{location_id}/lakes/{lake_id}/content/{content_id}
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.types.Content:
                 Content represents a user-visible
                 notebook or a sql script
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = content.GetContentRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, content.GetContentRequest):
+            request = content.GetContentRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if name is not None:
             request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.get_content,
-            default_retry=retries.Retry(
-                initial=1.0,
-                maximum=10.0,
-                multiplier=1.3,
-                predicate=retries.if_exception_type(
-                    core_exceptions.ServiceUnavailable,
-                ),
-                deadline=60.0,
-            ),
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.get_content
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -707,15 +757,15 @@
                 policy is being requested. See the
                 operation documentation for the
                 appropriate value for this field.
 
                 This corresponds to the ``resource`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.iam.v1.policy_pb2.Policy:
@@ -748,55 +798,45 @@
 
                    For a description of IAM and its features, see the
                    [IAM
                    documentation](\ https://cloud.google.com/iam/docs/).
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([resource])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # The request isn't a proto-plus wrapped type,
-        # so it must be constructed via keyword expansion.
+        # - The request isn't a proto-plus wrapped type,
+        #   so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = iam_policy_pb2.GetIamPolicyRequest(**request)
         elif not request:
-            request = iam_policy_pb2.GetIamPolicyRequest(
-                resource=resource,
-            )
+            request = iam_policy_pb2.GetIamPolicyRequest(resource=resource)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.get_iam_policy,
-            default_retry=retries.Retry(
-                initial=1.0,
-                maximum=10.0,
-                multiplier=1.3,
-                predicate=retries.if_exception_type(
-                    core_exceptions.ServiceUnavailable,
-                ),
-                deadline=60.0,
-            ),
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.get_iam_policy
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("resource", request.resource),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -844,15 +884,15 @@
 
                 # Handle the response
                 print(response)
 
         Args:
             request (Optional[Union[google.iam.v1.iam_policy_pb2.SetIamPolicyRequest, dict]]):
                 The request object. Request message for ``SetIamPolicy`` method.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.iam.v1.policy_pb2.Policy:
@@ -885,33 +925,36 @@
 
                    For a description of IAM and its features, see the
                    [IAM
                    documentation](\ https://cloud.google.com/iam/docs/).
 
         """
         # Create or coerce a protobuf request object.
-        # The request isn't a proto-plus wrapped type,
-        # so it must be constructed via keyword expansion.
+        # - The request isn't a proto-plus wrapped type,
+        #   so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = iam_policy_pb2.SetIamPolicyRequest(**request)
+        elif not request:
+            request = iam_policy_pb2.SetIamPolicyRequest()
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.set_iam_policy,
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.set_iam_policy
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("resource", request.resource),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -966,53 +1009,47 @@
 
                 # Handle the response
                 print(response)
 
         Args:
             request (Optional[Union[google.iam.v1.iam_policy_pb2.TestIamPermissionsRequest, dict]]):
                 The request object. Request message for ``TestIamPermissions`` method.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.iam.v1.iam_policy_pb2.TestIamPermissionsResponse:
                 Response message for TestIamPermissions method.
         """
         # Create or coerce a protobuf request object.
-        # The request isn't a proto-plus wrapped type,
-        # so it must be constructed via keyword expansion.
+        # - The request isn't a proto-plus wrapped type,
+        #   so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = iam_policy_pb2.TestIamPermissionsRequest(**request)
+        elif not request:
+            request = iam_policy_pb2.TestIamPermissionsRequest()
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.test_iam_permissions,
-            default_retry=retries.Retry(
-                initial=1.0,
-                maximum=10.0,
-                multiplier=1.3,
-                predicate=retries.if_exception_type(
-                    core_exceptions.ServiceUnavailable,
-                ),
-                deadline=60.0,
-            ),
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.test_iam_permissions
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("resource", request.resource),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1065,15 +1102,15 @@
             parent (:class:`str`):
                 Required. The resource name of the parent lake:
                 projects/{project_id}/locations/{location_id}/lakes/{lake_id}
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.services.content_service.pagers.ListContentAsyncPager:
@@ -1081,53 +1118,48 @@
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = content.ListContentRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, content.ListContentRequest):
+            request = content.ListContentRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if parent is not None:
             request.parent = parent
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.list_content,
-            default_retry=retries.Retry(
-                initial=1.0,
-                maximum=10.0,
-                multiplier=1.3,
-                predicate=retries.if_exception_type(
-                    core_exceptions.ServiceUnavailable,
-                ),
-                deadline=60.0,
-            ),
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.list_content
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1154,15 +1186,15 @@
     ) -> operations_pb2.ListOperationsResponse:
         r"""Lists operations that match the specified filter in the request.
 
         Args:
             request (:class:`~.operations_pb2.ListOperationsRequest`):
                 The request object. Request message for
                 `ListOperations` method.
-            retry (google.api_core.retry.Retry): Designation of what errors,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors,
                     if any, should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         Returns:
             ~.operations_pb2.ListOperationsResponse:
                 Response message for ``ListOperations`` method.
@@ -1171,26 +1203,29 @@
         # The request isn't a proto-plus wrapped type,
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = operations_pb2.ListOperationsRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method.wrap_method(
+        rpc = gapic_v1.method_async.wrap_method(
             self._client._transport.list_operations,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1208,15 +1243,15 @@
     ) -> operations_pb2.Operation:
         r"""Gets the latest state of a long-running operation.
 
         Args:
             request (:class:`~.operations_pb2.GetOperationRequest`):
                 The request object. Request message for
                 `GetOperation` method.
-            retry (google.api_core.retry.Retry): Designation of what errors,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors,
                     if any, should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         Returns:
             ~.operations_pb2.Operation:
                 An ``Operation`` object.
@@ -1225,26 +1260,29 @@
         # The request isn't a proto-plus wrapped type,
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = operations_pb2.GetOperationRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method.wrap_method(
+        rpc = gapic_v1.method_async.wrap_method(
             self._client._transport.get_operation,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1267,15 +1305,15 @@
         If the server doesn't support this method, it returns
         `google.rpc.Code.UNIMPLEMENTED`.
 
         Args:
             request (:class:`~.operations_pb2.DeleteOperationRequest`):
                 The request object. Request message for
                 `DeleteOperation` method.
-            retry (google.api_core.retry.Retry): Designation of what errors,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors,
                     if any, should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         Returns:
             None
         """
@@ -1283,26 +1321,29 @@
         # The request isn't a proto-plus wrapped type,
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = operations_pb2.DeleteOperationRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method.wrap_method(
+        rpc = gapic_v1.method_async.wrap_method(
             self._client._transport.delete_operation,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1321,15 +1362,15 @@
         is not guaranteed.  If the server doesn't support this method, it returns
         `google.rpc.Code.UNIMPLEMENTED`.
 
         Args:
             request (:class:`~.operations_pb2.CancelOperationRequest`):
                 The request object. Request message for
                 `CancelOperation` method.
-            retry (google.api_core.retry.Retry): Designation of what errors,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors,
                     if any, should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         Returns:
             None
         """
@@ -1337,26 +1378,29 @@
         # The request isn't a proto-plus wrapped type,
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = operations_pb2.CancelOperationRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method.wrap_method(
+        rpc = gapic_v1.method_async.wrap_method(
             self._client._transport.cancel_operation,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1371,15 +1415,15 @@
     ) -> locations_pb2.Location:
         r"""Gets information about a location.
 
         Args:
             request (:class:`~.location_pb2.GetLocationRequest`):
                 The request object. Request message for
                 `GetLocation` method.
-            retry (google.api_core.retry.Retry): Designation of what errors,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors,
                  if any, should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         Returns:
             ~.location_pb2.Location:
                 Location object.
@@ -1388,26 +1432,29 @@
         # The request isn't a proto-plus wrapped type,
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = locations_pb2.GetLocationRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method.wrap_method(
+        rpc = gapic_v1.method_async.wrap_method(
             self._client._transport.get_location,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1425,15 +1472,15 @@
     ) -> locations_pb2.ListLocationsResponse:
         r"""Lists information about the supported locations for this service.
 
         Args:
             request (:class:`~.location_pb2.ListLocationsRequest`):
                 The request object. Request message for
                 `ListLocations` method.
-            retry (google.api_core.retry.Retry): Designation of what errors,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors,
                  if any, should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         Returns:
             ~.location_pb2.ListLocationsResponse:
                 Response message for ``ListLocations`` method.
@@ -1442,26 +1489,29 @@
         # The request isn't a proto-plus wrapped type,
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = locations_pb2.ListLocationsRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method.wrap_method(
+        rpc = gapic_v1.method_async.wrap_method(
             self._client._transport.list_locations,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/content_service/client.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/metadata_service/async_client.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,319 +1,147 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 from collections import OrderedDict
-import os
+import functools
 import re
 from typing import (
+    Callable,
     Dict,
     Mapping,
     MutableMapping,
     MutableSequence,
     Optional,
     Sequence,
     Tuple,
     Type,
     Union,
-    cast,
 )
 
-from google.api_core import client_options as client_options_lib
 from google.api_core import exceptions as core_exceptions
 from google.api_core import gapic_v1
-from google.api_core import retry as retries
+from google.api_core import retry_async as retries
+from google.api_core.client_options import ClientOptions
 from google.auth import credentials as ga_credentials  # type: ignore
-from google.auth.exceptions import MutualTLSChannelError  # type: ignore
-from google.auth.transport import mtls  # type: ignore
-from google.auth.transport.grpc import SslCredentials  # type: ignore
 from google.oauth2 import service_account  # type: ignore
 
 from google.cloud.dataplex_v1 import gapic_version as package_version
 
 try:
-    OptionalRetry = Union[retries.Retry, gapic_v1.method._MethodDefault]
+    OptionalRetry = Union[retries.AsyncRetry, gapic_v1.method._MethodDefault, None]
 except AttributeError:  # pragma: NO COVER
-    OptionalRetry = Union[retries.Retry, object]  # type: ignore
+    OptionalRetry = Union[retries.AsyncRetry, object, None]  # type: ignore
 
 from google.cloud.location import locations_pb2  # type: ignore
 from google.iam.v1 import iam_policy_pb2  # type: ignore
 from google.iam.v1 import policy_pb2  # type: ignore
 from google.longrunning import operations_pb2  # type: ignore
-from google.protobuf import field_mask_pb2  # type: ignore
 from google.protobuf import timestamp_pb2  # type: ignore
 
-from google.cloud.dataplex_v1.services.content_service import pagers
-from google.cloud.dataplex_v1.types import analyze
-from google.cloud.dataplex_v1.types import content
-from google.cloud.dataplex_v1.types import content as gcd_content
-
-from .transports.base import DEFAULT_CLIENT_INFO, ContentServiceTransport
-from .transports.grpc import ContentServiceGrpcTransport
-from .transports.grpc_asyncio import ContentServiceGrpcAsyncIOTransport
-
-
-class ContentServiceClientMeta(type):
-    """Metaclass for the ContentService client.
-
-    This provides class-level methods for building and retrieving
-    support objects (e.g. transport) without polluting the client instance
-    objects.
-    """
-
-    _transport_registry = (
-        OrderedDict()
-    )  # type: Dict[str, Type[ContentServiceTransport]]
-    _transport_registry["grpc"] = ContentServiceGrpcTransport
-    _transport_registry["grpc_asyncio"] = ContentServiceGrpcAsyncIOTransport
-
-    def get_transport_class(
-        cls,
-        label: Optional[str] = None,
-    ) -> Type[ContentServiceTransport]:
-        """Returns an appropriate transport class.
-
-        Args:
-            label: The name of the desired transport. If none is
-                provided, then the first transport in the registry is used.
-
-        Returns:
-            The transport class to use.
-        """
-        # If a specific transport is requested, return that one.
-        if label:
-            return cls._transport_registry[label]
+from google.cloud.dataplex_v1.services.metadata_service import pagers
+from google.cloud.dataplex_v1.types import metadata_
 
-        # No transport is requested; return the default (that is, the first one
-        # in the dictionary).
-        return next(iter(cls._transport_registry.values()))
+from .client import MetadataServiceClient
+from .transports.base import DEFAULT_CLIENT_INFO, MetadataServiceTransport
+from .transports.grpc_asyncio import MetadataServiceGrpcAsyncIOTransport
 
 
-class ContentServiceClient(metaclass=ContentServiceClientMeta):
-    """ContentService manages Notebook and SQL Scripts for Dataplex."""
-
-    @staticmethod
-    def _get_default_mtls_endpoint(api_endpoint):
-        """Converts api endpoint to mTLS endpoint.
-
-        Convert "*.sandbox.googleapis.com" and "*.googleapis.com" to
-        "*.mtls.sandbox.googleapis.com" and "*.mtls.googleapis.com" respectively.
-        Args:
-            api_endpoint (Optional[str]): the api endpoint to convert.
-        Returns:
-            str: converted mTLS api endpoint.
-        """
-        if not api_endpoint:
-            return api_endpoint
-
-        mtls_endpoint_re = re.compile(
-            r"(?P<name>[^.]+)(?P<mtls>\.mtls)?(?P<sandbox>\.sandbox)?(?P<googledomain>\.googleapis\.com)?"
-        )
-
-        m = mtls_endpoint_re.match(api_endpoint)
-        name, mtls, sandbox, googledomain = m.groups()
-        if mtls or not googledomain:
-            return api_endpoint
-
-        if sandbox:
-            return api_endpoint.replace(
-                "sandbox.googleapis.com", "mtls.sandbox.googleapis.com"
-            )
+class MetadataServiceAsyncClient:
+    """Metadata service manages metadata resources such as tables,
+    filesets and partitions.
+    """
 
-        return api_endpoint.replace(".googleapis.com", ".mtls.googleapis.com")
+    _client: MetadataServiceClient
 
-    DEFAULT_ENDPOINT = "dataplex.googleapis.com"
-    DEFAULT_MTLS_ENDPOINT = _get_default_mtls_endpoint.__func__(  # type: ignore
-        DEFAULT_ENDPOINT
+    # Copy defaults from the synchronous client for use here.
+    # Note: DEFAULT_ENDPOINT is deprecated. Use _DEFAULT_ENDPOINT_TEMPLATE instead.
+    DEFAULT_ENDPOINT = MetadataServiceClient.DEFAULT_ENDPOINT
+    DEFAULT_MTLS_ENDPOINT = MetadataServiceClient.DEFAULT_MTLS_ENDPOINT
+    _DEFAULT_ENDPOINT_TEMPLATE = MetadataServiceClient._DEFAULT_ENDPOINT_TEMPLATE
+    _DEFAULT_UNIVERSE = MetadataServiceClient._DEFAULT_UNIVERSE
+
+    entity_path = staticmethod(MetadataServiceClient.entity_path)
+    parse_entity_path = staticmethod(MetadataServiceClient.parse_entity_path)
+    partition_path = staticmethod(MetadataServiceClient.partition_path)
+    parse_partition_path = staticmethod(MetadataServiceClient.parse_partition_path)
+    zone_path = staticmethod(MetadataServiceClient.zone_path)
+    parse_zone_path = staticmethod(MetadataServiceClient.parse_zone_path)
+    common_billing_account_path = staticmethod(
+        MetadataServiceClient.common_billing_account_path
+    )
+    parse_common_billing_account_path = staticmethod(
+        MetadataServiceClient.parse_common_billing_account_path
+    )
+    common_folder_path = staticmethod(MetadataServiceClient.common_folder_path)
+    parse_common_folder_path = staticmethod(
+        MetadataServiceClient.parse_common_folder_path
+    )
+    common_organization_path = staticmethod(
+        MetadataServiceClient.common_organization_path
+    )
+    parse_common_organization_path = staticmethod(
+        MetadataServiceClient.parse_common_organization_path
+    )
+    common_project_path = staticmethod(MetadataServiceClient.common_project_path)
+    parse_common_project_path = staticmethod(
+        MetadataServiceClient.parse_common_project_path
+    )
+    common_location_path = staticmethod(MetadataServiceClient.common_location_path)
+    parse_common_location_path = staticmethod(
+        MetadataServiceClient.parse_common_location_path
     )
 
     @classmethod
     def from_service_account_info(cls, info: dict, *args, **kwargs):
         """Creates an instance of this client using the provided credentials
             info.
 
         Args:
             info (dict): The service account private key info.
             args: Additional arguments to pass to the constructor.
             kwargs: Additional arguments to pass to the constructor.
 
         Returns:
-            ContentServiceClient: The constructed client.
+            MetadataServiceAsyncClient: The constructed client.
         """
-        credentials = service_account.Credentials.from_service_account_info(info)
-        kwargs["credentials"] = credentials
-        return cls(*args, **kwargs)
+        return MetadataServiceClient.from_service_account_info.__func__(MetadataServiceAsyncClient, info, *args, **kwargs)  # type: ignore
 
     @classmethod
     def from_service_account_file(cls, filename: str, *args, **kwargs):
         """Creates an instance of this client using the provided credentials
             file.
 
         Args:
             filename (str): The path to the service account private key json
                 file.
             args: Additional arguments to pass to the constructor.
             kwargs: Additional arguments to pass to the constructor.
 
         Returns:
-            ContentServiceClient: The constructed client.
+            MetadataServiceAsyncClient: The constructed client.
         """
-        credentials = service_account.Credentials.from_service_account_file(filename)
-        kwargs["credentials"] = credentials
-        return cls(*args, **kwargs)
+        return MetadataServiceClient.from_service_account_file.__func__(MetadataServiceAsyncClient, filename, *args, **kwargs)  # type: ignore
 
     from_service_account_json = from_service_account_file
 
-    @property
-    def transport(self) -> ContentServiceTransport:
-        """Returns the transport used by the client instance.
-
-        Returns:
-            ContentServiceTransport: The transport used by the client
-                instance.
-        """
-        return self._transport
-
-    @staticmethod
-    def content_path(
-        project: str,
-        location: str,
-        lake: str,
-        content: str,
-    ) -> str:
-        """Returns a fully-qualified content string."""
-        return "projects/{project}/locations/{location}/lakes/{lake}/content/{content}".format(
-            project=project,
-            location=location,
-            lake=lake,
-            content=content,
-        )
-
-    @staticmethod
-    def parse_content_path(path: str) -> Dict[str, str]:
-        """Parses a content path into its component segments."""
-        m = re.match(
-            r"^projects/(?P<project>.+?)/locations/(?P<location>.+?)/lakes/(?P<lake>.+?)/content/(?P<content>.+?)$",
-            path,
-        )
-        return m.groupdict() if m else {}
-
-    @staticmethod
-    def lake_path(
-        project: str,
-        location: str,
-        lake: str,
-    ) -> str:
-        """Returns a fully-qualified lake string."""
-        return "projects/{project}/locations/{location}/lakes/{lake}".format(
-            project=project,
-            location=location,
-            lake=lake,
-        )
-
-    @staticmethod
-    def parse_lake_path(path: str) -> Dict[str, str]:
-        """Parses a lake path into its component segments."""
-        m = re.match(
-            r"^projects/(?P<project>.+?)/locations/(?P<location>.+?)/lakes/(?P<lake>.+?)$",
-            path,
-        )
-        return m.groupdict() if m else {}
-
-    @staticmethod
-    def common_billing_account_path(
-        billing_account: str,
-    ) -> str:
-        """Returns a fully-qualified billing_account string."""
-        return "billingAccounts/{billing_account}".format(
-            billing_account=billing_account,
-        )
-
-    @staticmethod
-    def parse_common_billing_account_path(path: str) -> Dict[str, str]:
-        """Parse a billing_account path into its component segments."""
-        m = re.match(r"^billingAccounts/(?P<billing_account>.+?)$", path)
-        return m.groupdict() if m else {}
-
-    @staticmethod
-    def common_folder_path(
-        folder: str,
-    ) -> str:
-        """Returns a fully-qualified folder string."""
-        return "folders/{folder}".format(
-            folder=folder,
-        )
-
-    @staticmethod
-    def parse_common_folder_path(path: str) -> Dict[str, str]:
-        """Parse a folder path into its component segments."""
-        m = re.match(r"^folders/(?P<folder>.+?)$", path)
-        return m.groupdict() if m else {}
-
-    @staticmethod
-    def common_organization_path(
-        organization: str,
-    ) -> str:
-        """Returns a fully-qualified organization string."""
-        return "organizations/{organization}".format(
-            organization=organization,
-        )
-
-    @staticmethod
-    def parse_common_organization_path(path: str) -> Dict[str, str]:
-        """Parse a organization path into its component segments."""
-        m = re.match(r"^organizations/(?P<organization>.+?)$", path)
-        return m.groupdict() if m else {}
-
-    @staticmethod
-    def common_project_path(
-        project: str,
-    ) -> str:
-        """Returns a fully-qualified project string."""
-        return "projects/{project}".format(
-            project=project,
-        )
-
-    @staticmethod
-    def parse_common_project_path(path: str) -> Dict[str, str]:
-        """Parse a project path into its component segments."""
-        m = re.match(r"^projects/(?P<project>.+?)$", path)
-        return m.groupdict() if m else {}
-
-    @staticmethod
-    def common_location_path(
-        project: str,
-        location: str,
-    ) -> str:
-        """Returns a fully-qualified location string."""
-        return "projects/{project}/locations/{location}".format(
-            project=project,
-            location=location,
-        )
-
-    @staticmethod
-    def parse_common_location_path(path: str) -> Dict[str, str]:
-        """Parse a location path into its component segments."""
-        m = re.match(r"^projects/(?P<project>.+?)/locations/(?P<location>.+?)$", path)
-        return m.groupdict() if m else {}
-
     @classmethod
     def get_mtls_endpoint_and_cert_source(
-        cls, client_options: Optional[client_options_lib.ClientOptions] = None
+        cls, client_options: Optional[ClientOptions] = None
     ):
         """Return the API endpoint and client cert source for mutual TLS.
 
         The client cert source is determined in the following order:
         (1) if `GOOGLE_API_USE_CLIENT_CERTIFICATE` environment variable is not "true", the
         client cert source is None.
         (2) if `client_options.client_cert_source` is provided, use the provided one; if the
@@ -337,1053 +165,1113 @@
         Returns:
             Tuple[str, Callable[[], Tuple[bytes, bytes]]]: returns the API endpoint and the
                 client cert source to use.
 
         Raises:
             google.auth.exceptions.MutualTLSChannelError: If any errors happen.
         """
-        if client_options is None:
-            client_options = client_options_lib.ClientOptions()
-        use_client_cert = os.getenv("GOOGLE_API_USE_CLIENT_CERTIFICATE", "false")
-        use_mtls_endpoint = os.getenv("GOOGLE_API_USE_MTLS_ENDPOINT", "auto")
-        if use_client_cert not in ("true", "false"):
-            raise ValueError(
-                "Environment variable `GOOGLE_API_USE_CLIENT_CERTIFICATE` must be either `true` or `false`"
-            )
-        if use_mtls_endpoint not in ("auto", "never", "always"):
-            raise MutualTLSChannelError(
-                "Environment variable `GOOGLE_API_USE_MTLS_ENDPOINT` must be `never`, `auto` or `always`"
-            )
+        return MetadataServiceClient.get_mtls_endpoint_and_cert_source(client_options)  # type: ignore
 
-        # Figure out the client cert source to use.
-        client_cert_source = None
-        if use_client_cert == "true":
-            if client_options.client_cert_source:
-                client_cert_source = client_options.client_cert_source
-            elif mtls.has_default_client_cert_source():
-                client_cert_source = mtls.default_client_cert_source()
-
-        # Figure out which api endpoint to use.
-        if client_options.api_endpoint is not None:
-            api_endpoint = client_options.api_endpoint
-        elif use_mtls_endpoint == "always" or (
-            use_mtls_endpoint == "auto" and client_cert_source
-        ):
-            api_endpoint = cls.DEFAULT_MTLS_ENDPOINT
-        else:
-            api_endpoint = cls.DEFAULT_ENDPOINT
+    @property
+    def transport(self) -> MetadataServiceTransport:
+        """Returns the transport used by the client instance.
 
-        return api_endpoint, client_cert_source
+        Returns:
+            MetadataServiceTransport: The transport used by the client instance.
+        """
+        return self._client.transport
+
+    @property
+    def api_endpoint(self):
+        """Return the API endpoint used by the client instance.
+
+        Returns:
+            str: The API endpoint used by the client instance.
+        """
+        return self._client._api_endpoint
+
+    @property
+    def universe_domain(self) -> str:
+        """Return the universe domain used by the client instance.
+
+        Returns:
+            str: The universe domain used
+                by the client instance.
+        """
+        return self._client._universe_domain
+
+    get_transport_class = functools.partial(
+        type(MetadataServiceClient).get_transport_class, type(MetadataServiceClient)
+    )
 
     def __init__(
         self,
         *,
         credentials: Optional[ga_credentials.Credentials] = None,
-        transport: Optional[Union[str, ContentServiceTransport]] = None,
-        client_options: Optional[Union[client_options_lib.ClientOptions, dict]] = None,
+        transport: Optional[
+            Union[
+                str, MetadataServiceTransport, Callable[..., MetadataServiceTransport]
+            ]
+        ] = "grpc_asyncio",
+        client_options: Optional[ClientOptions] = None,
         client_info: gapic_v1.client_info.ClientInfo = DEFAULT_CLIENT_INFO,
     ) -> None:
-        """Instantiates the content service client.
+        """Instantiates the metadata service async client.
 
         Args:
             credentials (Optional[google.auth.credentials.Credentials]): The
                 authorization credentials to attach to requests. These
                 credentials identify the application to the service; if none
                 are specified, the client will attempt to ascertain the
                 credentials from the environment.
-            transport (Union[str, ContentServiceTransport]): The
-                transport to use. If set to None, a transport is chosen
-                automatically.
-            client_options (Optional[Union[google.api_core.client_options.ClientOptions, dict]]): Custom options for the
-                client. It won't take effect if a ``transport`` instance is provided.
-                (1) The ``api_endpoint`` property can be used to override the
-                default endpoint provided by the client. GOOGLE_API_USE_MTLS_ENDPOINT
-                environment variable can also be used to override the endpoint:
+            transport (Optional[Union[str,MetadataServiceTransport,Callable[..., MetadataServiceTransport]]]):
+                The transport to use, or a Callable that constructs and returns a new transport to use.
+                If a Callable is given, it will be called with the same set of initialization
+                arguments as used in the MetadataServiceTransport constructor.
+                If set to None, a transport is chosen automatically.
+            client_options (Optional[Union[google.api_core.client_options.ClientOptions, dict]]):
+                Custom options for the client.
+
+                1. The ``api_endpoint`` property can be used to override the
+                default endpoint provided by the client when ``transport`` is
+                not explicitly provided. Only if this property is not set and
+                ``transport`` was not explicitly provided, the endpoint is
+                determined by the GOOGLE_API_USE_MTLS_ENDPOINT environment
+                variable, which have one of the following values:
                 "always" (always use the default mTLS endpoint), "never" (always
-                use the default regular endpoint) and "auto" (auto switch to the
-                default mTLS endpoint if client certificate is present, this is
-                the default value). However, the ``api_endpoint`` property takes
-                precedence if provided.
-                (2) If GOOGLE_API_USE_CLIENT_CERTIFICATE environment variable
+                use the default regular endpoint) and "auto" (auto-switch to the
+                default mTLS endpoint if client certificate is present; this is
+                the default value).
+
+                2. If the GOOGLE_API_USE_CLIENT_CERTIFICATE environment variable
                 is "true", then the ``client_cert_source`` property can be used
-                to provide client certificate for mutual TLS transport. If
+                to provide a client certificate for mTLS transport. If
                 not provided, the default SSL client certificate will be used if
                 present. If GOOGLE_API_USE_CLIENT_CERTIFICATE is "false" or not
                 set, no client certificate will be used.
+
+                3. The ``universe_domain`` property can be used to override the
+                default "googleapis.com" universe. Note that ``api_endpoint``
+                property still takes precedence; and ``universe_domain`` is
+                currently not supported for mTLS.
+
             client_info (google.api_core.gapic_v1.client_info.ClientInfo):
                 The client info used to send a user-agent string along with
                 API requests. If ``None``, then default info will be used.
                 Generally, you only need to set this if you're developing
                 your own client library.
 
         Raises:
-            google.auth.exceptions.MutualTLSChannelError: If mutual TLS transport
+            google.auth.exceptions.MutualTlsChannelError: If mutual TLS transport
                 creation failed for any reason.
         """
-        if isinstance(client_options, dict):
-            client_options = client_options_lib.from_dict(client_options)
-        if client_options is None:
-            client_options = client_options_lib.ClientOptions()
-        client_options = cast(client_options_lib.ClientOptions, client_options)
-
-        api_endpoint, client_cert_source_func = self.get_mtls_endpoint_and_cert_source(
-            client_options
+        self._client = MetadataServiceClient(
+            credentials=credentials,
+            transport=transport,
+            client_options=client_options,
+            client_info=client_info,
         )
 
-        api_key_value = getattr(client_options, "api_key", None)
-        if api_key_value and credentials:
-            raise ValueError(
-                "client_options.api_key and credentials are mutually exclusive"
-            )
-
-        # Save or instantiate the transport.
-        # Ordinarily, we provide the transport, but allowing a custom transport
-        # instance provides an extensibility point for unusual situations.
-        if isinstance(transport, ContentServiceTransport):
-            # transport is a ContentServiceTransport instance.
-            if credentials or client_options.credentials_file or api_key_value:
-                raise ValueError(
-                    "When providing a transport instance, "
-                    "provide its credentials directly."
-                )
-            if client_options.scopes:
-                raise ValueError(
-                    "When providing a transport instance, provide its scopes "
-                    "directly."
-                )
-            self._transport = transport
-        else:
-            import google.auth._default  # type: ignore
-
-            if api_key_value and hasattr(
-                google.auth._default, "get_api_key_credentials"
-            ):
-                credentials = google.auth._default.get_api_key_credentials(
-                    api_key_value
-                )
-
-            Transport = type(self).get_transport_class(transport)
-            self._transport = Transport(
-                credentials=credentials,
-                credentials_file=client_options.credentials_file,
-                host=api_endpoint,
-                scopes=client_options.scopes,
-                client_cert_source_for_mtls=client_cert_source_func,
-                quota_project_id=client_options.quota_project_id,
-                client_info=client_info,
-                always_use_jwt_access=True,
-                api_audience=client_options.api_audience,
-            )
-
-    def create_content(
+    async def create_entity(
         self,
-        request: Optional[Union[gcd_content.CreateContentRequest, dict]] = None,
+        request: Optional[Union[metadata_.CreateEntityRequest, dict]] = None,
         *,
         parent: Optional[str] = None,
-        content: Optional[analyze.Content] = None,
+        entity: Optional[metadata_.Entity] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
-    ) -> analyze.Content:
-        r"""Create a content.
+    ) -> metadata_.Entity:
+        r"""Create a metadata entity.
 
         .. code-block:: python
 
             # This snippet has been automatically generated and should be regarded as a
             # code template only.
             # It will require modifications to work:
             # - It may require correct/in-range values for request initialization.
             # - It may require specifying regional endpoints when creating the service
             #   client as shown in:
             #   https://googleapis.dev/python/google-api-core/latest/client_options.html
             from google.cloud import dataplex_v1
 
-            def sample_create_content():
+            async def sample_create_entity():
                 # Create a client
-                client = dataplex_v1.ContentServiceClient()
+                client = dataplex_v1.MetadataServiceAsyncClient()
 
                 # Initialize request argument(s)
-                content = dataplex_v1.Content()
-                content.data_text = "data_text_value"
-                content.sql_script.engine = "SPARK"
-                content.path = "path_value"
+                entity = dataplex_v1.Entity()
+                entity.id = "id_value"
+                entity.type_ = "FILESET"
+                entity.asset = "asset_value"
+                entity.data_path = "data_path_value"
+                entity.system = "BIGQUERY"
+                entity.format_.mime_type = "mime_type_value"
+                entity.schema.user_managed = True
 
-                request = dataplex_v1.CreateContentRequest(
+                request = dataplex_v1.CreateEntityRequest(
                     parent="parent_value",
-                    content=content,
+                    entity=entity,
                 )
 
                 # Make the request
-                response = client.create_content(request=request)
+                response = await client.create_entity(request=request)
 
                 # Handle the response
                 print(response)
 
         Args:
-            request (Union[google.cloud.dataplex_v1.types.CreateContentRequest, dict]):
-                The request object. Create content request.
-            parent (str):
-                Required. The resource name of the parent lake:
-                projects/{project_id}/locations/{location_id}/lakes/{lake_id}
+            request (Optional[Union[google.cloud.dataplex_v1.types.CreateEntityRequest, dict]]):
+                The request object. Create a metadata entity request.
+            parent (:class:`str`):
+                Required. The resource name of the parent zone:
+                ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}``.
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            content (google.cloud.dataplex_v1.types.Content):
-                Required. Content resource.
-                This corresponds to the ``content`` field
+            entity (:class:`google.cloud.dataplex_v1.types.Entity`):
+                Required. Entity resource.
+                This corresponds to the ``entity`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
-            google.cloud.dataplex_v1.types.Content:
-                Content represents a user-visible
-                notebook or a sql script
+            google.cloud.dataplex_v1.types.Entity:
+                Represents tables and fileset
+                metadata contained within a zone.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
-        has_flattened_params = any([parent, content])
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
+        has_flattened_params = any([parent, entity])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a gcd_content.CreateContentRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
-        if not isinstance(request, gcd_content.CreateContentRequest):
-            request = gcd_content.CreateContentRequest(request)
-            # If we have keyword arguments corresponding to fields on the
-            # request, apply these.
-            if parent is not None:
-                request.parent = parent
-            if content is not None:
-                request.content = content
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, metadata_.CreateEntityRequest):
+            request = metadata_.CreateEntityRequest(request)
+
+        # If we have keyword arguments corresponding to fields on the
+        # request, apply these.
+        if parent is not None:
+            request.parent = parent
+        if entity is not None:
+            request.entity = entity
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = self._transport._wrapped_methods[self._transport.create_content]
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.create_entity
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
-        response = rpc(
+        response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
-    def update_content(
+    async def update_entity(
         self,
-        request: Optional[Union[gcd_content.UpdateContentRequest, dict]] = None,
+        request: Optional[Union[metadata_.UpdateEntityRequest, dict]] = None,
         *,
-        content: Optional[analyze.Content] = None,
-        update_mask: Optional[field_mask_pb2.FieldMask] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
-    ) -> analyze.Content:
-        r"""Update a content. Only supports full resource update.
+    ) -> metadata_.Entity:
+        r"""Update a metadata entity. Only supports full resource
+        update.
 
         .. code-block:: python
 
             # This snippet has been automatically generated and should be regarded as a
             # code template only.
             # It will require modifications to work:
             # - It may require correct/in-range values for request initialization.
             # - It may require specifying regional endpoints when creating the service
             #   client as shown in:
             #   https://googleapis.dev/python/google-api-core/latest/client_options.html
             from google.cloud import dataplex_v1
 
-            def sample_update_content():
+            async def sample_update_entity():
                 # Create a client
-                client = dataplex_v1.ContentServiceClient()
+                client = dataplex_v1.MetadataServiceAsyncClient()
 
                 # Initialize request argument(s)
-                content = dataplex_v1.Content()
-                content.data_text = "data_text_value"
-                content.sql_script.engine = "SPARK"
-                content.path = "path_value"
+                entity = dataplex_v1.Entity()
+                entity.id = "id_value"
+                entity.type_ = "FILESET"
+                entity.asset = "asset_value"
+                entity.data_path = "data_path_value"
+                entity.system = "BIGQUERY"
+                entity.format_.mime_type = "mime_type_value"
+                entity.schema.user_managed = True
 
-                request = dataplex_v1.UpdateContentRequest(
-                    content=content,
+                request = dataplex_v1.UpdateEntityRequest(
+                    entity=entity,
                 )
 
                 # Make the request
-                response = client.update_content(request=request)
+                response = await client.update_entity(request=request)
 
                 # Handle the response
                 print(response)
 
         Args:
-            request (Union[google.cloud.dataplex_v1.types.UpdateContentRequest, dict]):
-                The request object. Update content request.
-            content (google.cloud.dataplex_v1.types.Content):
-                Required. Update description. Only fields specified in
-                ``update_mask`` are updated.
-
-                This corresponds to the ``content`` field
-                on the ``request`` instance; if ``request`` is provided, this
-                should not be set.
-            update_mask (google.protobuf.field_mask_pb2.FieldMask):
-                Required. Mask of fields to update.
-                This corresponds to the ``update_mask`` field
-                on the ``request`` instance; if ``request`` is provided, this
-                should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            request (Optional[Union[google.cloud.dataplex_v1.types.UpdateEntityRequest, dict]]):
+                The request object. Update a metadata entity request.
+                The exiting entity will be fully
+                replaced by the entity in the request.
+                The entity ID is mutable. To modify the
+                ID, use the current entity ID in the
+                request URL and specify the new ID in
+                the request body.
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
-            google.cloud.dataplex_v1.types.Content:
-                Content represents a user-visible
-                notebook or a sql script
+            google.cloud.dataplex_v1.types.Entity:
+                Represents tables and fileset
+                metadata contained within a zone.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
-        has_flattened_params = any([content, update_mask])
-        if request is not None and has_flattened_params:
-            raise ValueError(
-                "If the `request` argument is set, then none of "
-                "the individual field arguments should be set."
-            )
-
-        # Minor optimization to avoid making a copy if the user passes
-        # in a gcd_content.UpdateContentRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
-        if not isinstance(request, gcd_content.UpdateContentRequest):
-            request = gcd_content.UpdateContentRequest(request)
-            # If we have keyword arguments corresponding to fields on the
-            # request, apply these.
-            if content is not None:
-                request.content = content
-            if update_mask is not None:
-                request.update_mask = update_mask
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, metadata_.UpdateEntityRequest):
+            request = metadata_.UpdateEntityRequest(request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = self._transport._wrapped_methods[self._transport.update_content]
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.update_entity
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata(
-                (("content.name", request.content.name),)
+                (("entity.name", request.entity.name),)
             ),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
-        response = rpc(
+        response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
-    def delete_content(
+    async def delete_entity(
         self,
-        request: Optional[Union[content.DeleteContentRequest, dict]] = None,
+        request: Optional[Union[metadata_.DeleteEntityRequest, dict]] = None,
         *,
         name: Optional[str] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
     ) -> None:
-        r"""Delete a content.
+        r"""Delete a metadata entity.
 
         .. code-block:: python
 
             # This snippet has been automatically generated and should be regarded as a
             # code template only.
             # It will require modifications to work:
             # - It may require correct/in-range values for request initialization.
             # - It may require specifying regional endpoints when creating the service
             #   client as shown in:
             #   https://googleapis.dev/python/google-api-core/latest/client_options.html
             from google.cloud import dataplex_v1
 
-            def sample_delete_content():
+            async def sample_delete_entity():
                 # Create a client
-                client = dataplex_v1.ContentServiceClient()
+                client = dataplex_v1.MetadataServiceAsyncClient()
 
                 # Initialize request argument(s)
-                request = dataplex_v1.DeleteContentRequest(
+                request = dataplex_v1.DeleteEntityRequest(
                     name="name_value",
+                    etag="etag_value",
                 )
 
                 # Make the request
-                client.delete_content(request=request)
+                await client.delete_entity(request=request)
 
         Args:
-            request (Union[google.cloud.dataplex_v1.types.DeleteContentRequest, dict]):
-                The request object. Delete content request.
-            name (str):
-                Required. The resource name of the content:
-                projects/{project_id}/locations/{location_id}/lakes/{lake_id}/content/{content_id}
+            request (Optional[Union[google.cloud.dataplex_v1.types.DeleteEntityRequest, dict]]):
+                The request object. Delete a metadata entity request.
+            name (:class:`str`):
+                Required. The resource name of the entity:
+                ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/entities/{entity_id}``.
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a content.DeleteContentRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
-        if not isinstance(request, content.DeleteContentRequest):
-            request = content.DeleteContentRequest(request)
-            # If we have keyword arguments corresponding to fields on the
-            # request, apply these.
-            if name is not None:
-                request.name = name
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, metadata_.DeleteEntityRequest):
+            request = metadata_.DeleteEntityRequest(request)
+
+        # If we have keyword arguments corresponding to fields on the
+        # request, apply these.
+        if name is not None:
+            request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = self._transport._wrapped_methods[self._transport.delete_content]
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.delete_entity
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
-        rpc(
+        await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
-    def get_content(
+    async def get_entity(
         self,
-        request: Optional[Union[content.GetContentRequest, dict]] = None,
+        request: Optional[Union[metadata_.GetEntityRequest, dict]] = None,
         *,
         name: Optional[str] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
-    ) -> analyze.Content:
-        r"""Get a content resource.
+    ) -> metadata_.Entity:
+        r"""Get a metadata entity.
 
         .. code-block:: python
 
             # This snippet has been automatically generated and should be regarded as a
             # code template only.
             # It will require modifications to work:
             # - It may require correct/in-range values for request initialization.
             # - It may require specifying regional endpoints when creating the service
             #   client as shown in:
             #   https://googleapis.dev/python/google-api-core/latest/client_options.html
             from google.cloud import dataplex_v1
 
-            def sample_get_content():
+            async def sample_get_entity():
                 # Create a client
-                client = dataplex_v1.ContentServiceClient()
+                client = dataplex_v1.MetadataServiceAsyncClient()
 
                 # Initialize request argument(s)
-                request = dataplex_v1.GetContentRequest(
+                request = dataplex_v1.GetEntityRequest(
                     name="name_value",
                 )
 
                 # Make the request
-                response = client.get_content(request=request)
+                response = await client.get_entity(request=request)
 
                 # Handle the response
                 print(response)
 
         Args:
-            request (Union[google.cloud.dataplex_v1.types.GetContentRequest, dict]):
-                The request object. Get content request.
-            name (str):
-                Required. The resource name of the content:
-                projects/{project_id}/locations/{location_id}/lakes/{lake_id}/content/{content_id}
+            request (Optional[Union[google.cloud.dataplex_v1.types.GetEntityRequest, dict]]):
+                The request object. Get metadata entity request.
+            name (:class:`str`):
+                Required. The resource name of the entity:
+                ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/entities/{entity_id}.``
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
-            google.cloud.dataplex_v1.types.Content:
-                Content represents a user-visible
-                notebook or a sql script
+            google.cloud.dataplex_v1.types.Entity:
+                Represents tables and fileset
+                metadata contained within a zone.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a content.GetContentRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
-        if not isinstance(request, content.GetContentRequest):
-            request = content.GetContentRequest(request)
-            # If we have keyword arguments corresponding to fields on the
-            # request, apply these.
-            if name is not None:
-                request.name = name
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, metadata_.GetEntityRequest):
+            request = metadata_.GetEntityRequest(request)
+
+        # If we have keyword arguments corresponding to fields on the
+        # request, apply these.
+        if name is not None:
+            request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = self._transport._wrapped_methods[self._transport.get_content]
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.get_entity
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
-        response = rpc(
+        response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
-    def get_iam_policy(
+    async def list_entities(
         self,
-        request: Optional[Union[iam_policy_pb2.GetIamPolicyRequest, dict]] = None,
+        request: Optional[Union[metadata_.ListEntitiesRequest, dict]] = None,
         *,
-        resource: Optional[str] = None,
+        parent: Optional[str] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
-    ) -> policy_pb2.Policy:
-        r"""Gets the access control policy for a contentitem resource. A
-        ``NOT_FOUND`` error is returned if the resource does not exist.
-        An empty policy is returned if the resource exists but does not
-        have a policy set on it.
-
-        Caller must have Google IAM ``dataplex.content.getIamPolicy``
-        permission on the resource.
+    ) -> pagers.ListEntitiesAsyncPager:
+        r"""List metadata entities in a zone.
 
         .. code-block:: python
 
             # This snippet has been automatically generated and should be regarded as a
             # code template only.
             # It will require modifications to work:
             # - It may require correct/in-range values for request initialization.
             # - It may require specifying regional endpoints when creating the service
             #   client as shown in:
             #   https://googleapis.dev/python/google-api-core/latest/client_options.html
             from google.cloud import dataplex_v1
-            from google.iam.v1 import iam_policy_pb2  # type: ignore
 
-            def sample_get_iam_policy():
+            async def sample_list_entities():
                 # Create a client
-                client = dataplex_v1.ContentServiceClient()
+                client = dataplex_v1.MetadataServiceAsyncClient()
 
                 # Initialize request argument(s)
-                request = iam_policy_pb2.GetIamPolicyRequest(
-                    resource="resource_value",
+                request = dataplex_v1.ListEntitiesRequest(
+                    parent="parent_value",
+                    view="FILESETS",
                 )
 
                 # Make the request
-                response = client.get_iam_policy(request=request)
+                page_result = client.list_entities(request=request)
 
                 # Handle the response
-                print(response)
+                async for response in page_result:
+                    print(response)
 
         Args:
-            request (Union[google.iam.v1.iam_policy_pb2.GetIamPolicyRequest, dict]):
-                The request object. Request message for ``GetIamPolicy`` method.
-            resource (str):
-                REQUIRED: The resource for which the
-                policy is being requested. See the
-                operation documentation for the
-                appropriate value for this field.
+            request (Optional[Union[google.cloud.dataplex_v1.types.ListEntitiesRequest, dict]]):
+                The request object. List metadata entities request.
+            parent (:class:`str`):
+                Required. The resource name of the parent zone:
+                ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}``.
 
-                This corresponds to the ``resource`` field
+                This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
-            google.iam.v1.policy_pb2.Policy:
-                An Identity and Access Management (IAM) policy, which specifies access
-                   controls for Google Cloud resources.
-
-                   A Policy is a collection of bindings. A binding binds
-                   one or more members, or principals, to a single role.
-                   Principals can be user accounts, service accounts,
-                   Google groups, and domains (such as G Suite). A role
-                   is a named list of permissions; each role can be an
-                   IAM predefined role or a user-created custom role.
-
-                   For some types of Google Cloud resources, a binding
-                   can also specify a condition, which is a logical
-                   expression that allows access to a resource only if
-                   the expression evaluates to true. A condition can add
-                   constraints based on attributes of the request, the
-                   resource, or both. To learn which resources support
-                   conditions in their IAM policies, see the [IAM
-                   documentation](\ https://cloud.google.com/iam/help/conditions/resource-policies).
-
-                   **JSON example:**
-
-                   :literal:`\`     {       "bindings": [         {           "role": "roles/resourcemanager.organizationAdmin",           "members": [             "user:mike@example.com",             "group:admins@example.com",             "domain:google.com",             "serviceAccount:my-project-id@appspot.gserviceaccount.com"           ]         },         {           "role": "roles/resourcemanager.organizationViewer",           "members": [             "user:eve@example.com"           ],           "condition": {             "title": "expirable access",             "description": "Does not grant access after Sep 2020",             "expression": "request.time <             timestamp('2020-10-01T00:00:00.000Z')",           }         }       ],       "etag": "BwWWja0YfJA=",       "version": 3     }`\ \`
-
-                   **YAML example:**
-
-                   :literal:`\`     bindings:     - members:       - user:mike@example.com       - group:admins@example.com       - domain:google.com       - serviceAccount:my-project-id@appspot.gserviceaccount.com       role: roles/resourcemanager.organizationAdmin     - members:       - user:eve@example.com       role: roles/resourcemanager.organizationViewer       condition:         title: expirable access         description: Does not grant access after Sep 2020         expression: request.time < timestamp('2020-10-01T00:00:00.000Z')     etag: BwWWja0YfJA=     version: 3`\ \`
-
-                   For a description of IAM and its features, see the
-                   [IAM
-                   documentation](\ https://cloud.google.com/iam/docs/).
+            google.cloud.dataplex_v1.services.metadata_service.pagers.ListEntitiesAsyncPager:
+                List metadata entities response.
+
+                Iterating over this object will yield
+                results and resolve additional pages
+                automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
-        has_flattened_params = any([resource])
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
+        has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        if isinstance(request, dict):
-            # The request isn't a proto-plus wrapped type,
-            # so it must be constructed via keyword expansion.
-            request = iam_policy_pb2.GetIamPolicyRequest(**request)
-        elif not request:
-            # Null request, just make one.
-            request = iam_policy_pb2.GetIamPolicyRequest()
-            if resource is not None:
-                request.resource = resource
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, metadata_.ListEntitiesRequest):
+            request = metadata_.ListEntitiesRequest(request)
+
+        # If we have keyword arguments corresponding to fields on the
+        # request, apply these.
+        if parent is not None:
+            request.parent = parent
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = self._transport._wrapped_methods[self._transport.get_iam_policy]
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.list_entities
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
-            gapic_v1.routing_header.to_grpc_metadata((("resource", request.resource),)),
+            gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
-        response = rpc(
+        response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
+        # This method is paged; wrap the response in a pager, which provides
+        # an `__aiter__` convenience method.
+        response = pagers.ListEntitiesAsyncPager(
+            method=rpc,
+            request=request,
+            response=response,
+            metadata=metadata,
+        )
+
         # Done; return the response.
         return response
 
-    def set_iam_policy(
+    async def create_partition(
         self,
-        request: Optional[Union[iam_policy_pb2.SetIamPolicyRequest, dict]] = None,
+        request: Optional[Union[metadata_.CreatePartitionRequest, dict]] = None,
         *,
+        parent: Optional[str] = None,
+        partition: Optional[metadata_.Partition] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
-    ) -> policy_pb2.Policy:
-        r"""Sets the access control policy on the specified contentitem
-        resource. Replaces any existing policy.
-
-        Caller must have Google IAM ``dataplex.content.setIamPolicy``
-        permission on the resource.
+    ) -> metadata_.Partition:
+        r"""Create a metadata partition.
 
         .. code-block:: python
 
             # This snippet has been automatically generated and should be regarded as a
             # code template only.
             # It will require modifications to work:
             # - It may require correct/in-range values for request initialization.
             # - It may require specifying regional endpoints when creating the service
             #   client as shown in:
             #   https://googleapis.dev/python/google-api-core/latest/client_options.html
             from google.cloud import dataplex_v1
-            from google.iam.v1 import iam_policy_pb2  # type: ignore
 
-            def sample_set_iam_policy():
+            async def sample_create_partition():
                 # Create a client
-                client = dataplex_v1.ContentServiceClient()
+                client = dataplex_v1.MetadataServiceAsyncClient()
 
                 # Initialize request argument(s)
-                request = iam_policy_pb2.SetIamPolicyRequest(
-                    resource="resource_value",
+                partition = dataplex_v1.Partition()
+                partition.values = ['values_value1', 'values_value2']
+                partition.location = "location_value"
+
+                request = dataplex_v1.CreatePartitionRequest(
+                    parent="parent_value",
+                    partition=partition,
                 )
 
                 # Make the request
-                response = client.set_iam_policy(request=request)
+                response = await client.create_partition(request=request)
 
                 # Handle the response
                 print(response)
 
         Args:
-            request (Union[google.iam.v1.iam_policy_pb2.SetIamPolicyRequest, dict]):
-                The request object. Request message for ``SetIamPolicy`` method.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            request (Optional[Union[google.cloud.dataplex_v1.types.CreatePartitionRequest, dict]]):
+                The request object. Create metadata partition request.
+            parent (:class:`str`):
+                Required. The resource name of the parent zone:
+                ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/entities/{entity_id}``.
+
+                This corresponds to the ``parent`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            partition (:class:`google.cloud.dataplex_v1.types.Partition`):
+                Required. Partition resource.
+                This corresponds to the ``partition`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
-            google.iam.v1.policy_pb2.Policy:
-                An Identity and Access Management (IAM) policy, which specifies access
-                   controls for Google Cloud resources.
-
-                   A Policy is a collection of bindings. A binding binds
-                   one or more members, or principals, to a single role.
-                   Principals can be user accounts, service accounts,
-                   Google groups, and domains (such as G Suite). A role
-                   is a named list of permissions; each role can be an
-                   IAM predefined role or a user-created custom role.
-
-                   For some types of Google Cloud resources, a binding
-                   can also specify a condition, which is a logical
-                   expression that allows access to a resource only if
-                   the expression evaluates to true. A condition can add
-                   constraints based on attributes of the request, the
-                   resource, or both. To learn which resources support
-                   conditions in their IAM policies, see the [IAM
-                   documentation](\ https://cloud.google.com/iam/help/conditions/resource-policies).
-
-                   **JSON example:**
-
-                   :literal:`\`     {       "bindings": [         {           "role": "roles/resourcemanager.organizationAdmin",           "members": [             "user:mike@example.com",             "group:admins@example.com",             "domain:google.com",             "serviceAccount:my-project-id@appspot.gserviceaccount.com"           ]         },         {           "role": "roles/resourcemanager.organizationViewer",           "members": [             "user:eve@example.com"           ],           "condition": {             "title": "expirable access",             "description": "Does not grant access after Sep 2020",             "expression": "request.time <             timestamp('2020-10-01T00:00:00.000Z')",           }         }       ],       "etag": "BwWWja0YfJA=",       "version": 3     }`\ \`
-
-                   **YAML example:**
-
-                   :literal:`\`     bindings:     - members:       - user:mike@example.com       - group:admins@example.com       - domain:google.com       - serviceAccount:my-project-id@appspot.gserviceaccount.com       role: roles/resourcemanager.organizationAdmin     - members:       - user:eve@example.com       role: roles/resourcemanager.organizationViewer       condition:         title: expirable access         description: Does not grant access after Sep 2020         expression: request.time < timestamp('2020-10-01T00:00:00.000Z')     etag: BwWWja0YfJA=     version: 3`\ \`
-
-                   For a description of IAM and its features, see the
-                   [IAM
-                   documentation](\ https://cloud.google.com/iam/docs/).
+            google.cloud.dataplex_v1.types.Partition:
+                Represents partition metadata
+                contained within entity instances.
 
         """
         # Create or coerce a protobuf request object.
-        if isinstance(request, dict):
-            # The request isn't a proto-plus wrapped type,
-            # so it must be constructed via keyword expansion.
-            request = iam_policy_pb2.SetIamPolicyRequest(**request)
-        elif not request:
-            # Null request, just make one.
-            request = iam_policy_pb2.SetIamPolicyRequest()
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
+        has_flattened_params = any([parent, partition])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, metadata_.CreatePartitionRequest):
+            request = metadata_.CreatePartitionRequest(request)
+
+        # If we have keyword arguments corresponding to fields on the
+        # request, apply these.
+        if parent is not None:
+            request.parent = parent
+        if partition is not None:
+            request.partition = partition
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = self._transport._wrapped_methods[self._transport.set_iam_policy]
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.create_partition
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
-            gapic_v1.routing_header.to_grpc_metadata((("resource", request.resource),)),
+            gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
-        response = rpc(
+        response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
-    def test_iam_permissions(
+    async def delete_partition(
         self,
-        request: Optional[Union[iam_policy_pb2.TestIamPermissionsRequest, dict]] = None,
+        request: Optional[Union[metadata_.DeletePartitionRequest, dict]] = None,
         *,
+        name: Optional[str] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
-    ) -> iam_policy_pb2.TestIamPermissionsResponse:
-        r"""Returns the caller's permissions on a resource. If the resource
-        does not exist, an empty set of permissions is returned (a
-        ``NOT_FOUND`` error is not returned).
-
-        A caller is not required to have Google IAM permission to make
-        this request.
-
-        Note: This operation is designed to be used for building
-        permission-aware UIs and command-line tools, not for
-        authorization checking. This operation may "fail open" without
-        warning.
+    ) -> None:
+        r"""Delete a metadata partition.
 
         .. code-block:: python
 
             # This snippet has been automatically generated and should be regarded as a
             # code template only.
             # It will require modifications to work:
             # - It may require correct/in-range values for request initialization.
             # - It may require specifying regional endpoints when creating the service
             #   client as shown in:
             #   https://googleapis.dev/python/google-api-core/latest/client_options.html
             from google.cloud import dataplex_v1
-            from google.iam.v1 import iam_policy_pb2  # type: ignore
 
-            def sample_test_iam_permissions():
+            async def sample_delete_partition():
                 # Create a client
-                client = dataplex_v1.ContentServiceClient()
+                client = dataplex_v1.MetadataServiceAsyncClient()
 
                 # Initialize request argument(s)
-                request = iam_policy_pb2.TestIamPermissionsRequest(
-                    resource="resource_value",
-                    permissions=['permissions_value1', 'permissions_value2'],
+                request = dataplex_v1.DeletePartitionRequest(
+                    name="name_value",
                 )
 
                 # Make the request
-                response = client.test_iam_permissions(request=request)
+                await client.delete_partition(request=request)
+
+        Args:
+            request (Optional[Union[google.cloud.dataplex_v1.types.DeletePartitionRequest, dict]]):
+                The request object. Delete metadata partition request.
+            name (:class:`str`):
+                Required. The resource name of the partition. format:
+                ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/entities/{entity_id}/partitions/{partition_value_path}``.
+                The {partition_value_path} segment consists of an
+                ordered sequence of partition values separated by "/".
+                All values must be provided.
+
+                This corresponds to the ``name`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+        """
+        # Create or coerce a protobuf request object.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
+        has_flattened_params = any([name])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, metadata_.DeletePartitionRequest):
+            request = metadata_.DeletePartitionRequest(request)
+
+        # If we have keyword arguments corresponding to fields on the
+        # request, apply these.
+        if name is not None:
+            request.name = name
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.delete_partition
+        ]
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
+        )
+
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
+        # Send the request.
+        await rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+    async def get_partition(
+        self,
+        request: Optional[Union[metadata_.GetPartitionRequest, dict]] = None,
+        *,
+        name: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> metadata_.Partition:
+        r"""Get a metadata partition of an entity.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import dataplex_v1
+
+            async def sample_get_partition():
+                # Create a client
+                client = dataplex_v1.MetadataServiceAsyncClient()
+
+                # Initialize request argument(s)
+                request = dataplex_v1.GetPartitionRequest(
+                    name="name_value",
+                )
+
+                # Make the request
+                response = await client.get_partition(request=request)
 
                 # Handle the response
                 print(response)
 
         Args:
-            request (Union[google.iam.v1.iam_policy_pb2.TestIamPermissionsRequest, dict]):
-                The request object. Request message for ``TestIamPermissions`` method.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            request (Optional[Union[google.cloud.dataplex_v1.types.GetPartitionRequest, dict]]):
+                The request object. Get metadata partition request.
+            name (:class:`str`):
+                Required. The resource name of the partition:
+                ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/entities/{entity_id}/partitions/{partition_value_path}``.
+                The {partition_value_path} segment consists of an
+                ordered sequence of partition values separated by "/".
+                All values must be provided.
+
+                This corresponds to the ``name`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
-            google.iam.v1.iam_policy_pb2.TestIamPermissionsResponse:
-                Response message for TestIamPermissions method.
+            google.cloud.dataplex_v1.types.Partition:
+                Represents partition metadata
+                contained within entity instances.
+
         """
         # Create or coerce a protobuf request object.
-        if isinstance(request, dict):
-            # The request isn't a proto-plus wrapped type,
-            # so it must be constructed via keyword expansion.
-            request = iam_policy_pb2.TestIamPermissionsRequest(**request)
-        elif not request:
-            # Null request, just make one.
-            request = iam_policy_pb2.TestIamPermissionsRequest()
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
+        has_flattened_params = any([name])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, metadata_.GetPartitionRequest):
+            request = metadata_.GetPartitionRequest(request)
+
+        # If we have keyword arguments corresponding to fields on the
+        # request, apply these.
+        if name is not None:
+            request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = self._transport._wrapped_methods[self._transport.test_iam_permissions]
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.get_partition
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
-            gapic_v1.routing_header.to_grpc_metadata((("resource", request.resource),)),
+            gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
-        response = rpc(
+        response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
-    def list_content(
+    async def list_partitions(
         self,
-        request: Optional[Union[content.ListContentRequest, dict]] = None,
+        request: Optional[Union[metadata_.ListPartitionsRequest, dict]] = None,
         *,
         parent: Optional[str] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
-    ) -> pagers.ListContentPager:
-        r"""List content.
+    ) -> pagers.ListPartitionsAsyncPager:
+        r"""List metadata partitions of an entity.
 
         .. code-block:: python
 
             # This snippet has been automatically generated and should be regarded as a
             # code template only.
             # It will require modifications to work:
             # - It may require correct/in-range values for request initialization.
             # - It may require specifying regional endpoints when creating the service
             #   client as shown in:
             #   https://googleapis.dev/python/google-api-core/latest/client_options.html
             from google.cloud import dataplex_v1
 
-            def sample_list_content():
+            async def sample_list_partitions():
                 # Create a client
-                client = dataplex_v1.ContentServiceClient()
+                client = dataplex_v1.MetadataServiceAsyncClient()
 
                 # Initialize request argument(s)
-                request = dataplex_v1.ListContentRequest(
+                request = dataplex_v1.ListPartitionsRequest(
                     parent="parent_value",
                 )
 
                 # Make the request
-                page_result = client.list_content(request=request)
+                page_result = client.list_partitions(request=request)
 
                 # Handle the response
-                for response in page_result:
+                async for response in page_result:
                     print(response)
 
         Args:
-            request (Union[google.cloud.dataplex_v1.types.ListContentRequest, dict]):
-                The request object. List content request. Returns the
-                BASIC Content view.
-            parent (str):
-                Required. The resource name of the parent lake:
-                projects/{project_id}/locations/{location_id}/lakes/{lake_id}
+            request (Optional[Union[google.cloud.dataplex_v1.types.ListPartitionsRequest, dict]]):
+                The request object. List metadata partitions request.
+            parent (:class:`str`):
+                Required. The resource name of the parent entity:
+                ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/entities/{entity_id}``.
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
-            google.cloud.dataplex_v1.services.content_service.pagers.ListContentPager:
-                List content response.
+            google.cloud.dataplex_v1.services.metadata_service.pagers.ListPartitionsAsyncPager:
+                List metadata partitions response.
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a content.ListContentRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
-        if not isinstance(request, content.ListContentRequest):
-            request = content.ListContentRequest(request)
-            # If we have keyword arguments corresponding to fields on the
-            # request, apply these.
-            if parent is not None:
-                request.parent = parent
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, metadata_.ListPartitionsRequest):
+            request = metadata_.ListPartitionsRequest(request)
+
+        # If we have keyword arguments corresponding to fields on the
+        # request, apply these.
+        if parent is not None:
+            request.parent = parent
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = self._transport._wrapped_methods[self._transport.list_content]
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.list_partitions
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
-        response = rpc(
+        response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
         # This method is paged; wrap the response in a pager, which provides
-        # an `__iter__` convenience method.
-        response = pagers.ListContentPager(
+        # an `__aiter__` convenience method.
+        response = pagers.ListPartitionsAsyncPager(
             method=rpc,
             request=request,
             response=response,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
-    def __enter__(self) -> "ContentServiceClient":
-        return self
-
-    def __exit__(self, type, value, traceback):
-        """Releases underlying transport's resources.
-
-        .. warning::
-            ONLY use as a context manager if the transport is NOT shared
-            with other clients! Exiting the with block will CLOSE the transport
-            and may cause errors in other clients!
-        """
-        self.transport.close()
-
-    def list_operations(
+    async def list_operations(
         self,
         request: Optional[operations_pb2.ListOperationsRequest] = None,
         *,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
     ) -> operations_pb2.ListOperationsResponse:
         r"""Lists operations that match the specified filter in the request.
 
         Args:
             request (:class:`~.operations_pb2.ListOperationsRequest`):
                 The request object. Request message for
                 `ListOperations` method.
-            retry (google.api_core.retry.Retry): Designation of what errors,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors,
                     if any, should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         Returns:
             ~.operations_pb2.ListOperationsResponse:
                 Response message for ``ListOperations`` method.
@@ -1392,52 +1280,55 @@
         # The request isn't a proto-plus wrapped type,
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = operations_pb2.ListOperationsRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method.wrap_method(
-            self._transport.list_operations,
+        rpc = gapic_v1.method_async.wrap_method(
+            self._client._transport.list_operations,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
-        response = rpc(
+        response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
-    def get_operation(
+    async def get_operation(
         self,
         request: Optional[operations_pb2.GetOperationRequest] = None,
         *,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
     ) -> operations_pb2.Operation:
         r"""Gets the latest state of a long-running operation.
 
         Args:
             request (:class:`~.operations_pb2.GetOperationRequest`):
                 The request object. Request message for
                 `GetOperation` method.
-            retry (google.api_core.retry.Retry): Designation of what errors,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors,
                     if any, should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         Returns:
             ~.operations_pb2.Operation:
                 An ``Operation`` object.
@@ -1446,38 +1337,41 @@
         # The request isn't a proto-plus wrapped type,
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = operations_pb2.GetOperationRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method.wrap_method(
-            self._transport.get_operation,
+        rpc = gapic_v1.method_async.wrap_method(
+            self._client._transport.get_operation,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
-        response = rpc(
+        response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
-    def delete_operation(
+    async def delete_operation(
         self,
         request: Optional[operations_pb2.DeleteOperationRequest] = None,
         *,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
     ) -> None:
@@ -1488,15 +1382,15 @@
         If the server doesn't support this method, it returns
         `google.rpc.Code.UNIMPLEMENTED`.
 
         Args:
             request (:class:`~.operations_pb2.DeleteOperationRequest`):
                 The request object. Request message for
                 `DeleteOperation` method.
-            retry (google.api_core.retry.Retry): Designation of what errors,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors,
                     if any, should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         Returns:
             None
         """
@@ -1504,35 +1398,38 @@
         # The request isn't a proto-plus wrapped type,
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = operations_pb2.DeleteOperationRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method.wrap_method(
-            self._transport.delete_operation,
+        rpc = gapic_v1.method_async.wrap_method(
+            self._client._transport.delete_operation,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
-        rpc(
+        await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
-    def cancel_operation(
+    async def cancel_operation(
         self,
         request: Optional[operations_pb2.CancelOperationRequest] = None,
         *,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
     ) -> None:
@@ -1542,15 +1439,15 @@
         is not guaranteed.  If the server doesn't support this method, it returns
         `google.rpc.Code.UNIMPLEMENTED`.
 
         Args:
             request (:class:`~.operations_pb2.CancelOperationRequest`):
                 The request object. Request message for
                 `CancelOperation` method.
-            retry (google.api_core.retry.Retry): Designation of what errors,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors,
                     if any, should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         Returns:
             None
         """
@@ -1558,49 +1455,52 @@
         # The request isn't a proto-plus wrapped type,
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = operations_pb2.CancelOperationRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method.wrap_method(
-            self._transport.cancel_operation,
+        rpc = gapic_v1.method_async.wrap_method(
+            self._client._transport.cancel_operation,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
-        rpc(
+        await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
-    def get_location(
+    async def get_location(
         self,
         request: Optional[locations_pb2.GetLocationRequest] = None,
         *,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
     ) -> locations_pb2.Location:
         r"""Gets information about a location.
 
         Args:
             request (:class:`~.location_pb2.GetLocationRequest`):
                 The request object. Request message for
                 `GetLocation` method.
-            retry (google.api_core.retry.Retry): Designation of what errors,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors,
                  if any, should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         Returns:
             ~.location_pb2.Location:
                 Location object.
@@ -1609,52 +1509,55 @@
         # The request isn't a proto-plus wrapped type,
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = locations_pb2.GetLocationRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method.wrap_method(
-            self._transport.get_location,
+        rpc = gapic_v1.method_async.wrap_method(
+            self._client._transport.get_location,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
-        response = rpc(
+        response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
-    def list_locations(
+    async def list_locations(
         self,
         request: Optional[locations_pb2.ListLocationsRequest] = None,
         *,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
     ) -> locations_pb2.ListLocationsResponse:
         r"""Lists information about the supported locations for this service.
 
         Args:
             request (:class:`~.location_pb2.ListLocationsRequest`):
                 The request object. Request message for
                 `ListLocations` method.
-            retry (google.api_core.retry.Retry): Designation of what errors,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors,
                  if any, should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         Returns:
             ~.location_pb2.ListLocationsResponse:
                 Response message for ``ListLocations`` method.
@@ -1663,37 +1566,46 @@
         # The request isn't a proto-plus wrapped type,
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = locations_pb2.ListLocationsRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method.wrap_method(
-            self._transport.list_locations,
+        rpc = gapic_v1.method_async.wrap_method(
+            self._client._transport.list_locations,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
-        response = rpc(
+        response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
+    async def __aenter__(self) -> "MetadataServiceAsyncClient":
+        return self
+
+    async def __aexit__(self, exc_type, exc, tb):
+        await self.transport.close()
+
 
 DEFAULT_CLIENT_INFO = gapic_v1.client_info.ClientInfo(
     gapic_version=package_version.__version__
 )
 
 
-__all__ = ("ContentServiceClient",)
+__all__ = ("MetadataServiceAsyncClient",)
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/content_service/pagers.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/content_service/pagers.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/content_service/transports/__init__.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/catalog_service/transports/__init__.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,21 +12,21 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 from collections import OrderedDict
 from typing import Dict, Type
 
-from .base import ContentServiceTransport
-from .grpc import ContentServiceGrpcTransport
-from .grpc_asyncio import ContentServiceGrpcAsyncIOTransport
+from .base import CatalogServiceTransport
+from .grpc import CatalogServiceGrpcTransport
+from .grpc_asyncio import CatalogServiceGrpcAsyncIOTransport
 
 # Compile a registry of transports.
-_transport_registry = OrderedDict()  # type: Dict[str, Type[ContentServiceTransport]]
-_transport_registry["grpc"] = ContentServiceGrpcTransport
-_transport_registry["grpc_asyncio"] = ContentServiceGrpcAsyncIOTransport
+_transport_registry = OrderedDict()  # type: Dict[str, Type[CatalogServiceTransport]]
+_transport_registry["grpc"] = CatalogServiceGrpcTransport
+_transport_registry["grpc_asyncio"] = CatalogServiceGrpcAsyncIOTransport
 
 __all__ = (
-    "ContentServiceTransport",
-    "ContentServiceGrpcTransport",
-    "ContentServiceGrpcAsyncIOTransport",
+    "CatalogServiceTransport",
+    "CatalogServiceGrpcTransport",
+    "CatalogServiceGrpcAsyncIOTransport",
 )
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/content_service/transports/base.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/content_service/transports/base.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -59,15 +59,15 @@
         api_audience: Optional[str] = None,
         **kwargs,
     ) -> None:
         """Instantiate the transport.
 
         Args:
             host (Optional[str]):
-                 The hostname to connect to.
+                 The hostname to connect to (default: 'dataplex.googleapis.com').
             credentials (Optional[google.auth.credentials.Credentials]): The
                 authorization credentials to attach to requests. These
                 credentials identify the application to the service; if none
                 are specified, the client will attempt to ascertain the
                 credentials from the environment.
             credentials_file (Optional[str]): A file with credentials that can
                 be loaded with :func:`google.auth.load_credentials_from_file`.
@@ -122,14 +122,18 @@
         self._credentials = credentials
 
         # Save the hostname. Default to port 443 (HTTPS) if none is specified.
         if ":" not in host:
             host += ":443"
         self._host = host
 
+    @property
+    def host(self):
+        return self._host
+
     def _prep_wrapped_messages(self, client_info):
         # Precompute the wrapped methods.
         self._wrapped_methods = {
             self.create_content: gapic_v1.method.wrap_method(
                 self.create_content,
                 default_timeout=60.0,
                 client_info=client_info,
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/content_service/transports/grpc.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/content_service/transports/grpc.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -52,56 +52,59 @@
     def __init__(
         self,
         *,
         host: str = "dataplex.googleapis.com",
         credentials: Optional[ga_credentials.Credentials] = None,
         credentials_file: Optional[str] = None,
         scopes: Optional[Sequence[str]] = None,
-        channel: Optional[grpc.Channel] = None,
+        channel: Optional[Union[grpc.Channel, Callable[..., grpc.Channel]]] = None,
         api_mtls_endpoint: Optional[str] = None,
         client_cert_source: Optional[Callable[[], Tuple[bytes, bytes]]] = None,
         ssl_channel_credentials: Optional[grpc.ChannelCredentials] = None,
         client_cert_source_for_mtls: Optional[Callable[[], Tuple[bytes, bytes]]] = None,
         quota_project_id: Optional[str] = None,
         client_info: gapic_v1.client_info.ClientInfo = DEFAULT_CLIENT_INFO,
         always_use_jwt_access: Optional[bool] = False,
         api_audience: Optional[str] = None,
     ) -> None:
         """Instantiate the transport.
 
         Args:
             host (Optional[str]):
-                 The hostname to connect to.
+                 The hostname to connect to (default: 'dataplex.googleapis.com').
             credentials (Optional[google.auth.credentials.Credentials]): The
                 authorization credentials to attach to requests. These
                 credentials identify the application to the service; if none
                 are specified, the client will attempt to ascertain the
                 credentials from the environment.
-                This argument is ignored if ``channel`` is provided.
+                This argument is ignored if a ``channel`` instance is provided.
             credentials_file (Optional[str]): A file with credentials that can
                 be loaded with :func:`google.auth.load_credentials_from_file`.
-                This argument is ignored if ``channel`` is provided.
+                This argument is ignored if a ``channel`` instance is provided.
             scopes (Optional(Sequence[str])): A list of scopes. This argument is
-                ignored if ``channel`` is provided.
-            channel (Optional[grpc.Channel]): A ``Channel`` instance through
-                which to make calls.
+                ignored if a ``channel`` instance is provided.
+            channel (Optional[Union[grpc.Channel, Callable[..., grpc.Channel]]]):
+                A ``Channel`` instance through which to make calls, or a Callable
+                that constructs and returns one. If set to None, ``self.create_channel``
+                is used to create the channel. If a Callable is given, it will be called
+                with the same arguments as used in ``self.create_channel``.
             api_mtls_endpoint (Optional[str]): Deprecated. The mutual TLS endpoint.
                 If provided, it overrides the ``host`` argument and tries to create
                 a mutual TLS channel with client SSL credentials from
                 ``client_cert_source`` or application default SSL credentials.
             client_cert_source (Optional[Callable[[], Tuple[bytes, bytes]]]):
                 Deprecated. A callback to provide client SSL certificate bytes and
                 private key bytes, both in PEM format. It is ignored if
                 ``api_mtls_endpoint`` is None.
             ssl_channel_credentials (grpc.ChannelCredentials): SSL credentials
-                for the grpc channel. It is ignored if ``channel`` is provided.
+                for the grpc channel. It is ignored if a ``channel`` instance is provided.
             client_cert_source_for_mtls (Optional[Callable[[], Tuple[bytes, bytes]]]):
                 A callback to provide client certificate bytes and private key bytes,
                 both in PEM format. It is used to configure a mutual TLS channel. It is
-                ignored if ``channel`` or ``ssl_channel_credentials`` is provided.
+                ignored if a ``channel`` instance or ``ssl_channel_credentials`` is provided.
             quota_project_id (Optional[str]): An optional project to use for billing
                 and quota.
             client_info (google.api_core.gapic_v1.client_info.ClientInfo):
                 The client info used to send a user-agent string along with
                 API requests. If ``None``, then default info will be used.
                 Generally, you only need to set this if you're developing
                 your own client library.
@@ -119,15 +122,15 @@
         self._stubs: Dict[str, Callable] = {}
 
         if api_mtls_endpoint:
             warnings.warn("api_mtls_endpoint is deprecated", DeprecationWarning)
         if client_cert_source:
             warnings.warn("client_cert_source is deprecated", DeprecationWarning)
 
-        if channel:
+        if isinstance(channel, grpc.Channel):
             # Ignore credentials if a channel was passed.
             credentials = False
             # If a channel was explicitly provided, set it.
             self._grpc_channel = channel
             self._ssl_channel_credentials = None
 
         else:
@@ -160,15 +163,17 @@
             quota_project_id=quota_project_id,
             client_info=client_info,
             always_use_jwt_access=always_use_jwt_access,
             api_audience=api_audience,
         )
 
         if not self._grpc_channel:
-            self._grpc_channel = type(self).create_channel(
+            # initialize with the provided callable or the default channel
+            channel_init = channel or type(self).create_channel
+            self._grpc_channel = channel_init(
                 self._host,
                 # use the credentials which are saved
                 credentials=self._credentials,
                 # Set ``credentials_file`` to ``None`` here as
                 # the credentials that we saved earlier should be used.
                 credentials_file=None,
                 scopes=self._scopes,
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/content_service/transports/grpc_asyncio.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/content_service/transports/grpc_asyncio.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,17 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 from typing import Awaitable, Callable, Dict, Optional, Sequence, Tuple, Union
 import warnings
 
+from google.api_core import exceptions as core_exceptions
 from google.api_core import gapic_v1, grpc_helpers_async
+from google.api_core import retry_async as retries
 from google.auth import credentials as ga_credentials  # type: ignore
 from google.auth.transport.grpc import SslCredentials  # type: ignore
 from google.cloud.location import locations_pb2  # type: ignore
 from google.iam.v1 import iam_policy_pb2  # type: ignore
 from google.iam.v1 import policy_pb2  # type: ignore
 from google.longrunning import operations_pb2  # type: ignore
 from google.protobuf import empty_pb2  # type: ignore
@@ -67,15 +69,14 @@
             credentials (Optional[~.Credentials]): The
                 authorization credentials to attach to requests. These
                 credentials identify this application to the service. If
                 none are specified, the client will attempt to ascertain
                 the credentials from the environment.
             credentials_file (Optional[str]): A file with credentials that can
                 be loaded with :func:`google.auth.load_credentials_from_file`.
-                This argument is ignored if ``channel`` is provided.
             scopes (Optional[Sequence[str]]): A optional list of scopes needed for this
                 service. These are only used when credentials are not specified and
                 are passed to :func:`google.auth.default`.
             quota_project_id (Optional[str]): An optional project to use for billing
                 and quota.
             kwargs (Optional[dict]): Keyword arguments, which are passed to the
                 channel creation.
@@ -97,57 +98,60 @@
     def __init__(
         self,
         *,
         host: str = "dataplex.googleapis.com",
         credentials: Optional[ga_credentials.Credentials] = None,
         credentials_file: Optional[str] = None,
         scopes: Optional[Sequence[str]] = None,
-        channel: Optional[aio.Channel] = None,
+        channel: Optional[Union[aio.Channel, Callable[..., aio.Channel]]] = None,
         api_mtls_endpoint: Optional[str] = None,
         client_cert_source: Optional[Callable[[], Tuple[bytes, bytes]]] = None,
         ssl_channel_credentials: Optional[grpc.ChannelCredentials] = None,
         client_cert_source_for_mtls: Optional[Callable[[], Tuple[bytes, bytes]]] = None,
         quota_project_id: Optional[str] = None,
         client_info: gapic_v1.client_info.ClientInfo = DEFAULT_CLIENT_INFO,
         always_use_jwt_access: Optional[bool] = False,
         api_audience: Optional[str] = None,
     ) -> None:
         """Instantiate the transport.
 
         Args:
             host (Optional[str]):
-                 The hostname to connect to.
+                 The hostname to connect to (default: 'dataplex.googleapis.com').
             credentials (Optional[google.auth.credentials.Credentials]): The
                 authorization credentials to attach to requests. These
                 credentials identify the application to the service; if none
                 are specified, the client will attempt to ascertain the
                 credentials from the environment.
-                This argument is ignored if ``channel`` is provided.
+                This argument is ignored if a ``channel`` instance is provided.
             credentials_file (Optional[str]): A file with credentials that can
                 be loaded with :func:`google.auth.load_credentials_from_file`.
-                This argument is ignored if ``channel`` is provided.
+                This argument is ignored if a ``channel`` instance is provided.
             scopes (Optional[Sequence[str]]): A optional list of scopes needed for this
                 service. These are only used when credentials are not specified and
                 are passed to :func:`google.auth.default`.
-            channel (Optional[aio.Channel]): A ``Channel`` instance through
-                which to make calls.
+            channel (Optional[Union[aio.Channel, Callable[..., aio.Channel]]]):
+                A ``Channel`` instance through which to make calls, or a Callable
+                that constructs and returns one. If set to None, ``self.create_channel``
+                is used to create the channel. If a Callable is given, it will be called
+                with the same arguments as used in ``self.create_channel``.
             api_mtls_endpoint (Optional[str]): Deprecated. The mutual TLS endpoint.
                 If provided, it overrides the ``host`` argument and tries to create
                 a mutual TLS channel with client SSL credentials from
                 ``client_cert_source`` or application default SSL credentials.
             client_cert_source (Optional[Callable[[], Tuple[bytes, bytes]]]):
                 Deprecated. A callback to provide client SSL certificate bytes and
                 private key bytes, both in PEM format. It is ignored if
                 ``api_mtls_endpoint`` is None.
             ssl_channel_credentials (grpc.ChannelCredentials): SSL credentials
-                for the grpc channel. It is ignored if ``channel`` is provided.
+                for the grpc channel. It is ignored if a ``channel`` instance is provided.
             client_cert_source_for_mtls (Optional[Callable[[], Tuple[bytes, bytes]]]):
                 A callback to provide client certificate bytes and private key bytes,
                 both in PEM format. It is used to configure a mutual TLS channel. It is
-                ignored if ``channel`` or ``ssl_channel_credentials`` is provided.
+                ignored if a ``channel`` instance or ``ssl_channel_credentials`` is provided.
             quota_project_id (Optional[str]): An optional project to use for billing
                 and quota.
             client_info (google.api_core.gapic_v1.client_info.ClientInfo):
                 The client info used to send a user-agent string along with
                 API requests. If ``None``, then default info will be used.
                 Generally, you only need to set this if you're developing
                 your own client library.
@@ -165,15 +169,15 @@
         self._stubs: Dict[str, Callable] = {}
 
         if api_mtls_endpoint:
             warnings.warn("api_mtls_endpoint is deprecated", DeprecationWarning)
         if client_cert_source:
             warnings.warn("client_cert_source is deprecated", DeprecationWarning)
 
-        if channel:
+        if isinstance(channel, aio.Channel):
             # Ignore credentials if a channel was passed.
             credentials = False
             # If a channel was explicitly provided, set it.
             self._grpc_channel = channel
             self._ssl_channel_credentials = None
         else:
             if api_mtls_endpoint:
@@ -205,15 +209,17 @@
             quota_project_id=quota_project_id,
             client_info=client_info,
             always_use_jwt_access=always_use_jwt_access,
             api_audience=api_audience,
         )
 
         if not self._grpc_channel:
-            self._grpc_channel = type(self).create_channel(
+            # initialize with the provided callable or the default channel
+            channel_init = channel or type(self).create_channel
+            self._grpc_channel = channel_init(
                 self._host,
                 # use the credentials which are saved
                 credentials=self._credentials,
                 # Set ``credentials_file`` to ``None`` here as
                 # the credentials that we saved earlier should be used.
                 credentials_file=None,
                 scopes=self._scopes,
@@ -465,14 +471,95 @@
             self._stubs["list_content"] = self.grpc_channel.unary_unary(
                 "/google.cloud.dataplex.v1.ContentService/ListContent",
                 request_serializer=content.ListContentRequest.serialize,
                 response_deserializer=content.ListContentResponse.deserialize,
             )
         return self._stubs["list_content"]
 
+    def _prep_wrapped_messages(self, client_info):
+        """Precompute the wrapped methods, overriding the base class method to use async wrappers."""
+        self._wrapped_methods = {
+            self.create_content: gapic_v1.method_async.wrap_method(
+                self.create_content,
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.update_content: gapic_v1.method_async.wrap_method(
+                self.update_content,
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.delete_content: gapic_v1.method_async.wrap_method(
+                self.delete_content,
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.get_content: gapic_v1.method_async.wrap_method(
+                self.get_content,
+                default_retry=retries.AsyncRetry(
+                    initial=1.0,
+                    maximum=10.0,
+                    multiplier=1.3,
+                    predicate=retries.if_exception_type(
+                        core_exceptions.ServiceUnavailable,
+                    ),
+                    deadline=60.0,
+                ),
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.get_iam_policy: gapic_v1.method_async.wrap_method(
+                self.get_iam_policy,
+                default_retry=retries.AsyncRetry(
+                    initial=1.0,
+                    maximum=10.0,
+                    multiplier=1.3,
+                    predicate=retries.if_exception_type(
+                        core_exceptions.ServiceUnavailable,
+                    ),
+                    deadline=60.0,
+                ),
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.set_iam_policy: gapic_v1.method_async.wrap_method(
+                self.set_iam_policy,
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.test_iam_permissions: gapic_v1.method_async.wrap_method(
+                self.test_iam_permissions,
+                default_retry=retries.AsyncRetry(
+                    initial=1.0,
+                    maximum=10.0,
+                    multiplier=1.3,
+                    predicate=retries.if_exception_type(
+                        core_exceptions.ServiceUnavailable,
+                    ),
+                    deadline=60.0,
+                ),
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.list_content: gapic_v1.method_async.wrap_method(
+                self.list_content,
+                default_retry=retries.AsyncRetry(
+                    initial=1.0,
+                    maximum=10.0,
+                    multiplier=1.3,
+                    predicate=retries.if_exception_type(
+                        core_exceptions.ServiceUnavailable,
+                    ),
+                    deadline=60.0,
+                ),
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+        }
+
     def close(self):
         return self.grpc_channel.close()
 
     @property
     def delete_operation(
         self,
     ) -> Callable[[operations_pb2.DeleteOperationRequest], None]:
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_scan_service/__init__.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_scan_service/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_scan_service/async_client.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_scan_service/async_client.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,38 +13,39 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 from collections import OrderedDict
 import functools
 import re
 from typing import (
+    Callable,
     Dict,
     Mapping,
     MutableMapping,
     MutableSequence,
     Optional,
     Sequence,
     Tuple,
     Type,
     Union,
 )
 
 from google.api_core import exceptions as core_exceptions
 from google.api_core import gapic_v1
-from google.api_core import retry as retries
+from google.api_core import retry_async as retries
 from google.api_core.client_options import ClientOptions
 from google.auth import credentials as ga_credentials  # type: ignore
 from google.oauth2 import service_account  # type: ignore
 
 from google.cloud.dataplex_v1 import gapic_version as package_version
 
 try:
-    OptionalRetry = Union[retries.Retry, gapic_v1.method._MethodDefault]
+    OptionalRetry = Union[retries.AsyncRetry, gapic_v1.method._MethodDefault, None]
 except AttributeError:  # pragma: NO COVER
-    OptionalRetry = Union[retries.Retry, object]  # type: ignore
+    OptionalRetry = Union[retries.AsyncRetry, object, None]  # type: ignore
 
 from google.api_core import operation  # type: ignore
 from google.api_core import operation_async  # type: ignore
 from google.cloud.location import locations_pb2  # type: ignore
 from google.iam.v1 import iam_policy_pb2  # type: ignore
 from google.iam.v1 import policy_pb2  # type: ignore
 from google.longrunning import operations_pb2  # type: ignore
@@ -72,16 +73,20 @@
     configured to run various types of data scanning workload and
     generate enriched metadata (e.g. Data Profile, Data Quality) for
     the data source.
     """
 
     _client: DataScanServiceClient
 
+    # Copy defaults from the synchronous client for use here.
+    # Note: DEFAULT_ENDPOINT is deprecated. Use _DEFAULT_ENDPOINT_TEMPLATE instead.
     DEFAULT_ENDPOINT = DataScanServiceClient.DEFAULT_ENDPOINT
     DEFAULT_MTLS_ENDPOINT = DataScanServiceClient.DEFAULT_MTLS_ENDPOINT
+    _DEFAULT_ENDPOINT_TEMPLATE = DataScanServiceClient._DEFAULT_ENDPOINT_TEMPLATE
+    _DEFAULT_UNIVERSE = DataScanServiceClient._DEFAULT_UNIVERSE
 
     data_scan_path = staticmethod(DataScanServiceClient.data_scan_path)
     parse_data_scan_path = staticmethod(DataScanServiceClient.parse_data_scan_path)
     data_scan_job_path = staticmethod(DataScanServiceClient.data_scan_job_path)
     parse_data_scan_job_path = staticmethod(
         DataScanServiceClient.parse_data_scan_job_path
     )
@@ -186,54 +191,94 @@
         """Returns the transport used by the client instance.
 
         Returns:
             DataScanServiceTransport: The transport used by the client instance.
         """
         return self._client.transport
 
+    @property
+    def api_endpoint(self):
+        """Return the API endpoint used by the client instance.
+
+        Returns:
+            str: The API endpoint used by the client instance.
+        """
+        return self._client._api_endpoint
+
+    @property
+    def universe_domain(self) -> str:
+        """Return the universe domain used by the client instance.
+
+        Returns:
+            str: The universe domain used
+                by the client instance.
+        """
+        return self._client._universe_domain
+
     get_transport_class = functools.partial(
         type(DataScanServiceClient).get_transport_class, type(DataScanServiceClient)
     )
 
     def __init__(
         self,
         *,
         credentials: Optional[ga_credentials.Credentials] = None,
-        transport: Union[str, DataScanServiceTransport] = "grpc_asyncio",
+        transport: Optional[
+            Union[
+                str, DataScanServiceTransport, Callable[..., DataScanServiceTransport]
+            ]
+        ] = "grpc_asyncio",
         client_options: Optional[ClientOptions] = None,
         client_info: gapic_v1.client_info.ClientInfo = DEFAULT_CLIENT_INFO,
     ) -> None:
-        """Instantiates the data scan service client.
+        """Instantiates the data scan service async client.
 
         Args:
             credentials (Optional[google.auth.credentials.Credentials]): The
                 authorization credentials to attach to requests. These
                 credentials identify the application to the service; if none
                 are specified, the client will attempt to ascertain the
                 credentials from the environment.
-            transport (Union[str, ~.DataScanServiceTransport]): The
-                transport to use. If set to None, a transport is chosen
-                automatically.
-            client_options (ClientOptions): Custom options for the client. It
-                won't take effect if a ``transport`` instance is provided.
-                (1) The ``api_endpoint`` property can be used to override the
-                default endpoint provided by the client. GOOGLE_API_USE_MTLS_ENDPOINT
-                environment variable can also be used to override the endpoint:
+            transport (Optional[Union[str,DataScanServiceTransport,Callable[..., DataScanServiceTransport]]]):
+                The transport to use, or a Callable that constructs and returns a new transport to use.
+                If a Callable is given, it will be called with the same set of initialization
+                arguments as used in the DataScanServiceTransport constructor.
+                If set to None, a transport is chosen automatically.
+            client_options (Optional[Union[google.api_core.client_options.ClientOptions, dict]]):
+                Custom options for the client.
+
+                1. The ``api_endpoint`` property can be used to override the
+                default endpoint provided by the client when ``transport`` is
+                not explicitly provided. Only if this property is not set and
+                ``transport`` was not explicitly provided, the endpoint is
+                determined by the GOOGLE_API_USE_MTLS_ENDPOINT environment
+                variable, which have one of the following values:
                 "always" (always use the default mTLS endpoint), "never" (always
-                use the default regular endpoint) and "auto" (auto switch to the
-                default mTLS endpoint if client certificate is present, this is
-                the default value). However, the ``api_endpoint`` property takes
-                precedence if provided.
-                (2) If GOOGLE_API_USE_CLIENT_CERTIFICATE environment variable
+                use the default regular endpoint) and "auto" (auto-switch to the
+                default mTLS endpoint if client certificate is present; this is
+                the default value).
+
+                2. If the GOOGLE_API_USE_CLIENT_CERTIFICATE environment variable
                 is "true", then the ``client_cert_source`` property can be used
-                to provide client certificate for mutual TLS transport. If
+                to provide a client certificate for mTLS transport. If
                 not provided, the default SSL client certificate will be used if
                 present. If GOOGLE_API_USE_CLIENT_CERTIFICATE is "false" or not
                 set, no client certificate will be used.
 
+                3. The ``universe_domain`` property can be used to override the
+                default "googleapis.com" universe. Note that ``api_endpoint``
+                property still takes precedence; and ``universe_domain`` is
+                currently not supported for mTLS.
+
+            client_info (google.api_core.gapic_v1.client_info.ClientInfo):
+                The client info used to send a user-agent string along with
+                API requests. If ``None``, then default info will be used.
+                Generally, you only need to set this if you're developing
+                your own client library.
+
         Raises:
             google.auth.exceptions.MutualTlsChannelError: If mutual TLS transport
                 creation failed for any reason.
         """
         self._client = DataScanServiceClient(
             credentials=credentials,
             transport=transport,
@@ -317,15 +362,15 @@
                 -  Must be between 1-63 characters.
                 -  Must be unique within the customer project /
                    location.
 
                 This corresponds to the ``data_scan_id`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.api_core.operation_async.AsyncOperation:
@@ -342,48 +387,52 @@
                    -  Data Profile: analyzes the data in table(s) and
                       generates insights about the structure, content
                       and relationships (such as null percent,
                       cardinality, min/max/mean, etc).
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent, data_scan, data_scan_id])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = datascans.CreateDataScanRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, datascans.CreateDataScanRequest):
+            request = datascans.CreateDataScanRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if parent is not None:
             request.parent = parent
         if data_scan is not None:
             request.data_scan = data_scan
         if data_scan_id is not None:
             request.data_scan_id = data_scan_id
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.create_data_scan,
-            default_timeout=None,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.create_data_scan
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -457,15 +506,15 @@
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             update_mask (:class:`google.protobuf.field_mask_pb2.FieldMask`):
                 Required. Mask of fields to update.
                 This corresponds to the ``update_mask`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.api_core.operation_async.AsyncOperation:
@@ -482,48 +531,52 @@
                    -  Data Profile: analyzes the data in table(s) and
                       generates insights about the structure, content
                       and relationships (such as null percent,
                       cardinality, min/max/mean, etc).
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([data_scan, update_mask])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = datascans.UpdateDataScanRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, datascans.UpdateDataScanRequest):
+            request = datascans.UpdateDataScanRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if data_scan is not None:
             request.data_scan = data_scan
         if update_mask is not None:
             request.update_mask = update_mask
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.update_data_scan,
-            default_timeout=None,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.update_data_scan
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata(
                 (("data_scan.name", request.data_scan.name),)
             ),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -589,15 +642,15 @@
                 where ``project`` refers to a *project_id* or
                 *project_number* and ``location_id`` refers to a GCP
                 region.
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.api_core.operation_async.AsyncOperation:
@@ -612,44 +665,48 @@
                          rpc Bar(google.protobuf.Empty) returns
                          (google.protobuf.Empty);
 
                       }
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = datascans.DeleteDataScanRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, datascans.DeleteDataScanRequest):
+            request = datascans.DeleteDataScanRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if name is not None:
             request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.delete_data_scan,
-            default_timeout=None,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.delete_data_scan
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -711,15 +768,15 @@
                 where ``project`` refers to a *project_id* or
                 *project_number* and ``location_id`` refers to a GCP
                 region.
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.types.DataScan:
@@ -734,44 +791,48 @@
                    -  Data Profile: analyzes the data in table(s) and
                       generates insights about the structure, content
                       and relationships (such as null percent,
                       cardinality, min/max/mean, etc).
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = datascans.GetDataScanRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, datascans.GetDataScanRequest):
+            request = datascans.GetDataScanRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if name is not None:
             request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.get_data_scan,
-            default_timeout=None,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.get_data_scan
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -825,15 +886,15 @@
                 ``projects/{project}/locations/{location_id}`` where
                 ``project`` refers to a *project_id* or *project_number*
                 and ``location_id`` refers to a GCP region.
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.services.data_scan_service.pagers.ListDataScansAsyncPager:
@@ -841,44 +902,48 @@
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = datascans.ListDataScansRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, datascans.ListDataScansRequest):
+            request = datascans.ListDataScansRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if parent is not None:
             request.parent = parent
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.list_data_scans,
-            default_timeout=None,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.list_data_scans
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -943,55 +1008,59 @@
                 region.
 
                 Only **OnDemand** data scans are allowed.
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.types.RunDataScanResponse:
                 Run DataScan Response.
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = datascans.RunDataScanRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, datascans.RunDataScanRequest):
+            request = datascans.RunDataScanRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if name is not None:
             request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.run_data_scan,
-            default_timeout=None,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.run_data_scan
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1045,57 +1114,61 @@
                 where ``project`` refers to a *project_id* or
                 *project_number* and ``location_id`` refers to a GCP
                 region.
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.types.DataScanJob:
                 A DataScanJob represents an instance
                 of DataScan execution.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = datascans.GetDataScanJobRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, datascans.GetDataScanJobRequest):
+            request = datascans.GetDataScanJobRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if name is not None:
             request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.get_data_scan_job,
-            default_timeout=None,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.get_data_scan_job
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1150,15 +1223,15 @@
                 where ``project`` refers to a *project_id* or
                 *project_number* and ``location_id`` refers to a GCP
                 region.
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.services.data_scan_service.pagers.ListDataScanJobsAsyncPager:
@@ -1166,44 +1239,48 @@
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = datascans.ListDataScanJobsRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, datascans.ListDataScanJobsRequest):
+            request = datascans.ListDataScanJobsRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if parent is not None:
             request.parent = parent
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.list_data_scan_jobs,
-            default_timeout=None,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.list_data_scan_jobs
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1216,29 +1293,142 @@
             response=response,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
+    async def generate_data_quality_rules(
+        self,
+        request: Optional[
+            Union[datascans.GenerateDataQualityRulesRequest, dict]
+        ] = None,
+        *,
+        name: Optional[str] = None,
+        retry: OptionalRetry = gapic_v1.method.DEFAULT,
+        timeout: Union[float, object] = gapic_v1.method.DEFAULT,
+        metadata: Sequence[Tuple[str, str]] = (),
+    ) -> datascans.GenerateDataQualityRulesResponse:
+        r"""Generates recommended DataQualityRule from a data
+        profiling DataScan.
+
+        .. code-block:: python
+
+            # This snippet has been automatically generated and should be regarded as a
+            # code template only.
+            # It will require modifications to work:
+            # - It may require correct/in-range values for request initialization.
+            # - It may require specifying regional endpoints when creating the service
+            #   client as shown in:
+            #   https://googleapis.dev/python/google-api-core/latest/client_options.html
+            from google.cloud import dataplex_v1
+
+            async def sample_generate_data_quality_rules():
+                # Create a client
+                client = dataplex_v1.DataScanServiceAsyncClient()
+
+                # Initialize request argument(s)
+                request = dataplex_v1.GenerateDataQualityRulesRequest(
+                    name="name_value",
+                )
+
+                # Make the request
+                response = await client.generate_data_quality_rules(request=request)
+
+                # Handle the response
+                print(response)
+
+        Args:
+            request (Optional[Union[google.cloud.dataplex_v1.types.GenerateDataQualityRulesRequest, dict]]):
+                The request object. Generate recommended DataQualityRules
+                request.
+            name (:class:`str`):
+                Required. The name should be either
+
+                -  the name of a datascan with at least one successful
+                   completed data profiling job, or
+                -  the name of a successful completed data profiling
+                   datascan job.
+
+                This corresponds to the ``name`` field
+                on the ``request`` instance; if ``request`` is provided, this
+                should not be set.
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
+                should be retried.
+            timeout (float): The timeout for this request.
+            metadata (Sequence[Tuple[str, str]]): Strings which should be
+                sent along with the request as metadata.
+
+        Returns:
+            google.cloud.dataplex_v1.types.GenerateDataQualityRulesResponse:
+                Generate recommended DataQualityRules
+                response.
+
+        """
+        # Create or coerce a protobuf request object.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
+        has_flattened_params = any([name])
+        if request is not None and has_flattened_params:
+            raise ValueError(
+                "If the `request` argument is set, then none of "
+                "the individual field arguments should be set."
+            )
+
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, datascans.GenerateDataQualityRulesRequest):
+            request = datascans.GenerateDataQualityRulesRequest(request)
+
+        # If we have keyword arguments corresponding to fields on the
+        # request, apply these.
+        if name is not None:
+            request.name = name
+
+        # Wrap the RPC method; this adds retry and timeout information,
+        # and friendly error handling.
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.generate_data_quality_rules
+        ]
+
+        # Certain fields should be provided within the metadata header;
+        # add these here.
+        metadata = tuple(metadata) + (
+            gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
+        )
+
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
+        # Send the request.
+        response = await rpc(
+            request,
+            retry=retry,
+            timeout=timeout,
+            metadata=metadata,
+        )
+
+        # Done; return the response.
+        return response
+
     async def list_operations(
         self,
         request: Optional[operations_pb2.ListOperationsRequest] = None,
         *,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
     ) -> operations_pb2.ListOperationsResponse:
         r"""Lists operations that match the specified filter in the request.
 
         Args:
             request (:class:`~.operations_pb2.ListOperationsRequest`):
                 The request object. Request message for
                 `ListOperations` method.
-            retry (google.api_core.retry.Retry): Designation of what errors,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors,
                     if any, should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         Returns:
             ~.operations_pb2.ListOperationsResponse:
                 Response message for ``ListOperations`` method.
@@ -1247,26 +1437,29 @@
         # The request isn't a proto-plus wrapped type,
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = operations_pb2.ListOperationsRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method.wrap_method(
+        rpc = gapic_v1.method_async.wrap_method(
             self._client._transport.list_operations,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1284,15 +1477,15 @@
     ) -> operations_pb2.Operation:
         r"""Gets the latest state of a long-running operation.
 
         Args:
             request (:class:`~.operations_pb2.GetOperationRequest`):
                 The request object. Request message for
                 `GetOperation` method.
-            retry (google.api_core.retry.Retry): Designation of what errors,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors,
                     if any, should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         Returns:
             ~.operations_pb2.Operation:
                 An ``Operation`` object.
@@ -1301,26 +1494,29 @@
         # The request isn't a proto-plus wrapped type,
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = operations_pb2.GetOperationRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method.wrap_method(
+        rpc = gapic_v1.method_async.wrap_method(
             self._client._transport.get_operation,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1343,15 +1539,15 @@
         If the server doesn't support this method, it returns
         `google.rpc.Code.UNIMPLEMENTED`.
 
         Args:
             request (:class:`~.operations_pb2.DeleteOperationRequest`):
                 The request object. Request message for
                 `DeleteOperation` method.
-            retry (google.api_core.retry.Retry): Designation of what errors,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors,
                     if any, should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         Returns:
             None
         """
@@ -1359,26 +1555,29 @@
         # The request isn't a proto-plus wrapped type,
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = operations_pb2.DeleteOperationRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method.wrap_method(
+        rpc = gapic_v1.method_async.wrap_method(
             self._client._transport.delete_operation,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1397,15 +1596,15 @@
         is not guaranteed.  If the server doesn't support this method, it returns
         `google.rpc.Code.UNIMPLEMENTED`.
 
         Args:
             request (:class:`~.operations_pb2.CancelOperationRequest`):
                 The request object. Request message for
                 `CancelOperation` method.
-            retry (google.api_core.retry.Retry): Designation of what errors,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors,
                     if any, should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         Returns:
             None
         """
@@ -1413,26 +1612,29 @@
         # The request isn't a proto-plus wrapped type,
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = operations_pb2.CancelOperationRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method.wrap_method(
+        rpc = gapic_v1.method_async.wrap_method(
             self._client._transport.cancel_operation,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1447,15 +1649,15 @@
     ) -> locations_pb2.Location:
         r"""Gets information about a location.
 
         Args:
             request (:class:`~.location_pb2.GetLocationRequest`):
                 The request object. Request message for
                 `GetLocation` method.
-            retry (google.api_core.retry.Retry): Designation of what errors,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors,
                  if any, should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         Returns:
             ~.location_pb2.Location:
                 Location object.
@@ -1464,26 +1666,29 @@
         # The request isn't a proto-plus wrapped type,
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = locations_pb2.GetLocationRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method.wrap_method(
+        rpc = gapic_v1.method_async.wrap_method(
             self._client._transport.get_location,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1501,15 +1706,15 @@
     ) -> locations_pb2.ListLocationsResponse:
         r"""Lists information about the supported locations for this service.
 
         Args:
             request (:class:`~.location_pb2.ListLocationsRequest`):
                 The request object. Request message for
                 `ListLocations` method.
-            retry (google.api_core.retry.Retry): Designation of what errors,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors,
                  if any, should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         Returns:
             ~.location_pb2.ListLocationsResponse:
                 Response message for ``ListLocations`` method.
@@ -1518,26 +1723,29 @@
         # The request isn't a proto-plus wrapped type,
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = locations_pb2.ListLocationsRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method.wrap_method(
+        rpc = gapic_v1.method_async.wrap_method(
             self._client._transport.list_locations,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_scan_service/client.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/content_service/client.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,86 +13,80 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 from collections import OrderedDict
 import os
 import re
 from typing import (
+    Callable,
     Dict,
     Mapping,
     MutableMapping,
     MutableSequence,
     Optional,
     Sequence,
     Tuple,
     Type,
     Union,
     cast,
 )
+import warnings
 
 from google.api_core import client_options as client_options_lib
 from google.api_core import exceptions as core_exceptions
 from google.api_core import gapic_v1
 from google.api_core import retry as retries
 from google.auth import credentials as ga_credentials  # type: ignore
 from google.auth.exceptions import MutualTLSChannelError  # type: ignore
 from google.auth.transport import mtls  # type: ignore
 from google.auth.transport.grpc import SslCredentials  # type: ignore
 from google.oauth2 import service_account  # type: ignore
 
 from google.cloud.dataplex_v1 import gapic_version as package_version
 
 try:
-    OptionalRetry = Union[retries.Retry, gapic_v1.method._MethodDefault]
+    OptionalRetry = Union[retries.Retry, gapic_v1.method._MethodDefault, None]
 except AttributeError:  # pragma: NO COVER
-    OptionalRetry = Union[retries.Retry, object]  # type: ignore
+    OptionalRetry = Union[retries.Retry, object, None]  # type: ignore
 
-from google.api_core import operation  # type: ignore
-from google.api_core import operation_async  # type: ignore
 from google.cloud.location import locations_pb2  # type: ignore
 from google.iam.v1 import iam_policy_pb2  # type: ignore
 from google.iam.v1 import policy_pb2  # type: ignore
 from google.longrunning import operations_pb2  # type: ignore
-from google.protobuf import empty_pb2  # type: ignore
 from google.protobuf import field_mask_pb2  # type: ignore
 from google.protobuf import timestamp_pb2  # type: ignore
 
-from google.cloud.dataplex_v1.services.data_scan_service import pagers
-from google.cloud.dataplex_v1.types import (
-    data_profile,
-    data_quality,
-    datascans,
-    processing,
-    resources,
-    service,
-)
-
-from .transports.base import DEFAULT_CLIENT_INFO, DataScanServiceTransport
-from .transports.grpc import DataScanServiceGrpcTransport
-from .transports.grpc_asyncio import DataScanServiceGrpcAsyncIOTransport
+from google.cloud.dataplex_v1.services.content_service import pagers
+from google.cloud.dataplex_v1.types import analyze
+from google.cloud.dataplex_v1.types import content
+from google.cloud.dataplex_v1.types import content as gcd_content
+
+from .transports.base import DEFAULT_CLIENT_INFO, ContentServiceTransport
+from .transports.grpc import ContentServiceGrpcTransport
+from .transports.grpc_asyncio import ContentServiceGrpcAsyncIOTransport
 
 
-class DataScanServiceClientMeta(type):
-    """Metaclass for the DataScanService client.
+class ContentServiceClientMeta(type):
+    """Metaclass for the ContentService client.
 
     This provides class-level methods for building and retrieving
     support objects (e.g. transport) without polluting the client instance
     objects.
     """
 
     _transport_registry = (
         OrderedDict()
-    )  # type: Dict[str, Type[DataScanServiceTransport]]
-    _transport_registry["grpc"] = DataScanServiceGrpcTransport
-    _transport_registry["grpc_asyncio"] = DataScanServiceGrpcAsyncIOTransport
+    )  # type: Dict[str, Type[ContentServiceTransport]]
+    _transport_registry["grpc"] = ContentServiceGrpcTransport
+    _transport_registry["grpc_asyncio"] = ContentServiceGrpcAsyncIOTransport
 
     def get_transport_class(
         cls,
         label: Optional[str] = None,
-    ) -> Type[DataScanServiceTransport]:
+    ) -> Type[ContentServiceTransport]:
         """Returns an appropriate transport class.
 
         Args:
             label: The name of the desired transport. If none is
                 provided, then the first transport in the registry is used.
 
         Returns:
@@ -103,20 +97,16 @@
             return cls._transport_registry[label]
 
         # No transport is requested; return the default (that is, the first one
         # in the dictionary).
         return next(iter(cls._transport_registry.values()))
 
 
-class DataScanServiceClient(metaclass=DataScanServiceClientMeta):
-    """DataScanService manages DataScan resources which can be
-    configured to run various types of data scanning workload and
-    generate enriched metadata (e.g. Data Profile, Data Quality) for
-    the data source.
-    """
+class ContentServiceClient(metaclass=ContentServiceClientMeta):
+    """ContentService manages Notebook and SQL Scripts for Dataplex."""
 
     @staticmethod
     def _get_default_mtls_endpoint(api_endpoint):
         """Converts api endpoint to mTLS endpoint.
 
         Convert "*.sandbox.googleapis.com" and "*.googleapis.com" to
         "*.mtls.sandbox.googleapis.com" and "*.mtls.googleapis.com" respectively.
@@ -140,31 +130,35 @@
         if sandbox:
             return api_endpoint.replace(
                 "sandbox.googleapis.com", "mtls.sandbox.googleapis.com"
             )
 
         return api_endpoint.replace(".googleapis.com", ".mtls.googleapis.com")
 
+    # Note: DEFAULT_ENDPOINT is deprecated. Use _DEFAULT_ENDPOINT_TEMPLATE instead.
     DEFAULT_ENDPOINT = "dataplex.googleapis.com"
     DEFAULT_MTLS_ENDPOINT = _get_default_mtls_endpoint.__func__(  # type: ignore
         DEFAULT_ENDPOINT
     )
 
+    _DEFAULT_ENDPOINT_TEMPLATE = "dataplex.{UNIVERSE_DOMAIN}"
+    _DEFAULT_UNIVERSE = "googleapis.com"
+
     @classmethod
     def from_service_account_info(cls, info: dict, *args, **kwargs):
         """Creates an instance of this client using the provided credentials
             info.
 
         Args:
             info (dict): The service account private key info.
             args: Additional arguments to pass to the constructor.
             kwargs: Additional arguments to pass to the constructor.
 
         Returns:
-            DataScanServiceClient: The constructed client.
+            ContentServiceClient: The constructed client.
         """
         credentials = service_account.Credentials.from_service_account_info(info)
         kwargs["credentials"] = credentials
         return cls(*args, **kwargs)
 
     @classmethod
     def from_service_account_file(cls, filename: str, *args, **kwargs):
@@ -174,100 +168,74 @@
         Args:
             filename (str): The path to the service account private key json
                 file.
             args: Additional arguments to pass to the constructor.
             kwargs: Additional arguments to pass to the constructor.
 
         Returns:
-            DataScanServiceClient: The constructed client.
+            ContentServiceClient: The constructed client.
         """
         credentials = service_account.Credentials.from_service_account_file(filename)
         kwargs["credentials"] = credentials
         return cls(*args, **kwargs)
 
     from_service_account_json = from_service_account_file
 
     @property
-    def transport(self) -> DataScanServiceTransport:
+    def transport(self) -> ContentServiceTransport:
         """Returns the transport used by the client instance.
 
         Returns:
-            DataScanServiceTransport: The transport used by the client
+            ContentServiceTransport: The transport used by the client
                 instance.
         """
         return self._transport
 
     @staticmethod
-    def data_scan_path(
-        project: str,
-        location: str,
-        dataScan: str,
-    ) -> str:
-        """Returns a fully-qualified data_scan string."""
-        return "projects/{project}/locations/{location}/dataScans/{dataScan}".format(
-            project=project,
-            location=location,
-            dataScan=dataScan,
-        )
-
-    @staticmethod
-    def parse_data_scan_path(path: str) -> Dict[str, str]:
-        """Parses a data_scan path into its component segments."""
-        m = re.match(
-            r"^projects/(?P<project>.+?)/locations/(?P<location>.+?)/dataScans/(?P<dataScan>.+?)$",
-            path,
-        )
-        return m.groupdict() if m else {}
-
-    @staticmethod
-    def data_scan_job_path(
+    def content_path(
         project: str,
         location: str,
-        dataScan: str,
-        job: str,
+        lake: str,
+        content: str,
     ) -> str:
-        """Returns a fully-qualified data_scan_job string."""
-        return "projects/{project}/locations/{location}/dataScans/{dataScan}/jobs/{job}".format(
+        """Returns a fully-qualified content string."""
+        return "projects/{project}/locations/{location}/lakes/{lake}/content/{content}".format(
             project=project,
             location=location,
-            dataScan=dataScan,
-            job=job,
+            lake=lake,
+            content=content,
         )
 
     @staticmethod
-    def parse_data_scan_job_path(path: str) -> Dict[str, str]:
-        """Parses a data_scan_job path into its component segments."""
+    def parse_content_path(path: str) -> Dict[str, str]:
+        """Parses a content path into its component segments."""
         m = re.match(
-            r"^projects/(?P<project>.+?)/locations/(?P<location>.+?)/dataScans/(?P<dataScan>.+?)/jobs/(?P<job>.+?)$",
+            r"^projects/(?P<project>.+?)/locations/(?P<location>.+?)/lakes/(?P<lake>.+?)/content/(?P<content>.+?)$",
             path,
         )
         return m.groupdict() if m else {}
 
     @staticmethod
-    def entity_path(
+    def lake_path(
         project: str,
         location: str,
         lake: str,
-        zone: str,
-        entity: str,
     ) -> str:
-        """Returns a fully-qualified entity string."""
-        return "projects/{project}/locations/{location}/lakes/{lake}/zones/{zone}/entities/{entity}".format(
+        """Returns a fully-qualified lake string."""
+        return "projects/{project}/locations/{location}/lakes/{lake}".format(
             project=project,
             location=location,
             lake=lake,
-            zone=zone,
-            entity=entity,
         )
 
     @staticmethod
-    def parse_entity_path(path: str) -> Dict[str, str]:
-        """Parses a entity path into its component segments."""
+    def parse_lake_path(path: str) -> Dict[str, str]:
+        """Parses a lake path into its component segments."""
         m = re.match(
-            r"^projects/(?P<project>.+?)/locations/(?P<location>.+?)/lakes/(?P<lake>.+?)/zones/(?P<zone>.+?)/entities/(?P<entity>.+?)$",
+            r"^projects/(?P<project>.+?)/locations/(?P<location>.+?)/lakes/(?P<lake>.+?)$",
             path,
         )
         return m.groupdict() if m else {}
 
     @staticmethod
     def common_billing_account_path(
         billing_account: str,
@@ -345,15 +313,15 @@
         m = re.match(r"^projects/(?P<project>.+?)/locations/(?P<location>.+?)$", path)
         return m.groupdict() if m else {}
 
     @classmethod
     def get_mtls_endpoint_and_cert_source(
         cls, client_options: Optional[client_options_lib.ClientOptions] = None
     ):
-        """Return the API endpoint and client cert source for mutual TLS.
+        """Deprecated. Return the API endpoint and client cert source for mutual TLS.
 
         The client cert source is determined in the following order:
         (1) if `GOOGLE_API_USE_CLIENT_CERTIFICATE` environment variable is not "true", the
         client cert source is None.
         (2) if `client_options.client_cert_source` is provided, use the provided one; if the
         default client cert source exists, use the default one; otherwise the client cert
         source is None.
@@ -375,14 +343,19 @@
         Returns:
             Tuple[str, Callable[[], Tuple[bytes, bytes]]]: returns the API endpoint and the
                 client cert source to use.
 
         Raises:
             google.auth.exceptions.MutualTLSChannelError: If any errors happen.
         """
+
+        warnings.warn(
+            "get_mtls_endpoint_and_cert_source is deprecated. Use the api_endpoint property instead.",
+            DeprecationWarning,
+        )
         if client_options is None:
             client_options = client_options_lib.ClientOptions()
         use_client_cert = os.getenv("GOOGLE_API_USE_CLIENT_CERTIFICATE", "false")
         use_mtls_endpoint = os.getenv("GOOGLE_API_USE_MTLS_ENDPOINT", "auto")
         if use_client_cert not in ("true", "false"):
             raise ValueError(
                 "Environment variable `GOOGLE_API_USE_CLIENT_CERTIFICATE` must be either `true` or `false`"
@@ -408,1094 +381,1230 @@
         ):
             api_endpoint = cls.DEFAULT_MTLS_ENDPOINT
         else:
             api_endpoint = cls.DEFAULT_ENDPOINT
 
         return api_endpoint, client_cert_source
 
+    @staticmethod
+    def _read_environment_variables():
+        """Returns the environment variables used by the client.
+
+        Returns:
+            Tuple[bool, str, str]: returns the GOOGLE_API_USE_CLIENT_CERTIFICATE,
+            GOOGLE_API_USE_MTLS_ENDPOINT, and GOOGLE_CLOUD_UNIVERSE_DOMAIN environment variables.
+
+        Raises:
+            ValueError: If GOOGLE_API_USE_CLIENT_CERTIFICATE is not
+                any of ["true", "false"].
+            google.auth.exceptions.MutualTLSChannelError: If GOOGLE_API_USE_MTLS_ENDPOINT
+                is not any of ["auto", "never", "always"].
+        """
+        use_client_cert = os.getenv(
+            "GOOGLE_API_USE_CLIENT_CERTIFICATE", "false"
+        ).lower()
+        use_mtls_endpoint = os.getenv("GOOGLE_API_USE_MTLS_ENDPOINT", "auto").lower()
+        universe_domain_env = os.getenv("GOOGLE_CLOUD_UNIVERSE_DOMAIN")
+        if use_client_cert not in ("true", "false"):
+            raise ValueError(
+                "Environment variable `GOOGLE_API_USE_CLIENT_CERTIFICATE` must be either `true` or `false`"
+            )
+        if use_mtls_endpoint not in ("auto", "never", "always"):
+            raise MutualTLSChannelError(
+                "Environment variable `GOOGLE_API_USE_MTLS_ENDPOINT` must be `never`, `auto` or `always`"
+            )
+        return use_client_cert == "true", use_mtls_endpoint, universe_domain_env
+
+    @staticmethod
+    def _get_client_cert_source(provided_cert_source, use_cert_flag):
+        """Return the client cert source to be used by the client.
+
+        Args:
+            provided_cert_source (bytes): The client certificate source provided.
+            use_cert_flag (bool): A flag indicating whether to use the client certificate.
+
+        Returns:
+            bytes or None: The client cert source to be used by the client.
+        """
+        client_cert_source = None
+        if use_cert_flag:
+            if provided_cert_source:
+                client_cert_source = provided_cert_source
+            elif mtls.has_default_client_cert_source():
+                client_cert_source = mtls.default_client_cert_source()
+        return client_cert_source
+
+    @staticmethod
+    def _get_api_endpoint(
+        api_override, client_cert_source, universe_domain, use_mtls_endpoint
+    ):
+        """Return the API endpoint used by the client.
+
+        Args:
+            api_override (str): The API endpoint override. If specified, this is always
+                the return value of this function and the other arguments are not used.
+            client_cert_source (bytes): The client certificate source used by the client.
+            universe_domain (str): The universe domain used by the client.
+            use_mtls_endpoint (str): How to use the mTLS endpoint, which depends also on the other parameters.
+                Possible values are "always", "auto", or "never".
+
+        Returns:
+            str: The API endpoint to be used by the client.
+        """
+        if api_override is not None:
+            api_endpoint = api_override
+        elif use_mtls_endpoint == "always" or (
+            use_mtls_endpoint == "auto" and client_cert_source
+        ):
+            _default_universe = ContentServiceClient._DEFAULT_UNIVERSE
+            if universe_domain != _default_universe:
+                raise MutualTLSChannelError(
+                    f"mTLS is not supported in any universe other than {_default_universe}."
+                )
+            api_endpoint = ContentServiceClient.DEFAULT_MTLS_ENDPOINT
+        else:
+            api_endpoint = ContentServiceClient._DEFAULT_ENDPOINT_TEMPLATE.format(
+                UNIVERSE_DOMAIN=universe_domain
+            )
+        return api_endpoint
+
+    @staticmethod
+    def _get_universe_domain(
+        client_universe_domain: Optional[str], universe_domain_env: Optional[str]
+    ) -> str:
+        """Return the universe domain used by the client.
+
+        Args:
+            client_universe_domain (Optional[str]): The universe domain configured via the client options.
+            universe_domain_env (Optional[str]): The universe domain configured via the "GOOGLE_CLOUD_UNIVERSE_DOMAIN" environment variable.
+
+        Returns:
+            str: The universe domain to be used by the client.
+
+        Raises:
+            ValueError: If the universe domain is an empty string.
+        """
+        universe_domain = ContentServiceClient._DEFAULT_UNIVERSE
+        if client_universe_domain is not None:
+            universe_domain = client_universe_domain
+        elif universe_domain_env is not None:
+            universe_domain = universe_domain_env
+        if len(universe_domain.strip()) == 0:
+            raise ValueError("Universe Domain cannot be an empty string.")
+        return universe_domain
+
+    @staticmethod
+    def _compare_universes(
+        client_universe: str, credentials: ga_credentials.Credentials
+    ) -> bool:
+        """Returns True iff the universe domains used by the client and credentials match.
+
+        Args:
+            client_universe (str): The universe domain configured via the client options.
+            credentials (ga_credentials.Credentials): The credentials being used in the client.
+
+        Returns:
+            bool: True iff client_universe matches the universe in credentials.
+
+        Raises:
+            ValueError: when client_universe does not match the universe in credentials.
+        """
+
+        default_universe = ContentServiceClient._DEFAULT_UNIVERSE
+        credentials_universe = getattr(credentials, "universe_domain", default_universe)
+
+        if client_universe != credentials_universe:
+            raise ValueError(
+                "The configured universe domain "
+                f"({client_universe}) does not match the universe domain "
+                f"found in the credentials ({credentials_universe}). "
+                "If you haven't configured the universe domain explicitly, "
+                f"`{default_universe}` is the default."
+            )
+        return True
+
+    def _validate_universe_domain(self):
+        """Validates client's and credentials' universe domains are consistent.
+
+        Returns:
+            bool: True iff the configured universe domain is valid.
+
+        Raises:
+            ValueError: If the configured universe domain is not valid.
+        """
+        self._is_universe_domain_valid = (
+            self._is_universe_domain_valid
+            or ContentServiceClient._compare_universes(
+                self.universe_domain, self.transport._credentials
+            )
+        )
+        return self._is_universe_domain_valid
+
+    @property
+    def api_endpoint(self):
+        """Return the API endpoint used by the client instance.
+
+        Returns:
+            str: The API endpoint used by the client instance.
+        """
+        return self._api_endpoint
+
+    @property
+    def universe_domain(self) -> str:
+        """Return the universe domain used by the client instance.
+
+        Returns:
+            str: The universe domain used by the client instance.
+        """
+        return self._universe_domain
+
     def __init__(
         self,
         *,
         credentials: Optional[ga_credentials.Credentials] = None,
-        transport: Optional[Union[str, DataScanServiceTransport]] = None,
+        transport: Optional[
+            Union[str, ContentServiceTransport, Callable[..., ContentServiceTransport]]
+        ] = None,
         client_options: Optional[Union[client_options_lib.ClientOptions, dict]] = None,
         client_info: gapic_v1.client_info.ClientInfo = DEFAULT_CLIENT_INFO,
     ) -> None:
-        """Instantiates the data scan service client.
+        """Instantiates the content service client.
 
         Args:
             credentials (Optional[google.auth.credentials.Credentials]): The
                 authorization credentials to attach to requests. These
                 credentials identify the application to the service; if none
                 are specified, the client will attempt to ascertain the
                 credentials from the environment.
-            transport (Union[str, DataScanServiceTransport]): The
-                transport to use. If set to None, a transport is chosen
-                automatically.
-            client_options (Optional[Union[google.api_core.client_options.ClientOptions, dict]]): Custom options for the
-                client. It won't take effect if a ``transport`` instance is provided.
-                (1) The ``api_endpoint`` property can be used to override the
-                default endpoint provided by the client. GOOGLE_API_USE_MTLS_ENDPOINT
-                environment variable can also be used to override the endpoint:
+            transport (Optional[Union[str,ContentServiceTransport,Callable[..., ContentServiceTransport]]]):
+                The transport to use, or a Callable that constructs and returns a new transport.
+                If a Callable is given, it will be called with the same set of initialization
+                arguments as used in the ContentServiceTransport constructor.
+                If set to None, a transport is chosen automatically.
+            client_options (Optional[Union[google.api_core.client_options.ClientOptions, dict]]):
+                Custom options for the client.
+
+                1. The ``api_endpoint`` property can be used to override the
+                default endpoint provided by the client when ``transport`` is
+                not explicitly provided. Only if this property is not set and
+                ``transport`` was not explicitly provided, the endpoint is
+                determined by the GOOGLE_API_USE_MTLS_ENDPOINT environment
+                variable, which have one of the following values:
                 "always" (always use the default mTLS endpoint), "never" (always
-                use the default regular endpoint) and "auto" (auto switch to the
-                default mTLS endpoint if client certificate is present, this is
-                the default value). However, the ``api_endpoint`` property takes
-                precedence if provided.
-                (2) If GOOGLE_API_USE_CLIENT_CERTIFICATE environment variable
+                use the default regular endpoint) and "auto" (auto-switch to the
+                default mTLS endpoint if client certificate is present; this is
+                the default value).
+
+                2. If the GOOGLE_API_USE_CLIENT_CERTIFICATE environment variable
                 is "true", then the ``client_cert_source`` property can be used
-                to provide client certificate for mutual TLS transport. If
+                to provide a client certificate for mTLS transport. If
                 not provided, the default SSL client certificate will be used if
                 present. If GOOGLE_API_USE_CLIENT_CERTIFICATE is "false" or not
                 set, no client certificate will be used.
+
+                3. The ``universe_domain`` property can be used to override the
+                default "googleapis.com" universe. Note that the ``api_endpoint``
+                property still takes precedence; and ``universe_domain`` is
+                currently not supported for mTLS.
+
             client_info (google.api_core.gapic_v1.client_info.ClientInfo):
                 The client info used to send a user-agent string along with
                 API requests. If ``None``, then default info will be used.
                 Generally, you only need to set this if you're developing
                 your own client library.
 
         Raises:
             google.auth.exceptions.MutualTLSChannelError: If mutual TLS transport
                 creation failed for any reason.
         """
-        if isinstance(client_options, dict):
-            client_options = client_options_lib.from_dict(client_options)
-        if client_options is None:
-            client_options = client_options_lib.ClientOptions()
-        client_options = cast(client_options_lib.ClientOptions, client_options)
-
-        api_endpoint, client_cert_source_func = self.get_mtls_endpoint_and_cert_source(
-            client_options
+        self._client_options = client_options
+        if isinstance(self._client_options, dict):
+            self._client_options = client_options_lib.from_dict(self._client_options)
+        if self._client_options is None:
+            self._client_options = client_options_lib.ClientOptions()
+        self._client_options = cast(
+            client_options_lib.ClientOptions, self._client_options
+        )
+
+        universe_domain_opt = getattr(self._client_options, "universe_domain", None)
+
+        (
+            self._use_client_cert,
+            self._use_mtls_endpoint,
+            self._universe_domain_env,
+        ) = ContentServiceClient._read_environment_variables()
+        self._client_cert_source = ContentServiceClient._get_client_cert_source(
+            self._client_options.client_cert_source, self._use_client_cert
+        )
+        self._universe_domain = ContentServiceClient._get_universe_domain(
+            universe_domain_opt, self._universe_domain_env
         )
+        self._api_endpoint = None  # updated below, depending on `transport`
+
+        # Initialize the universe domain validation.
+        self._is_universe_domain_valid = False
 
-        api_key_value = getattr(client_options, "api_key", None)
+        api_key_value = getattr(self._client_options, "api_key", None)
         if api_key_value and credentials:
             raise ValueError(
                 "client_options.api_key and credentials are mutually exclusive"
             )
 
         # Save or instantiate the transport.
         # Ordinarily, we provide the transport, but allowing a custom transport
         # instance provides an extensibility point for unusual situations.
-        if isinstance(transport, DataScanServiceTransport):
-            # transport is a DataScanServiceTransport instance.
-            if credentials or client_options.credentials_file or api_key_value:
+        transport_provided = isinstance(transport, ContentServiceTransport)
+        if transport_provided:
+            # transport is a ContentServiceTransport instance.
+            if credentials or self._client_options.credentials_file or api_key_value:
                 raise ValueError(
                     "When providing a transport instance, "
                     "provide its credentials directly."
                 )
-            if client_options.scopes:
+            if self._client_options.scopes:
                 raise ValueError(
                     "When providing a transport instance, provide its scopes "
                     "directly."
                 )
-            self._transport = transport
-        else:
+            self._transport = cast(ContentServiceTransport, transport)
+            self._api_endpoint = self._transport.host
+
+        self._api_endpoint = (
+            self._api_endpoint
+            or ContentServiceClient._get_api_endpoint(
+                self._client_options.api_endpoint,
+                self._client_cert_source,
+                self._universe_domain,
+                self._use_mtls_endpoint,
+            )
+        )
+
+        if not transport_provided:
             import google.auth._default  # type: ignore
 
             if api_key_value and hasattr(
                 google.auth._default, "get_api_key_credentials"
             ):
                 credentials = google.auth._default.get_api_key_credentials(
                     api_key_value
                 )
 
-            Transport = type(self).get_transport_class(transport)
-            self._transport = Transport(
+            transport_init: Union[
+                Type[ContentServiceTransport], Callable[..., ContentServiceTransport]
+            ] = (
+                type(self).get_transport_class(transport)
+                if isinstance(transport, str) or transport is None
+                else cast(Callable[..., ContentServiceTransport], transport)
+            )
+            # initialize with the provided callable or the passed in class
+            self._transport = transport_init(
                 credentials=credentials,
-                credentials_file=client_options.credentials_file,
-                host=api_endpoint,
-                scopes=client_options.scopes,
-                client_cert_source_for_mtls=client_cert_source_func,
-                quota_project_id=client_options.quota_project_id,
+                credentials_file=self._client_options.credentials_file,
+                host=self._api_endpoint,
+                scopes=self._client_options.scopes,
+                client_cert_source_for_mtls=self._client_cert_source,
+                quota_project_id=self._client_options.quota_project_id,
                 client_info=client_info,
                 always_use_jwt_access=True,
-                api_audience=client_options.api_audience,
+                api_audience=self._client_options.api_audience,
             )
 
-    def create_data_scan(
+    def create_content(
         self,
-        request: Optional[Union[datascans.CreateDataScanRequest, dict]] = None,
+        request: Optional[Union[gcd_content.CreateContentRequest, dict]] = None,
         *,
         parent: Optional[str] = None,
-        data_scan: Optional[datascans.DataScan] = None,
-        data_scan_id: Optional[str] = None,
+        content: Optional[analyze.Content] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
-    ) -> operation.Operation:
-        r"""Creates a DataScan resource.
+    ) -> analyze.Content:
+        r"""Create a content.
 
         .. code-block:: python
 
             # This snippet has been automatically generated and should be regarded as a
             # code template only.
             # It will require modifications to work:
             # - It may require correct/in-range values for request initialization.
             # - It may require specifying regional endpoints when creating the service
             #   client as shown in:
             #   https://googleapis.dev/python/google-api-core/latest/client_options.html
             from google.cloud import dataplex_v1
 
-            def sample_create_data_scan():
+            def sample_create_content():
                 # Create a client
-                client = dataplex_v1.DataScanServiceClient()
+                client = dataplex_v1.ContentServiceClient()
 
                 # Initialize request argument(s)
-                data_scan = dataplex_v1.DataScan()
-                data_scan.data_quality_spec.rules.dimension = "dimension_value"
-                data_scan.data.entity = "entity_value"
+                content = dataplex_v1.Content()
+                content.data_text = "data_text_value"
+                content.sql_script.engine = "SPARK"
+                content.path = "path_value"
 
-                request = dataplex_v1.CreateDataScanRequest(
+                request = dataplex_v1.CreateContentRequest(
                     parent="parent_value",
-                    data_scan=data_scan,
-                    data_scan_id="data_scan_id_value",
+                    content=content,
                 )
 
                 # Make the request
-                operation = client.create_data_scan(request=request)
-
-                print("Waiting for operation to complete...")
-
-                response = operation.result()
+                response = client.create_content(request=request)
 
                 # Handle the response
                 print(response)
 
         Args:
-            request (Union[google.cloud.dataplex_v1.types.CreateDataScanRequest, dict]):
-                The request object. Create dataScan request.
+            request (Union[google.cloud.dataplex_v1.types.CreateContentRequest, dict]):
+                The request object. Create content request.
             parent (str):
-                Required. The resource name of the parent location:
-                ``projects/{project}/locations/{location_id}`` where
-                ``project`` refers to a *project_id* or *project_number*
-                and ``location_id`` refers to a GCP region.
+                Required. The resource name of the parent lake:
+                projects/{project_id}/locations/{location_id}/lakes/{lake_id}
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            data_scan (google.cloud.dataplex_v1.types.DataScan):
-                Required. DataScan resource.
-                This corresponds to the ``data_scan`` field
-                on the ``request`` instance; if ``request`` is provided, this
-                should not be set.
-            data_scan_id (str):
-                Required. DataScan identifier.
-
-                -  Must contain only lowercase letters, numbers and
-                   hyphens.
-                -  Must start with a letter.
-                -  Must end with a number or a letter.
-                -  Must be between 1-63 characters.
-                -  Must be unique within the customer project /
-                   location.
-
-                This corresponds to the ``data_scan_id`` field
+            content (google.cloud.dataplex_v1.types.Content):
+                Required. Content resource.
+                This corresponds to the ``content`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             retry (google.api_core.retry.Retry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
-            google.api_core.operation.Operation:
-                An object representing a long-running operation.
-
-                The result type for the operation will be :class:`google.cloud.dataplex_v1.types.DataScan` Represents a user-visible job which provides the insights for the related
-                   data source.
-
-                   For example:
-
-                   -  Data Quality: generates queries based on the rules
-                      and runs against the data to get data quality
-                      check results.
-                   -  Data Profile: analyzes the data in table(s) and
-                      generates insights about the structure, content
-                      and relationships (such as null percent,
-                      cardinality, min/max/mean, etc).
+            google.cloud.dataplex_v1.types.Content:
+                Content represents a user-visible
+                notebook or a sql script
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
-        has_flattened_params = any([parent, data_scan, data_scan_id])
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
+        has_flattened_params = any([parent, content])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a datascans.CreateDataScanRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
-        if not isinstance(request, datascans.CreateDataScanRequest):
-            request = datascans.CreateDataScanRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, gcd_content.CreateContentRequest):
+            request = gcd_content.CreateContentRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if parent is not None:
                 request.parent = parent
-            if data_scan is not None:
-                request.data_scan = data_scan
-            if data_scan_id is not None:
-                request.data_scan_id = data_scan_id
+            if content is not None:
+                request.content = content
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = self._transport._wrapped_methods[self._transport.create_data_scan]
+        rpc = self._transport._wrapped_methods[self._transport.create_content]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
-        # Wrap the response in an operation future.
-        response = operation.from_gapic(
-            response,
-            self._transport.operations_client,
-            datascans.DataScan,
-            metadata_type=service.OperationMetadata,
-        )
-
         # Done; return the response.
         return response
 
-    def update_data_scan(
+    def update_content(
         self,
-        request: Optional[Union[datascans.UpdateDataScanRequest, dict]] = None,
+        request: Optional[Union[gcd_content.UpdateContentRequest, dict]] = None,
         *,
-        data_scan: Optional[datascans.DataScan] = None,
+        content: Optional[analyze.Content] = None,
         update_mask: Optional[field_mask_pb2.FieldMask] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
-    ) -> operation.Operation:
-        r"""Updates a DataScan resource.
+    ) -> analyze.Content:
+        r"""Update a content. Only supports full resource update.
 
         .. code-block:: python
 
             # This snippet has been automatically generated and should be regarded as a
             # code template only.
             # It will require modifications to work:
             # - It may require correct/in-range values for request initialization.
             # - It may require specifying regional endpoints when creating the service
             #   client as shown in:
             #   https://googleapis.dev/python/google-api-core/latest/client_options.html
             from google.cloud import dataplex_v1
 
-            def sample_update_data_scan():
+            def sample_update_content():
                 # Create a client
-                client = dataplex_v1.DataScanServiceClient()
+                client = dataplex_v1.ContentServiceClient()
 
                 # Initialize request argument(s)
-                data_scan = dataplex_v1.DataScan()
-                data_scan.data_quality_spec.rules.dimension = "dimension_value"
-                data_scan.data.entity = "entity_value"
+                content = dataplex_v1.Content()
+                content.data_text = "data_text_value"
+                content.sql_script.engine = "SPARK"
+                content.path = "path_value"
 
-                request = dataplex_v1.UpdateDataScanRequest(
-                    data_scan=data_scan,
+                request = dataplex_v1.UpdateContentRequest(
+                    content=content,
                 )
 
                 # Make the request
-                operation = client.update_data_scan(request=request)
-
-                print("Waiting for operation to complete...")
-
-                response = operation.result()
+                response = client.update_content(request=request)
 
                 # Handle the response
                 print(response)
 
         Args:
-            request (Union[google.cloud.dataplex_v1.types.UpdateDataScanRequest, dict]):
-                The request object. Update dataScan request.
-            data_scan (google.cloud.dataplex_v1.types.DataScan):
-                Required. DataScan resource to be updated.
+            request (Union[google.cloud.dataplex_v1.types.UpdateContentRequest, dict]):
+                The request object. Update content request.
+            content (google.cloud.dataplex_v1.types.Content):
+                Required. Update description. Only fields specified in
+                ``update_mask`` are updated.
 
-                Only fields specified in ``update_mask`` are updated.
-
-                This corresponds to the ``data_scan`` field
+                This corresponds to the ``content`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             update_mask (google.protobuf.field_mask_pb2.FieldMask):
                 Required. Mask of fields to update.
                 This corresponds to the ``update_mask`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             retry (google.api_core.retry.Retry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
-            google.api_core.operation.Operation:
-                An object representing a long-running operation.
-
-                The result type for the operation will be :class:`google.cloud.dataplex_v1.types.DataScan` Represents a user-visible job which provides the insights for the related
-                   data source.
-
-                   For example:
-
-                   -  Data Quality: generates queries based on the rules
-                      and runs against the data to get data quality
-                      check results.
-                   -  Data Profile: analyzes the data in table(s) and
-                      generates insights about the structure, content
-                      and relationships (such as null percent,
-                      cardinality, min/max/mean, etc).
+            google.cloud.dataplex_v1.types.Content:
+                Content represents a user-visible
+                notebook or a sql script
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
-        has_flattened_params = any([data_scan, update_mask])
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
+        has_flattened_params = any([content, update_mask])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a datascans.UpdateDataScanRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
-        if not isinstance(request, datascans.UpdateDataScanRequest):
-            request = datascans.UpdateDataScanRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, gcd_content.UpdateContentRequest):
+            request = gcd_content.UpdateContentRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
-            if data_scan is not None:
-                request.data_scan = data_scan
+            if content is not None:
+                request.content = content
             if update_mask is not None:
                 request.update_mask = update_mask
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = self._transport._wrapped_methods[self._transport.update_data_scan]
+        rpc = self._transport._wrapped_methods[self._transport.update_content]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata(
-                (("data_scan.name", request.data_scan.name),)
+                (("content.name", request.content.name),)
             ),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
-        # Wrap the response in an operation future.
-        response = operation.from_gapic(
-            response,
-            self._transport.operations_client,
-            datascans.DataScan,
-            metadata_type=service.OperationMetadata,
-        )
-
         # Done; return the response.
         return response
 
-    def delete_data_scan(
+    def delete_content(
         self,
-        request: Optional[Union[datascans.DeleteDataScanRequest, dict]] = None,
+        request: Optional[Union[content.DeleteContentRequest, dict]] = None,
         *,
         name: Optional[str] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
-    ) -> operation.Operation:
-        r"""Deletes a DataScan resource.
+    ) -> None:
+        r"""Delete a content.
 
         .. code-block:: python
 
             # This snippet has been automatically generated and should be regarded as a
             # code template only.
             # It will require modifications to work:
             # - It may require correct/in-range values for request initialization.
             # - It may require specifying regional endpoints when creating the service
             #   client as shown in:
             #   https://googleapis.dev/python/google-api-core/latest/client_options.html
             from google.cloud import dataplex_v1
 
-            def sample_delete_data_scan():
+            def sample_delete_content():
                 # Create a client
-                client = dataplex_v1.DataScanServiceClient()
+                client = dataplex_v1.ContentServiceClient()
 
                 # Initialize request argument(s)
-                request = dataplex_v1.DeleteDataScanRequest(
+                request = dataplex_v1.DeleteContentRequest(
                     name="name_value",
                 )
 
                 # Make the request
-                operation = client.delete_data_scan(request=request)
-
-                print("Waiting for operation to complete...")
-
-                response = operation.result()
-
-                # Handle the response
-                print(response)
+                client.delete_content(request=request)
 
         Args:
-            request (Union[google.cloud.dataplex_v1.types.DeleteDataScanRequest, dict]):
-                The request object. Delete dataScan request.
+            request (Union[google.cloud.dataplex_v1.types.DeleteContentRequest, dict]):
+                The request object. Delete content request.
             name (str):
-                Required. The resource name of the dataScan:
-                ``projects/{project}/locations/{location_id}/dataScans/{data_scan_id}``
-                where ``project`` refers to a *project_id* or
-                *project_number* and ``location_id`` refers to a GCP
-                region.
+                Required. The resource name of the content:
+                projects/{project_id}/locations/{location_id}/lakes/{lake_id}/content/{content_id}
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             retry (google.api_core.retry.Retry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
-
-        Returns:
-            google.api_core.operation.Operation:
-                An object representing a long-running operation.
-
-                The result type for the operation will be :class:`google.protobuf.empty_pb2.Empty` A generic empty message that you can re-use to avoid defining duplicated
-                   empty messages in your APIs. A typical example is to
-                   use it as the request or the response type of an API
-                   method. For instance:
-
-                      service Foo {
-                         rpc Bar(google.protobuf.Empty) returns
-                         (google.protobuf.Empty);
-
-                      }
-
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a datascans.DeleteDataScanRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
-        if not isinstance(request, datascans.DeleteDataScanRequest):
-            request = datascans.DeleteDataScanRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, content.DeleteContentRequest):
+            request = content.DeleteContentRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if name is not None:
                 request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = self._transport._wrapped_methods[self._transport.delete_data_scan]
+        rpc = self._transport._wrapped_methods[self._transport.delete_content]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
-        response = rpc(
+        rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
-        # Wrap the response in an operation future.
-        response = operation.from_gapic(
-            response,
-            self._transport.operations_client,
-            empty_pb2.Empty,
-            metadata_type=service.OperationMetadata,
-        )
-
-        # Done; return the response.
-        return response
-
-    def get_data_scan(
+    def get_content(
         self,
-        request: Optional[Union[datascans.GetDataScanRequest, dict]] = None,
+        request: Optional[Union[content.GetContentRequest, dict]] = None,
         *,
         name: Optional[str] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
-    ) -> datascans.DataScan:
-        r"""Gets a DataScan resource.
+    ) -> analyze.Content:
+        r"""Get a content resource.
 
         .. code-block:: python
 
             # This snippet has been automatically generated and should be regarded as a
             # code template only.
             # It will require modifications to work:
             # - It may require correct/in-range values for request initialization.
             # - It may require specifying regional endpoints when creating the service
             #   client as shown in:
             #   https://googleapis.dev/python/google-api-core/latest/client_options.html
             from google.cloud import dataplex_v1
 
-            def sample_get_data_scan():
+            def sample_get_content():
                 # Create a client
-                client = dataplex_v1.DataScanServiceClient()
+                client = dataplex_v1.ContentServiceClient()
 
                 # Initialize request argument(s)
-                request = dataplex_v1.GetDataScanRequest(
+                request = dataplex_v1.GetContentRequest(
                     name="name_value",
                 )
 
                 # Make the request
-                response = client.get_data_scan(request=request)
+                response = client.get_content(request=request)
 
                 # Handle the response
                 print(response)
 
         Args:
-            request (Union[google.cloud.dataplex_v1.types.GetDataScanRequest, dict]):
-                The request object. Get dataScan request.
+            request (Union[google.cloud.dataplex_v1.types.GetContentRequest, dict]):
+                The request object. Get content request.
             name (str):
-                Required. The resource name of the dataScan:
-                ``projects/{project}/locations/{location_id}/dataScans/{data_scan_id}``
-                where ``project`` refers to a *project_id* or
-                *project_number* and ``location_id`` refers to a GCP
-                region.
+                Required. The resource name of the content:
+                projects/{project_id}/locations/{location_id}/lakes/{lake_id}/content/{content_id}
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             retry (google.api_core.retry.Retry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
-            google.cloud.dataplex_v1.types.DataScan:
-                Represents a user-visible job which provides the insights for the related
-                   data source.
-
-                   For example:
-
-                   -  Data Quality: generates queries based on the rules
-                      and runs against the data to get data quality
-                      check results.
-                   -  Data Profile: analyzes the data in table(s) and
-                      generates insights about the structure, content
-                      and relationships (such as null percent,
-                      cardinality, min/max/mean, etc).
+            google.cloud.dataplex_v1.types.Content:
+                Content represents a user-visible
+                notebook or a sql script
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a datascans.GetDataScanRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
-        if not isinstance(request, datascans.GetDataScanRequest):
-            request = datascans.GetDataScanRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, content.GetContentRequest):
+            request = content.GetContentRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if name is not None:
                 request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = self._transport._wrapped_methods[self._transport.get_data_scan]
+        rpc = self._transport._wrapped_methods[self._transport.get_content]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
-    def list_data_scans(
+    def get_iam_policy(
         self,
-        request: Optional[Union[datascans.ListDataScansRequest, dict]] = None,
+        request: Optional[Union[iam_policy_pb2.GetIamPolicyRequest, dict]] = None,
         *,
-        parent: Optional[str] = None,
+        resource: Optional[str] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
-    ) -> pagers.ListDataScansPager:
-        r"""Lists DataScans.
+    ) -> policy_pb2.Policy:
+        r"""Gets the access control policy for a contentitem resource. A
+        ``NOT_FOUND`` error is returned if the resource does not exist.
+        An empty policy is returned if the resource exists but does not
+        have a policy set on it.
+
+        Caller must have Google IAM ``dataplex.content.getIamPolicy``
+        permission on the resource.
 
         .. code-block:: python
 
             # This snippet has been automatically generated and should be regarded as a
             # code template only.
             # It will require modifications to work:
             # - It may require correct/in-range values for request initialization.
             # - It may require specifying regional endpoints when creating the service
             #   client as shown in:
             #   https://googleapis.dev/python/google-api-core/latest/client_options.html
             from google.cloud import dataplex_v1
+            from google.iam.v1 import iam_policy_pb2  # type: ignore
 
-            def sample_list_data_scans():
+            def sample_get_iam_policy():
                 # Create a client
-                client = dataplex_v1.DataScanServiceClient()
+                client = dataplex_v1.ContentServiceClient()
 
                 # Initialize request argument(s)
-                request = dataplex_v1.ListDataScansRequest(
-                    parent="parent_value",
+                request = iam_policy_pb2.GetIamPolicyRequest(
+                    resource="resource_value",
                 )
 
                 # Make the request
-                page_result = client.list_data_scans(request=request)
+                response = client.get_iam_policy(request=request)
 
                 # Handle the response
-                for response in page_result:
-                    print(response)
+                print(response)
 
         Args:
-            request (Union[google.cloud.dataplex_v1.types.ListDataScansRequest, dict]):
-                The request object. List dataScans request.
-            parent (str):
-                Required. The resource name of the parent location:
-                ``projects/{project}/locations/{location_id}`` where
-                ``project`` refers to a *project_id* or *project_number*
-                and ``location_id`` refers to a GCP region.
+            request (Union[google.iam.v1.iam_policy_pb2.GetIamPolicyRequest, dict]):
+                The request object. Request message for ``GetIamPolicy`` method.
+            resource (str):
+                REQUIRED: The resource for which the
+                policy is being requested. See the
+                operation documentation for the
+                appropriate value for this field.
 
-                This corresponds to the ``parent`` field
+                This corresponds to the ``resource`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             retry (google.api_core.retry.Retry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
-            google.cloud.dataplex_v1.services.data_scan_service.pagers.ListDataScansPager:
-                List dataScans response.
-
-                Iterating over this object will yield
-                results and resolve additional pages
-                automatically.
+            google.iam.v1.policy_pb2.Policy:
+                An Identity and Access Management (IAM) policy, which specifies access
+                   controls for Google Cloud resources.
+
+                   A Policy is a collection of bindings. A binding binds
+                   one or more members, or principals, to a single role.
+                   Principals can be user accounts, service accounts,
+                   Google groups, and domains (such as G Suite). A role
+                   is a named list of permissions; each role can be an
+                   IAM predefined role or a user-created custom role.
+
+                   For some types of Google Cloud resources, a binding
+                   can also specify a condition, which is a logical
+                   expression that allows access to a resource only if
+                   the expression evaluates to true. A condition can add
+                   constraints based on attributes of the request, the
+                   resource, or both. To learn which resources support
+                   conditions in their IAM policies, see the [IAM
+                   documentation](\ https://cloud.google.com/iam/help/conditions/resource-policies).
+
+                   **JSON example:**
+
+                   :literal:`\`     {       "bindings": [         {           "role": "roles/resourcemanager.organizationAdmin",           "members": [             "user:mike@example.com",             "group:admins@example.com",             "domain:google.com",             "serviceAccount:my-project-id@appspot.gserviceaccount.com"           ]         },         {           "role": "roles/resourcemanager.organizationViewer",           "members": [             "user:eve@example.com"           ],           "condition": {             "title": "expirable access",             "description": "Does not grant access after Sep 2020",             "expression": "request.time <             timestamp('2020-10-01T00:00:00.000Z')",           }         }       ],       "etag": "BwWWja0YfJA=",       "version": 3     }`\ \`
+
+                   **YAML example:**
+
+                   :literal:`\`     bindings:     - members:       - user:mike@example.com       - group:admins@example.com       - domain:google.com       - serviceAccount:my-project-id@appspot.gserviceaccount.com       role: roles/resourcemanager.organizationAdmin     - members:       - user:eve@example.com       role: roles/resourcemanager.organizationViewer       condition:         title: expirable access         description: Does not grant access after Sep 2020         expression: request.time < timestamp('2020-10-01T00:00:00.000Z')     etag: BwWWja0YfJA=     version: 3`\ \`
+
+                   For a description of IAM and its features, see the
+                   [IAM
+                   documentation](\ https://cloud.google.com/iam/docs/).
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
-        has_flattened_params = any([parent])
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
+        has_flattened_params = any([resource])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a datascans.ListDataScansRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
-        if not isinstance(request, datascans.ListDataScansRequest):
-            request = datascans.ListDataScansRequest(request)
-            # If we have keyword arguments corresponding to fields on the
-            # request, apply these.
-            if parent is not None:
-                request.parent = parent
+        if isinstance(request, dict):
+            # - The request isn't a proto-plus wrapped type,
+            #   so it must be constructed via keyword expansion.
+            request = iam_policy_pb2.GetIamPolicyRequest(**request)
+        elif not request:
+            # Null request, just make one.
+            request = iam_policy_pb2.GetIamPolicyRequest()
+            if resource is not None:
+                request.resource = resource
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = self._transport._wrapped_methods[self._transport.list_data_scans]
+        rpc = self._transport._wrapped_methods[self._transport.get_iam_policy]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
-            gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
+            gapic_v1.routing_header.to_grpc_metadata((("resource", request.resource),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
-        # This method is paged; wrap the response in a pager, which provides
-        # an `__iter__` convenience method.
-        response = pagers.ListDataScansPager(
-            method=rpc,
-            request=request,
-            response=response,
-            metadata=metadata,
-        )
-
         # Done; return the response.
         return response
 
-    def run_data_scan(
+    def set_iam_policy(
         self,
-        request: Optional[Union[datascans.RunDataScanRequest, dict]] = None,
+        request: Optional[Union[iam_policy_pb2.SetIamPolicyRequest, dict]] = None,
         *,
-        name: Optional[str] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
-    ) -> datascans.RunDataScanResponse:
-        r"""Runs an on-demand execution of a DataScan
+    ) -> policy_pb2.Policy:
+        r"""Sets the access control policy on the specified contentitem
+        resource. Replaces any existing policy.
+
+        Caller must have Google IAM ``dataplex.content.setIamPolicy``
+        permission on the resource.
 
         .. code-block:: python
 
             # This snippet has been automatically generated and should be regarded as a
             # code template only.
             # It will require modifications to work:
             # - It may require correct/in-range values for request initialization.
             # - It may require specifying regional endpoints when creating the service
             #   client as shown in:
             #   https://googleapis.dev/python/google-api-core/latest/client_options.html
             from google.cloud import dataplex_v1
+            from google.iam.v1 import iam_policy_pb2  # type: ignore
 
-            def sample_run_data_scan():
+            def sample_set_iam_policy():
                 # Create a client
-                client = dataplex_v1.DataScanServiceClient()
+                client = dataplex_v1.ContentServiceClient()
 
                 # Initialize request argument(s)
-                request = dataplex_v1.RunDataScanRequest(
-                    name="name_value",
+                request = iam_policy_pb2.SetIamPolicyRequest(
+                    resource="resource_value",
                 )
 
                 # Make the request
-                response = client.run_data_scan(request=request)
+                response = client.set_iam_policy(request=request)
 
                 # Handle the response
                 print(response)
 
         Args:
-            request (Union[google.cloud.dataplex_v1.types.RunDataScanRequest, dict]):
-                The request object. Run DataScan Request
-            name (str):
-                Required. The resource name of the DataScan:
-                ``projects/{project}/locations/{location_id}/dataScans/{data_scan_id}``.
-                where ``project`` refers to a *project_id* or
-                *project_number* and ``location_id`` refers to a GCP
-                region.
-
-                Only **OnDemand** data scans are allowed.
-
-                This corresponds to the ``name`` field
-                on the ``request`` instance; if ``request`` is provided, this
-                should not be set.
+            request (Union[google.iam.v1.iam_policy_pb2.SetIamPolicyRequest, dict]):
+                The request object. Request message for ``SetIamPolicy`` method.
             retry (google.api_core.retry.Retry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
-            google.cloud.dataplex_v1.types.RunDataScanResponse:
-                Run DataScan Response.
+            google.iam.v1.policy_pb2.Policy:
+                An Identity and Access Management (IAM) policy, which specifies access
+                   controls for Google Cloud resources.
+
+                   A Policy is a collection of bindings. A binding binds
+                   one or more members, or principals, to a single role.
+                   Principals can be user accounts, service accounts,
+                   Google groups, and domains (such as G Suite). A role
+                   is a named list of permissions; each role can be an
+                   IAM predefined role or a user-created custom role.
+
+                   For some types of Google Cloud resources, a binding
+                   can also specify a condition, which is a logical
+                   expression that allows access to a resource only if
+                   the expression evaluates to true. A condition can add
+                   constraints based on attributes of the request, the
+                   resource, or both. To learn which resources support
+                   conditions in their IAM policies, see the [IAM
+                   documentation](\ https://cloud.google.com/iam/help/conditions/resource-policies).
+
+                   **JSON example:**
+
+                   :literal:`\`     {       "bindings": [         {           "role": "roles/resourcemanager.organizationAdmin",           "members": [             "user:mike@example.com",             "group:admins@example.com",             "domain:google.com",             "serviceAccount:my-project-id@appspot.gserviceaccount.com"           ]         },         {           "role": "roles/resourcemanager.organizationViewer",           "members": [             "user:eve@example.com"           ],           "condition": {             "title": "expirable access",             "description": "Does not grant access after Sep 2020",             "expression": "request.time <             timestamp('2020-10-01T00:00:00.000Z')",           }         }       ],       "etag": "BwWWja0YfJA=",       "version": 3     }`\ \`
+
+                   **YAML example:**
+
+                   :literal:`\`     bindings:     - members:       - user:mike@example.com       - group:admins@example.com       - domain:google.com       - serviceAccount:my-project-id@appspot.gserviceaccount.com       role: roles/resourcemanager.organizationAdmin     - members:       - user:eve@example.com       role: roles/resourcemanager.organizationViewer       condition:         title: expirable access         description: Does not grant access after Sep 2020         expression: request.time < timestamp('2020-10-01T00:00:00.000Z')     etag: BwWWja0YfJA=     version: 3`\ \`
+
+                   For a description of IAM and its features, see the
+                   [IAM
+                   documentation](\ https://cloud.google.com/iam/docs/).
+
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
-        has_flattened_params = any([name])
-        if request is not None and has_flattened_params:
-            raise ValueError(
-                "If the `request` argument is set, then none of "
-                "the individual field arguments should be set."
-            )
-
-        # Minor optimization to avoid making a copy if the user passes
-        # in a datascans.RunDataScanRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
-        if not isinstance(request, datascans.RunDataScanRequest):
-            request = datascans.RunDataScanRequest(request)
-            # If we have keyword arguments corresponding to fields on the
-            # request, apply these.
-            if name is not None:
-                request.name = name
+        if isinstance(request, dict):
+            # - The request isn't a proto-plus wrapped type,
+            #   so it must be constructed via keyword expansion.
+            request = iam_policy_pb2.SetIamPolicyRequest(**request)
+        elif not request:
+            # Null request, just make one.
+            request = iam_policy_pb2.SetIamPolicyRequest()
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = self._transport._wrapped_methods[self._transport.run_data_scan]
+        rpc = self._transport._wrapped_methods[self._transport.set_iam_policy]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
-            gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
+            gapic_v1.routing_header.to_grpc_metadata((("resource", request.resource),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
-    def get_data_scan_job(
+    def test_iam_permissions(
         self,
-        request: Optional[Union[datascans.GetDataScanJobRequest, dict]] = None,
+        request: Optional[Union[iam_policy_pb2.TestIamPermissionsRequest, dict]] = None,
         *,
-        name: Optional[str] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
-    ) -> datascans.DataScanJob:
-        r"""Gets a DataScanJob resource.
+    ) -> iam_policy_pb2.TestIamPermissionsResponse:
+        r"""Returns the caller's permissions on a resource. If the resource
+        does not exist, an empty set of permissions is returned (a
+        ``NOT_FOUND`` error is not returned).
+
+        A caller is not required to have Google IAM permission to make
+        this request.
+
+        Note: This operation is designed to be used for building
+        permission-aware UIs and command-line tools, not for
+        authorization checking. This operation may "fail open" without
+        warning.
 
         .. code-block:: python
 
             # This snippet has been automatically generated and should be regarded as a
             # code template only.
             # It will require modifications to work:
             # - It may require correct/in-range values for request initialization.
             # - It may require specifying regional endpoints when creating the service
             #   client as shown in:
             #   https://googleapis.dev/python/google-api-core/latest/client_options.html
             from google.cloud import dataplex_v1
+            from google.iam.v1 import iam_policy_pb2  # type: ignore
 
-            def sample_get_data_scan_job():
+            def sample_test_iam_permissions():
                 # Create a client
-                client = dataplex_v1.DataScanServiceClient()
+                client = dataplex_v1.ContentServiceClient()
 
                 # Initialize request argument(s)
-                request = dataplex_v1.GetDataScanJobRequest(
-                    name="name_value",
+                request = iam_policy_pb2.TestIamPermissionsRequest(
+                    resource="resource_value",
+                    permissions=['permissions_value1', 'permissions_value2'],
                 )
 
                 # Make the request
-                response = client.get_data_scan_job(request=request)
+                response = client.test_iam_permissions(request=request)
 
                 # Handle the response
                 print(response)
 
         Args:
-            request (Union[google.cloud.dataplex_v1.types.GetDataScanJobRequest, dict]):
-                The request object. Get DataScanJob request.
-            name (str):
-                Required. The resource name of the DataScanJob:
-                ``projects/{project}/locations/{location_id}/dataScans/{data_scan_id}/jobs/{data_scan_job_id}``
-                where ``project`` refers to a *project_id* or
-                *project_number* and ``location_id`` refers to a GCP
-                region.
-
-                This corresponds to the ``name`` field
-                on the ``request`` instance; if ``request`` is provided, this
-                should not be set.
+            request (Union[google.iam.v1.iam_policy_pb2.TestIamPermissionsRequest, dict]):
+                The request object. Request message for ``TestIamPermissions`` method.
             retry (google.api_core.retry.Retry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
-            google.cloud.dataplex_v1.types.DataScanJob:
-                A DataScanJob represents an instance
-                of DataScan execution.
-
+            google.iam.v1.iam_policy_pb2.TestIamPermissionsResponse:
+                Response message for TestIamPermissions method.
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
-        has_flattened_params = any([name])
-        if request is not None and has_flattened_params:
-            raise ValueError(
-                "If the `request` argument is set, then none of "
-                "the individual field arguments should be set."
-            )
-
-        # Minor optimization to avoid making a copy if the user passes
-        # in a datascans.GetDataScanJobRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
-        if not isinstance(request, datascans.GetDataScanJobRequest):
-            request = datascans.GetDataScanJobRequest(request)
-            # If we have keyword arguments corresponding to fields on the
-            # request, apply these.
-            if name is not None:
-                request.name = name
+        if isinstance(request, dict):
+            # - The request isn't a proto-plus wrapped type,
+            #   so it must be constructed via keyword expansion.
+            request = iam_policy_pb2.TestIamPermissionsRequest(**request)
+        elif not request:
+            # Null request, just make one.
+            request = iam_policy_pb2.TestIamPermissionsRequest()
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = self._transport._wrapped_methods[self._transport.get_data_scan_job]
+        rpc = self._transport._wrapped_methods[self._transport.test_iam_permissions]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
-            gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
+            gapic_v1.routing_header.to_grpc_metadata((("resource", request.resource),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
-    def list_data_scan_jobs(
+    def list_content(
         self,
-        request: Optional[Union[datascans.ListDataScanJobsRequest, dict]] = None,
+        request: Optional[Union[content.ListContentRequest, dict]] = None,
         *,
         parent: Optional[str] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
-    ) -> pagers.ListDataScanJobsPager:
-        r"""Lists DataScanJobs under the given DataScan.
+    ) -> pagers.ListContentPager:
+        r"""List content.
 
         .. code-block:: python
 
             # This snippet has been automatically generated and should be regarded as a
             # code template only.
             # It will require modifications to work:
             # - It may require correct/in-range values for request initialization.
             # - It may require specifying regional endpoints when creating the service
             #   client as shown in:
             #   https://googleapis.dev/python/google-api-core/latest/client_options.html
             from google.cloud import dataplex_v1
 
-            def sample_list_data_scan_jobs():
+            def sample_list_content():
                 # Create a client
-                client = dataplex_v1.DataScanServiceClient()
+                client = dataplex_v1.ContentServiceClient()
 
                 # Initialize request argument(s)
-                request = dataplex_v1.ListDataScanJobsRequest(
+                request = dataplex_v1.ListContentRequest(
                     parent="parent_value",
                 )
 
                 # Make the request
-                page_result = client.list_data_scan_jobs(request=request)
+                page_result = client.list_content(request=request)
 
                 # Handle the response
                 for response in page_result:
                     print(response)
 
         Args:
-            request (Union[google.cloud.dataplex_v1.types.ListDataScanJobsRequest, dict]):
-                The request object. List DataScanJobs request.
+            request (Union[google.cloud.dataplex_v1.types.ListContentRequest, dict]):
+                The request object. List content request. Returns the
+                BASIC Content view.
             parent (str):
-                Required. The resource name of the parent environment:
-                ``projects/{project}/locations/{location_id}/dataScans/{data_scan_id}``
-                where ``project`` refers to a *project_id* or
-                *project_number* and ``location_id`` refers to a GCP
-                region.
+                Required. The resource name of the parent lake:
+                projects/{project_id}/locations/{location_id}/lakes/{lake_id}
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             retry (google.api_core.retry.Retry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
-            google.cloud.dataplex_v1.services.data_scan_service.pagers.ListDataScanJobsPager:
-                List DataScanJobs response.
+            google.cloud.dataplex_v1.services.content_service.pagers.ListContentPager:
+                List content response.
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a datascans.ListDataScanJobsRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
-        if not isinstance(request, datascans.ListDataScanJobsRequest):
-            request = datascans.ListDataScanJobsRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, content.ListContentRequest):
+            request = content.ListContentRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if parent is not None:
                 request.parent = parent
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = self._transport._wrapped_methods[self._transport.list_data_scan_jobs]
+        rpc = self._transport._wrapped_methods[self._transport.list_content]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
         # This method is paged; wrap the response in a pager, which provides
         # an `__iter__` convenience method.
-        response = pagers.ListDataScanJobsPager(
+        response = pagers.ListContentPager(
             method=rpc,
             request=request,
             response=response,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
-    def __enter__(self) -> "DataScanServiceClient":
+    def __enter__(self) -> "ContentServiceClient":
         return self
 
     def __exit__(self, type, value, traceback):
         """Releases underlying transport's resources.
 
         .. warning::
             ONLY use as a context manager if the transport is NOT shared
@@ -1543,14 +1652,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1597,14 +1709,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1655,14 +1770,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1709,14 +1827,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1760,14 +1881,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1814,14 +1938,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1831,8 +1958,8 @@
 
 
 DEFAULT_CLIENT_INFO = gapic_v1.client_info.ClientInfo(
     gapic_version=package_version.__version__
 )
 
 
-__all__ = ("DataScanServiceClient",)
+__all__ = ("ContentServiceClient",)
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_scan_service/pagers.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_scan_service/pagers.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_scan_service/transports/__init__.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_scan_service/transports/__init__.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_scan_service/transports/base.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_scan_service/transports/base.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -56,15 +56,15 @@
         api_audience: Optional[str] = None,
         **kwargs,
     ) -> None:
         """Instantiate the transport.
 
         Args:
             host (Optional[str]):
-                 The hostname to connect to.
+                 The hostname to connect to (default: 'dataplex.googleapis.com').
             credentials (Optional[google.auth.credentials.Credentials]): The
                 authorization credentials to attach to requests. These
                 credentials identify the application to the service; if none
                 are specified, the client will attempt to ascertain the
                 credentials from the environment.
             credentials_file (Optional[str]): A file with credentials that can
                 be loaded with :func:`google.auth.load_credentials_from_file`.
@@ -119,14 +119,18 @@
         self._credentials = credentials
 
         # Save the hostname. Default to port 443 (HTTPS) if none is specified.
         if ":" not in host:
             host += ":443"
         self._host = host
 
+    @property
+    def host(self):
+        return self._host
+
     def _prep_wrapped_messages(self, client_info):
         # Precompute the wrapped methods.
         self._wrapped_methods = {
             self.create_data_scan: gapic_v1.method.wrap_method(
                 self.create_data_scan,
                 default_timeout=None,
                 client_info=client_info,
@@ -162,14 +166,19 @@
                 client_info=client_info,
             ),
             self.list_data_scan_jobs: gapic_v1.method.wrap_method(
                 self.list_data_scan_jobs,
                 default_timeout=None,
                 client_info=client_info,
             ),
+            self.generate_data_quality_rules: gapic_v1.method.wrap_method(
+                self.generate_data_quality_rules,
+                default_timeout=None,
+                client_info=client_info,
+            ),
         }
 
     def close(self):
         """Closes resources associated with the transport.
 
         .. warning::
              Only call this method if the transport is NOT shared
@@ -256,14 +265,26 @@
             datascans.ListDataScanJobsResponse,
             Awaitable[datascans.ListDataScanJobsResponse],
         ],
     ]:
         raise NotImplementedError()
 
     @property
+    def generate_data_quality_rules(
+        self,
+    ) -> Callable[
+        [datascans.GenerateDataQualityRulesRequest],
+        Union[
+            datascans.GenerateDataQualityRulesResponse,
+            Awaitable[datascans.GenerateDataQualityRulesResponse],
+        ],
+    ]:
+        raise NotImplementedError()
+
+    @property
     def list_operations(
         self,
     ) -> Callable[
         [operations_pb2.ListOperationsRequest],
         Union[
             operations_pb2.ListOperationsResponse,
             Awaitable[operations_pb2.ListOperationsResponse],
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_scan_service/transports/grpc.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_scan_service/transports/grpc.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -52,56 +52,59 @@
     def __init__(
         self,
         *,
         host: str = "dataplex.googleapis.com",
         credentials: Optional[ga_credentials.Credentials] = None,
         credentials_file: Optional[str] = None,
         scopes: Optional[Sequence[str]] = None,
-        channel: Optional[grpc.Channel] = None,
+        channel: Optional[Union[grpc.Channel, Callable[..., grpc.Channel]]] = None,
         api_mtls_endpoint: Optional[str] = None,
         client_cert_source: Optional[Callable[[], Tuple[bytes, bytes]]] = None,
         ssl_channel_credentials: Optional[grpc.ChannelCredentials] = None,
         client_cert_source_for_mtls: Optional[Callable[[], Tuple[bytes, bytes]]] = None,
         quota_project_id: Optional[str] = None,
         client_info: gapic_v1.client_info.ClientInfo = DEFAULT_CLIENT_INFO,
         always_use_jwt_access: Optional[bool] = False,
         api_audience: Optional[str] = None,
     ) -> None:
         """Instantiate the transport.
 
         Args:
             host (Optional[str]):
-                 The hostname to connect to.
+                 The hostname to connect to (default: 'dataplex.googleapis.com').
             credentials (Optional[google.auth.credentials.Credentials]): The
                 authorization credentials to attach to requests. These
                 credentials identify the application to the service; if none
                 are specified, the client will attempt to ascertain the
                 credentials from the environment.
-                This argument is ignored if ``channel`` is provided.
+                This argument is ignored if a ``channel`` instance is provided.
             credentials_file (Optional[str]): A file with credentials that can
                 be loaded with :func:`google.auth.load_credentials_from_file`.
-                This argument is ignored if ``channel`` is provided.
+                This argument is ignored if a ``channel`` instance is provided.
             scopes (Optional(Sequence[str])): A list of scopes. This argument is
-                ignored if ``channel`` is provided.
-            channel (Optional[grpc.Channel]): A ``Channel`` instance through
-                which to make calls.
+                ignored if a ``channel`` instance is provided.
+            channel (Optional[Union[grpc.Channel, Callable[..., grpc.Channel]]]):
+                A ``Channel`` instance through which to make calls, or a Callable
+                that constructs and returns one. If set to None, ``self.create_channel``
+                is used to create the channel. If a Callable is given, it will be called
+                with the same arguments as used in ``self.create_channel``.
             api_mtls_endpoint (Optional[str]): Deprecated. The mutual TLS endpoint.
                 If provided, it overrides the ``host`` argument and tries to create
                 a mutual TLS channel with client SSL credentials from
                 ``client_cert_source`` or application default SSL credentials.
             client_cert_source (Optional[Callable[[], Tuple[bytes, bytes]]]):
                 Deprecated. A callback to provide client SSL certificate bytes and
                 private key bytes, both in PEM format. It is ignored if
                 ``api_mtls_endpoint`` is None.
             ssl_channel_credentials (grpc.ChannelCredentials): SSL credentials
-                for the grpc channel. It is ignored if ``channel`` is provided.
+                for the grpc channel. It is ignored if a ``channel`` instance is provided.
             client_cert_source_for_mtls (Optional[Callable[[], Tuple[bytes, bytes]]]):
                 A callback to provide client certificate bytes and private key bytes,
                 both in PEM format. It is used to configure a mutual TLS channel. It is
-                ignored if ``channel`` or ``ssl_channel_credentials`` is provided.
+                ignored if a ``channel`` instance or ``ssl_channel_credentials`` is provided.
             quota_project_id (Optional[str]): An optional project to use for billing
                 and quota.
             client_info (google.api_core.gapic_v1.client_info.ClientInfo):
                 The client info used to send a user-agent string along with
                 API requests. If ``None``, then default info will be used.
                 Generally, you only need to set this if you're developing
                 your own client library.
@@ -120,15 +123,15 @@
         self._operations_client: Optional[operations_v1.OperationsClient] = None
 
         if api_mtls_endpoint:
             warnings.warn("api_mtls_endpoint is deprecated", DeprecationWarning)
         if client_cert_source:
             warnings.warn("client_cert_source is deprecated", DeprecationWarning)
 
-        if channel:
+        if isinstance(channel, grpc.Channel):
             # Ignore credentials if a channel was passed.
             credentials = False
             # If a channel was explicitly provided, set it.
             self._grpc_channel = channel
             self._ssl_channel_credentials = None
 
         else:
@@ -161,15 +164,17 @@
             quota_project_id=quota_project_id,
             client_info=client_info,
             always_use_jwt_access=always_use_jwt_access,
             api_audience=api_audience,
         )
 
         if not self._grpc_channel:
-            self._grpc_channel = type(self).create_channel(
+            # initialize with the provided callable or the default channel
+            channel_init = channel or type(self).create_channel
+            self._grpc_channel = channel_init(
                 self._host,
                 # use the credentials which are saved
                 credentials=self._credentials,
                 # Set ``credentials_file`` to ``None`` here as
                 # the credentials that we saved earlier should be used.
                 credentials_file=None,
                 scopes=self._scopes,
@@ -456,14 +461,44 @@
             self._stubs["list_data_scan_jobs"] = self.grpc_channel.unary_unary(
                 "/google.cloud.dataplex.v1.DataScanService/ListDataScanJobs",
                 request_serializer=datascans.ListDataScanJobsRequest.serialize,
                 response_deserializer=datascans.ListDataScanJobsResponse.deserialize,
             )
         return self._stubs["list_data_scan_jobs"]
 
+    @property
+    def generate_data_quality_rules(
+        self,
+    ) -> Callable[
+        [datascans.GenerateDataQualityRulesRequest],
+        datascans.GenerateDataQualityRulesResponse,
+    ]:
+        r"""Return a callable for the generate data quality rules method over gRPC.
+
+        Generates recommended DataQualityRule from a data
+        profiling DataScan.
+
+        Returns:
+            Callable[[~.GenerateDataQualityRulesRequest],
+                    ~.GenerateDataQualityRulesResponse]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "generate_data_quality_rules" not in self._stubs:
+            self._stubs["generate_data_quality_rules"] = self.grpc_channel.unary_unary(
+                "/google.cloud.dataplex.v1.DataScanService/GenerateDataQualityRules",
+                request_serializer=datascans.GenerateDataQualityRulesRequest.serialize,
+                response_deserializer=datascans.GenerateDataQualityRulesResponse.deserialize,
+            )
+        return self._stubs["generate_data_quality_rules"]
+
     def close(self):
         self.grpc_channel.close()
 
     @property
     def delete_operation(
         self,
     ) -> Callable[[operations_pb2.DeleteOperationRequest], None]:
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_scan_service/transports/grpc_asyncio.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_scan_service/transports/grpc_asyncio.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,17 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 from typing import Awaitable, Callable, Dict, Optional, Sequence, Tuple, Union
 import warnings
 
+from google.api_core import exceptions as core_exceptions
 from google.api_core import gapic_v1, grpc_helpers_async, operations_v1
+from google.api_core import retry_async as retries
 from google.auth import credentials as ga_credentials  # type: ignore
 from google.auth.transport.grpc import SslCredentials  # type: ignore
 from google.cloud.location import locations_pb2  # type: ignore
 from google.iam.v1 import iam_policy_pb2  # type: ignore
 from google.iam.v1 import policy_pb2  # type: ignore
 from google.longrunning import operations_pb2  # type: ignore
 import grpc  # type: ignore
@@ -67,15 +69,14 @@
             credentials (Optional[~.Credentials]): The
                 authorization credentials to attach to requests. These
                 credentials identify this application to the service. If
                 none are specified, the client will attempt to ascertain
                 the credentials from the environment.
             credentials_file (Optional[str]): A file with credentials that can
                 be loaded with :func:`google.auth.load_credentials_from_file`.
-                This argument is ignored if ``channel`` is provided.
             scopes (Optional[Sequence[str]]): A optional list of scopes needed for this
                 service. These are only used when credentials are not specified and
                 are passed to :func:`google.auth.default`.
             quota_project_id (Optional[str]): An optional project to use for billing
                 and quota.
             kwargs (Optional[dict]): Keyword arguments, which are passed to the
                 channel creation.
@@ -97,57 +98,60 @@
     def __init__(
         self,
         *,
         host: str = "dataplex.googleapis.com",
         credentials: Optional[ga_credentials.Credentials] = None,
         credentials_file: Optional[str] = None,
         scopes: Optional[Sequence[str]] = None,
-        channel: Optional[aio.Channel] = None,
+        channel: Optional[Union[aio.Channel, Callable[..., aio.Channel]]] = None,
         api_mtls_endpoint: Optional[str] = None,
         client_cert_source: Optional[Callable[[], Tuple[bytes, bytes]]] = None,
         ssl_channel_credentials: Optional[grpc.ChannelCredentials] = None,
         client_cert_source_for_mtls: Optional[Callable[[], Tuple[bytes, bytes]]] = None,
         quota_project_id: Optional[str] = None,
         client_info: gapic_v1.client_info.ClientInfo = DEFAULT_CLIENT_INFO,
         always_use_jwt_access: Optional[bool] = False,
         api_audience: Optional[str] = None,
     ) -> None:
         """Instantiate the transport.
 
         Args:
             host (Optional[str]):
-                 The hostname to connect to.
+                 The hostname to connect to (default: 'dataplex.googleapis.com').
             credentials (Optional[google.auth.credentials.Credentials]): The
                 authorization credentials to attach to requests. These
                 credentials identify the application to the service; if none
                 are specified, the client will attempt to ascertain the
                 credentials from the environment.
-                This argument is ignored if ``channel`` is provided.
+                This argument is ignored if a ``channel`` instance is provided.
             credentials_file (Optional[str]): A file with credentials that can
                 be loaded with :func:`google.auth.load_credentials_from_file`.
-                This argument is ignored if ``channel`` is provided.
+                This argument is ignored if a ``channel`` instance is provided.
             scopes (Optional[Sequence[str]]): A optional list of scopes needed for this
                 service. These are only used when credentials are not specified and
                 are passed to :func:`google.auth.default`.
-            channel (Optional[aio.Channel]): A ``Channel`` instance through
-                which to make calls.
+            channel (Optional[Union[aio.Channel, Callable[..., aio.Channel]]]):
+                A ``Channel`` instance through which to make calls, or a Callable
+                that constructs and returns one. If set to None, ``self.create_channel``
+                is used to create the channel. If a Callable is given, it will be called
+                with the same arguments as used in ``self.create_channel``.
             api_mtls_endpoint (Optional[str]): Deprecated. The mutual TLS endpoint.
                 If provided, it overrides the ``host`` argument and tries to create
                 a mutual TLS channel with client SSL credentials from
                 ``client_cert_source`` or application default SSL credentials.
             client_cert_source (Optional[Callable[[], Tuple[bytes, bytes]]]):
                 Deprecated. A callback to provide client SSL certificate bytes and
                 private key bytes, both in PEM format. It is ignored if
                 ``api_mtls_endpoint`` is None.
             ssl_channel_credentials (grpc.ChannelCredentials): SSL credentials
-                for the grpc channel. It is ignored if ``channel`` is provided.
+                for the grpc channel. It is ignored if a ``channel`` instance is provided.
             client_cert_source_for_mtls (Optional[Callable[[], Tuple[bytes, bytes]]]):
                 A callback to provide client certificate bytes and private key bytes,
                 both in PEM format. It is used to configure a mutual TLS channel. It is
-                ignored if ``channel`` or ``ssl_channel_credentials`` is provided.
+                ignored if a ``channel`` instance or ``ssl_channel_credentials`` is provided.
             quota_project_id (Optional[str]): An optional project to use for billing
                 and quota.
             client_info (google.api_core.gapic_v1.client_info.ClientInfo):
                 The client info used to send a user-agent string along with
                 API requests. If ``None``, then default info will be used.
                 Generally, you only need to set this if you're developing
                 your own client library.
@@ -166,15 +170,15 @@
         self._operations_client: Optional[operations_v1.OperationsAsyncClient] = None
 
         if api_mtls_endpoint:
             warnings.warn("api_mtls_endpoint is deprecated", DeprecationWarning)
         if client_cert_source:
             warnings.warn("client_cert_source is deprecated", DeprecationWarning)
 
-        if channel:
+        if isinstance(channel, aio.Channel):
             # Ignore credentials if a channel was passed.
             credentials = False
             # If a channel was explicitly provided, set it.
             self._grpc_channel = channel
             self._ssl_channel_credentials = None
         else:
             if api_mtls_endpoint:
@@ -206,15 +210,17 @@
             quota_project_id=quota_project_id,
             client_info=client_info,
             always_use_jwt_access=always_use_jwt_access,
             api_audience=api_audience,
         )
 
         if not self._grpc_channel:
-            self._grpc_channel = type(self).create_channel(
+            # initialize with the provided callable or the default channel
+            channel_init = channel or type(self).create_channel
+            self._grpc_channel = channel_init(
                 self._host,
                 # use the credentials which are saved
                 credentials=self._credentials,
                 # Set ``credentials_file`` to ``None`` here as
                 # the credentials that we saved earlier should be used.
                 credentials_file=None,
                 scopes=self._scopes,
@@ -472,14 +478,94 @@
             self._stubs["list_data_scan_jobs"] = self.grpc_channel.unary_unary(
                 "/google.cloud.dataplex.v1.DataScanService/ListDataScanJobs",
                 request_serializer=datascans.ListDataScanJobsRequest.serialize,
                 response_deserializer=datascans.ListDataScanJobsResponse.deserialize,
             )
         return self._stubs["list_data_scan_jobs"]
 
+    @property
+    def generate_data_quality_rules(
+        self,
+    ) -> Callable[
+        [datascans.GenerateDataQualityRulesRequest],
+        Awaitable[datascans.GenerateDataQualityRulesResponse],
+    ]:
+        r"""Return a callable for the generate data quality rules method over gRPC.
+
+        Generates recommended DataQualityRule from a data
+        profiling DataScan.
+
+        Returns:
+            Callable[[~.GenerateDataQualityRulesRequest],
+                    Awaitable[~.GenerateDataQualityRulesResponse]]:
+                A function that, when called, will call the underlying RPC
+                on the server.
+        """
+        # Generate a "stub function" on-the-fly which will actually make
+        # the request.
+        # gRPC handles serialization and deserialization, so we just need
+        # to pass in the functions for each.
+        if "generate_data_quality_rules" not in self._stubs:
+            self._stubs["generate_data_quality_rules"] = self.grpc_channel.unary_unary(
+                "/google.cloud.dataplex.v1.DataScanService/GenerateDataQualityRules",
+                request_serializer=datascans.GenerateDataQualityRulesRequest.serialize,
+                response_deserializer=datascans.GenerateDataQualityRulesResponse.deserialize,
+            )
+        return self._stubs["generate_data_quality_rules"]
+
+    def _prep_wrapped_messages(self, client_info):
+        """Precompute the wrapped methods, overriding the base class method to use async wrappers."""
+        self._wrapped_methods = {
+            self.create_data_scan: gapic_v1.method_async.wrap_method(
+                self.create_data_scan,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+            self.update_data_scan: gapic_v1.method_async.wrap_method(
+                self.update_data_scan,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+            self.delete_data_scan: gapic_v1.method_async.wrap_method(
+                self.delete_data_scan,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+            self.get_data_scan: gapic_v1.method_async.wrap_method(
+                self.get_data_scan,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+            self.list_data_scans: gapic_v1.method_async.wrap_method(
+                self.list_data_scans,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+            self.run_data_scan: gapic_v1.method_async.wrap_method(
+                self.run_data_scan,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+            self.get_data_scan_job: gapic_v1.method_async.wrap_method(
+                self.get_data_scan_job,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+            self.list_data_scan_jobs: gapic_v1.method_async.wrap_method(
+                self.list_data_scan_jobs,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+            self.generate_data_quality_rules: gapic_v1.method_async.wrap_method(
+                self.generate_data_quality_rules,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+        }
+
     def close(self):
         return self.grpc_channel.close()
 
     @property
     def delete_operation(
         self,
     ) -> Callable[[operations_pb2.DeleteOperationRequest], None]:
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_taxonomy_service/__init__.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_taxonomy_service/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_taxonomy_service/async_client.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_taxonomy_service/async_client.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,38 +13,39 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 from collections import OrderedDict
 import functools
 import re
 from typing import (
+    Callable,
     Dict,
     Mapping,
     MutableMapping,
     MutableSequence,
     Optional,
     Sequence,
     Tuple,
     Type,
     Union,
 )
 
 from google.api_core import exceptions as core_exceptions
 from google.api_core import gapic_v1
-from google.api_core import retry as retries
+from google.api_core import retry_async as retries
 from google.api_core.client_options import ClientOptions
 from google.auth import credentials as ga_credentials  # type: ignore
 from google.oauth2 import service_account  # type: ignore
 
 from google.cloud.dataplex_v1 import gapic_version as package_version
 
 try:
-    OptionalRetry = Union[retries.Retry, gapic_v1.method._MethodDefault]
+    OptionalRetry = Union[retries.AsyncRetry, gapic_v1.method._MethodDefault, None]
 except AttributeError:  # pragma: NO COVER
-    OptionalRetry = Union[retries.Retry, object]  # type: ignore
+    OptionalRetry = Union[retries.AsyncRetry, object, None]  # type: ignore
 
 from google.api_core import operation  # type: ignore
 from google.api_core import operation_async  # type: ignore
 from google.cloud.location import locations_pb2  # type: ignore
 from google.iam.v1 import iam_policy_pb2  # type: ignore
 from google.iam.v1 import policy_pb2  # type: ignore
 from google.longrunning import operations_pb2  # type: ignore
@@ -66,16 +67,20 @@
     """DataTaxonomyService enables attribute-based governance. The
     resources currently offered include DataTaxonomy and
     DataAttribute.
     """
 
     _client: DataTaxonomyServiceClient
 
+    # Copy defaults from the synchronous client for use here.
+    # Note: DEFAULT_ENDPOINT is deprecated. Use _DEFAULT_ENDPOINT_TEMPLATE instead.
     DEFAULT_ENDPOINT = DataTaxonomyServiceClient.DEFAULT_ENDPOINT
     DEFAULT_MTLS_ENDPOINT = DataTaxonomyServiceClient.DEFAULT_MTLS_ENDPOINT
+    _DEFAULT_ENDPOINT_TEMPLATE = DataTaxonomyServiceClient._DEFAULT_ENDPOINT_TEMPLATE
+    _DEFAULT_UNIVERSE = DataTaxonomyServiceClient._DEFAULT_UNIVERSE
 
     data_attribute_path = staticmethod(DataTaxonomyServiceClient.data_attribute_path)
     parse_data_attribute_path = staticmethod(
         DataTaxonomyServiceClient.parse_data_attribute_path
     )
     data_attribute_binding_path = staticmethod(
         DataTaxonomyServiceClient.data_attribute_binding_path
@@ -186,55 +191,97 @@
         """Returns the transport used by the client instance.
 
         Returns:
             DataTaxonomyServiceTransport: The transport used by the client instance.
         """
         return self._client.transport
 
+    @property
+    def api_endpoint(self):
+        """Return the API endpoint used by the client instance.
+
+        Returns:
+            str: The API endpoint used by the client instance.
+        """
+        return self._client._api_endpoint
+
+    @property
+    def universe_domain(self) -> str:
+        """Return the universe domain used by the client instance.
+
+        Returns:
+            str: The universe domain used
+                by the client instance.
+        """
+        return self._client._universe_domain
+
     get_transport_class = functools.partial(
         type(DataTaxonomyServiceClient).get_transport_class,
         type(DataTaxonomyServiceClient),
     )
 
     def __init__(
         self,
         *,
         credentials: Optional[ga_credentials.Credentials] = None,
-        transport: Union[str, DataTaxonomyServiceTransport] = "grpc_asyncio",
+        transport: Optional[
+            Union[
+                str,
+                DataTaxonomyServiceTransport,
+                Callable[..., DataTaxonomyServiceTransport],
+            ]
+        ] = "grpc_asyncio",
         client_options: Optional[ClientOptions] = None,
         client_info: gapic_v1.client_info.ClientInfo = DEFAULT_CLIENT_INFO,
     ) -> None:
-        """Instantiates the data taxonomy service client.
+        """Instantiates the data taxonomy service async client.
 
         Args:
             credentials (Optional[google.auth.credentials.Credentials]): The
                 authorization credentials to attach to requests. These
                 credentials identify the application to the service; if none
                 are specified, the client will attempt to ascertain the
                 credentials from the environment.
-            transport (Union[str, ~.DataTaxonomyServiceTransport]): The
-                transport to use. If set to None, a transport is chosen
-                automatically.
-            client_options (ClientOptions): Custom options for the client. It
-                won't take effect if a ``transport`` instance is provided.
-                (1) The ``api_endpoint`` property can be used to override the
-                default endpoint provided by the client. GOOGLE_API_USE_MTLS_ENDPOINT
-                environment variable can also be used to override the endpoint:
+            transport (Optional[Union[str,DataTaxonomyServiceTransport,Callable[..., DataTaxonomyServiceTransport]]]):
+                The transport to use, or a Callable that constructs and returns a new transport to use.
+                If a Callable is given, it will be called with the same set of initialization
+                arguments as used in the DataTaxonomyServiceTransport constructor.
+                If set to None, a transport is chosen automatically.
+            client_options (Optional[Union[google.api_core.client_options.ClientOptions, dict]]):
+                Custom options for the client.
+
+                1. The ``api_endpoint`` property can be used to override the
+                default endpoint provided by the client when ``transport`` is
+                not explicitly provided. Only if this property is not set and
+                ``transport`` was not explicitly provided, the endpoint is
+                determined by the GOOGLE_API_USE_MTLS_ENDPOINT environment
+                variable, which have one of the following values:
                 "always" (always use the default mTLS endpoint), "never" (always
-                use the default regular endpoint) and "auto" (auto switch to the
-                default mTLS endpoint if client certificate is present, this is
-                the default value). However, the ``api_endpoint`` property takes
-                precedence if provided.
-                (2) If GOOGLE_API_USE_CLIENT_CERTIFICATE environment variable
+                use the default regular endpoint) and "auto" (auto-switch to the
+                default mTLS endpoint if client certificate is present; this is
+                the default value).
+
+                2. If the GOOGLE_API_USE_CLIENT_CERTIFICATE environment variable
                 is "true", then the ``client_cert_source`` property can be used
-                to provide client certificate for mutual TLS transport. If
+                to provide a client certificate for mTLS transport. If
                 not provided, the default SSL client certificate will be used if
                 present. If GOOGLE_API_USE_CLIENT_CERTIFICATE is "false" or not
                 set, no client certificate will be used.
 
+                3. The ``universe_domain`` property can be used to override the
+                default "googleapis.com" universe. Note that ``api_endpoint``
+                property still takes precedence; and ``universe_domain`` is
+                currently not supported for mTLS.
+
+            client_info (google.api_core.gapic_v1.client_info.ClientInfo):
+                The client info used to send a user-agent string along with
+                API requests. If ``None``, then default info will be used.
+                Generally, you only need to set this if you're developing
+                your own client library.
+
         Raises:
             google.auth.exceptions.MutualTlsChannelError: If mutual TLS transport
                 creation failed for any reason.
         """
         self._client = DataTaxonomyServiceClient(
             credentials=credentials,
             transport=transport,
@@ -314,15 +361,15 @@
                 -  Must be between 1-63 characters.
                 -  Must end with a number or a letter.
                 -  Must be unique within the Project.
 
                 This corresponds to the ``data_taxonomy_id`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.api_core.operation_async.AsyncOperation:
@@ -331,48 +378,52 @@
                 The result type for the operation will be :class:`google.cloud.dataplex_v1.types.DataTaxonomy` DataTaxonomy represents a set of hierarchical DataAttributes resources,
                    grouped with a common theme Eg:
                    'SensitiveDataTaxonomy' can have attributes to manage
                    PII data. It is defined at project level.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent, data_taxonomy, data_taxonomy_id])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = gcd_data_taxonomy.CreateDataTaxonomyRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, gcd_data_taxonomy.CreateDataTaxonomyRequest):
+            request = gcd_data_taxonomy.CreateDataTaxonomyRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if parent is not None:
             request.parent = parent
         if data_taxonomy is not None:
             request.data_taxonomy = data_taxonomy
         if data_taxonomy_id is not None:
             request.data_taxonomy_id = data_taxonomy_id
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.create_data_taxonomy,
-            default_timeout=None,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.create_data_taxonomy
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -442,15 +493,15 @@
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             update_mask (:class:`google.protobuf.field_mask_pb2.FieldMask`):
                 Required. Mask of fields to update.
                 This corresponds to the ``update_mask`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.api_core.operation_async.AsyncOperation:
@@ -459,48 +510,52 @@
                 The result type for the operation will be :class:`google.cloud.dataplex_v1.types.DataTaxonomy` DataTaxonomy represents a set of hierarchical DataAttributes resources,
                    grouped with a common theme Eg:
                    'SensitiveDataTaxonomy' can have attributes to manage
                    PII data. It is defined at project level.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([data_taxonomy, update_mask])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = gcd_data_taxonomy.UpdateDataTaxonomyRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, gcd_data_taxonomy.UpdateDataTaxonomyRequest):
+            request = gcd_data_taxonomy.UpdateDataTaxonomyRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if data_taxonomy is not None:
             request.data_taxonomy = data_taxonomy
         if update_mask is not None:
             request.update_mask = update_mask
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.update_data_taxonomy,
-            default_timeout=None,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.update_data_taxonomy
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata(
                 (("data_taxonomy.name", request.data_taxonomy.name),)
             ),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -565,15 +620,15 @@
             name (:class:`str`):
                 Required. The resource name of the DataTaxonomy:
                 projects/{project_number}/locations/{location_id}/dataTaxonomies/{data_taxonomy_id}
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.api_core.operation_async.AsyncOperation:
@@ -588,44 +643,48 @@
                          rpc Bar(google.protobuf.Empty) returns
                          (google.protobuf.Empty);
 
                       }
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = data_taxonomy.DeleteDataTaxonomyRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, data_taxonomy.DeleteDataTaxonomyRequest):
+            request = data_taxonomy.DeleteDataTaxonomyRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if name is not None:
             request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.delete_data_taxonomy,
-            default_timeout=None,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.delete_data_taxonomy
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -688,15 +747,15 @@
                 location, of the form:
                 projects/{project_number}/locations/{location_id} where
                 ``location_id`` refers to a GCP region.
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.services.data_taxonomy_service.pagers.ListDataTaxonomiesAsyncPager:
@@ -704,44 +763,48 @@
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = data_taxonomy.ListDataTaxonomiesRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, data_taxonomy.ListDataTaxonomiesRequest):
+            request = data_taxonomy.ListDataTaxonomiesRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if parent is not None:
             request.parent = parent
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.list_data_taxonomies,
-            default_timeout=None,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.list_data_taxonomies
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -801,15 +864,15 @@
             name (:class:`str`):
                 Required. The resource name of the DataTaxonomy:
                 projects/{project_number}/locations/{location_id}/dataTaxonomies/{data_taxonomy_id}
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.types.DataTaxonomy:
@@ -818,44 +881,48 @@
                 grouped with a common theme Eg:
                 'SensitiveDataTaxonomy' can have
                 attributes to manage PII data. It is
                 defined at project level.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = data_taxonomy.GetDataTaxonomyRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, data_taxonomy.GetDataTaxonomyRequest):
+            request = data_taxonomy.GetDataTaxonomyRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if name is not None:
             request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.get_data_taxonomy,
-            default_timeout=None,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.get_data_taxonomy
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -939,65 +1006,69 @@
                 -  Must be between 1-63 characters.
                 -  Must end with a number or a letter.
                 -  Must be unique within the Location.
 
                 This corresponds to the ``data_attribute_binding_id`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.api_core.operation_async.AsyncOperation:
                 An object representing a long-running operation.
 
                 The result type for the operation will be :class:`google.cloud.dataplex_v1.types.DataAttributeBinding` DataAttributeBinding represents binding of attributes to resources. Eg: Bind
                    'CustomerInfo' entity with 'PII' attribute.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any(
             [parent, data_attribute_binding, data_attribute_binding_id]
         )
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = data_taxonomy.CreateDataAttributeBindingRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, data_taxonomy.CreateDataAttributeBindingRequest):
+            request = data_taxonomy.CreateDataAttributeBindingRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if parent is not None:
             request.parent = parent
         if data_attribute_binding is not None:
             request.data_attribute_binding = data_attribute_binding
         if data_attribute_binding_id is not None:
             request.data_attribute_binding_id = data_attribute_binding_id
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.create_data_attribute_binding,
-            default_timeout=None,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.create_data_attribute_binding
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1071,63 +1142,67 @@
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             update_mask (:class:`google.protobuf.field_mask_pb2.FieldMask`):
                 Required. Mask of fields to update.
                 This corresponds to the ``update_mask`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.api_core.operation_async.AsyncOperation:
                 An object representing a long-running operation.
 
                 The result type for the operation will be :class:`google.cloud.dataplex_v1.types.DataAttributeBinding` DataAttributeBinding represents binding of attributes to resources. Eg: Bind
                    'CustomerInfo' entity with 'PII' attribute.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([data_attribute_binding, update_mask])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = data_taxonomy.UpdateDataAttributeBindingRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, data_taxonomy.UpdateDataAttributeBindingRequest):
+            request = data_taxonomy.UpdateDataAttributeBindingRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if data_attribute_binding is not None:
             request.data_attribute_binding = data_attribute_binding
         if update_mask is not None:
             request.update_mask = update_mask
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.update_data_attribute_binding,
-            default_timeout=None,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.update_data_attribute_binding
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata(
                 (("data_attribute_binding.name", request.data_attribute_binding.name),)
             ),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1195,15 +1270,15 @@
             name (:class:`str`):
                 Required. The resource name of the DataAttributeBinding:
                 projects/{project_number}/locations/{location_id}/dataAttributeBindings/{data_attribute_binding_id}
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.api_core.operation_async.AsyncOperation:
@@ -1218,44 +1293,48 @@
                          rpc Bar(google.protobuf.Empty) returns
                          (google.protobuf.Empty);
 
                       }
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = data_taxonomy.DeleteDataAttributeBindingRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, data_taxonomy.DeleteDataAttributeBindingRequest):
+            request = data_taxonomy.DeleteDataAttributeBindingRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if name is not None:
             request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.delete_data_attribute_binding,
-            default_timeout=None,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.delete_data_attribute_binding
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1318,15 +1397,15 @@
             parent (:class:`str`):
                 Required. The resource name of the Location:
                 projects/{project_number}/locations/{location_id}
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.services.data_taxonomy_service.pagers.ListDataAttributeBindingsAsyncPager:
@@ -1334,44 +1413,48 @@
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = data_taxonomy.ListDataAttributeBindingsRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, data_taxonomy.ListDataAttributeBindingsRequest):
+            request = data_taxonomy.ListDataAttributeBindingsRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if parent is not None:
             request.parent = parent
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.list_data_attribute_bindings,
-            default_timeout=None,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.list_data_attribute_bindings
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1433,59 +1516,63 @@
             name (:class:`str`):
                 Required. The resource name of the DataAttributeBinding:
                 projects/{project_number}/locations/{location_id}/dataAttributeBindings/{data_attribute_binding_id}
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.types.DataAttributeBinding:
                 DataAttributeBinding represents
                 binding of attributes to resources. Eg:
                 Bind 'CustomerInfo' entity with 'PII'
                 attribute.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = data_taxonomy.GetDataAttributeBindingRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, data_taxonomy.GetDataAttributeBindingRequest):
+            request = data_taxonomy.GetDataAttributeBindingRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if name is not None:
             request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.get_data_attribute_binding,
-            default_timeout=None,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.get_data_attribute_binding
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1561,15 +1648,15 @@
                 -  Must be between 1-63 characters.
                 -  Must end with a number or a letter.
                 -  Must be unique within the DataTaxonomy.
 
                 This corresponds to the ``data_attribute_id`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.api_core.operation_async.AsyncOperation:
@@ -1580,48 +1667,52 @@
                    hierarchy. A single dataAttribute resource can
                    contain specs of multiple types
 
                    :literal:`\` PII   - ResourceAccessSpec :                 - readers :foo@bar.com   - DataAccessSpec :                 - readers :bar@foo.com`\ \`
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent, data_attribute, data_attribute_id])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = data_taxonomy.CreateDataAttributeRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, data_taxonomy.CreateDataAttributeRequest):
+            request = data_taxonomy.CreateDataAttributeRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if parent is not None:
             request.parent = parent
         if data_attribute is not None:
             request.data_attribute = data_attribute
         if data_attribute_id is not None:
             request.data_attribute_id = data_attribute_id
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.create_data_attribute,
-            default_timeout=None,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.create_data_attribute
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1689,15 +1780,15 @@
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             update_mask (:class:`google.protobuf.field_mask_pb2.FieldMask`):
                 Required. Mask of fields to update.
                 This corresponds to the ``update_mask`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.api_core.operation_async.AsyncOperation:
@@ -1708,48 +1799,52 @@
                    hierarchy. A single dataAttribute resource can
                    contain specs of multiple types
 
                    :literal:`\` PII   - ResourceAccessSpec :                 - readers :foo@bar.com   - DataAccessSpec :                 - readers :bar@foo.com`\ \`
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([data_attribute, update_mask])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = data_taxonomy.UpdateDataAttributeRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, data_taxonomy.UpdateDataAttributeRequest):
+            request = data_taxonomy.UpdateDataAttributeRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if data_attribute is not None:
             request.data_attribute = data_attribute
         if update_mask is not None:
             request.update_mask = update_mask
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.update_data_attribute,
-            default_timeout=None,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.update_data_attribute
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata(
                 (("data_attribute.name", request.data_attribute.name),)
             ),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1812,15 +1907,15 @@
             name (:class:`str`):
                 Required. The resource name of the DataAttribute:
                 projects/{project_number}/locations/{location_id}/dataTaxonomies/{dataTaxonomy}/attributes/{data_attribute_id}
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.api_core.operation_async.AsyncOperation:
@@ -1835,44 +1930,48 @@
                          rpc Bar(google.protobuf.Empty) returns
                          (google.protobuf.Empty);
 
                       }
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = data_taxonomy.DeleteDataAttributeRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, data_taxonomy.DeleteDataAttributeRequest):
+            request = data_taxonomy.DeleteDataAttributeRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if name is not None:
             request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.delete_data_attribute,
-            default_timeout=None,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.delete_data_attribute
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1932,15 +2031,15 @@
             parent (:class:`str`):
                 Required. The resource name of the DataTaxonomy:
                 projects/{project_number}/locations/{location_id}/dataTaxonomies/{data_taxonomy_id}
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.services.data_taxonomy_service.pagers.ListDataAttributesAsyncPager:
@@ -1948,44 +2047,48 @@
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = data_taxonomy.ListDataAttributesRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, data_taxonomy.ListDataAttributesRequest):
+            request = data_taxonomy.ListDataAttributesRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if parent is not None:
             request.parent = parent
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.list_data_attributes,
-            default_timeout=None,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.list_data_attributes
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2045,15 +2148,15 @@
             name (:class:`str`):
                 Required. The resource name of the dataAttribute:
                 projects/{project_number}/locations/{location_id}/dataTaxonomies/{dataTaxonomy}/attributes/{data_attribute_id}
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.types.DataAttribute:
@@ -2062,44 +2165,48 @@
                    hierarchy. A single dataAttribute resource can
                    contain specs of multiple types
 
                    :literal:`\` PII   - ResourceAccessSpec :                 - readers :foo@bar.com   - DataAccessSpec :                 - readers :bar@foo.com`\ \`
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = data_taxonomy.GetDataAttributeRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, data_taxonomy.GetDataAttributeRequest):
+            request = data_taxonomy.GetDataAttributeRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if name is not None:
             request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.get_data_attribute,
-            default_timeout=None,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.get_data_attribute
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2117,15 +2224,15 @@
     ) -> operations_pb2.ListOperationsResponse:
         r"""Lists operations that match the specified filter in the request.
 
         Args:
             request (:class:`~.operations_pb2.ListOperationsRequest`):
                 The request object. Request message for
                 `ListOperations` method.
-            retry (google.api_core.retry.Retry): Designation of what errors,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors,
                     if any, should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         Returns:
             ~.operations_pb2.ListOperationsResponse:
                 Response message for ``ListOperations`` method.
@@ -2134,26 +2241,29 @@
         # The request isn't a proto-plus wrapped type,
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = operations_pb2.ListOperationsRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method.wrap_method(
+        rpc = gapic_v1.method_async.wrap_method(
             self._client._transport.list_operations,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2171,15 +2281,15 @@
     ) -> operations_pb2.Operation:
         r"""Gets the latest state of a long-running operation.
 
         Args:
             request (:class:`~.operations_pb2.GetOperationRequest`):
                 The request object. Request message for
                 `GetOperation` method.
-            retry (google.api_core.retry.Retry): Designation of what errors,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors,
                     if any, should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         Returns:
             ~.operations_pb2.Operation:
                 An ``Operation`` object.
@@ -2188,26 +2298,29 @@
         # The request isn't a proto-plus wrapped type,
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = operations_pb2.GetOperationRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method.wrap_method(
+        rpc = gapic_v1.method_async.wrap_method(
             self._client._transport.get_operation,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2230,15 +2343,15 @@
         If the server doesn't support this method, it returns
         `google.rpc.Code.UNIMPLEMENTED`.
 
         Args:
             request (:class:`~.operations_pb2.DeleteOperationRequest`):
                 The request object. Request message for
                 `DeleteOperation` method.
-            retry (google.api_core.retry.Retry): Designation of what errors,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors,
                     if any, should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         Returns:
             None
         """
@@ -2246,26 +2359,29 @@
         # The request isn't a proto-plus wrapped type,
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = operations_pb2.DeleteOperationRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method.wrap_method(
+        rpc = gapic_v1.method_async.wrap_method(
             self._client._transport.delete_operation,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2284,15 +2400,15 @@
         is not guaranteed.  If the server doesn't support this method, it returns
         `google.rpc.Code.UNIMPLEMENTED`.
 
         Args:
             request (:class:`~.operations_pb2.CancelOperationRequest`):
                 The request object. Request message for
                 `CancelOperation` method.
-            retry (google.api_core.retry.Retry): Designation of what errors,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors,
                     if any, should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         Returns:
             None
         """
@@ -2300,26 +2416,29 @@
         # The request isn't a proto-plus wrapped type,
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = operations_pb2.CancelOperationRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method.wrap_method(
+        rpc = gapic_v1.method_async.wrap_method(
             self._client._transport.cancel_operation,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2334,15 +2453,15 @@
     ) -> locations_pb2.Location:
         r"""Gets information about a location.
 
         Args:
             request (:class:`~.location_pb2.GetLocationRequest`):
                 The request object. Request message for
                 `GetLocation` method.
-            retry (google.api_core.retry.Retry): Designation of what errors,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors,
                  if any, should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         Returns:
             ~.location_pb2.Location:
                 Location object.
@@ -2351,26 +2470,29 @@
         # The request isn't a proto-plus wrapped type,
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = locations_pb2.GetLocationRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method.wrap_method(
+        rpc = gapic_v1.method_async.wrap_method(
             self._client._transport.get_location,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2388,15 +2510,15 @@
     ) -> locations_pb2.ListLocationsResponse:
         r"""Lists information about the supported locations for this service.
 
         Args:
             request (:class:`~.location_pb2.ListLocationsRequest`):
                 The request object. Request message for
                 `ListLocations` method.
-            retry (google.api_core.retry.Retry): Designation of what errors,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors,
                  if any, should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         Returns:
             ~.location_pb2.ListLocationsResponse:
                 Response message for ``ListLocations`` method.
@@ -2405,26 +2527,29 @@
         # The request isn't a proto-plus wrapped type,
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = locations_pb2.ListLocationsRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method.wrap_method(
+        rpc = gapic_v1.method_async.wrap_method(
             self._client._transport.list_locations,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_taxonomy_service/client.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_taxonomy_service/client.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,42 +13,44 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 from collections import OrderedDict
 import os
 import re
 from typing import (
+    Callable,
     Dict,
     Mapping,
     MutableMapping,
     MutableSequence,
     Optional,
     Sequence,
     Tuple,
     Type,
     Union,
     cast,
 )
+import warnings
 
 from google.api_core import client_options as client_options_lib
 from google.api_core import exceptions as core_exceptions
 from google.api_core import gapic_v1
 from google.api_core import retry as retries
 from google.auth import credentials as ga_credentials  # type: ignore
 from google.auth.exceptions import MutualTLSChannelError  # type: ignore
 from google.auth.transport import mtls  # type: ignore
 from google.auth.transport.grpc import SslCredentials  # type: ignore
 from google.oauth2 import service_account  # type: ignore
 
 from google.cloud.dataplex_v1 import gapic_version as package_version
 
 try:
-    OptionalRetry = Union[retries.Retry, gapic_v1.method._MethodDefault]
+    OptionalRetry = Union[retries.Retry, gapic_v1.method._MethodDefault, None]
 except AttributeError:  # pragma: NO COVER
-    OptionalRetry = Union[retries.Retry, object]  # type: ignore
+    OptionalRetry = Union[retries.Retry, object, None]  # type: ignore
 
 from google.api_core import operation  # type: ignore
 from google.api_core import operation_async  # type: ignore
 from google.cloud.location import locations_pb2  # type: ignore
 from google.iam.v1 import iam_policy_pb2  # type: ignore
 from google.iam.v1 import policy_pb2  # type: ignore
 from google.longrunning import operations_pb2  # type: ignore
@@ -134,19 +136,23 @@
         if sandbox:
             return api_endpoint.replace(
                 "sandbox.googleapis.com", "mtls.sandbox.googleapis.com"
             )
 
         return api_endpoint.replace(".googleapis.com", ".mtls.googleapis.com")
 
+    # Note: DEFAULT_ENDPOINT is deprecated. Use _DEFAULT_ENDPOINT_TEMPLATE instead.
     DEFAULT_ENDPOINT = "dataplex.googleapis.com"
     DEFAULT_MTLS_ENDPOINT = _get_default_mtls_endpoint.__func__(  # type: ignore
         DEFAULT_ENDPOINT
     )
 
+    _DEFAULT_ENDPOINT_TEMPLATE = "dataplex.{UNIVERSE_DOMAIN}"
+    _DEFAULT_UNIVERSE = "googleapis.com"
+
     @classmethod
     def from_service_account_info(cls, info: dict, *args, **kwargs):
         """Creates an instance of this client using the provided credentials
             info.
 
         Args:
             info (dict): The service account private key info.
@@ -335,15 +341,15 @@
         m = re.match(r"^projects/(?P<project>.+?)/locations/(?P<location>.+?)$", path)
         return m.groupdict() if m else {}
 
     @classmethod
     def get_mtls_endpoint_and_cert_source(
         cls, client_options: Optional[client_options_lib.ClientOptions] = None
     ):
-        """Return the API endpoint and client cert source for mutual TLS.
+        """Deprecated. Return the API endpoint and client cert source for mutual TLS.
 
         The client cert source is determined in the following order:
         (1) if `GOOGLE_API_USE_CLIENT_CERTIFICATE` environment variable is not "true", the
         client cert source is None.
         (2) if `client_options.client_cert_source` is provided, use the provided one; if the
         default client cert source exists, use the default one; otherwise the client cert
         source is None.
@@ -365,14 +371,19 @@
         Returns:
             Tuple[str, Callable[[], Tuple[bytes, bytes]]]: returns the API endpoint and the
                 client cert source to use.
 
         Raises:
             google.auth.exceptions.MutualTLSChannelError: If any errors happen.
         """
+
+        warnings.warn(
+            "get_mtls_endpoint_and_cert_source is deprecated. Use the api_endpoint property instead.",
+            DeprecationWarning,
+        )
         if client_options is None:
             client_options = client_options_lib.ClientOptions()
         use_client_cert = os.getenv("GOOGLE_API_USE_CLIENT_CERTIFICATE", "false")
         use_mtls_endpoint = os.getenv("GOOGLE_API_USE_MTLS_ENDPOINT", "auto")
         if use_client_cert not in ("true", "false"):
             raise ValueError(
                 "Environment variable `GOOGLE_API_USE_CLIENT_CERTIFICATE` must be either `true` or `false`"
@@ -398,112 +409,340 @@
         ):
             api_endpoint = cls.DEFAULT_MTLS_ENDPOINT
         else:
             api_endpoint = cls.DEFAULT_ENDPOINT
 
         return api_endpoint, client_cert_source
 
+    @staticmethod
+    def _read_environment_variables():
+        """Returns the environment variables used by the client.
+
+        Returns:
+            Tuple[bool, str, str]: returns the GOOGLE_API_USE_CLIENT_CERTIFICATE,
+            GOOGLE_API_USE_MTLS_ENDPOINT, and GOOGLE_CLOUD_UNIVERSE_DOMAIN environment variables.
+
+        Raises:
+            ValueError: If GOOGLE_API_USE_CLIENT_CERTIFICATE is not
+                any of ["true", "false"].
+            google.auth.exceptions.MutualTLSChannelError: If GOOGLE_API_USE_MTLS_ENDPOINT
+                is not any of ["auto", "never", "always"].
+        """
+        use_client_cert = os.getenv(
+            "GOOGLE_API_USE_CLIENT_CERTIFICATE", "false"
+        ).lower()
+        use_mtls_endpoint = os.getenv("GOOGLE_API_USE_MTLS_ENDPOINT", "auto").lower()
+        universe_domain_env = os.getenv("GOOGLE_CLOUD_UNIVERSE_DOMAIN")
+        if use_client_cert not in ("true", "false"):
+            raise ValueError(
+                "Environment variable `GOOGLE_API_USE_CLIENT_CERTIFICATE` must be either `true` or `false`"
+            )
+        if use_mtls_endpoint not in ("auto", "never", "always"):
+            raise MutualTLSChannelError(
+                "Environment variable `GOOGLE_API_USE_MTLS_ENDPOINT` must be `never`, `auto` or `always`"
+            )
+        return use_client_cert == "true", use_mtls_endpoint, universe_domain_env
+
+    @staticmethod
+    def _get_client_cert_source(provided_cert_source, use_cert_flag):
+        """Return the client cert source to be used by the client.
+
+        Args:
+            provided_cert_source (bytes): The client certificate source provided.
+            use_cert_flag (bool): A flag indicating whether to use the client certificate.
+
+        Returns:
+            bytes or None: The client cert source to be used by the client.
+        """
+        client_cert_source = None
+        if use_cert_flag:
+            if provided_cert_source:
+                client_cert_source = provided_cert_source
+            elif mtls.has_default_client_cert_source():
+                client_cert_source = mtls.default_client_cert_source()
+        return client_cert_source
+
+    @staticmethod
+    def _get_api_endpoint(
+        api_override, client_cert_source, universe_domain, use_mtls_endpoint
+    ):
+        """Return the API endpoint used by the client.
+
+        Args:
+            api_override (str): The API endpoint override. If specified, this is always
+                the return value of this function and the other arguments are not used.
+            client_cert_source (bytes): The client certificate source used by the client.
+            universe_domain (str): The universe domain used by the client.
+            use_mtls_endpoint (str): How to use the mTLS endpoint, which depends also on the other parameters.
+                Possible values are "always", "auto", or "never".
+
+        Returns:
+            str: The API endpoint to be used by the client.
+        """
+        if api_override is not None:
+            api_endpoint = api_override
+        elif use_mtls_endpoint == "always" or (
+            use_mtls_endpoint == "auto" and client_cert_source
+        ):
+            _default_universe = DataTaxonomyServiceClient._DEFAULT_UNIVERSE
+            if universe_domain != _default_universe:
+                raise MutualTLSChannelError(
+                    f"mTLS is not supported in any universe other than {_default_universe}."
+                )
+            api_endpoint = DataTaxonomyServiceClient.DEFAULT_MTLS_ENDPOINT
+        else:
+            api_endpoint = DataTaxonomyServiceClient._DEFAULT_ENDPOINT_TEMPLATE.format(
+                UNIVERSE_DOMAIN=universe_domain
+            )
+        return api_endpoint
+
+    @staticmethod
+    def _get_universe_domain(
+        client_universe_domain: Optional[str], universe_domain_env: Optional[str]
+    ) -> str:
+        """Return the universe domain used by the client.
+
+        Args:
+            client_universe_domain (Optional[str]): The universe domain configured via the client options.
+            universe_domain_env (Optional[str]): The universe domain configured via the "GOOGLE_CLOUD_UNIVERSE_DOMAIN" environment variable.
+
+        Returns:
+            str: The universe domain to be used by the client.
+
+        Raises:
+            ValueError: If the universe domain is an empty string.
+        """
+        universe_domain = DataTaxonomyServiceClient._DEFAULT_UNIVERSE
+        if client_universe_domain is not None:
+            universe_domain = client_universe_domain
+        elif universe_domain_env is not None:
+            universe_domain = universe_domain_env
+        if len(universe_domain.strip()) == 0:
+            raise ValueError("Universe Domain cannot be an empty string.")
+        return universe_domain
+
+    @staticmethod
+    def _compare_universes(
+        client_universe: str, credentials: ga_credentials.Credentials
+    ) -> bool:
+        """Returns True iff the universe domains used by the client and credentials match.
+
+        Args:
+            client_universe (str): The universe domain configured via the client options.
+            credentials (ga_credentials.Credentials): The credentials being used in the client.
+
+        Returns:
+            bool: True iff client_universe matches the universe in credentials.
+
+        Raises:
+            ValueError: when client_universe does not match the universe in credentials.
+        """
+
+        default_universe = DataTaxonomyServiceClient._DEFAULT_UNIVERSE
+        credentials_universe = getattr(credentials, "universe_domain", default_universe)
+
+        if client_universe != credentials_universe:
+            raise ValueError(
+                "The configured universe domain "
+                f"({client_universe}) does not match the universe domain "
+                f"found in the credentials ({credentials_universe}). "
+                "If you haven't configured the universe domain explicitly, "
+                f"`{default_universe}` is the default."
+            )
+        return True
+
+    def _validate_universe_domain(self):
+        """Validates client's and credentials' universe domains are consistent.
+
+        Returns:
+            bool: True iff the configured universe domain is valid.
+
+        Raises:
+            ValueError: If the configured universe domain is not valid.
+        """
+        self._is_universe_domain_valid = (
+            self._is_universe_domain_valid
+            or DataTaxonomyServiceClient._compare_universes(
+                self.universe_domain, self.transport._credentials
+            )
+        )
+        return self._is_universe_domain_valid
+
+    @property
+    def api_endpoint(self):
+        """Return the API endpoint used by the client instance.
+
+        Returns:
+            str: The API endpoint used by the client instance.
+        """
+        return self._api_endpoint
+
+    @property
+    def universe_domain(self) -> str:
+        """Return the universe domain used by the client instance.
+
+        Returns:
+            str: The universe domain used by the client instance.
+        """
+        return self._universe_domain
+
     def __init__(
         self,
         *,
         credentials: Optional[ga_credentials.Credentials] = None,
-        transport: Optional[Union[str, DataTaxonomyServiceTransport]] = None,
+        transport: Optional[
+            Union[
+                str,
+                DataTaxonomyServiceTransport,
+                Callable[..., DataTaxonomyServiceTransport],
+            ]
+        ] = None,
         client_options: Optional[Union[client_options_lib.ClientOptions, dict]] = None,
         client_info: gapic_v1.client_info.ClientInfo = DEFAULT_CLIENT_INFO,
     ) -> None:
         """Instantiates the data taxonomy service client.
 
         Args:
             credentials (Optional[google.auth.credentials.Credentials]): The
                 authorization credentials to attach to requests. These
                 credentials identify the application to the service; if none
                 are specified, the client will attempt to ascertain the
                 credentials from the environment.
-            transport (Union[str, DataTaxonomyServiceTransport]): The
-                transport to use. If set to None, a transport is chosen
-                automatically.
-            client_options (Optional[Union[google.api_core.client_options.ClientOptions, dict]]): Custom options for the
-                client. It won't take effect if a ``transport`` instance is provided.
-                (1) The ``api_endpoint`` property can be used to override the
-                default endpoint provided by the client. GOOGLE_API_USE_MTLS_ENDPOINT
-                environment variable can also be used to override the endpoint:
+            transport (Optional[Union[str,DataTaxonomyServiceTransport,Callable[..., DataTaxonomyServiceTransport]]]):
+                The transport to use, or a Callable that constructs and returns a new transport.
+                If a Callable is given, it will be called with the same set of initialization
+                arguments as used in the DataTaxonomyServiceTransport constructor.
+                If set to None, a transport is chosen automatically.
+            client_options (Optional[Union[google.api_core.client_options.ClientOptions, dict]]):
+                Custom options for the client.
+
+                1. The ``api_endpoint`` property can be used to override the
+                default endpoint provided by the client when ``transport`` is
+                not explicitly provided. Only if this property is not set and
+                ``transport`` was not explicitly provided, the endpoint is
+                determined by the GOOGLE_API_USE_MTLS_ENDPOINT environment
+                variable, which have one of the following values:
                 "always" (always use the default mTLS endpoint), "never" (always
-                use the default regular endpoint) and "auto" (auto switch to the
-                default mTLS endpoint if client certificate is present, this is
-                the default value). However, the ``api_endpoint`` property takes
-                precedence if provided.
-                (2) If GOOGLE_API_USE_CLIENT_CERTIFICATE environment variable
+                use the default regular endpoint) and "auto" (auto-switch to the
+                default mTLS endpoint if client certificate is present; this is
+                the default value).
+
+                2. If the GOOGLE_API_USE_CLIENT_CERTIFICATE environment variable
                 is "true", then the ``client_cert_source`` property can be used
-                to provide client certificate for mutual TLS transport. If
+                to provide a client certificate for mTLS transport. If
                 not provided, the default SSL client certificate will be used if
                 present. If GOOGLE_API_USE_CLIENT_CERTIFICATE is "false" or not
                 set, no client certificate will be used.
+
+                3. The ``universe_domain`` property can be used to override the
+                default "googleapis.com" universe. Note that the ``api_endpoint``
+                property still takes precedence; and ``universe_domain`` is
+                currently not supported for mTLS.
+
             client_info (google.api_core.gapic_v1.client_info.ClientInfo):
                 The client info used to send a user-agent string along with
                 API requests. If ``None``, then default info will be used.
                 Generally, you only need to set this if you're developing
                 your own client library.
 
         Raises:
             google.auth.exceptions.MutualTLSChannelError: If mutual TLS transport
                 creation failed for any reason.
         """
-        if isinstance(client_options, dict):
-            client_options = client_options_lib.from_dict(client_options)
-        if client_options is None:
-            client_options = client_options_lib.ClientOptions()
-        client_options = cast(client_options_lib.ClientOptions, client_options)
-
-        api_endpoint, client_cert_source_func = self.get_mtls_endpoint_and_cert_source(
-            client_options
+        self._client_options = client_options
+        if isinstance(self._client_options, dict):
+            self._client_options = client_options_lib.from_dict(self._client_options)
+        if self._client_options is None:
+            self._client_options = client_options_lib.ClientOptions()
+        self._client_options = cast(
+            client_options_lib.ClientOptions, self._client_options
+        )
+
+        universe_domain_opt = getattr(self._client_options, "universe_domain", None)
+
+        (
+            self._use_client_cert,
+            self._use_mtls_endpoint,
+            self._universe_domain_env,
+        ) = DataTaxonomyServiceClient._read_environment_variables()
+        self._client_cert_source = DataTaxonomyServiceClient._get_client_cert_source(
+            self._client_options.client_cert_source, self._use_client_cert
+        )
+        self._universe_domain = DataTaxonomyServiceClient._get_universe_domain(
+            universe_domain_opt, self._universe_domain_env
         )
+        self._api_endpoint = None  # updated below, depending on `transport`
+
+        # Initialize the universe domain validation.
+        self._is_universe_domain_valid = False
 
-        api_key_value = getattr(client_options, "api_key", None)
+        api_key_value = getattr(self._client_options, "api_key", None)
         if api_key_value and credentials:
             raise ValueError(
                 "client_options.api_key and credentials are mutually exclusive"
             )
 
         # Save or instantiate the transport.
         # Ordinarily, we provide the transport, but allowing a custom transport
         # instance provides an extensibility point for unusual situations.
-        if isinstance(transport, DataTaxonomyServiceTransport):
+        transport_provided = isinstance(transport, DataTaxonomyServiceTransport)
+        if transport_provided:
             # transport is a DataTaxonomyServiceTransport instance.
-            if credentials or client_options.credentials_file or api_key_value:
+            if credentials or self._client_options.credentials_file or api_key_value:
                 raise ValueError(
                     "When providing a transport instance, "
                     "provide its credentials directly."
                 )
-            if client_options.scopes:
+            if self._client_options.scopes:
                 raise ValueError(
                     "When providing a transport instance, provide its scopes "
                     "directly."
                 )
-            self._transport = transport
-        else:
+            self._transport = cast(DataTaxonomyServiceTransport, transport)
+            self._api_endpoint = self._transport.host
+
+        self._api_endpoint = (
+            self._api_endpoint
+            or DataTaxonomyServiceClient._get_api_endpoint(
+                self._client_options.api_endpoint,
+                self._client_cert_source,
+                self._universe_domain,
+                self._use_mtls_endpoint,
+            )
+        )
+
+        if not transport_provided:
             import google.auth._default  # type: ignore
 
             if api_key_value and hasattr(
                 google.auth._default, "get_api_key_credentials"
             ):
                 credentials = google.auth._default.get_api_key_credentials(
                     api_key_value
                 )
 
-            Transport = type(self).get_transport_class(transport)
-            self._transport = Transport(
+            transport_init: Union[
+                Type[DataTaxonomyServiceTransport],
+                Callable[..., DataTaxonomyServiceTransport],
+            ] = (
+                type(self).get_transport_class(transport)
+                if isinstance(transport, str) or transport is None
+                else cast(Callable[..., DataTaxonomyServiceTransport], transport)
+            )
+            # initialize with the provided callable or the passed in class
+            self._transport = transport_init(
                 credentials=credentials,
-                credentials_file=client_options.credentials_file,
-                host=api_endpoint,
-                scopes=client_options.scopes,
-                client_cert_source_for_mtls=client_cert_source_func,
-                quota_project_id=client_options.quota_project_id,
+                credentials_file=self._client_options.credentials_file,
+                host=self._api_endpoint,
+                scopes=self._client_options.scopes,
+                client_cert_source_for_mtls=self._client_cert_source,
+                quota_project_id=self._client_options.quota_project_id,
                 client_info=client_info,
                 always_use_jwt_access=True,
-                api_audience=client_options.api_audience,
+                api_audience=self._client_options.api_audience,
             )
 
     def create_data_taxonomy(
         self,
         request: Optional[
             Union[gcd_data_taxonomy.CreateDataTaxonomyRequest, dict]
         ] = None,
@@ -591,27 +830,25 @@
                 The result type for the operation will be :class:`google.cloud.dataplex_v1.types.DataTaxonomy` DataTaxonomy represents a set of hierarchical DataAttributes resources,
                    grouped with a common theme Eg:
                    'SensitiveDataTaxonomy' can have attributes to manage
                    PII data. It is defined at project level.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent, data_taxonomy, data_taxonomy_id])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a gcd_data_taxonomy.CreateDataTaxonomyRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, gcd_data_taxonomy.CreateDataTaxonomyRequest):
             request = gcd_data_taxonomy.CreateDataTaxonomyRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if parent is not None:
                 request.parent = parent
             if data_taxonomy is not None:
@@ -625,14 +862,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -719,27 +959,25 @@
                 The result type for the operation will be :class:`google.cloud.dataplex_v1.types.DataTaxonomy` DataTaxonomy represents a set of hierarchical DataAttributes resources,
                    grouped with a common theme Eg:
                    'SensitiveDataTaxonomy' can have attributes to manage
                    PII data. It is defined at project level.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([data_taxonomy, update_mask])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a gcd_data_taxonomy.UpdateDataTaxonomyRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, gcd_data_taxonomy.UpdateDataTaxonomyRequest):
             request = gcd_data_taxonomy.UpdateDataTaxonomyRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if data_taxonomy is not None:
                 request.data_taxonomy = data_taxonomy
             if update_mask is not None:
@@ -753,14 +991,17 @@
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata(
                 (("data_taxonomy.name", request.data_taxonomy.name),)
             ),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -848,27 +1089,25 @@
                          rpc Bar(google.protobuf.Empty) returns
                          (google.protobuf.Empty);
 
                       }
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a data_taxonomy.DeleteDataTaxonomyRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, data_taxonomy.DeleteDataTaxonomyRequest):
             request = data_taxonomy.DeleteDataTaxonomyRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if name is not None:
                 request.name = name
 
@@ -878,14 +1117,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -964,27 +1206,25 @@
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a data_taxonomy.ListDataTaxonomiesRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, data_taxonomy.ListDataTaxonomiesRequest):
             request = data_taxonomy.ListDataTaxonomiesRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if parent is not None:
                 request.parent = parent
 
@@ -994,14 +1234,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1078,27 +1321,25 @@
                 grouped with a common theme Eg:
                 'SensitiveDataTaxonomy' can have
                 attributes to manage PII data. It is
                 defined at project level.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a data_taxonomy.GetDataTaxonomyRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, data_taxonomy.GetDataTaxonomyRequest):
             request = data_taxonomy.GetDataTaxonomyRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if name is not None:
                 request.name = name
 
@@ -1108,14 +1349,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1214,29 +1458,27 @@
                 An object representing a long-running operation.
 
                 The result type for the operation will be :class:`google.cloud.dataplex_v1.types.DataAttributeBinding` DataAttributeBinding represents binding of attributes to resources. Eg: Bind
                    'CustomerInfo' entity with 'PII' attribute.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any(
             [parent, data_attribute_binding, data_attribute_binding_id]
         )
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a data_taxonomy.CreateDataAttributeBindingRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, data_taxonomy.CreateDataAttributeBindingRequest):
             request = data_taxonomy.CreateDataAttributeBindingRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if parent is not None:
                 request.parent = parent
             if data_attribute_binding is not None:
@@ -1252,14 +1494,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1348,27 +1593,25 @@
                 An object representing a long-running operation.
 
                 The result type for the operation will be :class:`google.cloud.dataplex_v1.types.DataAttributeBinding` DataAttributeBinding represents binding of attributes to resources. Eg: Bind
                    'CustomerInfo' entity with 'PII' attribute.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([data_attribute_binding, update_mask])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a data_taxonomy.UpdateDataAttributeBindingRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, data_taxonomy.UpdateDataAttributeBindingRequest):
             request = data_taxonomy.UpdateDataAttributeBindingRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if data_attribute_binding is not None:
                 request.data_attribute_binding = data_attribute_binding
             if update_mask is not None:
@@ -1384,14 +1627,17 @@
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata(
                 (("data_attribute_binding.name", request.data_attribute_binding.name),)
             ),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1482,27 +1728,25 @@
                          rpc Bar(google.protobuf.Empty) returns
                          (google.protobuf.Empty);
 
                       }
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a data_taxonomy.DeleteDataAttributeBindingRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, data_taxonomy.DeleteDataAttributeBindingRequest):
             request = data_taxonomy.DeleteDataAttributeBindingRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if name is not None:
                 request.name = name
 
@@ -1514,14 +1758,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1600,27 +1847,25 @@
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a data_taxonomy.ListDataAttributeBindingsRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, data_taxonomy.ListDataAttributeBindingsRequest):
             request = data_taxonomy.ListDataAttributeBindingsRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if parent is not None:
                 request.parent = parent
 
@@ -1632,14 +1877,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1716,27 +1964,25 @@
                 DataAttributeBinding represents
                 binding of attributes to resources. Eg:
                 Bind 'CustomerInfo' entity with 'PII'
                 attribute.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a data_taxonomy.GetDataAttributeBindingRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, data_taxonomy.GetDataAttributeBindingRequest):
             request = data_taxonomy.GetDataAttributeBindingRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if name is not None:
                 request.name = name
 
@@ -1748,14 +1994,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1850,27 +2099,25 @@
                    hierarchy. A single dataAttribute resource can
                    contain specs of multiple types
 
                    :literal:`\` PII   - ResourceAccessSpec :                 - readers :foo@bar.com   - DataAccessSpec :                 - readers :bar@foo.com`\ \`
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent, data_attribute, data_attribute_id])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a data_taxonomy.CreateDataAttributeRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, data_taxonomy.CreateDataAttributeRequest):
             request = data_taxonomy.CreateDataAttributeRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if parent is not None:
                 request.parent = parent
             if data_attribute is not None:
@@ -1884,14 +2131,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1978,27 +2228,25 @@
                    hierarchy. A single dataAttribute resource can
                    contain specs of multiple types
 
                    :literal:`\` PII   - ResourceAccessSpec :                 - readers :foo@bar.com   - DataAccessSpec :                 - readers :bar@foo.com`\ \`
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([data_attribute, update_mask])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a data_taxonomy.UpdateDataAttributeRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, data_taxonomy.UpdateDataAttributeRequest):
             request = data_taxonomy.UpdateDataAttributeRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if data_attribute is not None:
                 request.data_attribute = data_attribute
             if update_mask is not None:
@@ -2012,14 +2260,17 @@
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata(
                 (("data_attribute.name", request.data_attribute.name),)
             ),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2105,27 +2356,25 @@
                          rpc Bar(google.protobuf.Empty) returns
                          (google.protobuf.Empty);
 
                       }
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a data_taxonomy.DeleteDataAttributeRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, data_taxonomy.DeleteDataAttributeRequest):
             request = data_taxonomy.DeleteDataAttributeRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if name is not None:
                 request.name = name
 
@@ -2135,14 +2384,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2218,27 +2470,25 @@
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a data_taxonomy.ListDataAttributesRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, data_taxonomy.ListDataAttributesRequest):
             request = data_taxonomy.ListDataAttributesRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if parent is not None:
                 request.parent = parent
 
@@ -2248,14 +2498,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2332,27 +2585,25 @@
                    hierarchy. A single dataAttribute resource can
                    contain specs of multiple types
 
                    :literal:`\` PII   - ResourceAccessSpec :                 - readers :foo@bar.com   - DataAccessSpec :                 - readers :bar@foo.com`\ \`
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a data_taxonomy.GetDataAttributeRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, data_taxonomy.GetDataAttributeRequest):
             request = data_taxonomy.GetDataAttributeRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if name is not None:
                 request.name = name
 
@@ -2362,14 +2613,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2429,14 +2683,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2483,14 +2740,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2541,14 +2801,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2595,14 +2858,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2646,14 +2912,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2700,14 +2969,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_taxonomy_service/pagers.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_taxonomy_service/pagers.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_taxonomy_service/transports/__init__.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_taxonomy_service/transports/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_taxonomy_service/transports/base.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_taxonomy_service/transports/base.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -57,15 +57,15 @@
         api_audience: Optional[str] = None,
         **kwargs,
     ) -> None:
         """Instantiate the transport.
 
         Args:
             host (Optional[str]):
-                 The hostname to connect to.
+                 The hostname to connect to (default: 'dataplex.googleapis.com').
             credentials (Optional[google.auth.credentials.Credentials]): The
                 authorization credentials to attach to requests. These
                 credentials identify the application to the service; if none
                 are specified, the client will attempt to ascertain the
                 credentials from the environment.
             credentials_file (Optional[str]): A file with credentials that can
                 be loaded with :func:`google.auth.load_credentials_from_file`.
@@ -120,14 +120,18 @@
         self._credentials = credentials
 
         # Save the hostname. Default to port 443 (HTTPS) if none is specified.
         if ":" not in host:
             host += ":443"
         self._host = host
 
+    @property
+    def host(self):
+        return self._host
+
     def _prep_wrapped_messages(self, client_info):
         # Precompute the wrapped methods.
         self._wrapped_methods = {
             self.create_data_taxonomy: gapic_v1.method.wrap_method(
                 self.create_data_taxonomy,
                 default_timeout=None,
                 client_info=client_info,
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_taxonomy_service/transports/grpc.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_taxonomy_service/transports/grpc.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -52,56 +52,59 @@
     def __init__(
         self,
         *,
         host: str = "dataplex.googleapis.com",
         credentials: Optional[ga_credentials.Credentials] = None,
         credentials_file: Optional[str] = None,
         scopes: Optional[Sequence[str]] = None,
-        channel: Optional[grpc.Channel] = None,
+        channel: Optional[Union[grpc.Channel, Callable[..., grpc.Channel]]] = None,
         api_mtls_endpoint: Optional[str] = None,
         client_cert_source: Optional[Callable[[], Tuple[bytes, bytes]]] = None,
         ssl_channel_credentials: Optional[grpc.ChannelCredentials] = None,
         client_cert_source_for_mtls: Optional[Callable[[], Tuple[bytes, bytes]]] = None,
         quota_project_id: Optional[str] = None,
         client_info: gapic_v1.client_info.ClientInfo = DEFAULT_CLIENT_INFO,
         always_use_jwt_access: Optional[bool] = False,
         api_audience: Optional[str] = None,
     ) -> None:
         """Instantiate the transport.
 
         Args:
             host (Optional[str]):
-                 The hostname to connect to.
+                 The hostname to connect to (default: 'dataplex.googleapis.com').
             credentials (Optional[google.auth.credentials.Credentials]): The
                 authorization credentials to attach to requests. These
                 credentials identify the application to the service; if none
                 are specified, the client will attempt to ascertain the
                 credentials from the environment.
-                This argument is ignored if ``channel`` is provided.
+                This argument is ignored if a ``channel`` instance is provided.
             credentials_file (Optional[str]): A file with credentials that can
                 be loaded with :func:`google.auth.load_credentials_from_file`.
-                This argument is ignored if ``channel`` is provided.
+                This argument is ignored if a ``channel`` instance is provided.
             scopes (Optional(Sequence[str])): A list of scopes. This argument is
-                ignored if ``channel`` is provided.
-            channel (Optional[grpc.Channel]): A ``Channel`` instance through
-                which to make calls.
+                ignored if a ``channel`` instance is provided.
+            channel (Optional[Union[grpc.Channel, Callable[..., grpc.Channel]]]):
+                A ``Channel`` instance through which to make calls, or a Callable
+                that constructs and returns one. If set to None, ``self.create_channel``
+                is used to create the channel. If a Callable is given, it will be called
+                with the same arguments as used in ``self.create_channel``.
             api_mtls_endpoint (Optional[str]): Deprecated. The mutual TLS endpoint.
                 If provided, it overrides the ``host`` argument and tries to create
                 a mutual TLS channel with client SSL credentials from
                 ``client_cert_source`` or application default SSL credentials.
             client_cert_source (Optional[Callable[[], Tuple[bytes, bytes]]]):
                 Deprecated. A callback to provide client SSL certificate bytes and
                 private key bytes, both in PEM format. It is ignored if
                 ``api_mtls_endpoint`` is None.
             ssl_channel_credentials (grpc.ChannelCredentials): SSL credentials
-                for the grpc channel. It is ignored if ``channel`` is provided.
+                for the grpc channel. It is ignored if a ``channel`` instance is provided.
             client_cert_source_for_mtls (Optional[Callable[[], Tuple[bytes, bytes]]]):
                 A callback to provide client certificate bytes and private key bytes,
                 both in PEM format. It is used to configure a mutual TLS channel. It is
-                ignored if ``channel`` or ``ssl_channel_credentials`` is provided.
+                ignored if a ``channel`` instance or ``ssl_channel_credentials`` is provided.
             quota_project_id (Optional[str]): An optional project to use for billing
                 and quota.
             client_info (google.api_core.gapic_v1.client_info.ClientInfo):
                 The client info used to send a user-agent string along with
                 API requests. If ``None``, then default info will be used.
                 Generally, you only need to set this if you're developing
                 your own client library.
@@ -120,15 +123,15 @@
         self._operations_client: Optional[operations_v1.OperationsClient] = None
 
         if api_mtls_endpoint:
             warnings.warn("api_mtls_endpoint is deprecated", DeprecationWarning)
         if client_cert_source:
             warnings.warn("client_cert_source is deprecated", DeprecationWarning)
 
-        if channel:
+        if isinstance(channel, grpc.Channel):
             # Ignore credentials if a channel was passed.
             credentials = False
             # If a channel was explicitly provided, set it.
             self._grpc_channel = channel
             self._ssl_channel_credentials = None
 
         else:
@@ -161,15 +164,17 @@
             quota_project_id=quota_project_id,
             client_info=client_info,
             always_use_jwt_access=always_use_jwt_access,
             api_audience=api_audience,
         )
 
         if not self._grpc_channel:
-            self._grpc_channel = type(self).create_channel(
+            # initialize with the provided callable or the default channel
+            channel_init = channel or type(self).create_channel
+            self._grpc_channel = channel_init(
                 self._host,
                 # use the credentials which are saved
                 credentials=self._credentials,
                 # Set ``credentials_file`` to ``None`` here as
                 # the credentials that we saved earlier should be used.
                 credentials_file=None,
                 scopes=self._scopes,
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/data_taxonomy_service/transports/grpc_asyncio.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/data_taxonomy_service/transports/grpc_asyncio.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,17 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 from typing import Awaitable, Callable, Dict, Optional, Sequence, Tuple, Union
 import warnings
 
+from google.api_core import exceptions as core_exceptions
 from google.api_core import gapic_v1, grpc_helpers_async, operations_v1
+from google.api_core import retry_async as retries
 from google.auth import credentials as ga_credentials  # type: ignore
 from google.auth.transport.grpc import SslCredentials  # type: ignore
 from google.cloud.location import locations_pb2  # type: ignore
 from google.iam.v1 import iam_policy_pb2  # type: ignore
 from google.iam.v1 import policy_pb2  # type: ignore
 from google.longrunning import operations_pb2  # type: ignore
 import grpc  # type: ignore
@@ -67,15 +69,14 @@
             credentials (Optional[~.Credentials]): The
                 authorization credentials to attach to requests. These
                 credentials identify this application to the service. If
                 none are specified, the client will attempt to ascertain
                 the credentials from the environment.
             credentials_file (Optional[str]): A file with credentials that can
                 be loaded with :func:`google.auth.load_credentials_from_file`.
-                This argument is ignored if ``channel`` is provided.
             scopes (Optional[Sequence[str]]): A optional list of scopes needed for this
                 service. These are only used when credentials are not specified and
                 are passed to :func:`google.auth.default`.
             quota_project_id (Optional[str]): An optional project to use for billing
                 and quota.
             kwargs (Optional[dict]): Keyword arguments, which are passed to the
                 channel creation.
@@ -97,57 +98,60 @@
     def __init__(
         self,
         *,
         host: str = "dataplex.googleapis.com",
         credentials: Optional[ga_credentials.Credentials] = None,
         credentials_file: Optional[str] = None,
         scopes: Optional[Sequence[str]] = None,
-        channel: Optional[aio.Channel] = None,
+        channel: Optional[Union[aio.Channel, Callable[..., aio.Channel]]] = None,
         api_mtls_endpoint: Optional[str] = None,
         client_cert_source: Optional[Callable[[], Tuple[bytes, bytes]]] = None,
         ssl_channel_credentials: Optional[grpc.ChannelCredentials] = None,
         client_cert_source_for_mtls: Optional[Callable[[], Tuple[bytes, bytes]]] = None,
         quota_project_id: Optional[str] = None,
         client_info: gapic_v1.client_info.ClientInfo = DEFAULT_CLIENT_INFO,
         always_use_jwt_access: Optional[bool] = False,
         api_audience: Optional[str] = None,
     ) -> None:
         """Instantiate the transport.
 
         Args:
             host (Optional[str]):
-                 The hostname to connect to.
+                 The hostname to connect to (default: 'dataplex.googleapis.com').
             credentials (Optional[google.auth.credentials.Credentials]): The
                 authorization credentials to attach to requests. These
                 credentials identify the application to the service; if none
                 are specified, the client will attempt to ascertain the
                 credentials from the environment.
-                This argument is ignored if ``channel`` is provided.
+                This argument is ignored if a ``channel`` instance is provided.
             credentials_file (Optional[str]): A file with credentials that can
                 be loaded with :func:`google.auth.load_credentials_from_file`.
-                This argument is ignored if ``channel`` is provided.
+                This argument is ignored if a ``channel`` instance is provided.
             scopes (Optional[Sequence[str]]): A optional list of scopes needed for this
                 service. These are only used when credentials are not specified and
                 are passed to :func:`google.auth.default`.
-            channel (Optional[aio.Channel]): A ``Channel`` instance through
-                which to make calls.
+            channel (Optional[Union[aio.Channel, Callable[..., aio.Channel]]]):
+                A ``Channel`` instance through which to make calls, or a Callable
+                that constructs and returns one. If set to None, ``self.create_channel``
+                is used to create the channel. If a Callable is given, it will be called
+                with the same arguments as used in ``self.create_channel``.
             api_mtls_endpoint (Optional[str]): Deprecated. The mutual TLS endpoint.
                 If provided, it overrides the ``host`` argument and tries to create
                 a mutual TLS channel with client SSL credentials from
                 ``client_cert_source`` or application default SSL credentials.
             client_cert_source (Optional[Callable[[], Tuple[bytes, bytes]]]):
                 Deprecated. A callback to provide client SSL certificate bytes and
                 private key bytes, both in PEM format. It is ignored if
                 ``api_mtls_endpoint`` is None.
             ssl_channel_credentials (grpc.ChannelCredentials): SSL credentials
-                for the grpc channel. It is ignored if ``channel`` is provided.
+                for the grpc channel. It is ignored if a ``channel`` instance is provided.
             client_cert_source_for_mtls (Optional[Callable[[], Tuple[bytes, bytes]]]):
                 A callback to provide client certificate bytes and private key bytes,
                 both in PEM format. It is used to configure a mutual TLS channel. It is
-                ignored if ``channel`` or ``ssl_channel_credentials`` is provided.
+                ignored if a ``channel`` instance or ``ssl_channel_credentials`` is provided.
             quota_project_id (Optional[str]): An optional project to use for billing
                 and quota.
             client_info (google.api_core.gapic_v1.client_info.ClientInfo):
                 The client info used to send a user-agent string along with
                 API requests. If ``None``, then default info will be used.
                 Generally, you only need to set this if you're developing
                 your own client library.
@@ -166,15 +170,15 @@
         self._operations_client: Optional[operations_v1.OperationsAsyncClient] = None
 
         if api_mtls_endpoint:
             warnings.warn("api_mtls_endpoint is deprecated", DeprecationWarning)
         if client_cert_source:
             warnings.warn("client_cert_source is deprecated", DeprecationWarning)
 
-        if channel:
+        if isinstance(channel, aio.Channel):
             # Ignore credentials if a channel was passed.
             credentials = False
             # If a channel was explicitly provided, set it.
             self._grpc_channel = channel
             self._ssl_channel_credentials = None
         else:
             if api_mtls_endpoint:
@@ -206,15 +210,17 @@
             quota_project_id=quota_project_id,
             client_info=client_info,
             always_use_jwt_access=always_use_jwt_access,
             api_audience=api_audience,
         )
 
         if not self._grpc_channel:
-            self._grpc_channel = type(self).create_channel(
+            # initialize with the provided callable or the default channel
+            channel_init = channel or type(self).create_channel
+            self._grpc_channel = channel_init(
                 self._host,
                 # use the credentials which are saved
                 credentials=self._credentials,
                 # Set ``credentials_file`` to ``None`` here as
                 # the credentials that we saved earlier should be used.
                 credentials_file=None,
                 scopes=self._scopes,
@@ -692,14 +698,94 @@
             self._stubs["get_data_attribute"] = self.grpc_channel.unary_unary(
                 "/google.cloud.dataplex.v1.DataTaxonomyService/GetDataAttribute",
                 request_serializer=data_taxonomy.GetDataAttributeRequest.serialize,
                 response_deserializer=data_taxonomy.DataAttribute.deserialize,
             )
         return self._stubs["get_data_attribute"]
 
+    def _prep_wrapped_messages(self, client_info):
+        """Precompute the wrapped methods, overriding the base class method to use async wrappers."""
+        self._wrapped_methods = {
+            self.create_data_taxonomy: gapic_v1.method_async.wrap_method(
+                self.create_data_taxonomy,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+            self.update_data_taxonomy: gapic_v1.method_async.wrap_method(
+                self.update_data_taxonomy,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+            self.delete_data_taxonomy: gapic_v1.method_async.wrap_method(
+                self.delete_data_taxonomy,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+            self.list_data_taxonomies: gapic_v1.method_async.wrap_method(
+                self.list_data_taxonomies,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+            self.get_data_taxonomy: gapic_v1.method_async.wrap_method(
+                self.get_data_taxonomy,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+            self.create_data_attribute_binding: gapic_v1.method_async.wrap_method(
+                self.create_data_attribute_binding,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+            self.update_data_attribute_binding: gapic_v1.method_async.wrap_method(
+                self.update_data_attribute_binding,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+            self.delete_data_attribute_binding: gapic_v1.method_async.wrap_method(
+                self.delete_data_attribute_binding,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+            self.list_data_attribute_bindings: gapic_v1.method_async.wrap_method(
+                self.list_data_attribute_bindings,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+            self.get_data_attribute_binding: gapic_v1.method_async.wrap_method(
+                self.get_data_attribute_binding,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+            self.create_data_attribute: gapic_v1.method_async.wrap_method(
+                self.create_data_attribute,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+            self.update_data_attribute: gapic_v1.method_async.wrap_method(
+                self.update_data_attribute,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+            self.delete_data_attribute: gapic_v1.method_async.wrap_method(
+                self.delete_data_attribute,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+            self.list_data_attributes: gapic_v1.method_async.wrap_method(
+                self.list_data_attributes,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+            self.get_data_attribute: gapic_v1.method_async.wrap_method(
+                self.get_data_attribute,
+                default_timeout=None,
+                client_info=client_info,
+            ),
+        }
+
     def close(self):
         return self.grpc_channel.close()
 
     @property
     def delete_operation(
         self,
     ) -> Callable[[operations_pb2.DeleteOperationRequest], None]:
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/dataplex_service/__init__.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/dataplex_service/__init__.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/dataplex_service/async_client.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/dataplex_service/async_client.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,38 +13,39 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 from collections import OrderedDict
 import functools
 import re
 from typing import (
+    Callable,
     Dict,
     Mapping,
     MutableMapping,
     MutableSequence,
     Optional,
     Sequence,
     Tuple,
     Type,
     Union,
 )
 
 from google.api_core import exceptions as core_exceptions
 from google.api_core import gapic_v1
-from google.api_core import retry as retries
+from google.api_core import retry_async as retries
 from google.api_core.client_options import ClientOptions
 from google.auth import credentials as ga_credentials  # type: ignore
 from google.oauth2 import service_account  # type: ignore
 
 from google.cloud.dataplex_v1 import gapic_version as package_version
 
 try:
-    OptionalRetry = Union[retries.Retry, gapic_v1.method._MethodDefault]
+    OptionalRetry = Union[retries.AsyncRetry, gapic_v1.method._MethodDefault, None]
 except AttributeError:  # pragma: NO COVER
-    OptionalRetry = Union[retries.Retry, object]  # type: ignore
+    OptionalRetry = Union[retries.AsyncRetry, object, None]  # type: ignore
 
 from google.api_core import operation  # type: ignore
 from google.api_core import operation_async  # type: ignore
 from google.cloud.location import locations_pb2  # type: ignore
 from google.iam.v1 import iam_policy_pb2  # type: ignore
 from google.iam.v1 import policy_pb2  # type: ignore
 from google.longrunning import operations_pb2  # type: ignore
@@ -67,16 +68,20 @@
     organize, manage, secure and catalog data across their
     organization located across cloud projects in a variety of
     storage systems including Cloud Storage and BigQuery.
     """
 
     _client: DataplexServiceClient
 
+    # Copy defaults from the synchronous client for use here.
+    # Note: DEFAULT_ENDPOINT is deprecated. Use _DEFAULT_ENDPOINT_TEMPLATE instead.
     DEFAULT_ENDPOINT = DataplexServiceClient.DEFAULT_ENDPOINT
     DEFAULT_MTLS_ENDPOINT = DataplexServiceClient.DEFAULT_MTLS_ENDPOINT
+    _DEFAULT_ENDPOINT_TEMPLATE = DataplexServiceClient._DEFAULT_ENDPOINT_TEMPLATE
+    _DEFAULT_UNIVERSE = DataplexServiceClient._DEFAULT_UNIVERSE
 
     action_path = staticmethod(DataplexServiceClient.action_path)
     parse_action_path = staticmethod(DataplexServiceClient.parse_action_path)
     asset_path = staticmethod(DataplexServiceClient.asset_path)
     parse_asset_path = staticmethod(DataplexServiceClient.parse_asset_path)
     environment_path = staticmethod(DataplexServiceClient.environment_path)
     parse_environment_path = staticmethod(DataplexServiceClient.parse_environment_path)
@@ -189,54 +194,94 @@
         """Returns the transport used by the client instance.
 
         Returns:
             DataplexServiceTransport: The transport used by the client instance.
         """
         return self._client.transport
 
+    @property
+    def api_endpoint(self):
+        """Return the API endpoint used by the client instance.
+
+        Returns:
+            str: The API endpoint used by the client instance.
+        """
+        return self._client._api_endpoint
+
+    @property
+    def universe_domain(self) -> str:
+        """Return the universe domain used by the client instance.
+
+        Returns:
+            str: The universe domain used
+                by the client instance.
+        """
+        return self._client._universe_domain
+
     get_transport_class = functools.partial(
         type(DataplexServiceClient).get_transport_class, type(DataplexServiceClient)
     )
 
     def __init__(
         self,
         *,
         credentials: Optional[ga_credentials.Credentials] = None,
-        transport: Union[str, DataplexServiceTransport] = "grpc_asyncio",
+        transport: Optional[
+            Union[
+                str, DataplexServiceTransport, Callable[..., DataplexServiceTransport]
+            ]
+        ] = "grpc_asyncio",
         client_options: Optional[ClientOptions] = None,
         client_info: gapic_v1.client_info.ClientInfo = DEFAULT_CLIENT_INFO,
     ) -> None:
-        """Instantiates the dataplex service client.
+        """Instantiates the dataplex service async client.
 
         Args:
             credentials (Optional[google.auth.credentials.Credentials]): The
                 authorization credentials to attach to requests. These
                 credentials identify the application to the service; if none
                 are specified, the client will attempt to ascertain the
                 credentials from the environment.
-            transport (Union[str, ~.DataplexServiceTransport]): The
-                transport to use. If set to None, a transport is chosen
-                automatically.
-            client_options (ClientOptions): Custom options for the client. It
-                won't take effect if a ``transport`` instance is provided.
-                (1) The ``api_endpoint`` property can be used to override the
-                default endpoint provided by the client. GOOGLE_API_USE_MTLS_ENDPOINT
-                environment variable can also be used to override the endpoint:
+            transport (Optional[Union[str,DataplexServiceTransport,Callable[..., DataplexServiceTransport]]]):
+                The transport to use, or a Callable that constructs and returns a new transport to use.
+                If a Callable is given, it will be called with the same set of initialization
+                arguments as used in the DataplexServiceTransport constructor.
+                If set to None, a transport is chosen automatically.
+            client_options (Optional[Union[google.api_core.client_options.ClientOptions, dict]]):
+                Custom options for the client.
+
+                1. The ``api_endpoint`` property can be used to override the
+                default endpoint provided by the client when ``transport`` is
+                not explicitly provided. Only if this property is not set and
+                ``transport`` was not explicitly provided, the endpoint is
+                determined by the GOOGLE_API_USE_MTLS_ENDPOINT environment
+                variable, which have one of the following values:
                 "always" (always use the default mTLS endpoint), "never" (always
-                use the default regular endpoint) and "auto" (auto switch to the
-                default mTLS endpoint if client certificate is present, this is
-                the default value). However, the ``api_endpoint`` property takes
-                precedence if provided.
-                (2) If GOOGLE_API_USE_CLIENT_CERTIFICATE environment variable
+                use the default regular endpoint) and "auto" (auto-switch to the
+                default mTLS endpoint if client certificate is present; this is
+                the default value).
+
+                2. If the GOOGLE_API_USE_CLIENT_CERTIFICATE environment variable
                 is "true", then the ``client_cert_source`` property can be used
-                to provide client certificate for mutual TLS transport. If
+                to provide a client certificate for mTLS transport. If
                 not provided, the default SSL client certificate will be used if
                 present. If GOOGLE_API_USE_CLIENT_CERTIFICATE is "false" or not
                 set, no client certificate will be used.
 
+                3. The ``universe_domain`` property can be used to override the
+                default "googleapis.com" universe. Note that ``api_endpoint``
+                property still takes precedence; and ``universe_domain`` is
+                currently not supported for mTLS.
+
+            client_info (google.api_core.gapic_v1.client_info.ClientInfo):
+                The client info used to send a user-agent string along with
+                API requests. If ``None``, then default info will be used.
+                Generally, you only need to set this if you're developing
+                your own client library.
+
         Raises:
             google.auth.exceptions.MutualTlsChannelError: If mutual TLS transport
                 creation failed for any reason.
         """
         self._client = DataplexServiceClient(
             credentials=credentials,
             transport=transport,
@@ -316,15 +361,15 @@
                 -  Must be between 1-63 characters.
                 -  Must be unique within the customer project /
                    location.
 
                 This corresponds to the ``lake_id`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.api_core.operation_async.AsyncOperation:
@@ -341,48 +386,52 @@
                    their data at scale, and provides data scientists and
                    data engineers an integrated experience to easily
                    search, discover, analyze and transform data and
                    associated metadata.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent, lake, lake_id])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.CreateLakeRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.CreateLakeRequest):
+            request = service.CreateLakeRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if parent is not None:
             request.parent = parent
         if lake is not None:
             request.lake = lake
         if lake_id is not None:
             request.lake_id = lake_id
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.create_lake,
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.create_lake
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -450,15 +499,15 @@
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             update_mask (:class:`google.protobuf.field_mask_pb2.FieldMask`):
                 Required. Mask of fields to update.
                 This corresponds to the ``update_mask`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.api_core.operation_async.AsyncOperation:
@@ -475,48 +524,52 @@
                    their data at scale, and provides data scientists and
                    data engineers an integrated experience to easily
                    search, discover, analyze and transform data and
                    associated metadata.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([lake, update_mask])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.UpdateLakeRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.UpdateLakeRequest):
+            request = service.UpdateLakeRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if lake is not None:
             request.lake = lake
         if update_mask is not None:
             request.update_mask = update_mask
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.update_lake,
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.update_lake
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata(
                 (("lake.name", request.lake.name),)
             ),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -580,15 +633,15 @@
             name (:class:`str`):
                 Required. The resource name of the lake:
                 ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}``.
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.api_core.operation_async.AsyncOperation:
@@ -603,44 +656,48 @@
                          rpc Bar(google.protobuf.Empty) returns
                          (google.protobuf.Empty);
 
                       }
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.DeleteLakeRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.DeleteLakeRequest):
+            request = service.DeleteLakeRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if name is not None:
             request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.delete_lake,
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.delete_lake
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -702,15 +759,15 @@
                 form:
                 ``projects/{project_number}/locations/{location_id}``
                 where ``location_id`` refers to a GCP region.
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.services.dataplex_service.pagers.ListLakesAsyncPager:
@@ -718,53 +775,48 @@
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.ListLakesRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.ListLakesRequest):
+            request = service.ListLakesRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if parent is not None:
             request.parent = parent
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.list_lakes,
-            default_retry=retries.Retry(
-                initial=1.0,
-                maximum=10.0,
-                multiplier=1.3,
-                predicate=retries.if_exception_type(
-                    core_exceptions.ServiceUnavailable,
-                ),
-                deadline=60.0,
-            ),
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.list_lakes
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -824,15 +876,15 @@
             name (:class:`str`):
                 Required. The resource name of the lake:
                 ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}``.
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.types.Lake:
@@ -851,53 +903,46 @@
                 provides data scientists and data
                 engineers an integrated experience to
                 easily search, discover, analyze and
                 transform data and associated metadata.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.GetLakeRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.GetLakeRequest):
+            request = service.GetLakeRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if name is not None:
             request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.get_lake,
-            default_retry=retries.Retry(
-                initial=1.0,
-                maximum=10.0,
-                multiplier=1.3,
-                predicate=retries.if_exception_type(
-                    core_exceptions.ServiceUnavailable,
-                ),
-                deadline=60.0,
-            ),
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[self._client._transport.get_lake]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -949,15 +994,15 @@
             parent (:class:`str`):
                 Required. The resource name of the parent lake:
                 ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}``.
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.services.dataplex_service.pagers.ListLakeActionsAsyncPager:
@@ -965,53 +1010,48 @@
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.ListLakeActionsRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.ListLakeActionsRequest):
+            request = service.ListLakeActionsRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if parent is not None:
             request.parent = parent
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.list_lake_actions,
-            default_retry=retries.Retry(
-                initial=1.0,
-                maximum=10.0,
-                multiplier=1.3,
-                predicate=retries.if_exception_type(
-                    core_exceptions.ServiceUnavailable,
-                ),
-                deadline=60.0,
-            ),
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.list_lake_actions
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1106,15 +1146,15 @@
                    a project.
                 -  Must not be one of the reserved IDs (i.e. "default",
                    "global-temp")
 
                 This corresponds to the ``zone_id`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.api_core.operation_async.AsyncOperation:
@@ -1124,48 +1164,52 @@
                    be used to map to organizational structure or
                    represent stages of data readiness from raw to
                    curated. It provides managing behavior that is shared
                    or inherited by all contained assets.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent, zone, zone_id])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.CreateZoneRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.CreateZoneRequest):
+            request = service.CreateZoneRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if parent is not None:
             request.parent = parent
         if zone is not None:
             request.zone = zone
         if zone_id is not None:
             request.zone_id = zone_id
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.create_zone,
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.create_zone
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1238,15 +1282,15 @@
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             update_mask (:class:`google.protobuf.field_mask_pb2.FieldMask`):
                 Required. Mask of fields to update.
                 This corresponds to the ``update_mask`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.api_core.operation_async.AsyncOperation:
@@ -1256,48 +1300,52 @@
                    be used to map to organizational structure or
                    represent stages of data readiness from raw to
                    curated. It provides managing behavior that is shared
                    or inherited by all contained assets.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([zone, update_mask])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.UpdateZoneRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.UpdateZoneRequest):
+            request = service.UpdateZoneRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if zone is not None:
             request.zone = zone
         if update_mask is not None:
             request.update_mask = update_mask
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.update_zone,
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.update_zone
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata(
                 (("zone.name", request.zone.name),)
             ),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1361,15 +1409,15 @@
             name (:class:`str`):
                 Required. The resource name of the zone:
                 ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}``.
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.api_core.operation_async.AsyncOperation:
@@ -1384,44 +1432,48 @@
                          rpc Bar(google.protobuf.Empty) returns
                          (google.protobuf.Empty);
 
                       }
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.DeleteZoneRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.DeleteZoneRequest):
+            request = service.DeleteZoneRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if name is not None:
             request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.delete_zone,
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.delete_zone
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1481,15 +1533,15 @@
             parent (:class:`str`):
                 Required. The resource name of the parent lake:
                 ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}``.
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.services.dataplex_service.pagers.ListZonesAsyncPager:
@@ -1497,53 +1549,48 @@
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.ListZonesRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.ListZonesRequest):
+            request = service.ListZonesRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if parent is not None:
             request.parent = parent
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.list_zones,
-            default_retry=retries.Retry(
-                initial=1.0,
-                maximum=10.0,
-                multiplier=1.3,
-                predicate=retries.if_exception_type(
-                    core_exceptions.ServiceUnavailable,
-                ),
-                deadline=60.0,
-            ),
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.list_zones
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1603,15 +1650,15 @@
             name (:class:`str`):
                 Required. The resource name of the zone:
                 ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}``.
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.types.Zone:
@@ -1622,53 +1669,46 @@
                 readiness from raw to curated. It
                 provides managing behavior that is
                 shared or inherited by all contained
                 assets.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.GetZoneRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.GetZoneRequest):
+            request = service.GetZoneRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if name is not None:
             request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.get_zone,
-            default_retry=retries.Retry(
-                initial=1.0,
-                maximum=10.0,
-                multiplier=1.3,
-                predicate=retries.if_exception_type(
-                    core_exceptions.ServiceUnavailable,
-                ),
-                deadline=60.0,
-            ),
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[self._client._transport.get_zone]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1720,15 +1760,15 @@
             parent (:class:`str`):
                 Required. The resource name of the parent zone:
                 ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}``.
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.services.dataplex_service.pagers.ListZoneActionsAsyncPager:
@@ -1736,53 +1776,48 @@
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.ListZoneActionsRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.ListZoneActionsRequest):
+            request = service.ListZoneActionsRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if parent is not None:
             request.parent = parent
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.list_zone_actions,
-            default_retry=retries.Retry(
-                initial=1.0,
-                maximum=10.0,
-                multiplier=1.3,
-                predicate=retries.if_exception_type(
-                    core_exceptions.ServiceUnavailable,
-                ),
-                deadline=60.0,
-            ),
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.list_zone_actions
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1873,63 +1908,67 @@
                 -  Must end with a number or a letter.
                 -  Must be between 1-63 characters.
                 -  Must be unique within the zone.
 
                 This corresponds to the ``asset_id`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.api_core.operation_async.AsyncOperation:
                 An object representing a long-running operation.
 
                 The result type for the operation will be :class:`google.cloud.dataplex_v1.types.Asset` An asset represents a cloud resource that is being managed within a lake as a
                    member of a zone.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent, asset, asset_id])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.CreateAssetRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.CreateAssetRequest):
+            request = service.CreateAssetRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if parent is not None:
             request.parent = parent
         if asset is not None:
             request.asset = asset
         if asset_id is not None:
             request.asset_id = asset_id
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.create_asset,
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.create_asset
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2001,63 +2040,67 @@
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             update_mask (:class:`google.protobuf.field_mask_pb2.FieldMask`):
                 Required. Mask of fields to update.
                 This corresponds to the ``update_mask`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.api_core.operation_async.AsyncOperation:
                 An object representing a long-running operation.
 
                 The result type for the operation will be :class:`google.cloud.dataplex_v1.types.Asset` An asset represents a cloud resource that is being managed within a lake as a
                    member of a zone.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([asset, update_mask])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.UpdateAssetRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.UpdateAssetRequest):
+            request = service.UpdateAssetRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if asset is not None:
             request.asset = asset
         if update_mask is not None:
             request.update_mask = update_mask
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.update_asset,
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.update_asset
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata(
                 (("asset.name", request.asset.name),)
             ),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2122,15 +2165,15 @@
             name (:class:`str`):
                 Required. The resource name of the asset:
                 ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/assets/{asset_id}``.
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.api_core.operation_async.AsyncOperation:
@@ -2145,44 +2188,48 @@
                          rpc Bar(google.protobuf.Empty) returns
                          (google.protobuf.Empty);
 
                       }
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.DeleteAssetRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.DeleteAssetRequest):
+            request = service.DeleteAssetRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if name is not None:
             request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.delete_asset,
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.delete_asset
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2242,15 +2289,15 @@
             parent (:class:`str`):
                 Required. The resource name of the parent zone:
                 ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}``.
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.services.dataplex_service.pagers.ListAssetsAsyncPager:
@@ -2258,53 +2305,48 @@
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.ListAssetsRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.ListAssetsRequest):
+            request = service.ListAssetsRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if parent is not None:
             request.parent = parent
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.list_assets,
-            default_retry=retries.Retry(
-                initial=1.0,
-                maximum=10.0,
-                multiplier=1.3,
-                predicate=retries.if_exception_type(
-                    core_exceptions.ServiceUnavailable,
-                ),
-                deadline=60.0,
-            ),
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.list_assets
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2364,67 +2406,62 @@
             name (:class:`str`):
                 Required. The resource name of the asset:
                 ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/assets/{asset_id}``.
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.types.Asset:
                 An asset represents a cloud resource
                 that is being managed within a lake as a
                 member of a zone.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.GetAssetRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.GetAssetRequest):
+            request = service.GetAssetRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if name is not None:
             request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.get_asset,
-            default_retry=retries.Retry(
-                initial=1.0,
-                maximum=10.0,
-                multiplier=1.3,
-                predicate=retries.if_exception_type(
-                    core_exceptions.ServiceUnavailable,
-                ),
-                deadline=60.0,
-            ),
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.get_asset
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2476,15 +2513,15 @@
             parent (:class:`str`):
                 Required. The resource name of the parent asset:
                 ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/assets/{asset_id}``.
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.services.dataplex_service.pagers.ListAssetActionsAsyncPager:
@@ -2492,53 +2529,48 @@
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.ListAssetActionsRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.ListAssetActionsRequest):
+            request = service.ListAssetActionsRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if parent is not None:
             request.parent = parent
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.list_asset_actions,
-            default_retry=retries.Retry(
-                initial=1.0,
-                maximum=10.0,
-                multiplier=1.3,
-                predicate=retries.if_exception_type(
-                    core_exceptions.ServiceUnavailable,
-                ),
-                deadline=60.0,
-            ),
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.list_asset_actions
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2622,15 +2654,15 @@
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             task_id (:class:`str`):
                 Required. Task identifier.
                 This corresponds to the ``task_id`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.api_core.operation_async.AsyncOperation:
@@ -2638,48 +2670,52 @@
 
                 The result type for the operation will be
                 :class:`google.cloud.dataplex_v1.types.Task` A task
                 represents a user-visible job.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent, task, task_id])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.CreateTaskRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.CreateTaskRequest):
+            request = service.CreateTaskRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if parent is not None:
             request.parent = parent
         if task is not None:
             request.task = task
         if task_id is not None:
             request.task_id = task_id
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.create_task,
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.create_task
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2754,15 +2790,15 @@
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             update_mask (:class:`google.protobuf.field_mask_pb2.FieldMask`):
                 Required. Mask of fields to update.
                 This corresponds to the ``update_mask`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.api_core.operation_async.AsyncOperation:
@@ -2770,48 +2806,52 @@
 
                 The result type for the operation will be
                 :class:`google.cloud.dataplex_v1.types.Task` A task
                 represents a user-visible job.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([task, update_mask])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.UpdateTaskRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.UpdateTaskRequest):
+            request = service.UpdateTaskRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if task is not None:
             request.task = task
         if update_mask is not None:
             request.update_mask = update_mask
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.update_task,
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.update_task
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata(
                 (("task.name", request.task.name),)
             ),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2874,15 +2914,15 @@
             name (:class:`str`):
                 Required. The resource name of the task:
                 ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}/task/{task_id}``.
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.api_core.operation_async.AsyncOperation:
@@ -2897,44 +2937,48 @@
                          rpc Bar(google.protobuf.Empty) returns
                          (google.protobuf.Empty);
 
                       }
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.DeleteTaskRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.DeleteTaskRequest):
+            request = service.DeleteTaskRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if name is not None:
             request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.delete_task,
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.delete_task
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2994,15 +3038,15 @@
             parent (:class:`str`):
                 Required. The resource name of the parent lake:
                 ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}``.
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.services.dataplex_service.pagers.ListTasksAsyncPager:
@@ -3010,53 +3054,48 @@
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.ListTasksRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.ListTasksRequest):
+            request = service.ListTasksRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if parent is not None:
             request.parent = parent
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.list_tasks,
-            default_retry=retries.Retry(
-                initial=1.0,
-                maximum=10.0,
-                multiplier=1.3,
-                predicate=retries.if_exception_type(
-                    core_exceptions.ServiceUnavailable,
-                ),
-                deadline=60.0,
-            ),
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.list_tasks
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -3116,64 +3155,57 @@
             name (:class:`str`):
                 Required. The resource name of the task:
                 ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}/tasks/{tasks_id}``.
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.types.Task:
                 A task represents a user-visible job.
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.GetTaskRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.GetTaskRequest):
+            request = service.GetTaskRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if name is not None:
             request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.get_task,
-            default_retry=retries.Retry(
-                initial=1.0,
-                maximum=10.0,
-                multiplier=1.3,
-                predicate=retries.if_exception_type(
-                    core_exceptions.ServiceUnavailable,
-                ),
-                deadline=60.0,
-            ),
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[self._client._transport.get_task]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -3225,15 +3257,15 @@
             parent (:class:`str`):
                 Required. The resource name of the parent environment:
                 ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}/tasks/{task_id}``.
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.services.dataplex_service.pagers.ListJobsAsyncPager:
@@ -3241,53 +3273,48 @@
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.ListJobsRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.ListJobsRequest):
+            request = service.ListJobsRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if parent is not None:
             request.parent = parent
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.list_jobs,
-            default_retry=retries.Retry(
-                initial=1.0,
-                maximum=10.0,
-                multiplier=1.3,
-                predicate=retries.if_exception_type(
-                    core_exceptions.ServiceUnavailable,
-                ),
-                deadline=60.0,
-            ),
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.list_jobs
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -3347,55 +3374,57 @@
             name (:class:`str`):
                 Required. The resource name of the task:
                 ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}/tasks/{task_id}``.
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.types.RunTaskResponse:
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.RunTaskRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.RunTaskRequest):
+            request = service.RunTaskRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if name is not None:
             request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.run_task,
-            default_timeout=None,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[self._client._transport.run_task]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -3446,66 +3475,59 @@
             name (:class:`str`):
                 Required. The resource name of the job:
                 ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}/tasks/{task_id}/jobs/{job_id}``.
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.types.Job:
                 A job represents an instance of a
                 task.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.GetJobRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.GetJobRequest):
+            request = service.GetJobRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if name is not None:
             request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.get_job,
-            default_retry=retries.Retry(
-                initial=1.0,
-                maximum=10.0,
-                multiplier=1.3,
-                predicate=retries.if_exception_type(
-                    core_exceptions.ServiceUnavailable,
-                ),
-                deadline=60.0,
-            ),
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[self._client._transport.get_job]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -3553,51 +3575,55 @@
             name (:class:`str`):
                 Required. The resource name of the job:
                 ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}/task/{task_id}/job/{job_id}``.
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.CancelJobRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.CancelJobRequest):
+            request = service.CancelJobRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if name is not None:
             request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.cancel_job,
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.cancel_job
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -3674,63 +3700,67 @@
                 -  Must be between 1-63 characters.
                 -  Must end with a number or a letter.
                 -  Must be unique within the lake.
 
                 This corresponds to the ``environment_id`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.api_core.operation_async.AsyncOperation:
                 An object representing a long-running operation.
 
                 The result type for the operation will be :class:`google.cloud.dataplex_v1.types.Environment` Environment represents a user-visible compute infrastructure for analytics
                    within a lake.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent, environment, environment_id])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.CreateEnvironmentRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.CreateEnvironmentRequest):
+            request = service.CreateEnvironmentRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if parent is not None:
             request.parent = parent
         if environment is not None:
             request.environment = environment
         if environment_id is not None:
             request.environment_id = environment_id
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.create_environment,
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.create_environment
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -3802,63 +3832,67 @@
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             update_mask (:class:`google.protobuf.field_mask_pb2.FieldMask`):
                 Required. Mask of fields to update.
                 This corresponds to the ``update_mask`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.api_core.operation_async.AsyncOperation:
                 An object representing a long-running operation.
 
                 The result type for the operation will be :class:`google.cloud.dataplex_v1.types.Environment` Environment represents a user-visible compute infrastructure for analytics
                    within a lake.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([environment, update_mask])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.UpdateEnvironmentRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.UpdateEnvironmentRequest):
+            request = service.UpdateEnvironmentRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if environment is not None:
             request.environment = environment
         if update_mask is not None:
             request.update_mask = update_mask
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.update_environment,
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.update_environment
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata(
                 (("environment.name", request.environment.name),)
             ),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -3923,15 +3957,15 @@
             name (:class:`str`):
                 Required. The resource name of the environment:
                 ``projects/{project_id}/locations/{location_id}/lakes/{lake_id}/environments/{environment_id}``.
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.api_core.operation_async.AsyncOperation:
@@ -3946,44 +3980,48 @@
                          rpc Bar(google.protobuf.Empty) returns
                          (google.protobuf.Empty);
 
                       }
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.DeleteEnvironmentRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.DeleteEnvironmentRequest):
+            request = service.DeleteEnvironmentRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if name is not None:
             request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.delete_environment,
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.delete_environment
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -4043,15 +4081,15 @@
             parent (:class:`str`):
                 Required. The resource name of the parent lake:
                 ``projects/{project_id}/locations/{location_id}/lakes/{lake_id}``.
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.services.dataplex_service.pagers.ListEnvironmentsAsyncPager:
@@ -4059,53 +4097,48 @@
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.ListEnvironmentsRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.ListEnvironmentsRequest):
+            request = service.ListEnvironmentsRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if parent is not None:
             request.parent = parent
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.list_environments,
-            default_retry=retries.Retry(
-                initial=1.0,
-                maximum=10.0,
-                multiplier=1.3,
-                predicate=retries.if_exception_type(
-                    core_exceptions.ServiceUnavailable,
-                ),
-                deadline=60.0,
-            ),
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.list_environments
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -4165,67 +4198,62 @@
             name (:class:`str`):
                 Required. The resource name of the environment:
                 ``projects/{project_id}/locations/{location_id}/lakes/{lake_id}/environments/{environment_id}``.
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.types.Environment:
                 Environment represents a user-visible
                 compute infrastructure for analytics
                 within a lake.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.GetEnvironmentRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.GetEnvironmentRequest):
+            request = service.GetEnvironmentRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if name is not None:
             request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.get_environment,
-            default_retry=retries.Retry(
-                initial=1.0,
-                maximum=10.0,
-                multiplier=1.3,
-                predicate=retries.if_exception_type(
-                    core_exceptions.ServiceUnavailable,
-                ),
-                deadline=60.0,
-            ),
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.get_environment
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -4277,15 +4305,15 @@
             parent (:class:`str`):
                 Required. The resource name of the parent environment:
                 ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}/environment/{environment_id}``.
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            retry (google.api_core.retry.Retry): Designation of what errors, if any,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.services.dataplex_service.pagers.ListSessionsAsyncPager:
@@ -4293,44 +4321,48 @@
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = service.ListSessionsRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, service.ListSessionsRequest):
+            request = service.ListSessionsRequest(request)
 
         # If we have keyword arguments corresponding to fields on the
         # request, apply these.
         if parent is not None:
             request.parent = parent
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.list_sessions,
-            default_timeout=None,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._client._transport._wrapped_methods[
+            self._client._transport.list_sessions
+        ]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -4357,15 +4389,15 @@
     ) -> operations_pb2.ListOperationsResponse:
         r"""Lists operations that match the specified filter in the request.
 
         Args:
             request (:class:`~.operations_pb2.ListOperationsRequest`):
                 The request object. Request message for
                 `ListOperations` method.
-            retry (google.api_core.retry.Retry): Designation of what errors,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors,
                     if any, should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         Returns:
             ~.operations_pb2.ListOperationsResponse:
                 Response message for ``ListOperations`` method.
@@ -4374,26 +4406,29 @@
         # The request isn't a proto-plus wrapped type,
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = operations_pb2.ListOperationsRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method.wrap_method(
+        rpc = gapic_v1.method_async.wrap_method(
             self._client._transport.list_operations,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -4411,15 +4446,15 @@
     ) -> operations_pb2.Operation:
         r"""Gets the latest state of a long-running operation.
 
         Args:
             request (:class:`~.operations_pb2.GetOperationRequest`):
                 The request object. Request message for
                 `GetOperation` method.
-            retry (google.api_core.retry.Retry): Designation of what errors,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors,
                     if any, should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         Returns:
             ~.operations_pb2.Operation:
                 An ``Operation`` object.
@@ -4428,26 +4463,29 @@
         # The request isn't a proto-plus wrapped type,
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = operations_pb2.GetOperationRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method.wrap_method(
+        rpc = gapic_v1.method_async.wrap_method(
             self._client._transport.get_operation,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -4470,15 +4508,15 @@
         If the server doesn't support this method, it returns
         `google.rpc.Code.UNIMPLEMENTED`.
 
         Args:
             request (:class:`~.operations_pb2.DeleteOperationRequest`):
                 The request object. Request message for
                 `DeleteOperation` method.
-            retry (google.api_core.retry.Retry): Designation of what errors,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors,
                     if any, should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         Returns:
             None
         """
@@ -4486,26 +4524,29 @@
         # The request isn't a proto-plus wrapped type,
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = operations_pb2.DeleteOperationRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method.wrap_method(
+        rpc = gapic_v1.method_async.wrap_method(
             self._client._transport.delete_operation,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -4524,15 +4565,15 @@
         is not guaranteed.  If the server doesn't support this method, it returns
         `google.rpc.Code.UNIMPLEMENTED`.
 
         Args:
             request (:class:`~.operations_pb2.CancelOperationRequest`):
                 The request object. Request message for
                 `CancelOperation` method.
-            retry (google.api_core.retry.Retry): Designation of what errors,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors,
                     if any, should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         Returns:
             None
         """
@@ -4540,26 +4581,29 @@
         # The request isn't a proto-plus wrapped type,
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = operations_pb2.CancelOperationRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method.wrap_method(
+        rpc = gapic_v1.method_async.wrap_method(
             self._client._transport.cancel_operation,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -4574,15 +4618,15 @@
     ) -> locations_pb2.Location:
         r"""Gets information about a location.
 
         Args:
             request (:class:`~.location_pb2.GetLocationRequest`):
                 The request object. Request message for
                 `GetLocation` method.
-            retry (google.api_core.retry.Retry): Designation of what errors,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors,
                  if any, should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         Returns:
             ~.location_pb2.Location:
                 Location object.
@@ -4591,26 +4635,29 @@
         # The request isn't a proto-plus wrapped type,
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = locations_pb2.GetLocationRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method.wrap_method(
+        rpc = gapic_v1.method_async.wrap_method(
             self._client._transport.get_location,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -4628,15 +4675,15 @@
     ) -> locations_pb2.ListLocationsResponse:
         r"""Lists information about the supported locations for this service.
 
         Args:
             request (:class:`~.location_pb2.ListLocationsRequest`):
                 The request object. Request message for
                 `ListLocations` method.
-            retry (google.api_core.retry.Retry): Designation of what errors,
+            retry (google.api_core.retry_async.AsyncRetry): Designation of what errors,
                  if any, should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         Returns:
             ~.location_pb2.ListLocationsResponse:
                 Response message for ``ListLocations`` method.
@@ -4645,26 +4692,29 @@
         # The request isn't a proto-plus wrapped type,
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = locations_pb2.ListLocationsRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method.wrap_method(
+        rpc = gapic_v1.method_async.wrap_method(
             self._client._transport.list_locations,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._client._validate_universe_domain()
+
         # Send the request.
         response = await rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/dataplex_service/client.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/dataplex_service/client.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -13,42 +13,44 @@
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 from collections import OrderedDict
 import os
 import re
 from typing import (
+    Callable,
     Dict,
     Mapping,
     MutableMapping,
     MutableSequence,
     Optional,
     Sequence,
     Tuple,
     Type,
     Union,
     cast,
 )
+import warnings
 
 from google.api_core import client_options as client_options_lib
 from google.api_core import exceptions as core_exceptions
 from google.api_core import gapic_v1
 from google.api_core import retry as retries
 from google.auth import credentials as ga_credentials  # type: ignore
 from google.auth.exceptions import MutualTLSChannelError  # type: ignore
 from google.auth.transport import mtls  # type: ignore
 from google.auth.transport.grpc import SslCredentials  # type: ignore
 from google.oauth2 import service_account  # type: ignore
 
 from google.cloud.dataplex_v1 import gapic_version as package_version
 
 try:
-    OptionalRetry = Union[retries.Retry, gapic_v1.method._MethodDefault]
+    OptionalRetry = Union[retries.Retry, gapic_v1.method._MethodDefault, None]
 except AttributeError:  # pragma: NO COVER
-    OptionalRetry = Union[retries.Retry, object]  # type: ignore
+    OptionalRetry = Union[retries.Retry, object, None]  # type: ignore
 
 from google.api_core import operation  # type: ignore
 from google.api_core import operation_async  # type: ignore
 from google.cloud.location import locations_pb2  # type: ignore
 from google.iam.v1 import iam_policy_pb2  # type: ignore
 from google.iam.v1 import policy_pb2  # type: ignore
 from google.longrunning import operations_pb2  # type: ignore
@@ -135,19 +137,23 @@
         if sandbox:
             return api_endpoint.replace(
                 "sandbox.googleapis.com", "mtls.sandbox.googleapis.com"
             )
 
         return api_endpoint.replace(".googleapis.com", ".mtls.googleapis.com")
 
+    # Note: DEFAULT_ENDPOINT is deprecated. Use _DEFAULT_ENDPOINT_TEMPLATE instead.
     DEFAULT_ENDPOINT = "dataplex.googleapis.com"
     DEFAULT_MTLS_ENDPOINT = _get_default_mtls_endpoint.__func__(  # type: ignore
         DEFAULT_ENDPOINT
     )
 
+    _DEFAULT_ENDPOINT_TEMPLATE = "dataplex.{UNIVERSE_DOMAIN}"
+    _DEFAULT_UNIVERSE = "googleapis.com"
+
     @classmethod
     def from_service_account_info(cls, info: dict, *args, **kwargs):
         """Creates an instance of this client using the provided credentials
             info.
 
         Args:
             info (dict): The service account private key info.
@@ -468,15 +474,15 @@
         m = re.match(r"^projects/(?P<project>.+?)/locations/(?P<location>.+?)$", path)
         return m.groupdict() if m else {}
 
     @classmethod
     def get_mtls_endpoint_and_cert_source(
         cls, client_options: Optional[client_options_lib.ClientOptions] = None
     ):
-        """Return the API endpoint and client cert source for mutual TLS.
+        """Deprecated. Return the API endpoint and client cert source for mutual TLS.
 
         The client cert source is determined in the following order:
         (1) if `GOOGLE_API_USE_CLIENT_CERTIFICATE` environment variable is not "true", the
         client cert source is None.
         (2) if `client_options.client_cert_source` is provided, use the provided one; if the
         default client cert source exists, use the default one; otherwise the client cert
         source is None.
@@ -498,14 +504,19 @@
         Returns:
             Tuple[str, Callable[[], Tuple[bytes, bytes]]]: returns the API endpoint and the
                 client cert source to use.
 
         Raises:
             google.auth.exceptions.MutualTLSChannelError: If any errors happen.
         """
+
+        warnings.warn(
+            "get_mtls_endpoint_and_cert_source is deprecated. Use the api_endpoint property instead.",
+            DeprecationWarning,
+        )
         if client_options is None:
             client_options = client_options_lib.ClientOptions()
         use_client_cert = os.getenv("GOOGLE_API_USE_CLIENT_CERTIFICATE", "false")
         use_mtls_endpoint = os.getenv("GOOGLE_API_USE_MTLS_ENDPOINT", "auto")
         if use_client_cert not in ("true", "false"):
             raise ValueError(
                 "Environment variable `GOOGLE_API_USE_CLIENT_CERTIFICATE` must be either `true` or `false`"
@@ -531,112 +542,337 @@
         ):
             api_endpoint = cls.DEFAULT_MTLS_ENDPOINT
         else:
             api_endpoint = cls.DEFAULT_ENDPOINT
 
         return api_endpoint, client_cert_source
 
+    @staticmethod
+    def _read_environment_variables():
+        """Returns the environment variables used by the client.
+
+        Returns:
+            Tuple[bool, str, str]: returns the GOOGLE_API_USE_CLIENT_CERTIFICATE,
+            GOOGLE_API_USE_MTLS_ENDPOINT, and GOOGLE_CLOUD_UNIVERSE_DOMAIN environment variables.
+
+        Raises:
+            ValueError: If GOOGLE_API_USE_CLIENT_CERTIFICATE is not
+                any of ["true", "false"].
+            google.auth.exceptions.MutualTLSChannelError: If GOOGLE_API_USE_MTLS_ENDPOINT
+                is not any of ["auto", "never", "always"].
+        """
+        use_client_cert = os.getenv(
+            "GOOGLE_API_USE_CLIENT_CERTIFICATE", "false"
+        ).lower()
+        use_mtls_endpoint = os.getenv("GOOGLE_API_USE_MTLS_ENDPOINT", "auto").lower()
+        universe_domain_env = os.getenv("GOOGLE_CLOUD_UNIVERSE_DOMAIN")
+        if use_client_cert not in ("true", "false"):
+            raise ValueError(
+                "Environment variable `GOOGLE_API_USE_CLIENT_CERTIFICATE` must be either `true` or `false`"
+            )
+        if use_mtls_endpoint not in ("auto", "never", "always"):
+            raise MutualTLSChannelError(
+                "Environment variable `GOOGLE_API_USE_MTLS_ENDPOINT` must be `never`, `auto` or `always`"
+            )
+        return use_client_cert == "true", use_mtls_endpoint, universe_domain_env
+
+    @staticmethod
+    def _get_client_cert_source(provided_cert_source, use_cert_flag):
+        """Return the client cert source to be used by the client.
+
+        Args:
+            provided_cert_source (bytes): The client certificate source provided.
+            use_cert_flag (bool): A flag indicating whether to use the client certificate.
+
+        Returns:
+            bytes or None: The client cert source to be used by the client.
+        """
+        client_cert_source = None
+        if use_cert_flag:
+            if provided_cert_source:
+                client_cert_source = provided_cert_source
+            elif mtls.has_default_client_cert_source():
+                client_cert_source = mtls.default_client_cert_source()
+        return client_cert_source
+
+    @staticmethod
+    def _get_api_endpoint(
+        api_override, client_cert_source, universe_domain, use_mtls_endpoint
+    ):
+        """Return the API endpoint used by the client.
+
+        Args:
+            api_override (str): The API endpoint override. If specified, this is always
+                the return value of this function and the other arguments are not used.
+            client_cert_source (bytes): The client certificate source used by the client.
+            universe_domain (str): The universe domain used by the client.
+            use_mtls_endpoint (str): How to use the mTLS endpoint, which depends also on the other parameters.
+                Possible values are "always", "auto", or "never".
+
+        Returns:
+            str: The API endpoint to be used by the client.
+        """
+        if api_override is not None:
+            api_endpoint = api_override
+        elif use_mtls_endpoint == "always" or (
+            use_mtls_endpoint == "auto" and client_cert_source
+        ):
+            _default_universe = DataplexServiceClient._DEFAULT_UNIVERSE
+            if universe_domain != _default_universe:
+                raise MutualTLSChannelError(
+                    f"mTLS is not supported in any universe other than {_default_universe}."
+                )
+            api_endpoint = DataplexServiceClient.DEFAULT_MTLS_ENDPOINT
+        else:
+            api_endpoint = DataplexServiceClient._DEFAULT_ENDPOINT_TEMPLATE.format(
+                UNIVERSE_DOMAIN=universe_domain
+            )
+        return api_endpoint
+
+    @staticmethod
+    def _get_universe_domain(
+        client_universe_domain: Optional[str], universe_domain_env: Optional[str]
+    ) -> str:
+        """Return the universe domain used by the client.
+
+        Args:
+            client_universe_domain (Optional[str]): The universe domain configured via the client options.
+            universe_domain_env (Optional[str]): The universe domain configured via the "GOOGLE_CLOUD_UNIVERSE_DOMAIN" environment variable.
+
+        Returns:
+            str: The universe domain to be used by the client.
+
+        Raises:
+            ValueError: If the universe domain is an empty string.
+        """
+        universe_domain = DataplexServiceClient._DEFAULT_UNIVERSE
+        if client_universe_domain is not None:
+            universe_domain = client_universe_domain
+        elif universe_domain_env is not None:
+            universe_domain = universe_domain_env
+        if len(universe_domain.strip()) == 0:
+            raise ValueError("Universe Domain cannot be an empty string.")
+        return universe_domain
+
+    @staticmethod
+    def _compare_universes(
+        client_universe: str, credentials: ga_credentials.Credentials
+    ) -> bool:
+        """Returns True iff the universe domains used by the client and credentials match.
+
+        Args:
+            client_universe (str): The universe domain configured via the client options.
+            credentials (ga_credentials.Credentials): The credentials being used in the client.
+
+        Returns:
+            bool: True iff client_universe matches the universe in credentials.
+
+        Raises:
+            ValueError: when client_universe does not match the universe in credentials.
+        """
+
+        default_universe = DataplexServiceClient._DEFAULT_UNIVERSE
+        credentials_universe = getattr(credentials, "universe_domain", default_universe)
+
+        if client_universe != credentials_universe:
+            raise ValueError(
+                "The configured universe domain "
+                f"({client_universe}) does not match the universe domain "
+                f"found in the credentials ({credentials_universe}). "
+                "If you haven't configured the universe domain explicitly, "
+                f"`{default_universe}` is the default."
+            )
+        return True
+
+    def _validate_universe_domain(self):
+        """Validates client's and credentials' universe domains are consistent.
+
+        Returns:
+            bool: True iff the configured universe domain is valid.
+
+        Raises:
+            ValueError: If the configured universe domain is not valid.
+        """
+        self._is_universe_domain_valid = (
+            self._is_universe_domain_valid
+            or DataplexServiceClient._compare_universes(
+                self.universe_domain, self.transport._credentials
+            )
+        )
+        return self._is_universe_domain_valid
+
+    @property
+    def api_endpoint(self):
+        """Return the API endpoint used by the client instance.
+
+        Returns:
+            str: The API endpoint used by the client instance.
+        """
+        return self._api_endpoint
+
+    @property
+    def universe_domain(self) -> str:
+        """Return the universe domain used by the client instance.
+
+        Returns:
+            str: The universe domain used by the client instance.
+        """
+        return self._universe_domain
+
     def __init__(
         self,
         *,
         credentials: Optional[ga_credentials.Credentials] = None,
-        transport: Optional[Union[str, DataplexServiceTransport]] = None,
+        transport: Optional[
+            Union[
+                str, DataplexServiceTransport, Callable[..., DataplexServiceTransport]
+            ]
+        ] = None,
         client_options: Optional[Union[client_options_lib.ClientOptions, dict]] = None,
         client_info: gapic_v1.client_info.ClientInfo = DEFAULT_CLIENT_INFO,
     ) -> None:
         """Instantiates the dataplex service client.
 
         Args:
             credentials (Optional[google.auth.credentials.Credentials]): The
                 authorization credentials to attach to requests. These
                 credentials identify the application to the service; if none
                 are specified, the client will attempt to ascertain the
                 credentials from the environment.
-            transport (Union[str, DataplexServiceTransport]): The
-                transport to use. If set to None, a transport is chosen
-                automatically.
-            client_options (Optional[Union[google.api_core.client_options.ClientOptions, dict]]): Custom options for the
-                client. It won't take effect if a ``transport`` instance is provided.
-                (1) The ``api_endpoint`` property can be used to override the
-                default endpoint provided by the client. GOOGLE_API_USE_MTLS_ENDPOINT
-                environment variable can also be used to override the endpoint:
+            transport (Optional[Union[str,DataplexServiceTransport,Callable[..., DataplexServiceTransport]]]):
+                The transport to use, or a Callable that constructs and returns a new transport.
+                If a Callable is given, it will be called with the same set of initialization
+                arguments as used in the DataplexServiceTransport constructor.
+                If set to None, a transport is chosen automatically.
+            client_options (Optional[Union[google.api_core.client_options.ClientOptions, dict]]):
+                Custom options for the client.
+
+                1. The ``api_endpoint`` property can be used to override the
+                default endpoint provided by the client when ``transport`` is
+                not explicitly provided. Only if this property is not set and
+                ``transport`` was not explicitly provided, the endpoint is
+                determined by the GOOGLE_API_USE_MTLS_ENDPOINT environment
+                variable, which have one of the following values:
                 "always" (always use the default mTLS endpoint), "never" (always
-                use the default regular endpoint) and "auto" (auto switch to the
-                default mTLS endpoint if client certificate is present, this is
-                the default value). However, the ``api_endpoint`` property takes
-                precedence if provided.
-                (2) If GOOGLE_API_USE_CLIENT_CERTIFICATE environment variable
+                use the default regular endpoint) and "auto" (auto-switch to the
+                default mTLS endpoint if client certificate is present; this is
+                the default value).
+
+                2. If the GOOGLE_API_USE_CLIENT_CERTIFICATE environment variable
                 is "true", then the ``client_cert_source`` property can be used
-                to provide client certificate for mutual TLS transport. If
+                to provide a client certificate for mTLS transport. If
                 not provided, the default SSL client certificate will be used if
                 present. If GOOGLE_API_USE_CLIENT_CERTIFICATE is "false" or not
                 set, no client certificate will be used.
+
+                3. The ``universe_domain`` property can be used to override the
+                default "googleapis.com" universe. Note that the ``api_endpoint``
+                property still takes precedence; and ``universe_domain`` is
+                currently not supported for mTLS.
+
             client_info (google.api_core.gapic_v1.client_info.ClientInfo):
                 The client info used to send a user-agent string along with
                 API requests. If ``None``, then default info will be used.
                 Generally, you only need to set this if you're developing
                 your own client library.
 
         Raises:
             google.auth.exceptions.MutualTLSChannelError: If mutual TLS transport
                 creation failed for any reason.
         """
-        if isinstance(client_options, dict):
-            client_options = client_options_lib.from_dict(client_options)
-        if client_options is None:
-            client_options = client_options_lib.ClientOptions()
-        client_options = cast(client_options_lib.ClientOptions, client_options)
-
-        api_endpoint, client_cert_source_func = self.get_mtls_endpoint_and_cert_source(
-            client_options
+        self._client_options = client_options
+        if isinstance(self._client_options, dict):
+            self._client_options = client_options_lib.from_dict(self._client_options)
+        if self._client_options is None:
+            self._client_options = client_options_lib.ClientOptions()
+        self._client_options = cast(
+            client_options_lib.ClientOptions, self._client_options
+        )
+
+        universe_domain_opt = getattr(self._client_options, "universe_domain", None)
+
+        (
+            self._use_client_cert,
+            self._use_mtls_endpoint,
+            self._universe_domain_env,
+        ) = DataplexServiceClient._read_environment_variables()
+        self._client_cert_source = DataplexServiceClient._get_client_cert_source(
+            self._client_options.client_cert_source, self._use_client_cert
+        )
+        self._universe_domain = DataplexServiceClient._get_universe_domain(
+            universe_domain_opt, self._universe_domain_env
         )
+        self._api_endpoint = None  # updated below, depending on `transport`
+
+        # Initialize the universe domain validation.
+        self._is_universe_domain_valid = False
 
-        api_key_value = getattr(client_options, "api_key", None)
+        api_key_value = getattr(self._client_options, "api_key", None)
         if api_key_value and credentials:
             raise ValueError(
                 "client_options.api_key and credentials are mutually exclusive"
             )
 
         # Save or instantiate the transport.
         # Ordinarily, we provide the transport, but allowing a custom transport
         # instance provides an extensibility point for unusual situations.
-        if isinstance(transport, DataplexServiceTransport):
+        transport_provided = isinstance(transport, DataplexServiceTransport)
+        if transport_provided:
             # transport is a DataplexServiceTransport instance.
-            if credentials or client_options.credentials_file or api_key_value:
+            if credentials or self._client_options.credentials_file or api_key_value:
                 raise ValueError(
                     "When providing a transport instance, "
                     "provide its credentials directly."
                 )
-            if client_options.scopes:
+            if self._client_options.scopes:
                 raise ValueError(
                     "When providing a transport instance, provide its scopes "
                     "directly."
                 )
-            self._transport = transport
-        else:
+            self._transport = cast(DataplexServiceTransport, transport)
+            self._api_endpoint = self._transport.host
+
+        self._api_endpoint = (
+            self._api_endpoint
+            or DataplexServiceClient._get_api_endpoint(
+                self._client_options.api_endpoint,
+                self._client_cert_source,
+                self._universe_domain,
+                self._use_mtls_endpoint,
+            )
+        )
+
+        if not transport_provided:
             import google.auth._default  # type: ignore
 
             if api_key_value and hasattr(
                 google.auth._default, "get_api_key_credentials"
             ):
                 credentials = google.auth._default.get_api_key_credentials(
                     api_key_value
                 )
 
-            Transport = type(self).get_transport_class(transport)
-            self._transport = Transport(
+            transport_init: Union[
+                Type[DataplexServiceTransport], Callable[..., DataplexServiceTransport]
+            ] = (
+                type(self).get_transport_class(transport)
+                if isinstance(transport, str) or transport is None
+                else cast(Callable[..., DataplexServiceTransport], transport)
+            )
+            # initialize with the provided callable or the passed in class
+            self._transport = transport_init(
                 credentials=credentials,
-                credentials_file=client_options.credentials_file,
-                host=api_endpoint,
-                scopes=client_options.scopes,
-                client_cert_source_for_mtls=client_cert_source_func,
-                quota_project_id=client_options.quota_project_id,
+                credentials_file=self._client_options.credentials_file,
+                host=self._api_endpoint,
+                scopes=self._client_options.scopes,
+                client_cert_source_for_mtls=self._client_cert_source,
+                quota_project_id=self._client_options.quota_project_id,
                 client_info=client_info,
                 always_use_jwt_access=True,
-                api_audience=client_options.api_audience,
+                api_audience=self._client_options.api_audience,
             )
 
     def create_lake(
         self,
         request: Optional[Union[service.CreateLakeRequest, dict]] = None,
         *,
         parent: Optional[str] = None,
@@ -732,27 +968,25 @@
                    their data at scale, and provides data scientists and
                    data engineers an integrated experience to easily
                    search, discover, analyze and transform data and
                    associated metadata.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent, lake, lake_id])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.CreateLakeRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.CreateLakeRequest):
             request = service.CreateLakeRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if parent is not None:
                 request.parent = parent
             if lake is not None:
@@ -766,14 +1000,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -866,27 +1103,25 @@
                    their data at scale, and provides data scientists and
                    data engineers an integrated experience to easily
                    search, discover, analyze and transform data and
                    associated metadata.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([lake, update_mask])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.UpdateLakeRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.UpdateLakeRequest):
             request = service.UpdateLakeRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if lake is not None:
                 request.lake = lake
             if update_mask is not None:
@@ -900,14 +1135,17 @@
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata(
                 (("lake.name", request.lake.name),)
             ),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -994,27 +1232,25 @@
                          rpc Bar(google.protobuf.Empty) returns
                          (google.protobuf.Empty);
 
                       }
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.DeleteLakeRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.DeleteLakeRequest):
             request = service.DeleteLakeRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if name is not None:
                 request.name = name
 
@@ -1024,14 +1260,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1109,27 +1348,25 @@
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.ListLakesRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.ListLakesRequest):
             request = service.ListLakesRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if parent is not None:
                 request.parent = parent
 
@@ -1139,14 +1376,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1233,27 +1473,25 @@
                 provides data scientists and data
                 engineers an integrated experience to
                 easily search, discover, analyze and
                 transform data and associated metadata.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.GetLakeRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.GetLakeRequest):
             request = service.GetLakeRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if name is not None:
                 request.name = name
 
@@ -1263,14 +1501,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1338,27 +1579,25 @@
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.ListLakeActionsRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.ListLakeActionsRequest):
             request = service.ListLakeActionsRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if parent is not None:
                 request.parent = parent
 
@@ -1368,14 +1607,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1488,27 +1730,25 @@
                    be used to map to organizational structure or
                    represent stages of data readiness from raw to
                    curated. It provides managing behavior that is shared
                    or inherited by all contained assets.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent, zone, zone_id])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.CreateZoneRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.CreateZoneRequest):
             request = service.CreateZoneRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if parent is not None:
                 request.parent = parent
             if zone is not None:
@@ -1522,14 +1762,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1620,27 +1863,25 @@
                    be used to map to organizational structure or
                    represent stages of data readiness from raw to
                    curated. It provides managing behavior that is shared
                    or inherited by all contained assets.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([zone, update_mask])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.UpdateZoneRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.UpdateZoneRequest):
             request = service.UpdateZoneRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if zone is not None:
                 request.zone = zone
             if update_mask is not None:
@@ -1654,14 +1895,17 @@
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata(
                 (("zone.name", request.zone.name),)
             ),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1748,27 +1992,25 @@
                          rpc Bar(google.protobuf.Empty) returns
                          (google.protobuf.Empty);
 
                       }
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.DeleteZoneRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.DeleteZoneRequest):
             request = service.DeleteZoneRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if name is not None:
                 request.name = name
 
@@ -1778,14 +2020,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1861,27 +2106,25 @@
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.ListZonesRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.ListZonesRequest):
             request = service.ListZonesRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if parent is not None:
                 request.parent = parent
 
@@ -1891,14 +2134,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -1977,27 +2223,25 @@
                 readiness from raw to curated. It
                 provides managing behavior that is
                 shared or inherited by all contained
                 assets.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.GetZoneRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.GetZoneRequest):
             request = service.GetZoneRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if name is not None:
                 request.name = name
 
@@ -2007,14 +2251,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2082,27 +2329,25 @@
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.ListZoneActionsRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.ListZoneActionsRequest):
             request = service.ListZoneActionsRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if parent is not None:
                 request.parent = parent
 
@@ -2112,14 +2357,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2225,27 +2473,25 @@
                 An object representing a long-running operation.
 
                 The result type for the operation will be :class:`google.cloud.dataplex_v1.types.Asset` An asset represents a cloud resource that is being managed within a lake as a
                    member of a zone.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent, asset, asset_id])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.CreateAssetRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.CreateAssetRequest):
             request = service.CreateAssetRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if parent is not None:
                 request.parent = parent
             if asset is not None:
@@ -2259,14 +2505,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2353,27 +2602,25 @@
                 An object representing a long-running operation.
 
                 The result type for the operation will be :class:`google.cloud.dataplex_v1.types.Asset` An asset represents a cloud resource that is being managed within a lake as a
                    member of a zone.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([asset, update_mask])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.UpdateAssetRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.UpdateAssetRequest):
             request = service.UpdateAssetRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if asset is not None:
                 request.asset = asset
             if update_mask is not None:
@@ -2387,14 +2634,17 @@
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata(
                 (("asset.name", request.asset.name),)
             ),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2482,27 +2732,25 @@
                          rpc Bar(google.protobuf.Empty) returns
                          (google.protobuf.Empty);
 
                       }
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.DeleteAssetRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.DeleteAssetRequest):
             request = service.DeleteAssetRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if name is not None:
                 request.name = name
 
@@ -2512,14 +2760,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2595,27 +2846,25 @@
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.ListAssetsRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.ListAssetsRequest):
             request = service.ListAssetsRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if parent is not None:
                 request.parent = parent
 
@@ -2625,14 +2874,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2706,27 +2958,25 @@
             google.cloud.dataplex_v1.types.Asset:
                 An asset represents a cloud resource
                 that is being managed within a lake as a
                 member of a zone.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.GetAssetRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.GetAssetRequest):
             request = service.GetAssetRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if name is not None:
                 request.name = name
 
@@ -2736,14 +2986,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2811,27 +3064,25 @@
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.ListAssetActionsRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.ListAssetActionsRequest):
             request = service.ListAssetActionsRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if parent is not None:
                 request.parent = parent
 
@@ -2841,14 +3092,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -2948,27 +3202,25 @@
 
                 The result type for the operation will be
                 :class:`google.cloud.dataplex_v1.types.Task` A task
                 represents a user-visible job.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent, task, task_id])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.CreateTaskRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.CreateTaskRequest):
             request = service.CreateTaskRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if parent is not None:
                 request.parent = parent
             if task is not None:
@@ -2982,14 +3234,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -3080,27 +3335,25 @@
 
                 The result type for the operation will be
                 :class:`google.cloud.dataplex_v1.types.Task` A task
                 represents a user-visible job.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([task, update_mask])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.UpdateTaskRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.UpdateTaskRequest):
             request = service.UpdateTaskRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if task is not None:
                 request.task = task
             if update_mask is not None:
@@ -3114,14 +3367,17 @@
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata(
                 (("task.name", request.task.name),)
             ),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -3207,27 +3463,25 @@
                          rpc Bar(google.protobuf.Empty) returns
                          (google.protobuf.Empty);
 
                       }
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.DeleteTaskRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.DeleteTaskRequest):
             request = service.DeleteTaskRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if name is not None:
                 request.name = name
 
@@ -3237,14 +3491,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -3320,27 +3577,25 @@
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.ListTasksRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.ListTasksRequest):
             request = service.ListTasksRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if parent is not None:
                 request.parent = parent
 
@@ -3350,14 +3605,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -3428,27 +3686,25 @@
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.types.Task:
                 A task represents a user-visible job.
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.GetTaskRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.GetTaskRequest):
             request = service.GetTaskRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if name is not None:
                 request.name = name
 
@@ -3458,14 +3714,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -3533,27 +3792,25 @@
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.ListJobsRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.ListJobsRequest):
             request = service.ListJobsRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if parent is not None:
                 request.parent = parent
 
@@ -3563,14 +3820,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -3641,27 +3901,25 @@
                 sent along with the request as metadata.
 
         Returns:
             google.cloud.dataplex_v1.types.RunTaskResponse:
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.RunTaskRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.RunTaskRequest):
             request = service.RunTaskRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if name is not None:
                 request.name = name
 
@@ -3671,14 +3929,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -3742,27 +4003,25 @@
         Returns:
             google.cloud.dataplex_v1.types.Job:
                 A job represents an instance of a
                 task.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.GetJobRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.GetJobRequest):
             request = service.GetJobRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if name is not None:
                 request.name = name
 
@@ -3772,14 +4031,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -3834,27 +4096,25 @@
             retry (google.api_core.retry.Retry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.CancelJobRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.CancelJobRequest):
             request = service.CancelJobRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if name is not None:
                 request.name = name
 
@@ -3864,14 +4124,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -3963,27 +4226,25 @@
                 An object representing a long-running operation.
 
                 The result type for the operation will be :class:`google.cloud.dataplex_v1.types.Environment` Environment represents a user-visible compute infrastructure for analytics
                    within a lake.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent, environment, environment_id])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.CreateEnvironmentRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.CreateEnvironmentRequest):
             request = service.CreateEnvironmentRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if parent is not None:
                 request.parent = parent
             if environment is not None:
@@ -3997,14 +4258,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -4091,27 +4355,25 @@
                 An object representing a long-running operation.
 
                 The result type for the operation will be :class:`google.cloud.dataplex_v1.types.Environment` Environment represents a user-visible compute infrastructure for analytics
                    within a lake.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([environment, update_mask])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.UpdateEnvironmentRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.UpdateEnvironmentRequest):
             request = service.UpdateEnvironmentRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if environment is not None:
                 request.environment = environment
             if update_mask is not None:
@@ -4125,14 +4387,17 @@
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata(
                 (("environment.name", request.environment.name),)
             ),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -4220,27 +4485,25 @@
                          rpc Bar(google.protobuf.Empty) returns
                          (google.protobuf.Empty);
 
                       }
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.DeleteEnvironmentRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.DeleteEnvironmentRequest):
             request = service.DeleteEnvironmentRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if name is not None:
                 request.name = name
 
@@ -4250,14 +4513,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -4333,27 +4599,25 @@
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.ListEnvironmentsRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.ListEnvironmentsRequest):
             request = service.ListEnvironmentsRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if parent is not None:
                 request.parent = parent
 
@@ -4363,14 +4627,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -4444,27 +4711,25 @@
             google.cloud.dataplex_v1.types.Environment:
                 Environment represents a user-visible
                 compute infrastructure for analytics
                 within a lake.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.GetEnvironmentRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.GetEnvironmentRequest):
             request = service.GetEnvironmentRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if name is not None:
                 request.name = name
 
@@ -4474,14 +4739,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -4549,27 +4817,25 @@
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        # Minor optimization to avoid making a copy if the user passes
-        # in a service.ListSessionsRequest.
-        # There's no risk of modifying the input as we've already verified
-        # there are no flattened fields.
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
         if not isinstance(request, service.ListSessionsRequest):
             request = service.ListSessionsRequest(request)
             # If we have keyword arguments corresponding to fields on the
             # request, apply these.
             if parent is not None:
                 request.parent = parent
 
@@ -4579,14 +4845,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -4655,14 +4924,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -4709,14 +4981,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -4767,14 +5042,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -4821,14 +5099,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -4872,14 +5153,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
@@ -4926,14 +5210,17 @@
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
         response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/dataplex_service/pagers.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/dataplex_service/pagers.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/dataplex_service/transports/__init__.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/dataplex_service/transports/__init__.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/dataplex_service/transports/base.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/dataplex_service/transports/base.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -57,15 +57,15 @@
         api_audience: Optional[str] = None,
         **kwargs,
     ) -> None:
         """Instantiate the transport.
 
         Args:
             host (Optional[str]):
-                 The hostname to connect to.
+                 The hostname to connect to (default: 'dataplex.googleapis.com').
             credentials (Optional[google.auth.credentials.Credentials]): The
                 authorization credentials to attach to requests. These
                 credentials identify the application to the service; if none
                 are specified, the client will attempt to ascertain the
                 credentials from the environment.
             credentials_file (Optional[str]): A file with credentials that can
                 be loaded with :func:`google.auth.load_credentials_from_file`.
@@ -120,14 +120,18 @@
         self._credentials = credentials
 
         # Save the hostname. Default to port 443 (HTTPS) if none is specified.
         if ":" not in host:
             host += ":443"
         self._host = host
 
+    @property
+    def host(self):
+        return self._host
+
     def _prep_wrapped_messages(self, client_info):
         # Precompute the wrapped methods.
         self._wrapped_methods = {
             self.create_lake: gapic_v1.method.wrap_method(
                 self.create_lake,
                 default_timeout=60.0,
                 client_info=client_info,
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/dataplex_service/transports/grpc.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/dataplex_service/transports/grpc.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -55,56 +55,59 @@
     def __init__(
         self,
         *,
         host: str = "dataplex.googleapis.com",
         credentials: Optional[ga_credentials.Credentials] = None,
         credentials_file: Optional[str] = None,
         scopes: Optional[Sequence[str]] = None,
-        channel: Optional[grpc.Channel] = None,
+        channel: Optional[Union[grpc.Channel, Callable[..., grpc.Channel]]] = None,
         api_mtls_endpoint: Optional[str] = None,
         client_cert_source: Optional[Callable[[], Tuple[bytes, bytes]]] = None,
         ssl_channel_credentials: Optional[grpc.ChannelCredentials] = None,
         client_cert_source_for_mtls: Optional[Callable[[], Tuple[bytes, bytes]]] = None,
         quota_project_id: Optional[str] = None,
         client_info: gapic_v1.client_info.ClientInfo = DEFAULT_CLIENT_INFO,
         always_use_jwt_access: Optional[bool] = False,
         api_audience: Optional[str] = None,
     ) -> None:
         """Instantiate the transport.
 
         Args:
             host (Optional[str]):
-                 The hostname to connect to.
+                 The hostname to connect to (default: 'dataplex.googleapis.com').
             credentials (Optional[google.auth.credentials.Credentials]): The
                 authorization credentials to attach to requests. These
                 credentials identify the application to the service; if none
                 are specified, the client will attempt to ascertain the
                 credentials from the environment.
-                This argument is ignored if ``channel`` is provided.
+                This argument is ignored if a ``channel`` instance is provided.
             credentials_file (Optional[str]): A file with credentials that can
                 be loaded with :func:`google.auth.load_credentials_from_file`.
-                This argument is ignored if ``channel`` is provided.
+                This argument is ignored if a ``channel`` instance is provided.
             scopes (Optional(Sequence[str])): A list of scopes. This argument is
-                ignored if ``channel`` is provided.
-            channel (Optional[grpc.Channel]): A ``Channel`` instance through
-                which to make calls.
+                ignored if a ``channel`` instance is provided.
+            channel (Optional[Union[grpc.Channel, Callable[..., grpc.Channel]]]):
+                A ``Channel`` instance through which to make calls, or a Callable
+                that constructs and returns one. If set to None, ``self.create_channel``
+                is used to create the channel. If a Callable is given, it will be called
+                with the same arguments as used in ``self.create_channel``.
             api_mtls_endpoint (Optional[str]): Deprecated. The mutual TLS endpoint.
                 If provided, it overrides the ``host`` argument and tries to create
                 a mutual TLS channel with client SSL credentials from
                 ``client_cert_source`` or application default SSL credentials.
             client_cert_source (Optional[Callable[[], Tuple[bytes, bytes]]]):
                 Deprecated. A callback to provide client SSL certificate bytes and
                 private key bytes, both in PEM format. It is ignored if
                 ``api_mtls_endpoint`` is None.
             ssl_channel_credentials (grpc.ChannelCredentials): SSL credentials
-                for the grpc channel. It is ignored if ``channel`` is provided.
+                for the grpc channel. It is ignored if a ``channel`` instance is provided.
             client_cert_source_for_mtls (Optional[Callable[[], Tuple[bytes, bytes]]]):
                 A callback to provide client certificate bytes and private key bytes,
                 both in PEM format. It is used to configure a mutual TLS channel. It is
-                ignored if ``channel`` or ``ssl_channel_credentials`` is provided.
+                ignored if a ``channel`` instance or ``ssl_channel_credentials`` is provided.
             quota_project_id (Optional[str]): An optional project to use for billing
                 and quota.
             client_info (google.api_core.gapic_v1.client_info.ClientInfo):
                 The client info used to send a user-agent string along with
                 API requests. If ``None``, then default info will be used.
                 Generally, you only need to set this if you're developing
                 your own client library.
@@ -123,15 +126,15 @@
         self._operations_client: Optional[operations_v1.OperationsClient] = None
 
         if api_mtls_endpoint:
             warnings.warn("api_mtls_endpoint is deprecated", DeprecationWarning)
         if client_cert_source:
             warnings.warn("client_cert_source is deprecated", DeprecationWarning)
 
-        if channel:
+        if isinstance(channel, grpc.Channel):
             # Ignore credentials if a channel was passed.
             credentials = False
             # If a channel was explicitly provided, set it.
             self._grpc_channel = channel
             self._ssl_channel_credentials = None
 
         else:
@@ -164,15 +167,17 @@
             quota_project_id=quota_project_id,
             client_info=client_info,
             always_use_jwt_access=always_use_jwt_access,
             api_audience=api_audience,
         )
 
         if not self._grpc_channel:
-            self._grpc_channel = type(self).create_channel(
+            # initialize with the provided callable or the default channel
+            channel_init = channel or type(self).create_channel
+            self._grpc_channel = channel_init(
                 self._host,
                 # use the credentials which are saved
                 credentials=self._credentials,
                 # Set ``credentials_file`` to ``None`` here as
                 # the credentials that we saved earlier should be used.
                 credentials_file=None,
                 scopes=self._scopes,
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/dataplex_service/transports/grpc_asyncio.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/catalog_service/transports/grpc_asyncio.py`

 * *Files 14% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,40 +12,41 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 from typing import Awaitable, Callable, Dict, Optional, Sequence, Tuple, Union
 import warnings
 
+from google.api_core import exceptions as core_exceptions
 from google.api_core import gapic_v1, grpc_helpers_async, operations_v1
+from google.api_core import retry_async as retries
 from google.auth import credentials as ga_credentials  # type: ignore
 from google.auth.transport.grpc import SslCredentials  # type: ignore
 from google.cloud.location import locations_pb2  # type: ignore
 from google.iam.v1 import iam_policy_pb2  # type: ignore
 from google.iam.v1 import policy_pb2  # type: ignore
 from google.longrunning import operations_pb2  # type: ignore
-from google.protobuf import empty_pb2  # type: ignore
 import grpc  # type: ignore
 from grpc.experimental import aio  # type: ignore
 
-from google.cloud.dataplex_v1.types import analyze, resources, service, tasks
+from google.cloud.dataplex_v1.types import catalog
 
-from .base import DEFAULT_CLIENT_INFO, DataplexServiceTransport
-from .grpc import DataplexServiceGrpcTransport
+from .base import DEFAULT_CLIENT_INFO, CatalogServiceTransport
+from .grpc import CatalogServiceGrpcTransport
 
 
-class DataplexServiceGrpcAsyncIOTransport(DataplexServiceTransport):
-    """gRPC AsyncIO backend transport for DataplexService.
+class CatalogServiceGrpcAsyncIOTransport(CatalogServiceTransport):
+    """gRPC AsyncIO backend transport for CatalogService.
 
-    Dataplex service provides data lakes as a service. The
-    primary resources offered by this service are Lakes, Zones and
-    Assets which collectively allow a data administrator to
-    organize, manage, secure and catalog data across their
-    organization located across cloud projects in a variety of
-    storage systems including Cloud Storage and BigQuery.
+    The primary resources offered by this service are
+    EntryGroups, EntryTypes, AspectTypes, Entry and Aspect which
+    collectively allow a data administrator to organize, manage,
+    secure and catalog data across their organization located across
+    cloud projects in a variety of storage systems including Cloud
+    Storage and BigQuery.
 
     This class defines the same methods as the primary client, so the
     primary client can load the underlying transport implementation
     and call it.
 
     It sends protocol buffers over the wire using gRPC (which is built on
     top of HTTP/2); the ``grpcio`` package must be installed.
@@ -70,15 +71,14 @@
             credentials (Optional[~.Credentials]): The
                 authorization credentials to attach to requests. These
                 credentials identify this application to the service. If
                 none are specified, the client will attempt to ascertain
                 the credentials from the environment.
             credentials_file (Optional[str]): A file with credentials that can
                 be loaded with :func:`google.auth.load_credentials_from_file`.
-                This argument is ignored if ``channel`` is provided.
             scopes (Optional[Sequence[str]]): A optional list of scopes needed for this
                 service. These are only used when credentials are not specified and
                 are passed to :func:`google.auth.default`.
             quota_project_id (Optional[str]): An optional project to use for billing
                 and quota.
             kwargs (Optional[dict]): Keyword arguments, which are passed to the
                 channel creation.
@@ -100,57 +100,60 @@
     def __init__(
         self,
         *,
         host: str = "dataplex.googleapis.com",
         credentials: Optional[ga_credentials.Credentials] = None,
         credentials_file: Optional[str] = None,
         scopes: Optional[Sequence[str]] = None,
-        channel: Optional[aio.Channel] = None,
+        channel: Optional[Union[aio.Channel, Callable[..., aio.Channel]]] = None,
         api_mtls_endpoint: Optional[str] = None,
         client_cert_source: Optional[Callable[[], Tuple[bytes, bytes]]] = None,
         ssl_channel_credentials: Optional[grpc.ChannelCredentials] = None,
         client_cert_source_for_mtls: Optional[Callable[[], Tuple[bytes, bytes]]] = None,
         quota_project_id: Optional[str] = None,
         client_info: gapic_v1.client_info.ClientInfo = DEFAULT_CLIENT_INFO,
         always_use_jwt_access: Optional[bool] = False,
         api_audience: Optional[str] = None,
     ) -> None:
         """Instantiate the transport.
 
         Args:
             host (Optional[str]):
-                 The hostname to connect to.
+                 The hostname to connect to (default: 'dataplex.googleapis.com').
             credentials (Optional[google.auth.credentials.Credentials]): The
                 authorization credentials to attach to requests. These
                 credentials identify the application to the service; if none
                 are specified, the client will attempt to ascertain the
                 credentials from the environment.
-                This argument is ignored if ``channel`` is provided.
+                This argument is ignored if a ``channel`` instance is provided.
             credentials_file (Optional[str]): A file with credentials that can
                 be loaded with :func:`google.auth.load_credentials_from_file`.
-                This argument is ignored if ``channel`` is provided.
+                This argument is ignored if a ``channel`` instance is provided.
             scopes (Optional[Sequence[str]]): A optional list of scopes needed for this
                 service. These are only used when credentials are not specified and
                 are passed to :func:`google.auth.default`.
-            channel (Optional[aio.Channel]): A ``Channel`` instance through
-                which to make calls.
+            channel (Optional[Union[aio.Channel, Callable[..., aio.Channel]]]):
+                A ``Channel`` instance through which to make calls, or a Callable
+                that constructs and returns one. If set to None, ``self.create_channel``
+                is used to create the channel. If a Callable is given, it will be called
+                with the same arguments as used in ``self.create_channel``.
             api_mtls_endpoint (Optional[str]): Deprecated. The mutual TLS endpoint.
                 If provided, it overrides the ``host`` argument and tries to create
                 a mutual TLS channel with client SSL credentials from
                 ``client_cert_source`` or application default SSL credentials.
             client_cert_source (Optional[Callable[[], Tuple[bytes, bytes]]]):
                 Deprecated. A callback to provide client SSL certificate bytes and
                 private key bytes, both in PEM format. It is ignored if
                 ``api_mtls_endpoint`` is None.
             ssl_channel_credentials (grpc.ChannelCredentials): SSL credentials
-                for the grpc channel. It is ignored if ``channel`` is provided.
+                for the grpc channel. It is ignored if a ``channel`` instance is provided.
             client_cert_source_for_mtls (Optional[Callable[[], Tuple[bytes, bytes]]]):
                 A callback to provide client certificate bytes and private key bytes,
                 both in PEM format. It is used to configure a mutual TLS channel. It is
-                ignored if ``channel`` or ``ssl_channel_credentials`` is provided.
+                ignored if a ``channel`` instance or ``ssl_channel_credentials`` is provided.
             quota_project_id (Optional[str]): An optional project to use for billing
                 and quota.
             client_info (google.api_core.gapic_v1.client_info.ClientInfo):
                 The client info used to send a user-agent string along with
                 API requests. If ``None``, then default info will be used.
                 Generally, you only need to set this if you're developing
                 your own client library.
@@ -169,15 +172,15 @@
         self._operations_client: Optional[operations_v1.OperationsAsyncClient] = None
 
         if api_mtls_endpoint:
             warnings.warn("api_mtls_endpoint is deprecated", DeprecationWarning)
         if client_cert_source:
             warnings.warn("client_cert_source is deprecated", DeprecationWarning)
 
-        if channel:
+        if isinstance(channel, aio.Channel):
             # Ignore credentials if a channel was passed.
             credentials = False
             # If a channel was explicitly provided, set it.
             self._grpc_channel = channel
             self._ssl_channel_credentials = None
         else:
             if api_mtls_endpoint:
@@ -209,15 +212,17 @@
             quota_project_id=quota_project_id,
             client_info=client_info,
             always_use_jwt_access=always_use_jwt_access,
             api_audience=api_audience,
         )
 
         if not self._grpc_channel:
-            self._grpc_channel = type(self).create_channel(
+            # initialize with the provided callable or the default channel
+            channel_init = channel or type(self).create_channel
+            self._grpc_channel = channel_init(
                 self._host,
                 # use the credentials which are saved
                 credentials=self._credentials,
                 # Set ``credentials_file`` to ``None`` here as
                 # the credentials that we saved earlier should be used.
                 credentials_file=None,
                 scopes=self._scopes,
@@ -255,884 +260,835 @@
                 self.grpc_channel
             )
 
         # Return the client from cache.
         return self._operations_client
 
     @property
-    def create_lake(
+    def create_entry_type(
         self,
-    ) -> Callable[[service.CreateLakeRequest], Awaitable[operations_pb2.Operation]]:
-        r"""Return a callable for the create lake method over gRPC.
-
-        Creates a lake resource.
-
-        Returns:
-            Callable[[~.CreateLakeRequest],
-                    Awaitable[~.Operation]]:
-                A function that, when called, will call the underlying RPC
-                on the server.
-        """
-        # Generate a "stub function" on-the-fly which will actually make
-        # the request.
-        # gRPC handles serialization and deserialization, so we just need
-        # to pass in the functions for each.
-        if "create_lake" not in self._stubs:
-            self._stubs["create_lake"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/CreateLake",
-                request_serializer=service.CreateLakeRequest.serialize,
-                response_deserializer=operations_pb2.Operation.FromString,
-            )
-        return self._stubs["create_lake"]
-
-    @property
-    def update_lake(
-        self,
-    ) -> Callable[[service.UpdateLakeRequest], Awaitable[operations_pb2.Operation]]:
-        r"""Return a callable for the update lake method over gRPC.
-
-        Updates a lake resource.
-
-        Returns:
-            Callable[[~.UpdateLakeRequest],
-                    Awaitable[~.Operation]]:
-                A function that, when called, will call the underlying RPC
-                on the server.
-        """
-        # Generate a "stub function" on-the-fly which will actually make
-        # the request.
-        # gRPC handles serialization and deserialization, so we just need
-        # to pass in the functions for each.
-        if "update_lake" not in self._stubs:
-            self._stubs["update_lake"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/UpdateLake",
-                request_serializer=service.UpdateLakeRequest.serialize,
-                response_deserializer=operations_pb2.Operation.FromString,
-            )
-        return self._stubs["update_lake"]
-
-    @property
-    def delete_lake(
-        self,
-    ) -> Callable[[service.DeleteLakeRequest], Awaitable[operations_pb2.Operation]]:
-        r"""Return a callable for the delete lake method over gRPC.
+    ) -> Callable[
+        [catalog.CreateEntryTypeRequest], Awaitable[operations_pb2.Operation]
+    ]:
+        r"""Return a callable for the create entry type method over gRPC.
 
-        Deletes a lake resource. All zones within the lake
-        must be deleted before the lake can be deleted.
+        Creates an EntryType
 
         Returns:
-            Callable[[~.DeleteLakeRequest],
+            Callable[[~.CreateEntryTypeRequest],
                     Awaitable[~.Operation]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
-        if "delete_lake" not in self._stubs:
-            self._stubs["delete_lake"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/DeleteLake",
-                request_serializer=service.DeleteLakeRequest.serialize,
+        if "create_entry_type" not in self._stubs:
+            self._stubs["create_entry_type"] = self.grpc_channel.unary_unary(
+                "/google.cloud.dataplex.v1.CatalogService/CreateEntryType",
+                request_serializer=catalog.CreateEntryTypeRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
-        return self._stubs["delete_lake"]
+        return self._stubs["create_entry_type"]
 
     @property
-    def list_lakes(
-        self,
-    ) -> Callable[[service.ListLakesRequest], Awaitable[service.ListLakesResponse]]:
-        r"""Return a callable for the list lakes method over gRPC.
-
-        Lists lake resources in a project and location.
-
-        Returns:
-            Callable[[~.ListLakesRequest],
-                    Awaitable[~.ListLakesResponse]]:
-                A function that, when called, will call the underlying RPC
-                on the server.
-        """
-        # Generate a "stub function" on-the-fly which will actually make
-        # the request.
-        # gRPC handles serialization and deserialization, so we just need
-        # to pass in the functions for each.
-        if "list_lakes" not in self._stubs:
-            self._stubs["list_lakes"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/ListLakes",
-                request_serializer=service.ListLakesRequest.serialize,
-                response_deserializer=service.ListLakesResponse.deserialize,
-            )
-        return self._stubs["list_lakes"]
-
-    @property
-    def get_lake(self) -> Callable[[service.GetLakeRequest], Awaitable[resources.Lake]]:
-        r"""Return a callable for the get lake method over gRPC.
-
-        Retrieves a lake resource.
-
-        Returns:
-            Callable[[~.GetLakeRequest],
-                    Awaitable[~.Lake]]:
-                A function that, when called, will call the underlying RPC
-                on the server.
-        """
-        # Generate a "stub function" on-the-fly which will actually make
-        # the request.
-        # gRPC handles serialization and deserialization, so we just need
-        # to pass in the functions for each.
-        if "get_lake" not in self._stubs:
-            self._stubs["get_lake"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/GetLake",
-                request_serializer=service.GetLakeRequest.serialize,
-                response_deserializer=resources.Lake.deserialize,
-            )
-        return self._stubs["get_lake"]
-
-    @property
-    def list_lake_actions(
+    def update_entry_type(
         self,
     ) -> Callable[
-        [service.ListLakeActionsRequest], Awaitable[service.ListActionsResponse]
+        [catalog.UpdateEntryTypeRequest], Awaitable[operations_pb2.Operation]
     ]:
-        r"""Return a callable for the list lake actions method over gRPC.
+        r"""Return a callable for the update entry type method over gRPC.
 
-        Lists action resources in a lake.
+        Updates a EntryType resource.
 
         Returns:
-            Callable[[~.ListLakeActionsRequest],
-                    Awaitable[~.ListActionsResponse]]:
-                A function that, when called, will call the underlying RPC
-                on the server.
-        """
-        # Generate a "stub function" on-the-fly which will actually make
-        # the request.
-        # gRPC handles serialization and deserialization, so we just need
-        # to pass in the functions for each.
-        if "list_lake_actions" not in self._stubs:
-            self._stubs["list_lake_actions"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/ListLakeActions",
-                request_serializer=service.ListLakeActionsRequest.serialize,
-                response_deserializer=service.ListActionsResponse.deserialize,
-            )
-        return self._stubs["list_lake_actions"]
-
-    @property
-    def create_zone(
-        self,
-    ) -> Callable[[service.CreateZoneRequest], Awaitable[operations_pb2.Operation]]:
-        r"""Return a callable for the create zone method over gRPC.
-
-        Creates a zone resource within a lake.
-
-        Returns:
-            Callable[[~.CreateZoneRequest],
+            Callable[[~.UpdateEntryTypeRequest],
                     Awaitable[~.Operation]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
-        if "create_zone" not in self._stubs:
-            self._stubs["create_zone"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/CreateZone",
-                request_serializer=service.CreateZoneRequest.serialize,
+        if "update_entry_type" not in self._stubs:
+            self._stubs["update_entry_type"] = self.grpc_channel.unary_unary(
+                "/google.cloud.dataplex.v1.CatalogService/UpdateEntryType",
+                request_serializer=catalog.UpdateEntryTypeRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
-        return self._stubs["create_zone"]
+        return self._stubs["update_entry_type"]
 
     @property
-    def update_zone(
+    def delete_entry_type(
         self,
-    ) -> Callable[[service.UpdateZoneRequest], Awaitable[operations_pb2.Operation]]:
-        r"""Return a callable for the update zone method over gRPC.
+    ) -> Callable[
+        [catalog.DeleteEntryTypeRequest], Awaitable[operations_pb2.Operation]
+    ]:
+        r"""Return a callable for the delete entry type method over gRPC.
 
-        Updates a zone resource.
+        Deletes a EntryType resource.
 
         Returns:
-            Callable[[~.UpdateZoneRequest],
+            Callable[[~.DeleteEntryTypeRequest],
                     Awaitable[~.Operation]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
-        if "update_zone" not in self._stubs:
-            self._stubs["update_zone"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/UpdateZone",
-                request_serializer=service.UpdateZoneRequest.serialize,
+        if "delete_entry_type" not in self._stubs:
+            self._stubs["delete_entry_type"] = self.grpc_channel.unary_unary(
+                "/google.cloud.dataplex.v1.CatalogService/DeleteEntryType",
+                request_serializer=catalog.DeleteEntryTypeRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
-        return self._stubs["update_zone"]
+        return self._stubs["delete_entry_type"]
 
     @property
-    def delete_zone(
+    def list_entry_types(
         self,
-    ) -> Callable[[service.DeleteZoneRequest], Awaitable[operations_pb2.Operation]]:
-        r"""Return a callable for the delete zone method over gRPC.
+    ) -> Callable[
+        [catalog.ListEntryTypesRequest], Awaitable[catalog.ListEntryTypesResponse]
+    ]:
+        r"""Return a callable for the list entry types method over gRPC.
 
-        Deletes a zone resource. All assets within a zone
-        must be deleted before the zone can be deleted.
+        Lists EntryType resources in a project and location.
 
         Returns:
-            Callable[[~.DeleteZoneRequest],
-                    Awaitable[~.Operation]]:
+            Callable[[~.ListEntryTypesRequest],
+                    Awaitable[~.ListEntryTypesResponse]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
-        if "delete_zone" not in self._stubs:
-            self._stubs["delete_zone"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/DeleteZone",
-                request_serializer=service.DeleteZoneRequest.serialize,
-                response_deserializer=operations_pb2.Operation.FromString,
+        if "list_entry_types" not in self._stubs:
+            self._stubs["list_entry_types"] = self.grpc_channel.unary_unary(
+                "/google.cloud.dataplex.v1.CatalogService/ListEntryTypes",
+                request_serializer=catalog.ListEntryTypesRequest.serialize,
+                response_deserializer=catalog.ListEntryTypesResponse.deserialize,
             )
-        return self._stubs["delete_zone"]
+        return self._stubs["list_entry_types"]
 
     @property
-    def list_zones(
+    def get_entry_type(
         self,
-    ) -> Callable[[service.ListZonesRequest], Awaitable[service.ListZonesResponse]]:
-        r"""Return a callable for the list zones method over gRPC.
+    ) -> Callable[[catalog.GetEntryTypeRequest], Awaitable[catalog.EntryType]]:
+        r"""Return a callable for the get entry type method over gRPC.
 
-        Lists zone resources in a lake.
+        Retrieves a EntryType resource.
 
         Returns:
-            Callable[[~.ListZonesRequest],
-                    Awaitable[~.ListZonesResponse]]:
+            Callable[[~.GetEntryTypeRequest],
+                    Awaitable[~.EntryType]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
-        if "list_zones" not in self._stubs:
-            self._stubs["list_zones"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/ListZones",
-                request_serializer=service.ListZonesRequest.serialize,
-                response_deserializer=service.ListZonesResponse.deserialize,
+        if "get_entry_type" not in self._stubs:
+            self._stubs["get_entry_type"] = self.grpc_channel.unary_unary(
+                "/google.cloud.dataplex.v1.CatalogService/GetEntryType",
+                request_serializer=catalog.GetEntryTypeRequest.serialize,
+                response_deserializer=catalog.EntryType.deserialize,
             )
-        return self._stubs["list_zones"]
+        return self._stubs["get_entry_type"]
 
     @property
-    def get_zone(self) -> Callable[[service.GetZoneRequest], Awaitable[resources.Zone]]:
-        r"""Return a callable for the get zone method over gRPC.
-
-        Retrieves a zone resource.
-
-        Returns:
-            Callable[[~.GetZoneRequest],
-                    Awaitable[~.Zone]]:
-                A function that, when called, will call the underlying RPC
-                on the server.
-        """
-        # Generate a "stub function" on-the-fly which will actually make
-        # the request.
-        # gRPC handles serialization and deserialization, so we just need
-        # to pass in the functions for each.
-        if "get_zone" not in self._stubs:
-            self._stubs["get_zone"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/GetZone",
-                request_serializer=service.GetZoneRequest.serialize,
-                response_deserializer=resources.Zone.deserialize,
-            )
-        return self._stubs["get_zone"]
-
-    @property
-    def list_zone_actions(
+    def create_aspect_type(
         self,
     ) -> Callable[
-        [service.ListZoneActionsRequest], Awaitable[service.ListActionsResponse]
+        [catalog.CreateAspectTypeRequest], Awaitable[operations_pb2.Operation]
     ]:
-        r"""Return a callable for the list zone actions method over gRPC.
+        r"""Return a callable for the create aspect type method over gRPC.
 
-        Lists action resources in a zone.
+        Creates an AspectType
 
         Returns:
-            Callable[[~.ListZoneActionsRequest],
-                    Awaitable[~.ListActionsResponse]]:
-                A function that, when called, will call the underlying RPC
-                on the server.
-        """
-        # Generate a "stub function" on-the-fly which will actually make
-        # the request.
-        # gRPC handles serialization and deserialization, so we just need
-        # to pass in the functions for each.
-        if "list_zone_actions" not in self._stubs:
-            self._stubs["list_zone_actions"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/ListZoneActions",
-                request_serializer=service.ListZoneActionsRequest.serialize,
-                response_deserializer=service.ListActionsResponse.deserialize,
-            )
-        return self._stubs["list_zone_actions"]
-
-    @property
-    def create_asset(
-        self,
-    ) -> Callable[[service.CreateAssetRequest], Awaitable[operations_pb2.Operation]]:
-        r"""Return a callable for the create asset method over gRPC.
-
-        Creates an asset resource.
-
-        Returns:
-            Callable[[~.CreateAssetRequest],
+            Callable[[~.CreateAspectTypeRequest],
                     Awaitable[~.Operation]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
-        if "create_asset" not in self._stubs:
-            self._stubs["create_asset"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/CreateAsset",
-                request_serializer=service.CreateAssetRequest.serialize,
+        if "create_aspect_type" not in self._stubs:
+            self._stubs["create_aspect_type"] = self.grpc_channel.unary_unary(
+                "/google.cloud.dataplex.v1.CatalogService/CreateAspectType",
+                request_serializer=catalog.CreateAspectTypeRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
-        return self._stubs["create_asset"]
+        return self._stubs["create_aspect_type"]
 
     @property
-    def update_asset(
+    def update_aspect_type(
         self,
-    ) -> Callable[[service.UpdateAssetRequest], Awaitable[operations_pb2.Operation]]:
-        r"""Return a callable for the update asset method over gRPC.
+    ) -> Callable[
+        [catalog.UpdateAspectTypeRequest], Awaitable[operations_pb2.Operation]
+    ]:
+        r"""Return a callable for the update aspect type method over gRPC.
 
-        Updates an asset resource.
+        Updates a AspectType resource.
 
         Returns:
-            Callable[[~.UpdateAssetRequest],
+            Callable[[~.UpdateAspectTypeRequest],
                     Awaitable[~.Operation]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
-        if "update_asset" not in self._stubs:
-            self._stubs["update_asset"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/UpdateAsset",
-                request_serializer=service.UpdateAssetRequest.serialize,
+        if "update_aspect_type" not in self._stubs:
+            self._stubs["update_aspect_type"] = self.grpc_channel.unary_unary(
+                "/google.cloud.dataplex.v1.CatalogService/UpdateAspectType",
+                request_serializer=catalog.UpdateAspectTypeRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
-        return self._stubs["update_asset"]
+        return self._stubs["update_aspect_type"]
 
     @property
-    def delete_asset(
+    def delete_aspect_type(
         self,
-    ) -> Callable[[service.DeleteAssetRequest], Awaitable[operations_pb2.Operation]]:
-        r"""Return a callable for the delete asset method over gRPC.
+    ) -> Callable[
+        [catalog.DeleteAspectTypeRequest], Awaitable[operations_pb2.Operation]
+    ]:
+        r"""Return a callable for the delete aspect type method over gRPC.
 
-        Deletes an asset resource. The referenced storage
-        resource is detached (default) or deleted based on the
-        associated Lifecycle policy.
+        Deletes a AspectType resource.
 
         Returns:
-            Callable[[~.DeleteAssetRequest],
+            Callable[[~.DeleteAspectTypeRequest],
                     Awaitable[~.Operation]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
-        if "delete_asset" not in self._stubs:
-            self._stubs["delete_asset"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/DeleteAsset",
-                request_serializer=service.DeleteAssetRequest.serialize,
+        if "delete_aspect_type" not in self._stubs:
+            self._stubs["delete_aspect_type"] = self.grpc_channel.unary_unary(
+                "/google.cloud.dataplex.v1.CatalogService/DeleteAspectType",
+                request_serializer=catalog.DeleteAspectTypeRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
-        return self._stubs["delete_asset"]
+        return self._stubs["delete_aspect_type"]
 
     @property
-    def list_assets(
+    def list_aspect_types(
         self,
-    ) -> Callable[[service.ListAssetsRequest], Awaitable[service.ListAssetsResponse]]:
-        r"""Return a callable for the list assets method over gRPC.
+    ) -> Callable[
+        [catalog.ListAspectTypesRequest], Awaitable[catalog.ListAspectTypesResponse]
+    ]:
+        r"""Return a callable for the list aspect types method over gRPC.
 
-        Lists asset resources in a zone.
+        Lists AspectType resources in a project and location.
 
         Returns:
-            Callable[[~.ListAssetsRequest],
-                    Awaitable[~.ListAssetsResponse]]:
+            Callable[[~.ListAspectTypesRequest],
+                    Awaitable[~.ListAspectTypesResponse]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
-        if "list_assets" not in self._stubs:
-            self._stubs["list_assets"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/ListAssets",
-                request_serializer=service.ListAssetsRequest.serialize,
-                response_deserializer=service.ListAssetsResponse.deserialize,
+        if "list_aspect_types" not in self._stubs:
+            self._stubs["list_aspect_types"] = self.grpc_channel.unary_unary(
+                "/google.cloud.dataplex.v1.CatalogService/ListAspectTypes",
+                request_serializer=catalog.ListAspectTypesRequest.serialize,
+                response_deserializer=catalog.ListAspectTypesResponse.deserialize,
             )
-        return self._stubs["list_assets"]
+        return self._stubs["list_aspect_types"]
 
     @property
-    def get_asset(
+    def get_aspect_type(
         self,
-    ) -> Callable[[service.GetAssetRequest], Awaitable[resources.Asset]]:
-        r"""Return a callable for the get asset method over gRPC.
+    ) -> Callable[[catalog.GetAspectTypeRequest], Awaitable[catalog.AspectType]]:
+        r"""Return a callable for the get aspect type method over gRPC.
 
-        Retrieves an asset resource.
+        Retrieves a AspectType resource.
 
         Returns:
-            Callable[[~.GetAssetRequest],
-                    Awaitable[~.Asset]]:
+            Callable[[~.GetAspectTypeRequest],
+                    Awaitable[~.AspectType]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
-        if "get_asset" not in self._stubs:
-            self._stubs["get_asset"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/GetAsset",
-                request_serializer=service.GetAssetRequest.serialize,
-                response_deserializer=resources.Asset.deserialize,
+        if "get_aspect_type" not in self._stubs:
+            self._stubs["get_aspect_type"] = self.grpc_channel.unary_unary(
+                "/google.cloud.dataplex.v1.CatalogService/GetAspectType",
+                request_serializer=catalog.GetAspectTypeRequest.serialize,
+                response_deserializer=catalog.AspectType.deserialize,
             )
-        return self._stubs["get_asset"]
+        return self._stubs["get_aspect_type"]
 
     @property
-    def list_asset_actions(
+    def create_entry_group(
         self,
     ) -> Callable[
-        [service.ListAssetActionsRequest], Awaitable[service.ListActionsResponse]
+        [catalog.CreateEntryGroupRequest], Awaitable[operations_pb2.Operation]
     ]:
-        r"""Return a callable for the list asset actions method over gRPC.
+        r"""Return a callable for the create entry group method over gRPC.
 
-        Lists action resources in an asset.
+        Creates an EntryGroup
 
         Returns:
-            Callable[[~.ListAssetActionsRequest],
-                    Awaitable[~.ListActionsResponse]]:
-                A function that, when called, will call the underlying RPC
-                on the server.
-        """
-        # Generate a "stub function" on-the-fly which will actually make
-        # the request.
-        # gRPC handles serialization and deserialization, so we just need
-        # to pass in the functions for each.
-        if "list_asset_actions" not in self._stubs:
-            self._stubs["list_asset_actions"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/ListAssetActions",
-                request_serializer=service.ListAssetActionsRequest.serialize,
-                response_deserializer=service.ListActionsResponse.deserialize,
-            )
-        return self._stubs["list_asset_actions"]
-
-    @property
-    def create_task(
-        self,
-    ) -> Callable[[service.CreateTaskRequest], Awaitable[operations_pb2.Operation]]:
-        r"""Return a callable for the create task method over gRPC.
-
-        Creates a task resource within a lake.
-
-        Returns:
-            Callable[[~.CreateTaskRequest],
+            Callable[[~.CreateEntryGroupRequest],
                     Awaitable[~.Operation]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
-        if "create_task" not in self._stubs:
-            self._stubs["create_task"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/CreateTask",
-                request_serializer=service.CreateTaskRequest.serialize,
+        if "create_entry_group" not in self._stubs:
+            self._stubs["create_entry_group"] = self.grpc_channel.unary_unary(
+                "/google.cloud.dataplex.v1.CatalogService/CreateEntryGroup",
+                request_serializer=catalog.CreateEntryGroupRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
-        return self._stubs["create_task"]
+        return self._stubs["create_entry_group"]
 
     @property
-    def update_task(
+    def update_entry_group(
         self,
-    ) -> Callable[[service.UpdateTaskRequest], Awaitable[operations_pb2.Operation]]:
-        r"""Return a callable for the update task method over gRPC.
+    ) -> Callable[
+        [catalog.UpdateEntryGroupRequest], Awaitable[operations_pb2.Operation]
+    ]:
+        r"""Return a callable for the update entry group method over gRPC.
 
-        Update the task resource.
+        Updates a EntryGroup resource.
 
         Returns:
-            Callable[[~.UpdateTaskRequest],
+            Callable[[~.UpdateEntryGroupRequest],
                     Awaitable[~.Operation]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
-        if "update_task" not in self._stubs:
-            self._stubs["update_task"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/UpdateTask",
-                request_serializer=service.UpdateTaskRequest.serialize,
+        if "update_entry_group" not in self._stubs:
+            self._stubs["update_entry_group"] = self.grpc_channel.unary_unary(
+                "/google.cloud.dataplex.v1.CatalogService/UpdateEntryGroup",
+                request_serializer=catalog.UpdateEntryGroupRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
-        return self._stubs["update_task"]
+        return self._stubs["update_entry_group"]
 
     @property
-    def delete_task(
+    def delete_entry_group(
         self,
-    ) -> Callable[[service.DeleteTaskRequest], Awaitable[operations_pb2.Operation]]:
-        r"""Return a callable for the delete task method over gRPC.
+    ) -> Callable[
+        [catalog.DeleteEntryGroupRequest], Awaitable[operations_pb2.Operation]
+    ]:
+        r"""Return a callable for the delete entry group method over gRPC.
 
-        Delete the task resource.
+        Deletes a EntryGroup resource.
 
         Returns:
-            Callable[[~.DeleteTaskRequest],
+            Callable[[~.DeleteEntryGroupRequest],
                     Awaitable[~.Operation]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
-        if "delete_task" not in self._stubs:
-            self._stubs["delete_task"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/DeleteTask",
-                request_serializer=service.DeleteTaskRequest.serialize,
+        if "delete_entry_group" not in self._stubs:
+            self._stubs["delete_entry_group"] = self.grpc_channel.unary_unary(
+                "/google.cloud.dataplex.v1.CatalogService/DeleteEntryGroup",
+                request_serializer=catalog.DeleteEntryGroupRequest.serialize,
                 response_deserializer=operations_pb2.Operation.FromString,
             )
-        return self._stubs["delete_task"]
-
-    @property
-    def list_tasks(
-        self,
-    ) -> Callable[[service.ListTasksRequest], Awaitable[service.ListTasksResponse]]:
-        r"""Return a callable for the list tasks method over gRPC.
-
-        Lists tasks under the given lake.
-
-        Returns:
-            Callable[[~.ListTasksRequest],
-                    Awaitable[~.ListTasksResponse]]:
-                A function that, when called, will call the underlying RPC
-                on the server.
-        """
-        # Generate a "stub function" on-the-fly which will actually make
-        # the request.
-        # gRPC handles serialization and deserialization, so we just need
-        # to pass in the functions for each.
-        if "list_tasks" not in self._stubs:
-            self._stubs["list_tasks"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/ListTasks",
-                request_serializer=service.ListTasksRequest.serialize,
-                response_deserializer=service.ListTasksResponse.deserialize,
-            )
-        return self._stubs["list_tasks"]
-
-    @property
-    def get_task(self) -> Callable[[service.GetTaskRequest], Awaitable[tasks.Task]]:
-        r"""Return a callable for the get task method over gRPC.
-
-        Get task resource.
-
-        Returns:
-            Callable[[~.GetTaskRequest],
-                    Awaitable[~.Task]]:
-                A function that, when called, will call the underlying RPC
-                on the server.
-        """
-        # Generate a "stub function" on-the-fly which will actually make
-        # the request.
-        # gRPC handles serialization and deserialization, so we just need
-        # to pass in the functions for each.
-        if "get_task" not in self._stubs:
-            self._stubs["get_task"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/GetTask",
-                request_serializer=service.GetTaskRequest.serialize,
-                response_deserializer=tasks.Task.deserialize,
-            )
-        return self._stubs["get_task"]
+        return self._stubs["delete_entry_group"]
 
     @property
-    def list_jobs(
+    def list_entry_groups(
         self,
-    ) -> Callable[[service.ListJobsRequest], Awaitable[service.ListJobsResponse]]:
-        r"""Return a callable for the list jobs method over gRPC.
+    ) -> Callable[
+        [catalog.ListEntryGroupsRequest], Awaitable[catalog.ListEntryGroupsResponse]
+    ]:
+        r"""Return a callable for the list entry groups method over gRPC.
 
-        Lists Jobs under the given task.
+        Lists EntryGroup resources in a project and location.
 
         Returns:
-            Callable[[~.ListJobsRequest],
-                    Awaitable[~.ListJobsResponse]]:
+            Callable[[~.ListEntryGroupsRequest],
+                    Awaitable[~.ListEntryGroupsResponse]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
-        if "list_jobs" not in self._stubs:
-            self._stubs["list_jobs"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/ListJobs",
-                request_serializer=service.ListJobsRequest.serialize,
-                response_deserializer=service.ListJobsResponse.deserialize,
+        if "list_entry_groups" not in self._stubs:
+            self._stubs["list_entry_groups"] = self.grpc_channel.unary_unary(
+                "/google.cloud.dataplex.v1.CatalogService/ListEntryGroups",
+                request_serializer=catalog.ListEntryGroupsRequest.serialize,
+                response_deserializer=catalog.ListEntryGroupsResponse.deserialize,
             )
-        return self._stubs["list_jobs"]
+        return self._stubs["list_entry_groups"]
 
     @property
-    def run_task(
+    def get_entry_group(
         self,
-    ) -> Callable[[service.RunTaskRequest], Awaitable[service.RunTaskResponse]]:
-        r"""Return a callable for the run task method over gRPC.
+    ) -> Callable[[catalog.GetEntryGroupRequest], Awaitable[catalog.EntryGroup]]:
+        r"""Return a callable for the get entry group method over gRPC.
 
-        Run an on demand execution of a Task.
+        Retrieves a EntryGroup resource.
 
         Returns:
-            Callable[[~.RunTaskRequest],
-                    Awaitable[~.RunTaskResponse]]:
+            Callable[[~.GetEntryGroupRequest],
+                    Awaitable[~.EntryGroup]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
-        if "run_task" not in self._stubs:
-            self._stubs["run_task"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/RunTask",
-                request_serializer=service.RunTaskRequest.serialize,
-                response_deserializer=service.RunTaskResponse.deserialize,
+        if "get_entry_group" not in self._stubs:
+            self._stubs["get_entry_group"] = self.grpc_channel.unary_unary(
+                "/google.cloud.dataplex.v1.CatalogService/GetEntryGroup",
+                request_serializer=catalog.GetEntryGroupRequest.serialize,
+                response_deserializer=catalog.EntryGroup.deserialize,
             )
-        return self._stubs["run_task"]
+        return self._stubs["get_entry_group"]
 
     @property
-    def get_job(self) -> Callable[[service.GetJobRequest], Awaitable[tasks.Job]]:
-        r"""Return a callable for the get job method over gRPC.
-
-        Get job resource.
-
-        Returns:
-            Callable[[~.GetJobRequest],
-                    Awaitable[~.Job]]:
-                A function that, when called, will call the underlying RPC
-                on the server.
-        """
-        # Generate a "stub function" on-the-fly which will actually make
-        # the request.
-        # gRPC handles serialization and deserialization, so we just need
-        # to pass in the functions for each.
-        if "get_job" not in self._stubs:
-            self._stubs["get_job"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/GetJob",
-                request_serializer=service.GetJobRequest.serialize,
-                response_deserializer=tasks.Job.deserialize,
-            )
-        return self._stubs["get_job"]
-
-    @property
-    def cancel_job(
+    def create_entry(
         self,
-    ) -> Callable[[service.CancelJobRequest], Awaitable[empty_pb2.Empty]]:
-        r"""Return a callable for the cancel job method over gRPC.
+    ) -> Callable[[catalog.CreateEntryRequest], Awaitable[catalog.Entry]]:
+        r"""Return a callable for the create entry method over gRPC.
 
-        Cancel jobs running for the task resource.
+        Creates an Entry.
 
         Returns:
-            Callable[[~.CancelJobRequest],
-                    Awaitable[~.Empty]]:
+            Callable[[~.CreateEntryRequest],
+                    Awaitable[~.Entry]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
-        if "cancel_job" not in self._stubs:
-            self._stubs["cancel_job"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/CancelJob",
-                request_serializer=service.CancelJobRequest.serialize,
-                response_deserializer=empty_pb2.Empty.FromString,
+        if "create_entry" not in self._stubs:
+            self._stubs["create_entry"] = self.grpc_channel.unary_unary(
+                "/google.cloud.dataplex.v1.CatalogService/CreateEntry",
+                request_serializer=catalog.CreateEntryRequest.serialize,
+                response_deserializer=catalog.Entry.deserialize,
             )
-        return self._stubs["cancel_job"]
+        return self._stubs["create_entry"]
 
     @property
-    def create_environment(
+    def update_entry(
         self,
-    ) -> Callable[
-        [service.CreateEnvironmentRequest], Awaitable[operations_pb2.Operation]
-    ]:
-        r"""Return a callable for the create environment method over gRPC.
+    ) -> Callable[[catalog.UpdateEntryRequest], Awaitable[catalog.Entry]]:
+        r"""Return a callable for the update entry method over gRPC.
 
-        Create an environment resource.
+        Updates an Entry.
 
         Returns:
-            Callable[[~.CreateEnvironmentRequest],
-                    Awaitable[~.Operation]]:
+            Callable[[~.UpdateEntryRequest],
+                    Awaitable[~.Entry]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
-        if "create_environment" not in self._stubs:
-            self._stubs["create_environment"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/CreateEnvironment",
-                request_serializer=service.CreateEnvironmentRequest.serialize,
-                response_deserializer=operations_pb2.Operation.FromString,
+        if "update_entry" not in self._stubs:
+            self._stubs["update_entry"] = self.grpc_channel.unary_unary(
+                "/google.cloud.dataplex.v1.CatalogService/UpdateEntry",
+                request_serializer=catalog.UpdateEntryRequest.serialize,
+                response_deserializer=catalog.Entry.deserialize,
             )
-        return self._stubs["create_environment"]
+        return self._stubs["update_entry"]
 
     @property
-    def update_environment(
+    def delete_entry(
         self,
-    ) -> Callable[
-        [service.UpdateEnvironmentRequest], Awaitable[operations_pb2.Operation]
-    ]:
-        r"""Return a callable for the update environment method over gRPC.
+    ) -> Callable[[catalog.DeleteEntryRequest], Awaitable[catalog.Entry]]:
+        r"""Return a callable for the delete entry method over gRPC.
 
-        Update the environment resource.
+        Deletes an Entry.
 
         Returns:
-            Callable[[~.UpdateEnvironmentRequest],
-                    Awaitable[~.Operation]]:
+            Callable[[~.DeleteEntryRequest],
+                    Awaitable[~.Entry]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
-        if "update_environment" not in self._stubs:
-            self._stubs["update_environment"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/UpdateEnvironment",
-                request_serializer=service.UpdateEnvironmentRequest.serialize,
-                response_deserializer=operations_pb2.Operation.FromString,
+        if "delete_entry" not in self._stubs:
+            self._stubs["delete_entry"] = self.grpc_channel.unary_unary(
+                "/google.cloud.dataplex.v1.CatalogService/DeleteEntry",
+                request_serializer=catalog.DeleteEntryRequest.serialize,
+                response_deserializer=catalog.Entry.deserialize,
             )
-        return self._stubs["update_environment"]
+        return self._stubs["delete_entry"]
 
     @property
-    def delete_environment(
+    def list_entries(
         self,
-    ) -> Callable[
-        [service.DeleteEnvironmentRequest], Awaitable[operations_pb2.Operation]
-    ]:
-        r"""Return a callable for the delete environment method over gRPC.
+    ) -> Callable[[catalog.ListEntriesRequest], Awaitable[catalog.ListEntriesResponse]]:
+        r"""Return a callable for the list entries method over gRPC.
 
-        Delete the environment resource. All the child
-        resources must have been deleted before environment
-        deletion can be initiated.
+        Lists entries within an entry group.
 
         Returns:
-            Callable[[~.DeleteEnvironmentRequest],
-                    Awaitable[~.Operation]]:
+            Callable[[~.ListEntriesRequest],
+                    Awaitable[~.ListEntriesResponse]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
-        if "delete_environment" not in self._stubs:
-            self._stubs["delete_environment"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/DeleteEnvironment",
-                request_serializer=service.DeleteEnvironmentRequest.serialize,
-                response_deserializer=operations_pb2.Operation.FromString,
+        if "list_entries" not in self._stubs:
+            self._stubs["list_entries"] = self.grpc_channel.unary_unary(
+                "/google.cloud.dataplex.v1.CatalogService/ListEntries",
+                request_serializer=catalog.ListEntriesRequest.serialize,
+                response_deserializer=catalog.ListEntriesResponse.deserialize,
             )
-        return self._stubs["delete_environment"]
+        return self._stubs["list_entries"]
 
     @property
-    def list_environments(
+    def get_entry(
         self,
-    ) -> Callable[
-        [service.ListEnvironmentsRequest], Awaitable[service.ListEnvironmentsResponse]
-    ]:
-        r"""Return a callable for the list environments method over gRPC.
+    ) -> Callable[[catalog.GetEntryRequest], Awaitable[catalog.Entry]]:
+        r"""Return a callable for the get entry method over gRPC.
 
-        Lists environments under the given lake.
+        Gets a single entry.
 
         Returns:
-            Callable[[~.ListEnvironmentsRequest],
-                    Awaitable[~.ListEnvironmentsResponse]]:
+            Callable[[~.GetEntryRequest],
+                    Awaitable[~.Entry]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
-        if "list_environments" not in self._stubs:
-            self._stubs["list_environments"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/ListEnvironments",
-                request_serializer=service.ListEnvironmentsRequest.serialize,
-                response_deserializer=service.ListEnvironmentsResponse.deserialize,
+        if "get_entry" not in self._stubs:
+            self._stubs["get_entry"] = self.grpc_channel.unary_unary(
+                "/google.cloud.dataplex.v1.CatalogService/GetEntry",
+                request_serializer=catalog.GetEntryRequest.serialize,
+                response_deserializer=catalog.Entry.deserialize,
             )
-        return self._stubs["list_environments"]
+        return self._stubs["get_entry"]
 
     @property
-    def get_environment(
+    def lookup_entry(
         self,
-    ) -> Callable[[service.GetEnvironmentRequest], Awaitable[analyze.Environment]]:
-        r"""Return a callable for the get environment method over gRPC.
+    ) -> Callable[[catalog.LookupEntryRequest], Awaitable[catalog.Entry]]:
+        r"""Return a callable for the lookup entry method over gRPC.
 
-        Get environment resource.
+        Looks up a single entry.
 
         Returns:
-            Callable[[~.GetEnvironmentRequest],
-                    Awaitable[~.Environment]]:
+            Callable[[~.LookupEntryRequest],
+                    Awaitable[~.Entry]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
-        if "get_environment" not in self._stubs:
-            self._stubs["get_environment"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/GetEnvironment",
-                request_serializer=service.GetEnvironmentRequest.serialize,
-                response_deserializer=analyze.Environment.deserialize,
+        if "lookup_entry" not in self._stubs:
+            self._stubs["lookup_entry"] = self.grpc_channel.unary_unary(
+                "/google.cloud.dataplex.v1.CatalogService/LookupEntry",
+                request_serializer=catalog.LookupEntryRequest.serialize,
+                response_deserializer=catalog.Entry.deserialize,
             )
-        return self._stubs["get_environment"]
+        return self._stubs["lookup_entry"]
 
     @property
-    def list_sessions(
+    def search_entries(
         self,
     ) -> Callable[
-        [service.ListSessionsRequest], Awaitable[service.ListSessionsResponse]
+        [catalog.SearchEntriesRequest], Awaitable[catalog.SearchEntriesResponse]
     ]:
-        r"""Return a callable for the list sessions method over gRPC.
+        r"""Return a callable for the search entries method over gRPC.
 
-        Lists session resources in an environment.
+        Searches for entries matching given query and scope.
 
         Returns:
-            Callable[[~.ListSessionsRequest],
-                    Awaitable[~.ListSessionsResponse]]:
+            Callable[[~.SearchEntriesRequest],
+                    Awaitable[~.SearchEntriesResponse]]:
                 A function that, when called, will call the underlying RPC
                 on the server.
         """
         # Generate a "stub function" on-the-fly which will actually make
         # the request.
         # gRPC handles serialization and deserialization, so we just need
         # to pass in the functions for each.
-        if "list_sessions" not in self._stubs:
-            self._stubs["list_sessions"] = self.grpc_channel.unary_unary(
-                "/google.cloud.dataplex.v1.DataplexService/ListSessions",
-                request_serializer=service.ListSessionsRequest.serialize,
-                response_deserializer=service.ListSessionsResponse.deserialize,
-            )
-        return self._stubs["list_sessions"]
+        if "search_entries" not in self._stubs:
+            self._stubs["search_entries"] = self.grpc_channel.unary_unary(
+                "/google.cloud.dataplex.v1.CatalogService/SearchEntries",
+                request_serializer=catalog.SearchEntriesRequest.serialize,
+                response_deserializer=catalog.SearchEntriesResponse.deserialize,
+            )
+        return self._stubs["search_entries"]
+
+    def _prep_wrapped_messages(self, client_info):
+        """Precompute the wrapped methods, overriding the base class method to use async wrappers."""
+        self._wrapped_methods = {
+            self.create_entry_type: gapic_v1.method_async.wrap_method(
+                self.create_entry_type,
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.update_entry_type: gapic_v1.method_async.wrap_method(
+                self.update_entry_type,
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.delete_entry_type: gapic_v1.method_async.wrap_method(
+                self.delete_entry_type,
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.list_entry_types: gapic_v1.method_async.wrap_method(
+                self.list_entry_types,
+                default_retry=retries.AsyncRetry(
+                    initial=1.0,
+                    maximum=10.0,
+                    multiplier=1.3,
+                    predicate=retries.if_exception_type(
+                        core_exceptions.ResourceExhausted,
+                        core_exceptions.ServiceUnavailable,
+                    ),
+                    deadline=60.0,
+                ),
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.get_entry_type: gapic_v1.method_async.wrap_method(
+                self.get_entry_type,
+                default_retry=retries.AsyncRetry(
+                    initial=1.0,
+                    maximum=10.0,
+                    multiplier=1.3,
+                    predicate=retries.if_exception_type(
+                        core_exceptions.ResourceExhausted,
+                        core_exceptions.ServiceUnavailable,
+                    ),
+                    deadline=60.0,
+                ),
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.create_aspect_type: gapic_v1.method_async.wrap_method(
+                self.create_aspect_type,
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.update_aspect_type: gapic_v1.method_async.wrap_method(
+                self.update_aspect_type,
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.delete_aspect_type: gapic_v1.method_async.wrap_method(
+                self.delete_aspect_type,
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.list_aspect_types: gapic_v1.method_async.wrap_method(
+                self.list_aspect_types,
+                default_retry=retries.AsyncRetry(
+                    initial=1.0,
+                    maximum=10.0,
+                    multiplier=1.3,
+                    predicate=retries.if_exception_type(
+                        core_exceptions.ResourceExhausted,
+                        core_exceptions.ServiceUnavailable,
+                    ),
+                    deadline=60.0,
+                ),
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.get_aspect_type: gapic_v1.method_async.wrap_method(
+                self.get_aspect_type,
+                default_retry=retries.AsyncRetry(
+                    initial=1.0,
+                    maximum=10.0,
+                    multiplier=1.3,
+                    predicate=retries.if_exception_type(
+                        core_exceptions.ResourceExhausted,
+                        core_exceptions.ServiceUnavailable,
+                    ),
+                    deadline=60.0,
+                ),
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.create_entry_group: gapic_v1.method_async.wrap_method(
+                self.create_entry_group,
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.update_entry_group: gapic_v1.method_async.wrap_method(
+                self.update_entry_group,
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.delete_entry_group: gapic_v1.method_async.wrap_method(
+                self.delete_entry_group,
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.list_entry_groups: gapic_v1.method_async.wrap_method(
+                self.list_entry_groups,
+                default_retry=retries.AsyncRetry(
+                    initial=1.0,
+                    maximum=10.0,
+                    multiplier=1.3,
+                    predicate=retries.if_exception_type(
+                        core_exceptions.ResourceExhausted,
+                        core_exceptions.ServiceUnavailable,
+                    ),
+                    deadline=60.0,
+                ),
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.get_entry_group: gapic_v1.method_async.wrap_method(
+                self.get_entry_group,
+                default_retry=retries.AsyncRetry(
+                    initial=1.0,
+                    maximum=10.0,
+                    multiplier=1.3,
+                    predicate=retries.if_exception_type(
+                        core_exceptions.ResourceExhausted,
+                        core_exceptions.ServiceUnavailable,
+                    ),
+                    deadline=60.0,
+                ),
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.create_entry: gapic_v1.method_async.wrap_method(
+                self.create_entry,
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.update_entry: gapic_v1.method_async.wrap_method(
+                self.update_entry,
+                default_retry=retries.AsyncRetry(
+                    initial=1.0,
+                    maximum=10.0,
+                    multiplier=1.3,
+                    predicate=retries.if_exception_type(
+                        core_exceptions.ResourceExhausted,
+                        core_exceptions.ServiceUnavailable,
+                    ),
+                    deadline=60.0,
+                ),
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.delete_entry: gapic_v1.method_async.wrap_method(
+                self.delete_entry,
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.list_entries: gapic_v1.method_async.wrap_method(
+                self.list_entries,
+                default_retry=retries.AsyncRetry(
+                    initial=1.0,
+                    maximum=10.0,
+                    multiplier=1.3,
+                    predicate=retries.if_exception_type(
+                        core_exceptions.ResourceExhausted,
+                        core_exceptions.ServiceUnavailable,
+                    ),
+                    deadline=20.0,
+                ),
+                default_timeout=20.0,
+                client_info=client_info,
+            ),
+            self.get_entry: gapic_v1.method_async.wrap_method(
+                self.get_entry,
+                default_retry=retries.AsyncRetry(
+                    initial=1.0,
+                    maximum=10.0,
+                    multiplier=1.3,
+                    predicate=retries.if_exception_type(
+                        core_exceptions.ResourceExhausted,
+                        core_exceptions.ServiceUnavailable,
+                    ),
+                    deadline=20.0,
+                ),
+                default_timeout=20.0,
+                client_info=client_info,
+            ),
+            self.lookup_entry: gapic_v1.method_async.wrap_method(
+                self.lookup_entry,
+                default_retry=retries.AsyncRetry(
+                    initial=1.0,
+                    maximum=10.0,
+                    multiplier=1.3,
+                    predicate=retries.if_exception_type(
+                        core_exceptions.ResourceExhausted,
+                        core_exceptions.ServiceUnavailable,
+                    ),
+                    deadline=20.0,
+                ),
+                default_timeout=20.0,
+                client_info=client_info,
+            ),
+            self.search_entries: gapic_v1.method_async.wrap_method(
+                self.search_entries,
+                default_retry=retries.AsyncRetry(
+                    initial=1.0,
+                    maximum=10.0,
+                    multiplier=1.3,
+                    predicate=retries.if_exception_type(
+                        core_exceptions.ResourceExhausted,
+                        core_exceptions.ServiceUnavailable,
+                    ),
+                    deadline=60.0,
+                ),
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+        }
 
     def close(self):
         return self.grpc_channel.close()
 
     @property
     def delete_operation(
         self,
@@ -1236,8 +1192,8 @@
                 "/google.cloud.location.Locations/GetLocation",
                 request_serializer=locations_pb2.GetLocationRequest.SerializeToString,
                 response_deserializer=locations_pb2.Location.FromString,
             )
         return self._stubs["get_location"]
 
 
-__all__ = ("DataplexServiceGrpcAsyncIOTransport",)
+__all__ = ("CatalogServiceGrpcAsyncIOTransport",)
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/metadata_service/__init__.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/metadata_service/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/metadata_service/async_client.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/metadata_service/client.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,144 +1,360 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
 # Unless required by applicable law or agreed to in writing, software
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 from collections import OrderedDict
-import functools
+import os
 import re
 from typing import (
+    Callable,
     Dict,
     Mapping,
     MutableMapping,
     MutableSequence,
     Optional,
     Sequence,
     Tuple,
     Type,
     Union,
+    cast,
 )
+import warnings
 
+from google.api_core import client_options as client_options_lib
 from google.api_core import exceptions as core_exceptions
 from google.api_core import gapic_v1
 from google.api_core import retry as retries
-from google.api_core.client_options import ClientOptions
 from google.auth import credentials as ga_credentials  # type: ignore
+from google.auth.exceptions import MutualTLSChannelError  # type: ignore
+from google.auth.transport import mtls  # type: ignore
+from google.auth.transport.grpc import SslCredentials  # type: ignore
 from google.oauth2 import service_account  # type: ignore
 
 from google.cloud.dataplex_v1 import gapic_version as package_version
 
 try:
-    OptionalRetry = Union[retries.Retry, gapic_v1.method._MethodDefault]
+    OptionalRetry = Union[retries.Retry, gapic_v1.method._MethodDefault, None]
 except AttributeError:  # pragma: NO COVER
-    OptionalRetry = Union[retries.Retry, object]  # type: ignore
+    OptionalRetry = Union[retries.Retry, object, None]  # type: ignore
 
 from google.cloud.location import locations_pb2  # type: ignore
 from google.iam.v1 import iam_policy_pb2  # type: ignore
 from google.iam.v1 import policy_pb2  # type: ignore
 from google.longrunning import operations_pb2  # type: ignore
 from google.protobuf import timestamp_pb2  # type: ignore
 
 from google.cloud.dataplex_v1.services.metadata_service import pagers
 from google.cloud.dataplex_v1.types import metadata_
 
-from .client import MetadataServiceClient
 from .transports.base import DEFAULT_CLIENT_INFO, MetadataServiceTransport
+from .transports.grpc import MetadataServiceGrpcTransport
 from .transports.grpc_asyncio import MetadataServiceGrpcAsyncIOTransport
 
 
-class MetadataServiceAsyncClient:
+class MetadataServiceClientMeta(type):
+    """Metaclass for the MetadataService client.
+
+    This provides class-level methods for building and retrieving
+    support objects (e.g. transport) without polluting the client instance
+    objects.
+    """
+
+    _transport_registry = (
+        OrderedDict()
+    )  # type: Dict[str, Type[MetadataServiceTransport]]
+    _transport_registry["grpc"] = MetadataServiceGrpcTransport
+    _transport_registry["grpc_asyncio"] = MetadataServiceGrpcAsyncIOTransport
+
+    def get_transport_class(
+        cls,
+        label: Optional[str] = None,
+    ) -> Type[MetadataServiceTransport]:
+        """Returns an appropriate transport class.
+
+        Args:
+            label: The name of the desired transport. If none is
+                provided, then the first transport in the registry is used.
+
+        Returns:
+            The transport class to use.
+        """
+        # If a specific transport is requested, return that one.
+        if label:
+            return cls._transport_registry[label]
+
+        # No transport is requested; return the default (that is, the first one
+        # in the dictionary).
+        return next(iter(cls._transport_registry.values()))
+
+
+class MetadataServiceClient(metaclass=MetadataServiceClientMeta):
     """Metadata service manages metadata resources such as tables,
     filesets and partitions.
     """
 
-    _client: MetadataServiceClient
+    @staticmethod
+    def _get_default_mtls_endpoint(api_endpoint):
+        """Converts api endpoint to mTLS endpoint.
 
-    DEFAULT_ENDPOINT = MetadataServiceClient.DEFAULT_ENDPOINT
-    DEFAULT_MTLS_ENDPOINT = MetadataServiceClient.DEFAULT_MTLS_ENDPOINT
+        Convert "*.sandbox.googleapis.com" and "*.googleapis.com" to
+        "*.mtls.sandbox.googleapis.com" and "*.mtls.googleapis.com" respectively.
+        Args:
+            api_endpoint (Optional[str]): the api endpoint to convert.
+        Returns:
+            str: converted mTLS api endpoint.
+        """
+        if not api_endpoint:
+            return api_endpoint
 
-    entity_path = staticmethod(MetadataServiceClient.entity_path)
-    parse_entity_path = staticmethod(MetadataServiceClient.parse_entity_path)
-    partition_path = staticmethod(MetadataServiceClient.partition_path)
-    parse_partition_path = staticmethod(MetadataServiceClient.parse_partition_path)
-    zone_path = staticmethod(MetadataServiceClient.zone_path)
-    parse_zone_path = staticmethod(MetadataServiceClient.parse_zone_path)
-    common_billing_account_path = staticmethod(
-        MetadataServiceClient.common_billing_account_path
-    )
-    parse_common_billing_account_path = staticmethod(
-        MetadataServiceClient.parse_common_billing_account_path
-    )
-    common_folder_path = staticmethod(MetadataServiceClient.common_folder_path)
-    parse_common_folder_path = staticmethod(
-        MetadataServiceClient.parse_common_folder_path
-    )
-    common_organization_path = staticmethod(
-        MetadataServiceClient.common_organization_path
-    )
-    parse_common_organization_path = staticmethod(
-        MetadataServiceClient.parse_common_organization_path
-    )
-    common_project_path = staticmethod(MetadataServiceClient.common_project_path)
-    parse_common_project_path = staticmethod(
-        MetadataServiceClient.parse_common_project_path
-    )
-    common_location_path = staticmethod(MetadataServiceClient.common_location_path)
-    parse_common_location_path = staticmethod(
-        MetadataServiceClient.parse_common_location_path
+        mtls_endpoint_re = re.compile(
+            r"(?P<name>[^.]+)(?P<mtls>\.mtls)?(?P<sandbox>\.sandbox)?(?P<googledomain>\.googleapis\.com)?"
+        )
+
+        m = mtls_endpoint_re.match(api_endpoint)
+        name, mtls, sandbox, googledomain = m.groups()
+        if mtls or not googledomain:
+            return api_endpoint
+
+        if sandbox:
+            return api_endpoint.replace(
+                "sandbox.googleapis.com", "mtls.sandbox.googleapis.com"
+            )
+
+        return api_endpoint.replace(".googleapis.com", ".mtls.googleapis.com")
+
+    # Note: DEFAULT_ENDPOINT is deprecated. Use _DEFAULT_ENDPOINT_TEMPLATE instead.
+    DEFAULT_ENDPOINT = "dataplex.googleapis.com"
+    DEFAULT_MTLS_ENDPOINT = _get_default_mtls_endpoint.__func__(  # type: ignore
+        DEFAULT_ENDPOINT
     )
 
+    _DEFAULT_ENDPOINT_TEMPLATE = "dataplex.{UNIVERSE_DOMAIN}"
+    _DEFAULT_UNIVERSE = "googleapis.com"
+
     @classmethod
     def from_service_account_info(cls, info: dict, *args, **kwargs):
         """Creates an instance of this client using the provided credentials
             info.
 
         Args:
             info (dict): The service account private key info.
             args: Additional arguments to pass to the constructor.
             kwargs: Additional arguments to pass to the constructor.
 
         Returns:
-            MetadataServiceAsyncClient: The constructed client.
+            MetadataServiceClient: The constructed client.
         """
-        return MetadataServiceClient.from_service_account_info.__func__(MetadataServiceAsyncClient, info, *args, **kwargs)  # type: ignore
+        credentials = service_account.Credentials.from_service_account_info(info)
+        kwargs["credentials"] = credentials
+        return cls(*args, **kwargs)
 
     @classmethod
     def from_service_account_file(cls, filename: str, *args, **kwargs):
         """Creates an instance of this client using the provided credentials
             file.
 
         Args:
             filename (str): The path to the service account private key json
                 file.
             args: Additional arguments to pass to the constructor.
             kwargs: Additional arguments to pass to the constructor.
 
         Returns:
-            MetadataServiceAsyncClient: The constructed client.
+            MetadataServiceClient: The constructed client.
         """
-        return MetadataServiceClient.from_service_account_file.__func__(MetadataServiceAsyncClient, filename, *args, **kwargs)  # type: ignore
+        credentials = service_account.Credentials.from_service_account_file(filename)
+        kwargs["credentials"] = credentials
+        return cls(*args, **kwargs)
 
     from_service_account_json = from_service_account_file
 
+    @property
+    def transport(self) -> MetadataServiceTransport:
+        """Returns the transport used by the client instance.
+
+        Returns:
+            MetadataServiceTransport: The transport used by the client
+                instance.
+        """
+        return self._transport
+
+    @staticmethod
+    def entity_path(
+        project: str,
+        location: str,
+        lake: str,
+        zone: str,
+        entity: str,
+    ) -> str:
+        """Returns a fully-qualified entity string."""
+        return "projects/{project}/locations/{location}/lakes/{lake}/zones/{zone}/entities/{entity}".format(
+            project=project,
+            location=location,
+            lake=lake,
+            zone=zone,
+            entity=entity,
+        )
+
+    @staticmethod
+    def parse_entity_path(path: str) -> Dict[str, str]:
+        """Parses a entity path into its component segments."""
+        m = re.match(
+            r"^projects/(?P<project>.+?)/locations/(?P<location>.+?)/lakes/(?P<lake>.+?)/zones/(?P<zone>.+?)/entities/(?P<entity>.+?)$",
+            path,
+        )
+        return m.groupdict() if m else {}
+
+    @staticmethod
+    def partition_path(
+        project: str,
+        location: str,
+        lake: str,
+        zone: str,
+        entity: str,
+        partition: str,
+    ) -> str:
+        """Returns a fully-qualified partition string."""
+        return "projects/{project}/locations/{location}/lakes/{lake}/zones/{zone}/entities/{entity}/partitions/{partition}".format(
+            project=project,
+            location=location,
+            lake=lake,
+            zone=zone,
+            entity=entity,
+            partition=partition,
+        )
+
+    @staticmethod
+    def parse_partition_path(path: str) -> Dict[str, str]:
+        """Parses a partition path into its component segments."""
+        m = re.match(
+            r"^projects/(?P<project>.+?)/locations/(?P<location>.+?)/lakes/(?P<lake>.+?)/zones/(?P<zone>.+?)/entities/(?P<entity>.+?)/partitions/(?P<partition>.+?)$",
+            path,
+        )
+        return m.groupdict() if m else {}
+
+    @staticmethod
+    def zone_path(
+        project: str,
+        location: str,
+        lake: str,
+        zone: str,
+    ) -> str:
+        """Returns a fully-qualified zone string."""
+        return (
+            "projects/{project}/locations/{location}/lakes/{lake}/zones/{zone}".format(
+                project=project,
+                location=location,
+                lake=lake,
+                zone=zone,
+            )
+        )
+
+    @staticmethod
+    def parse_zone_path(path: str) -> Dict[str, str]:
+        """Parses a zone path into its component segments."""
+        m = re.match(
+            r"^projects/(?P<project>.+?)/locations/(?P<location>.+?)/lakes/(?P<lake>.+?)/zones/(?P<zone>.+?)$",
+            path,
+        )
+        return m.groupdict() if m else {}
+
+    @staticmethod
+    def common_billing_account_path(
+        billing_account: str,
+    ) -> str:
+        """Returns a fully-qualified billing_account string."""
+        return "billingAccounts/{billing_account}".format(
+            billing_account=billing_account,
+        )
+
+    @staticmethod
+    def parse_common_billing_account_path(path: str) -> Dict[str, str]:
+        """Parse a billing_account path into its component segments."""
+        m = re.match(r"^billingAccounts/(?P<billing_account>.+?)$", path)
+        return m.groupdict() if m else {}
+
+    @staticmethod
+    def common_folder_path(
+        folder: str,
+    ) -> str:
+        """Returns a fully-qualified folder string."""
+        return "folders/{folder}".format(
+            folder=folder,
+        )
+
+    @staticmethod
+    def parse_common_folder_path(path: str) -> Dict[str, str]:
+        """Parse a folder path into its component segments."""
+        m = re.match(r"^folders/(?P<folder>.+?)$", path)
+        return m.groupdict() if m else {}
+
+    @staticmethod
+    def common_organization_path(
+        organization: str,
+    ) -> str:
+        """Returns a fully-qualified organization string."""
+        return "organizations/{organization}".format(
+            organization=organization,
+        )
+
+    @staticmethod
+    def parse_common_organization_path(path: str) -> Dict[str, str]:
+        """Parse a organization path into its component segments."""
+        m = re.match(r"^organizations/(?P<organization>.+?)$", path)
+        return m.groupdict() if m else {}
+
+    @staticmethod
+    def common_project_path(
+        project: str,
+    ) -> str:
+        """Returns a fully-qualified project string."""
+        return "projects/{project}".format(
+            project=project,
+        )
+
+    @staticmethod
+    def parse_common_project_path(path: str) -> Dict[str, str]:
+        """Parse a project path into its component segments."""
+        m = re.match(r"^projects/(?P<project>.+?)$", path)
+        return m.groupdict() if m else {}
+
+    @staticmethod
+    def common_location_path(
+        project: str,
+        location: str,
+    ) -> str:
+        """Returns a fully-qualified location string."""
+        return "projects/{project}/locations/{location}".format(
+            project=project,
+            location=location,
+        )
+
+    @staticmethod
+    def parse_common_location_path(path: str) -> Dict[str, str]:
+        """Parse a location path into its component segments."""
+        m = re.match(r"^projects/(?P<project>.+?)/locations/(?P<location>.+?)$", path)
+        return m.groupdict() if m else {}
+
     @classmethod
     def get_mtls_endpoint_and_cert_source(
-        cls, client_options: Optional[ClientOptions] = None
+        cls, client_options: Optional[client_options_lib.ClientOptions] = None
     ):
-        """Return the API endpoint and client cert source for mutual TLS.
+        """Deprecated. Return the API endpoint and client cert source for mutual TLS.
 
         The client cert source is determined in the following order:
         (1) if `GOOGLE_API_USE_CLIENT_CERTIFICATE` environment variable is not "true", the
         client cert source is None.
         (2) if `client_options.client_cert_source` is provided, use the provided one; if the
         default client cert source exists, use the default one; otherwise the client cert
         source is None.
@@ -160,77 +376,378 @@
         Returns:
             Tuple[str, Callable[[], Tuple[bytes, bytes]]]: returns the API endpoint and the
                 client cert source to use.
 
         Raises:
             google.auth.exceptions.MutualTLSChannelError: If any errors happen.
         """
-        return MetadataServiceClient.get_mtls_endpoint_and_cert_source(client_options)  # type: ignore
+
+        warnings.warn(
+            "get_mtls_endpoint_and_cert_source is deprecated. Use the api_endpoint property instead.",
+            DeprecationWarning,
+        )
+        if client_options is None:
+            client_options = client_options_lib.ClientOptions()
+        use_client_cert = os.getenv("GOOGLE_API_USE_CLIENT_CERTIFICATE", "false")
+        use_mtls_endpoint = os.getenv("GOOGLE_API_USE_MTLS_ENDPOINT", "auto")
+        if use_client_cert not in ("true", "false"):
+            raise ValueError(
+                "Environment variable `GOOGLE_API_USE_CLIENT_CERTIFICATE` must be either `true` or `false`"
+            )
+        if use_mtls_endpoint not in ("auto", "never", "always"):
+            raise MutualTLSChannelError(
+                "Environment variable `GOOGLE_API_USE_MTLS_ENDPOINT` must be `never`, `auto` or `always`"
+            )
+
+        # Figure out the client cert source to use.
+        client_cert_source = None
+        if use_client_cert == "true":
+            if client_options.client_cert_source:
+                client_cert_source = client_options.client_cert_source
+            elif mtls.has_default_client_cert_source():
+                client_cert_source = mtls.default_client_cert_source()
+
+        # Figure out which api endpoint to use.
+        if client_options.api_endpoint is not None:
+            api_endpoint = client_options.api_endpoint
+        elif use_mtls_endpoint == "always" or (
+            use_mtls_endpoint == "auto" and client_cert_source
+        ):
+            api_endpoint = cls.DEFAULT_MTLS_ENDPOINT
+        else:
+            api_endpoint = cls.DEFAULT_ENDPOINT
+
+        return api_endpoint, client_cert_source
+
+    @staticmethod
+    def _read_environment_variables():
+        """Returns the environment variables used by the client.
+
+        Returns:
+            Tuple[bool, str, str]: returns the GOOGLE_API_USE_CLIENT_CERTIFICATE,
+            GOOGLE_API_USE_MTLS_ENDPOINT, and GOOGLE_CLOUD_UNIVERSE_DOMAIN environment variables.
+
+        Raises:
+            ValueError: If GOOGLE_API_USE_CLIENT_CERTIFICATE is not
+                any of ["true", "false"].
+            google.auth.exceptions.MutualTLSChannelError: If GOOGLE_API_USE_MTLS_ENDPOINT
+                is not any of ["auto", "never", "always"].
+        """
+        use_client_cert = os.getenv(
+            "GOOGLE_API_USE_CLIENT_CERTIFICATE", "false"
+        ).lower()
+        use_mtls_endpoint = os.getenv("GOOGLE_API_USE_MTLS_ENDPOINT", "auto").lower()
+        universe_domain_env = os.getenv("GOOGLE_CLOUD_UNIVERSE_DOMAIN")
+        if use_client_cert not in ("true", "false"):
+            raise ValueError(
+                "Environment variable `GOOGLE_API_USE_CLIENT_CERTIFICATE` must be either `true` or `false`"
+            )
+        if use_mtls_endpoint not in ("auto", "never", "always"):
+            raise MutualTLSChannelError(
+                "Environment variable `GOOGLE_API_USE_MTLS_ENDPOINT` must be `never`, `auto` or `always`"
+            )
+        return use_client_cert == "true", use_mtls_endpoint, universe_domain_env
+
+    @staticmethod
+    def _get_client_cert_source(provided_cert_source, use_cert_flag):
+        """Return the client cert source to be used by the client.
+
+        Args:
+            provided_cert_source (bytes): The client certificate source provided.
+            use_cert_flag (bool): A flag indicating whether to use the client certificate.
+
+        Returns:
+            bytes or None: The client cert source to be used by the client.
+        """
+        client_cert_source = None
+        if use_cert_flag:
+            if provided_cert_source:
+                client_cert_source = provided_cert_source
+            elif mtls.has_default_client_cert_source():
+                client_cert_source = mtls.default_client_cert_source()
+        return client_cert_source
+
+    @staticmethod
+    def _get_api_endpoint(
+        api_override, client_cert_source, universe_domain, use_mtls_endpoint
+    ):
+        """Return the API endpoint used by the client.
+
+        Args:
+            api_override (str): The API endpoint override. If specified, this is always
+                the return value of this function and the other arguments are not used.
+            client_cert_source (bytes): The client certificate source used by the client.
+            universe_domain (str): The universe domain used by the client.
+            use_mtls_endpoint (str): How to use the mTLS endpoint, which depends also on the other parameters.
+                Possible values are "always", "auto", or "never".
+
+        Returns:
+            str: The API endpoint to be used by the client.
+        """
+        if api_override is not None:
+            api_endpoint = api_override
+        elif use_mtls_endpoint == "always" or (
+            use_mtls_endpoint == "auto" and client_cert_source
+        ):
+            _default_universe = MetadataServiceClient._DEFAULT_UNIVERSE
+            if universe_domain != _default_universe:
+                raise MutualTLSChannelError(
+                    f"mTLS is not supported in any universe other than {_default_universe}."
+                )
+            api_endpoint = MetadataServiceClient.DEFAULT_MTLS_ENDPOINT
+        else:
+            api_endpoint = MetadataServiceClient._DEFAULT_ENDPOINT_TEMPLATE.format(
+                UNIVERSE_DOMAIN=universe_domain
+            )
+        return api_endpoint
+
+    @staticmethod
+    def _get_universe_domain(
+        client_universe_domain: Optional[str], universe_domain_env: Optional[str]
+    ) -> str:
+        """Return the universe domain used by the client.
+
+        Args:
+            client_universe_domain (Optional[str]): The universe domain configured via the client options.
+            universe_domain_env (Optional[str]): The universe domain configured via the "GOOGLE_CLOUD_UNIVERSE_DOMAIN" environment variable.
+
+        Returns:
+            str: The universe domain to be used by the client.
+
+        Raises:
+            ValueError: If the universe domain is an empty string.
+        """
+        universe_domain = MetadataServiceClient._DEFAULT_UNIVERSE
+        if client_universe_domain is not None:
+            universe_domain = client_universe_domain
+        elif universe_domain_env is not None:
+            universe_domain = universe_domain_env
+        if len(universe_domain.strip()) == 0:
+            raise ValueError("Universe Domain cannot be an empty string.")
+        return universe_domain
+
+    @staticmethod
+    def _compare_universes(
+        client_universe: str, credentials: ga_credentials.Credentials
+    ) -> bool:
+        """Returns True iff the universe domains used by the client and credentials match.
+
+        Args:
+            client_universe (str): The universe domain configured via the client options.
+            credentials (ga_credentials.Credentials): The credentials being used in the client.
+
+        Returns:
+            bool: True iff client_universe matches the universe in credentials.
+
+        Raises:
+            ValueError: when client_universe does not match the universe in credentials.
+        """
+
+        default_universe = MetadataServiceClient._DEFAULT_UNIVERSE
+        credentials_universe = getattr(credentials, "universe_domain", default_universe)
+
+        if client_universe != credentials_universe:
+            raise ValueError(
+                "The configured universe domain "
+                f"({client_universe}) does not match the universe domain "
+                f"found in the credentials ({credentials_universe}). "
+                "If you haven't configured the universe domain explicitly, "
+                f"`{default_universe}` is the default."
+            )
+        return True
+
+    def _validate_universe_domain(self):
+        """Validates client's and credentials' universe domains are consistent.
+
+        Returns:
+            bool: True iff the configured universe domain is valid.
+
+        Raises:
+            ValueError: If the configured universe domain is not valid.
+        """
+        self._is_universe_domain_valid = (
+            self._is_universe_domain_valid
+            or MetadataServiceClient._compare_universes(
+                self.universe_domain, self.transport._credentials
+            )
+        )
+        return self._is_universe_domain_valid
 
     @property
-    def transport(self) -> MetadataServiceTransport:
-        """Returns the transport used by the client instance.
+    def api_endpoint(self):
+        """Return the API endpoint used by the client instance.
 
         Returns:
-            MetadataServiceTransport: The transport used by the client instance.
+            str: The API endpoint used by the client instance.
         """
-        return self._client.transport
+        return self._api_endpoint
 
-    get_transport_class = functools.partial(
-        type(MetadataServiceClient).get_transport_class, type(MetadataServiceClient)
-    )
+    @property
+    def universe_domain(self) -> str:
+        """Return the universe domain used by the client instance.
+
+        Returns:
+            str: The universe domain used by the client instance.
+        """
+        return self._universe_domain
 
     def __init__(
         self,
         *,
         credentials: Optional[ga_credentials.Credentials] = None,
-        transport: Union[str, MetadataServiceTransport] = "grpc_asyncio",
-        client_options: Optional[ClientOptions] = None,
+        transport: Optional[
+            Union[
+                str, MetadataServiceTransport, Callable[..., MetadataServiceTransport]
+            ]
+        ] = None,
+        client_options: Optional[Union[client_options_lib.ClientOptions, dict]] = None,
         client_info: gapic_v1.client_info.ClientInfo = DEFAULT_CLIENT_INFO,
     ) -> None:
         """Instantiates the metadata service client.
 
         Args:
             credentials (Optional[google.auth.credentials.Credentials]): The
                 authorization credentials to attach to requests. These
                 credentials identify the application to the service; if none
                 are specified, the client will attempt to ascertain the
                 credentials from the environment.
-            transport (Union[str, ~.MetadataServiceTransport]): The
-                transport to use. If set to None, a transport is chosen
-                automatically.
-            client_options (ClientOptions): Custom options for the client. It
-                won't take effect if a ``transport`` instance is provided.
-                (1) The ``api_endpoint`` property can be used to override the
-                default endpoint provided by the client. GOOGLE_API_USE_MTLS_ENDPOINT
-                environment variable can also be used to override the endpoint:
+            transport (Optional[Union[str,MetadataServiceTransport,Callable[..., MetadataServiceTransport]]]):
+                The transport to use, or a Callable that constructs and returns a new transport.
+                If a Callable is given, it will be called with the same set of initialization
+                arguments as used in the MetadataServiceTransport constructor.
+                If set to None, a transport is chosen automatically.
+            client_options (Optional[Union[google.api_core.client_options.ClientOptions, dict]]):
+                Custom options for the client.
+
+                1. The ``api_endpoint`` property can be used to override the
+                default endpoint provided by the client when ``transport`` is
+                not explicitly provided. Only if this property is not set and
+                ``transport`` was not explicitly provided, the endpoint is
+                determined by the GOOGLE_API_USE_MTLS_ENDPOINT environment
+                variable, which have one of the following values:
                 "always" (always use the default mTLS endpoint), "never" (always
-                use the default regular endpoint) and "auto" (auto switch to the
-                default mTLS endpoint if client certificate is present, this is
-                the default value). However, the ``api_endpoint`` property takes
-                precedence if provided.
-                (2) If GOOGLE_API_USE_CLIENT_CERTIFICATE environment variable
+                use the default regular endpoint) and "auto" (auto-switch to the
+                default mTLS endpoint if client certificate is present; this is
+                the default value).
+
+                2. If the GOOGLE_API_USE_CLIENT_CERTIFICATE environment variable
                 is "true", then the ``client_cert_source`` property can be used
-                to provide client certificate for mutual TLS transport. If
+                to provide a client certificate for mTLS transport. If
                 not provided, the default SSL client certificate will be used if
                 present. If GOOGLE_API_USE_CLIENT_CERTIFICATE is "false" or not
                 set, no client certificate will be used.
 
+                3. The ``universe_domain`` property can be used to override the
+                default "googleapis.com" universe. Note that the ``api_endpoint``
+                property still takes precedence; and ``universe_domain`` is
+                currently not supported for mTLS.
+
+            client_info (google.api_core.gapic_v1.client_info.ClientInfo):
+                The client info used to send a user-agent string along with
+                API requests. If ``None``, then default info will be used.
+                Generally, you only need to set this if you're developing
+                your own client library.
+
         Raises:
-            google.auth.exceptions.MutualTlsChannelError: If mutual TLS transport
+            google.auth.exceptions.MutualTLSChannelError: If mutual TLS transport
                 creation failed for any reason.
         """
-        self._client = MetadataServiceClient(
-            credentials=credentials,
-            transport=transport,
-            client_options=client_options,
-            client_info=client_info,
+        self._client_options = client_options
+        if isinstance(self._client_options, dict):
+            self._client_options = client_options_lib.from_dict(self._client_options)
+        if self._client_options is None:
+            self._client_options = client_options_lib.ClientOptions()
+        self._client_options = cast(
+            client_options_lib.ClientOptions, self._client_options
+        )
+
+        universe_domain_opt = getattr(self._client_options, "universe_domain", None)
+
+        (
+            self._use_client_cert,
+            self._use_mtls_endpoint,
+            self._universe_domain_env,
+        ) = MetadataServiceClient._read_environment_variables()
+        self._client_cert_source = MetadataServiceClient._get_client_cert_source(
+            self._client_options.client_cert_source, self._use_client_cert
+        )
+        self._universe_domain = MetadataServiceClient._get_universe_domain(
+            universe_domain_opt, self._universe_domain_env
         )
+        self._api_endpoint = None  # updated below, depending on `transport`
+
+        # Initialize the universe domain validation.
+        self._is_universe_domain_valid = False
 
-    async def create_entity(
+        api_key_value = getattr(self._client_options, "api_key", None)
+        if api_key_value and credentials:
+            raise ValueError(
+                "client_options.api_key and credentials are mutually exclusive"
+            )
+
+        # Save or instantiate the transport.
+        # Ordinarily, we provide the transport, but allowing a custom transport
+        # instance provides an extensibility point for unusual situations.
+        transport_provided = isinstance(transport, MetadataServiceTransport)
+        if transport_provided:
+            # transport is a MetadataServiceTransport instance.
+            if credentials or self._client_options.credentials_file or api_key_value:
+                raise ValueError(
+                    "When providing a transport instance, "
+                    "provide its credentials directly."
+                )
+            if self._client_options.scopes:
+                raise ValueError(
+                    "When providing a transport instance, provide its scopes "
+                    "directly."
+                )
+            self._transport = cast(MetadataServiceTransport, transport)
+            self._api_endpoint = self._transport.host
+
+        self._api_endpoint = (
+            self._api_endpoint
+            or MetadataServiceClient._get_api_endpoint(
+                self._client_options.api_endpoint,
+                self._client_cert_source,
+                self._universe_domain,
+                self._use_mtls_endpoint,
+            )
+        )
+
+        if not transport_provided:
+            import google.auth._default  # type: ignore
+
+            if api_key_value and hasattr(
+                google.auth._default, "get_api_key_credentials"
+            ):
+                credentials = google.auth._default.get_api_key_credentials(
+                    api_key_value
+                )
+
+            transport_init: Union[
+                Type[MetadataServiceTransport], Callable[..., MetadataServiceTransport]
+            ] = (
+                type(self).get_transport_class(transport)
+                if isinstance(transport, str) or transport is None
+                else cast(Callable[..., MetadataServiceTransport], transport)
+            )
+            # initialize with the provided callable or the passed in class
+            self._transport = transport_init(
+                credentials=credentials,
+                credentials_file=self._client_options.credentials_file,
+                host=self._api_endpoint,
+                scopes=self._client_options.scopes,
+                client_cert_source_for_mtls=self._client_cert_source,
+                quota_project_id=self._client_options.quota_project_id,
+                client_info=client_info,
+                always_use_jwt_access=True,
+                api_audience=self._client_options.api_audience,
+            )
+
+    def create_entity(
         self,
         request: Optional[Union[metadata_.CreateEntityRequest, dict]] = None,
         *,
         parent: Optional[str] = None,
         entity: Optional[metadata_.Entity] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
@@ -245,17 +762,17 @@
             # It will require modifications to work:
             # - It may require correct/in-range values for request initialization.
             # - It may require specifying regional endpoints when creating the service
             #   client as shown in:
             #   https://googleapis.dev/python/google-api-core/latest/client_options.html
             from google.cloud import dataplex_v1
 
-            async def sample_create_entity():
+            def sample_create_entity():
                 # Create a client
-                client = dataplex_v1.MetadataServiceAsyncClient()
+                client = dataplex_v1.MetadataServiceClient()
 
                 # Initialize request argument(s)
                 entity = dataplex_v1.Entity()
                 entity.id = "id_value"
                 entity.type_ = "FILESET"
                 entity.asset = "asset_value"
                 entity.data_path = "data_path_value"
@@ -265,30 +782,30 @@
 
                 request = dataplex_v1.CreateEntityRequest(
                     parent="parent_value",
                     entity=entity,
                 )
 
                 # Make the request
-                response = await client.create_entity(request=request)
+                response = client.create_entity(request=request)
 
                 # Handle the response
                 print(response)
 
         Args:
-            request (Optional[Union[google.cloud.dataplex_v1.types.CreateEntityRequest, dict]]):
+            request (Union[google.cloud.dataplex_v1.types.CreateEntityRequest, dict]):
                 The request object. Create a metadata entity request.
-            parent (:class:`str`):
+            parent (str):
                 Required. The resource name of the parent zone:
                 ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}``.
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            entity (:class:`google.cloud.dataplex_v1.types.Entity`):
+            entity (google.cloud.dataplex_v1.types.Entity):
                 Required. Entity resource.
                 This corresponds to the ``entity`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             retry (google.api_core.retry.Retry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
@@ -298,58 +815,59 @@
         Returns:
             google.cloud.dataplex_v1.types.Entity:
                 Represents tables and fileset
                 metadata contained within a zone.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent, entity])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = metadata_.CreateEntityRequest(request)
-
-        # If we have keyword arguments corresponding to fields on the
-        # request, apply these.
-        if parent is not None:
-            request.parent = parent
-        if entity is not None:
-            request.entity = entity
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, metadata_.CreateEntityRequest):
+            request = metadata_.CreateEntityRequest(request)
+            # If we have keyword arguments corresponding to fields on the
+            # request, apply these.
+            if parent is not None:
+                request.parent = parent
+            if entity is not None:
+                request.entity = entity
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.create_entity,
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._transport._wrapped_methods[self._transport.create_entity]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
-        response = await rpc(
+        response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
-    async def update_entity(
+    def update_entity(
         self,
         request: Optional[Union[metadata_.UpdateEntityRequest, dict]] = None,
         *,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
     ) -> metadata_.Entity:
@@ -363,17 +881,17 @@
             # It will require modifications to work:
             # - It may require correct/in-range values for request initialization.
             # - It may require specifying regional endpoints when creating the service
             #   client as shown in:
             #   https://googleapis.dev/python/google-api-core/latest/client_options.html
             from google.cloud import dataplex_v1
 
-            async def sample_update_entity():
+            def sample_update_entity():
                 # Create a client
-                client = dataplex_v1.MetadataServiceAsyncClient()
+                client = dataplex_v1.MetadataServiceClient()
 
                 # Initialize request argument(s)
                 entity = dataplex_v1.Entity()
                 entity.id = "id_value"
                 entity.type_ = "FILESET"
                 entity.asset = "asset_value"
                 entity.data_path = "data_path_value"
@@ -382,21 +900,21 @@
                 entity.schema.user_managed = True
 
                 request = dataplex_v1.UpdateEntityRequest(
                     entity=entity,
                 )
 
                 # Make the request
-                response = await client.update_entity(request=request)
+                response = client.update_entity(request=request)
 
                 # Handle the response
                 print(response)
 
         Args:
-            request (Optional[Union[google.cloud.dataplex_v1.types.UpdateEntityRequest, dict]]):
+            request (Union[google.cloud.dataplex_v1.types.UpdateEntityRequest, dict]):
                 The request object. Update a metadata entity request.
                 The exiting entity will be fully
                 replaced by the entity in the request.
                 The entity ID is mutable. To modify the
                 ID, use the current entity ID in the
                 request URL and specify the new ID in
                 the request body.
@@ -409,44 +927,46 @@
         Returns:
             google.cloud.dataplex_v1.types.Entity:
                 Represents tables and fileset
                 metadata contained within a zone.
 
         """
         # Create or coerce a protobuf request object.
-        request = metadata_.UpdateEntityRequest(request)
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, metadata_.UpdateEntityRequest):
+            request = metadata_.UpdateEntityRequest(request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.update_entity,
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._transport._wrapped_methods[self._transport.update_entity]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata(
                 (("entity.name", request.entity.name),)
             ),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
-        response = await rpc(
+        response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
-    async def delete_entity(
+    def delete_entity(
         self,
         request: Optional[Union[metadata_.DeleteEntityRequest, dict]] = None,
         *,
         name: Optional[str] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
@@ -460,83 +980,84 @@
             # It will require modifications to work:
             # - It may require correct/in-range values for request initialization.
             # - It may require specifying regional endpoints when creating the service
             #   client as shown in:
             #   https://googleapis.dev/python/google-api-core/latest/client_options.html
             from google.cloud import dataplex_v1
 
-            async def sample_delete_entity():
+            def sample_delete_entity():
                 # Create a client
-                client = dataplex_v1.MetadataServiceAsyncClient()
+                client = dataplex_v1.MetadataServiceClient()
 
                 # Initialize request argument(s)
                 request = dataplex_v1.DeleteEntityRequest(
                     name="name_value",
                     etag="etag_value",
                 )
 
                 # Make the request
-                await client.delete_entity(request=request)
+                client.delete_entity(request=request)
 
         Args:
-            request (Optional[Union[google.cloud.dataplex_v1.types.DeleteEntityRequest, dict]]):
+            request (Union[google.cloud.dataplex_v1.types.DeleteEntityRequest, dict]):
                 The request object. Delete a metadata entity request.
-            name (:class:`str`):
+            name (str):
                 Required. The resource name of the entity:
                 ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/entities/{entity_id}``.
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             retry (google.api_core.retry.Retry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = metadata_.DeleteEntityRequest(request)
-
-        # If we have keyword arguments corresponding to fields on the
-        # request, apply these.
-        if name is not None:
-            request.name = name
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, metadata_.DeleteEntityRequest):
+            request = metadata_.DeleteEntityRequest(request)
+            # If we have keyword arguments corresponding to fields on the
+            # request, apply these.
+            if name is not None:
+                request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.delete_entity,
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._transport._wrapped_methods[self._transport.delete_entity]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
-        await rpc(
+        rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
-    async def get_entity(
+    def get_entity(
         self,
         request: Optional[Union[metadata_.GetEntityRequest, dict]] = None,
         *,
         name: Optional[str] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
@@ -550,33 +1071,33 @@
             # It will require modifications to work:
             # - It may require correct/in-range values for request initialization.
             # - It may require specifying regional endpoints when creating the service
             #   client as shown in:
             #   https://googleapis.dev/python/google-api-core/latest/client_options.html
             from google.cloud import dataplex_v1
 
-            async def sample_get_entity():
+            def sample_get_entity():
                 # Create a client
-                client = dataplex_v1.MetadataServiceAsyncClient()
+                client = dataplex_v1.MetadataServiceClient()
 
                 # Initialize request argument(s)
                 request = dataplex_v1.GetEntityRequest(
                     name="name_value",
                 )
 
                 # Make the request
-                response = await client.get_entity(request=request)
+                response = client.get_entity(request=request)
 
                 # Handle the response
                 print(response)
 
         Args:
-            request (Optional[Union[google.cloud.dataplex_v1.types.GetEntityRequest, dict]]):
+            request (Union[google.cloud.dataplex_v1.types.GetEntityRequest, dict]):
                 The request object. Get metadata entity request.
-            name (:class:`str`):
+            name (str):
                 Required. The resource name of the entity:
                 ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/entities/{entity_id}.``
 
                 This corresponds to the ``name`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             retry (google.api_core.retry.Retry): Designation of what errors, if any,
@@ -588,189 +1109,173 @@
         Returns:
             google.cloud.dataplex_v1.types.Entity:
                 Represents tables and fileset
                 metadata contained within a zone.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = metadata_.GetEntityRequest(request)
-
-        # If we have keyword arguments corresponding to fields on the
-        # request, apply these.
-        if name is not None:
-            request.name = name
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, metadata_.GetEntityRequest):
+            request = metadata_.GetEntityRequest(request)
+            # If we have keyword arguments corresponding to fields on the
+            # request, apply these.
+            if name is not None:
+                request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.get_entity,
-            default_retry=retries.Retry(
-                initial=1.0,
-                maximum=10.0,
-                multiplier=1.3,
-                predicate=retries.if_exception_type(
-                    core_exceptions.ServiceUnavailable,
-                ),
-                deadline=60.0,
-            ),
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._transport._wrapped_methods[self._transport.get_entity]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
-        response = await rpc(
+        response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
-    async def list_entities(
+    def list_entities(
         self,
         request: Optional[Union[metadata_.ListEntitiesRequest, dict]] = None,
         *,
         parent: Optional[str] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
-    ) -> pagers.ListEntitiesAsyncPager:
+    ) -> pagers.ListEntitiesPager:
         r"""List metadata entities in a zone.
 
         .. code-block:: python
 
             # This snippet has been automatically generated and should be regarded as a
             # code template only.
             # It will require modifications to work:
             # - It may require correct/in-range values for request initialization.
             # - It may require specifying regional endpoints when creating the service
             #   client as shown in:
             #   https://googleapis.dev/python/google-api-core/latest/client_options.html
             from google.cloud import dataplex_v1
 
-            async def sample_list_entities():
+            def sample_list_entities():
                 # Create a client
-                client = dataplex_v1.MetadataServiceAsyncClient()
+                client = dataplex_v1.MetadataServiceClient()
 
                 # Initialize request argument(s)
                 request = dataplex_v1.ListEntitiesRequest(
                     parent="parent_value",
                     view="FILESETS",
                 )
 
                 # Make the request
                 page_result = client.list_entities(request=request)
 
                 # Handle the response
-                async for response in page_result:
+                for response in page_result:
                     print(response)
 
         Args:
-            request (Optional[Union[google.cloud.dataplex_v1.types.ListEntitiesRequest, dict]]):
+            request (Union[google.cloud.dataplex_v1.types.ListEntitiesRequest, dict]):
                 The request object. List metadata entities request.
-            parent (:class:`str`):
+            parent (str):
                 Required. The resource name of the parent zone:
                 ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}``.
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             retry (google.api_core.retry.Retry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
-            google.cloud.dataplex_v1.services.metadata_service.pagers.ListEntitiesAsyncPager:
+            google.cloud.dataplex_v1.services.metadata_service.pagers.ListEntitiesPager:
                 List metadata entities response.
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = metadata_.ListEntitiesRequest(request)
-
-        # If we have keyword arguments corresponding to fields on the
-        # request, apply these.
-        if parent is not None:
-            request.parent = parent
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, metadata_.ListEntitiesRequest):
+            request = metadata_.ListEntitiesRequest(request)
+            # If we have keyword arguments corresponding to fields on the
+            # request, apply these.
+            if parent is not None:
+                request.parent = parent
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.list_entities,
-            default_retry=retries.Retry(
-                initial=1.0,
-                maximum=10.0,
-                multiplier=1.3,
-                predicate=retries.if_exception_type(
-                    core_exceptions.ServiceUnavailable,
-                ),
-                deadline=60.0,
-            ),
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._transport._wrapped_methods[self._transport.list_entities]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
-        response = await rpc(
+        response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
         # This method is paged; wrap the response in a pager, which provides
-        # an `__aiter__` convenience method.
-        response = pagers.ListEntitiesAsyncPager(
+        # an `__iter__` convenience method.
+        response = pagers.ListEntitiesPager(
             method=rpc,
             request=request,
             response=response,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
-    async def create_partition(
+    def create_partition(
         self,
         request: Optional[Union[metadata_.CreatePartitionRequest, dict]] = None,
         *,
         parent: Optional[str] = None,
         partition: Optional[metadata_.Partition] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
@@ -785,45 +1290,45 @@
             # It will require modifications to work:
             # - It may require correct/in-range values for request initialization.
             # - It may require specifying regional endpoints when creating the service
             #   client as shown in:
             #   https://googleapis.dev/python/google-api-core/latest/client_options.html
             from google.cloud import dataplex_v1
 
-            async def sample_create_partition():
+            def sample_create_partition():
                 # Create a client
-                client = dataplex_v1.MetadataServiceAsyncClient()
+                client = dataplex_v1.MetadataServiceClient()
 
                 # Initialize request argument(s)
                 partition = dataplex_v1.Partition()
                 partition.values = ['values_value1', 'values_value2']
                 partition.location = "location_value"
 
                 request = dataplex_v1.CreatePartitionRequest(
                     parent="parent_value",
                     partition=partition,
                 )
 
                 # Make the request
-                response = await client.create_partition(request=request)
+                response = client.create_partition(request=request)
 
                 # Handle the response
                 print(response)
 
         Args:
-            request (Optional[Union[google.cloud.dataplex_v1.types.CreatePartitionRequest, dict]]):
+            request (Union[google.cloud.dataplex_v1.types.CreatePartitionRequest, dict]):
                 The request object. Create metadata partition request.
-            parent (:class:`str`):
+            parent (str):
                 Required. The resource name of the parent zone:
                 ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/entities/{entity_id}``.
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
-            partition (:class:`google.cloud.dataplex_v1.types.Partition`):
+            partition (google.cloud.dataplex_v1.types.Partition):
                 Required. Partition resource.
                 This corresponds to the ``partition`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             retry (google.api_core.retry.Retry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
@@ -833,58 +1338,59 @@
         Returns:
             google.cloud.dataplex_v1.types.Partition:
                 Represents partition metadata
                 contained within entity instances.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent, partition])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = metadata_.CreatePartitionRequest(request)
-
-        # If we have keyword arguments corresponding to fields on the
-        # request, apply these.
-        if parent is not None:
-            request.parent = parent
-        if partition is not None:
-            request.partition = partition
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, metadata_.CreatePartitionRequest):
+            request = metadata_.CreatePartitionRequest(request)
+            # If we have keyword arguments corresponding to fields on the
+            # request, apply these.
+            if parent is not None:
+                request.parent = parent
+            if partition is not None:
+                request.partition = partition
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.create_partition,
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._transport._wrapped_methods[self._transport.create_partition]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
-        response = await rpc(
+        response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
-    async def delete_partition(
+    def delete_partition(
         self,
         request: Optional[Union[metadata_.DeletePartitionRequest, dict]] = None,
         *,
         name: Optional[str] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
@@ -898,30 +1404,30 @@
             # It will require modifications to work:
             # - It may require correct/in-range values for request initialization.
             # - It may require specifying regional endpoints when creating the service
             #   client as shown in:
             #   https://googleapis.dev/python/google-api-core/latest/client_options.html
             from google.cloud import dataplex_v1
 
-            async def sample_delete_partition():
+            def sample_delete_partition():
                 # Create a client
-                client = dataplex_v1.MetadataServiceAsyncClient()
+                client = dataplex_v1.MetadataServiceClient()
 
                 # Initialize request argument(s)
                 request = dataplex_v1.DeletePartitionRequest(
                     name="name_value",
                 )
 
                 # Make the request
-                await client.delete_partition(request=request)
+                client.delete_partition(request=request)
 
         Args:
-            request (Optional[Union[google.cloud.dataplex_v1.types.DeletePartitionRequest, dict]]):
+            request (Union[google.cloud.dataplex_v1.types.DeletePartitionRequest, dict]):
                 The request object. Delete metadata partition request.
-            name (:class:`str`):
+            name (str):
                 Required. The resource name of the partition. format:
                 ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/entities/{entity_id}/partitions/{partition_value_path}``.
                 The {partition_value_path} segment consists of an
                 ordered sequence of partition values separated by "/".
                 All values must be provided.
 
                 This corresponds to the ``name`` field
@@ -930,53 +1436,54 @@
             retry (google.api_core.retry.Retry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = metadata_.DeletePartitionRequest(request)
-
-        # If we have keyword arguments corresponding to fields on the
-        # request, apply these.
-        if name is not None:
-            request.name = name
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, metadata_.DeletePartitionRequest):
+            request = metadata_.DeletePartitionRequest(request)
+            # If we have keyword arguments corresponding to fields on the
+            # request, apply these.
+            if name is not None:
+                request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.delete_partition,
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._transport._wrapped_methods[self._transport.delete_partition]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
-        await rpc(
+        rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
-    async def get_partition(
+    def get_partition(
         self,
         request: Optional[Union[metadata_.GetPartitionRequest, dict]] = None,
         *,
         name: Optional[str] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
@@ -990,33 +1497,33 @@
             # It will require modifications to work:
             # - It may require correct/in-range values for request initialization.
             # - It may require specifying regional endpoints when creating the service
             #   client as shown in:
             #   https://googleapis.dev/python/google-api-core/latest/client_options.html
             from google.cloud import dataplex_v1
 
-            async def sample_get_partition():
+            def sample_get_partition():
                 # Create a client
-                client = dataplex_v1.MetadataServiceAsyncClient()
+                client = dataplex_v1.MetadataServiceClient()
 
                 # Initialize request argument(s)
                 request = dataplex_v1.GetPartitionRequest(
                     name="name_value",
                 )
 
                 # Make the request
-                response = await client.get_partition(request=request)
+                response = client.get_partition(request=request)
 
                 # Handle the response
                 print(response)
 
         Args:
-            request (Optional[Union[google.cloud.dataplex_v1.types.GetPartitionRequest, dict]]):
+            request (Union[google.cloud.dataplex_v1.types.GetPartitionRequest, dict]):
                 The request object. Get metadata partition request.
-            name (:class:`str`):
+            name (str):
                 Required. The resource name of the partition:
                 ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/entities/{entity_id}/partitions/{partition_value_path}``.
                 The {partition_value_path} segment consists of an
                 ordered sequence of partition values separated by "/".
                 All values must be provided.
 
                 This corresponds to the ``name`` field
@@ -1031,188 +1538,185 @@
         Returns:
             google.cloud.dataplex_v1.types.Partition:
                 Represents partition metadata
                 contained within entity instances.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([name])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = metadata_.GetPartitionRequest(request)
-
-        # If we have keyword arguments corresponding to fields on the
-        # request, apply these.
-        if name is not None:
-            request.name = name
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, metadata_.GetPartitionRequest):
+            request = metadata_.GetPartitionRequest(request)
+            # If we have keyword arguments corresponding to fields on the
+            # request, apply these.
+            if name is not None:
+                request.name = name
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.get_partition,
-            default_retry=retries.Retry(
-                initial=1.0,
-                maximum=10.0,
-                multiplier=1.3,
-                predicate=retries.if_exception_type(
-                    core_exceptions.ServiceUnavailable,
-                ),
-                deadline=60.0,
-            ),
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._transport._wrapped_methods[self._transport.get_partition]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
-        response = await rpc(
+        response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
-    async def list_partitions(
+    def list_partitions(
         self,
         request: Optional[Union[metadata_.ListPartitionsRequest, dict]] = None,
         *,
         parent: Optional[str] = None,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
-    ) -> pagers.ListPartitionsAsyncPager:
+    ) -> pagers.ListPartitionsPager:
         r"""List metadata partitions of an entity.
 
         .. code-block:: python
 
             # This snippet has been automatically generated and should be regarded as a
             # code template only.
             # It will require modifications to work:
             # - It may require correct/in-range values for request initialization.
             # - It may require specifying regional endpoints when creating the service
             #   client as shown in:
             #   https://googleapis.dev/python/google-api-core/latest/client_options.html
             from google.cloud import dataplex_v1
 
-            async def sample_list_partitions():
+            def sample_list_partitions():
                 # Create a client
-                client = dataplex_v1.MetadataServiceAsyncClient()
+                client = dataplex_v1.MetadataServiceClient()
 
                 # Initialize request argument(s)
                 request = dataplex_v1.ListPartitionsRequest(
                     parent="parent_value",
                 )
 
                 # Make the request
                 page_result = client.list_partitions(request=request)
 
                 # Handle the response
-                async for response in page_result:
+                for response in page_result:
                     print(response)
 
         Args:
-            request (Optional[Union[google.cloud.dataplex_v1.types.ListPartitionsRequest, dict]]):
+            request (Union[google.cloud.dataplex_v1.types.ListPartitionsRequest, dict]):
                 The request object. List metadata partitions request.
-            parent (:class:`str`):
+            parent (str):
                 Required. The resource name of the parent entity:
                 ``projects/{project_number}/locations/{location_id}/lakes/{lake_id}/zones/{zone_id}/entities/{entity_id}``.
 
                 This corresponds to the ``parent`` field
                 on the ``request`` instance; if ``request`` is provided, this
                 should not be set.
             retry (google.api_core.retry.Retry): Designation of what errors, if any,
                 should be retried.
             timeout (float): The timeout for this request.
             metadata (Sequence[Tuple[str, str]]): Strings which should be
                 sent along with the request as metadata.
 
         Returns:
-            google.cloud.dataplex_v1.services.metadata_service.pagers.ListPartitionsAsyncPager:
+            google.cloud.dataplex_v1.services.metadata_service.pagers.ListPartitionsPager:
                 List metadata partitions response.
 
                 Iterating over this object will yield
                 results and resolve additional pages
                 automatically.
 
         """
         # Create or coerce a protobuf request object.
-        # Quick check: If we got a request object, we should *not* have
-        # gotten any keyword arguments that map to the request.
+        # - Quick check: If we got a request object, we should *not* have
+        #   gotten any keyword arguments that map to the request.
         has_flattened_params = any([parent])
         if request is not None and has_flattened_params:
             raise ValueError(
                 "If the `request` argument is set, then none of "
                 "the individual field arguments should be set."
             )
 
-        request = metadata_.ListPartitionsRequest(request)
-
-        # If we have keyword arguments corresponding to fields on the
-        # request, apply these.
-        if parent is not None:
-            request.parent = parent
+        # - Use the request object if provided (there's no risk of modifying the input as
+        #   there are no flattened fields), or create one.
+        if not isinstance(request, metadata_.ListPartitionsRequest):
+            request = metadata_.ListPartitionsRequest(request)
+            # If we have keyword arguments corresponding to fields on the
+            # request, apply these.
+            if parent is not None:
+                request.parent = parent
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
-        rpc = gapic_v1.method_async.wrap_method(
-            self._client._transport.list_partitions,
-            default_retry=retries.Retry(
-                initial=1.0,
-                maximum=10.0,
-                multiplier=1.3,
-                predicate=retries.if_exception_type(
-                    core_exceptions.ServiceUnavailable,
-                ),
-                deadline=60.0,
-            ),
-            default_timeout=60.0,
-            client_info=DEFAULT_CLIENT_INFO,
-        )
+        rpc = self._transport._wrapped_methods[self._transport.list_partitions]
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", request.parent),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
-        response = await rpc(
+        response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
         # This method is paged; wrap the response in a pager, which provides
-        # an `__aiter__` convenience method.
-        response = pagers.ListPartitionsAsyncPager(
+        # an `__iter__` convenience method.
+        response = pagers.ListPartitionsPager(
             method=rpc,
             request=request,
             response=response,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
-    async def list_operations(
+    def __enter__(self) -> "MetadataServiceClient":
+        return self
+
+    def __exit__(self, type, value, traceback):
+        """Releases underlying transport's resources.
+
+        .. warning::
+            ONLY use as a context manager if the transport is NOT shared
+            with other clients! Exiting the with block will CLOSE the transport
+            and may cause errors in other clients!
+        """
+        self.transport.close()
+
+    def list_operations(
         self,
         request: Optional[operations_pb2.ListOperationsRequest] = None,
         *,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
     ) -> operations_pb2.ListOperationsResponse:
@@ -1236,37 +1740,40 @@
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = operations_pb2.ListOperationsRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
         rpc = gapic_v1.method.wrap_method(
-            self._client._transport.list_operations,
+            self._transport.list_operations,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
-        response = await rpc(
+        response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
-    async def get_operation(
+    def get_operation(
         self,
         request: Optional[operations_pb2.GetOperationRequest] = None,
         *,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
     ) -> operations_pb2.Operation:
@@ -1290,37 +1797,40 @@
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = operations_pb2.GetOperationRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
         rpc = gapic_v1.method.wrap_method(
-            self._client._transport.get_operation,
+            self._transport.get_operation,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
-        response = await rpc(
+        response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
-    async def delete_operation(
+    def delete_operation(
         self,
         request: Optional[operations_pb2.DeleteOperationRequest] = None,
         *,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
     ) -> None:
@@ -1348,34 +1858,37 @@
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = operations_pb2.DeleteOperationRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
         rpc = gapic_v1.method.wrap_method(
-            self._client._transport.delete_operation,
+            self._transport.delete_operation,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
-        await rpc(
+        rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
-    async def cancel_operation(
+    def cancel_operation(
         self,
         request: Optional[operations_pb2.CancelOperationRequest] = None,
         *,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
     ) -> None:
@@ -1402,34 +1915,37 @@
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = operations_pb2.CancelOperationRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
         rpc = gapic_v1.method.wrap_method(
-            self._client._transport.cancel_operation,
+            self._transport.cancel_operation,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
-        await rpc(
+        rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
-    async def get_location(
+    def get_location(
         self,
         request: Optional[locations_pb2.GetLocationRequest] = None,
         *,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
     ) -> locations_pb2.Location:
@@ -1453,37 +1969,40 @@
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = locations_pb2.GetLocationRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
         rpc = gapic_v1.method.wrap_method(
-            self._client._transport.get_location,
+            self._transport.get_location,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
-        response = await rpc(
+        response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
-    async def list_locations(
+    def list_locations(
         self,
         request: Optional[locations_pb2.ListLocationsRequest] = None,
         *,
         retry: OptionalRetry = gapic_v1.method.DEFAULT,
         timeout: Union[float, object] = gapic_v1.method.DEFAULT,
         metadata: Sequence[Tuple[str, str]] = (),
     ) -> locations_pb2.ListLocationsResponse:
@@ -1507,42 +2026,39 @@
         # so it must be constructed via keyword expansion.
         if isinstance(request, dict):
             request = locations_pb2.ListLocationsRequest(**request)
 
         # Wrap the RPC method; this adds retry and timeout information,
         # and friendly error handling.
         rpc = gapic_v1.method.wrap_method(
-            self._client._transport.list_locations,
+            self._transport.list_locations,
             default_timeout=None,
             client_info=DEFAULT_CLIENT_INFO,
         )
 
         # Certain fields should be provided within the metadata header;
         # add these here.
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("name", request.name),)),
         )
 
+        # Validate the universe domain.
+        self._validate_universe_domain()
+
         # Send the request.
-        response = await rpc(
+        response = rpc(
             request,
             retry=retry,
             timeout=timeout,
             metadata=metadata,
         )
 
         # Done; return the response.
         return response
 
-    async def __aenter__(self) -> "MetadataServiceAsyncClient":
-        return self
-
-    async def __aexit__(self, exc_type, exc, tb):
-        await self.transport.close()
-
 
 DEFAULT_CLIENT_INFO = gapic_v1.client_info.ClientInfo(
     gapic_version=package_version.__version__
 )
 
 
-__all__ = ("MetadataServiceAsyncClient",)
+__all__ = ("MetadataServiceClient",)
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/metadata_service/pagers.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/metadata_service/pagers.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/metadata_service/transports/__init__.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/metadata_service/transports/__init__.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/metadata_service/transports/base.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/metadata_service/transports/base.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -57,15 +57,15 @@
         api_audience: Optional[str] = None,
         **kwargs,
     ) -> None:
         """Instantiate the transport.
 
         Args:
             host (Optional[str]):
-                 The hostname to connect to.
+                 The hostname to connect to (default: 'dataplex.googleapis.com').
             credentials (Optional[google.auth.credentials.Credentials]): The
                 authorization credentials to attach to requests. These
                 credentials identify the application to the service; if none
                 are specified, the client will attempt to ascertain the
                 credentials from the environment.
             credentials_file (Optional[str]): A file with credentials that can
                 be loaded with :func:`google.auth.load_credentials_from_file`.
@@ -120,14 +120,18 @@
         self._credentials = credentials
 
         # Save the hostname. Default to port 443 (HTTPS) if none is specified.
         if ":" not in host:
             host += ":443"
         self._host = host
 
+    @property
+    def host(self):
+        return self._host
+
     def _prep_wrapped_messages(self, client_info):
         # Precompute the wrapped methods.
         self._wrapped_methods = {
             self.create_entity: gapic_v1.method.wrap_method(
                 self.create_entity,
                 default_timeout=60.0,
                 client_info=client_info,
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/metadata_service/transports/grpc.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/metadata_service/transports/grpc.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -51,56 +51,59 @@
     def __init__(
         self,
         *,
         host: str = "dataplex.googleapis.com",
         credentials: Optional[ga_credentials.Credentials] = None,
         credentials_file: Optional[str] = None,
         scopes: Optional[Sequence[str]] = None,
-        channel: Optional[grpc.Channel] = None,
+        channel: Optional[Union[grpc.Channel, Callable[..., grpc.Channel]]] = None,
         api_mtls_endpoint: Optional[str] = None,
         client_cert_source: Optional[Callable[[], Tuple[bytes, bytes]]] = None,
         ssl_channel_credentials: Optional[grpc.ChannelCredentials] = None,
         client_cert_source_for_mtls: Optional[Callable[[], Tuple[bytes, bytes]]] = None,
         quota_project_id: Optional[str] = None,
         client_info: gapic_v1.client_info.ClientInfo = DEFAULT_CLIENT_INFO,
         always_use_jwt_access: Optional[bool] = False,
         api_audience: Optional[str] = None,
     ) -> None:
         """Instantiate the transport.
 
         Args:
             host (Optional[str]):
-                 The hostname to connect to.
+                 The hostname to connect to (default: 'dataplex.googleapis.com').
             credentials (Optional[google.auth.credentials.Credentials]): The
                 authorization credentials to attach to requests. These
                 credentials identify the application to the service; if none
                 are specified, the client will attempt to ascertain the
                 credentials from the environment.
-                This argument is ignored if ``channel`` is provided.
+                This argument is ignored if a ``channel`` instance is provided.
             credentials_file (Optional[str]): A file with credentials that can
                 be loaded with :func:`google.auth.load_credentials_from_file`.
-                This argument is ignored if ``channel`` is provided.
+                This argument is ignored if a ``channel`` instance is provided.
             scopes (Optional(Sequence[str])): A list of scopes. This argument is
-                ignored if ``channel`` is provided.
-            channel (Optional[grpc.Channel]): A ``Channel`` instance through
-                which to make calls.
+                ignored if a ``channel`` instance is provided.
+            channel (Optional[Union[grpc.Channel, Callable[..., grpc.Channel]]]):
+                A ``Channel`` instance through which to make calls, or a Callable
+                that constructs and returns one. If set to None, ``self.create_channel``
+                is used to create the channel. If a Callable is given, it will be called
+                with the same arguments as used in ``self.create_channel``.
             api_mtls_endpoint (Optional[str]): Deprecated. The mutual TLS endpoint.
                 If provided, it overrides the ``host`` argument and tries to create
                 a mutual TLS channel with client SSL credentials from
                 ``client_cert_source`` or application default SSL credentials.
             client_cert_source (Optional[Callable[[], Tuple[bytes, bytes]]]):
                 Deprecated. A callback to provide client SSL certificate bytes and
                 private key bytes, both in PEM format. It is ignored if
                 ``api_mtls_endpoint`` is None.
             ssl_channel_credentials (grpc.ChannelCredentials): SSL credentials
-                for the grpc channel. It is ignored if ``channel`` is provided.
+                for the grpc channel. It is ignored if a ``channel`` instance is provided.
             client_cert_source_for_mtls (Optional[Callable[[], Tuple[bytes, bytes]]]):
                 A callback to provide client certificate bytes and private key bytes,
                 both in PEM format. It is used to configure a mutual TLS channel. It is
-                ignored if ``channel`` or ``ssl_channel_credentials`` is provided.
+                ignored if a ``channel`` instance or ``ssl_channel_credentials`` is provided.
             quota_project_id (Optional[str]): An optional project to use for billing
                 and quota.
             client_info (google.api_core.gapic_v1.client_info.ClientInfo):
                 The client info used to send a user-agent string along with
                 API requests. If ``None``, then default info will be used.
                 Generally, you only need to set this if you're developing
                 your own client library.
@@ -118,15 +121,15 @@
         self._stubs: Dict[str, Callable] = {}
 
         if api_mtls_endpoint:
             warnings.warn("api_mtls_endpoint is deprecated", DeprecationWarning)
         if client_cert_source:
             warnings.warn("client_cert_source is deprecated", DeprecationWarning)
 
-        if channel:
+        if isinstance(channel, grpc.Channel):
             # Ignore credentials if a channel was passed.
             credentials = False
             # If a channel was explicitly provided, set it.
             self._grpc_channel = channel
             self._ssl_channel_credentials = None
 
         else:
@@ -159,15 +162,17 @@
             quota_project_id=quota_project_id,
             client_info=client_info,
             always_use_jwt_access=always_use_jwt_access,
             api_audience=api_audience,
         )
 
         if not self._grpc_channel:
-            self._grpc_channel = type(self).create_channel(
+            # initialize with the provided callable or the default channel
+            channel_init = channel or type(self).create_channel
+            self._grpc_channel = channel_init(
                 self._host,
                 # use the credentials which are saved
                 credentials=self._credentials,
                 # Set ``credentials_file`` to ``None`` here as
                 # the credentials that we saved earlier should be used.
                 credentials_file=None,
                 scopes=self._scopes,
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/services/metadata_service/transports/grpc_asyncio.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/services/metadata_service/transports/grpc_asyncio.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -12,15 +12,17 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 from typing import Awaitable, Callable, Dict, Optional, Sequence, Tuple, Union
 import warnings
 
+from google.api_core import exceptions as core_exceptions
 from google.api_core import gapic_v1, grpc_helpers_async
+from google.api_core import retry_async as retries
 from google.auth import credentials as ga_credentials  # type: ignore
 from google.auth.transport.grpc import SslCredentials  # type: ignore
 from google.cloud.location import locations_pb2  # type: ignore
 from google.iam.v1 import iam_policy_pb2  # type: ignore
 from google.iam.v1 import policy_pb2  # type: ignore
 from google.longrunning import operations_pb2  # type: ignore
 from google.protobuf import empty_pb2  # type: ignore
@@ -66,15 +68,14 @@
             credentials (Optional[~.Credentials]): The
                 authorization credentials to attach to requests. These
                 credentials identify this application to the service. If
                 none are specified, the client will attempt to ascertain
                 the credentials from the environment.
             credentials_file (Optional[str]): A file with credentials that can
                 be loaded with :func:`google.auth.load_credentials_from_file`.
-                This argument is ignored if ``channel`` is provided.
             scopes (Optional[Sequence[str]]): A optional list of scopes needed for this
                 service. These are only used when credentials are not specified and
                 are passed to :func:`google.auth.default`.
             quota_project_id (Optional[str]): An optional project to use for billing
                 and quota.
             kwargs (Optional[dict]): Keyword arguments, which are passed to the
                 channel creation.
@@ -96,57 +97,60 @@
     def __init__(
         self,
         *,
         host: str = "dataplex.googleapis.com",
         credentials: Optional[ga_credentials.Credentials] = None,
         credentials_file: Optional[str] = None,
         scopes: Optional[Sequence[str]] = None,
-        channel: Optional[aio.Channel] = None,
+        channel: Optional[Union[aio.Channel, Callable[..., aio.Channel]]] = None,
         api_mtls_endpoint: Optional[str] = None,
         client_cert_source: Optional[Callable[[], Tuple[bytes, bytes]]] = None,
         ssl_channel_credentials: Optional[grpc.ChannelCredentials] = None,
         client_cert_source_for_mtls: Optional[Callable[[], Tuple[bytes, bytes]]] = None,
         quota_project_id: Optional[str] = None,
         client_info: gapic_v1.client_info.ClientInfo = DEFAULT_CLIENT_INFO,
         always_use_jwt_access: Optional[bool] = False,
         api_audience: Optional[str] = None,
     ) -> None:
         """Instantiate the transport.
 
         Args:
             host (Optional[str]):
-                 The hostname to connect to.
+                 The hostname to connect to (default: 'dataplex.googleapis.com').
             credentials (Optional[google.auth.credentials.Credentials]): The
                 authorization credentials to attach to requests. These
                 credentials identify the application to the service; if none
                 are specified, the client will attempt to ascertain the
                 credentials from the environment.
-                This argument is ignored if ``channel`` is provided.
+                This argument is ignored if a ``channel`` instance is provided.
             credentials_file (Optional[str]): A file with credentials that can
                 be loaded with :func:`google.auth.load_credentials_from_file`.
-                This argument is ignored if ``channel`` is provided.
+                This argument is ignored if a ``channel`` instance is provided.
             scopes (Optional[Sequence[str]]): A optional list of scopes needed for this
                 service. These are only used when credentials are not specified and
                 are passed to :func:`google.auth.default`.
-            channel (Optional[aio.Channel]): A ``Channel`` instance through
-                which to make calls.
+            channel (Optional[Union[aio.Channel, Callable[..., aio.Channel]]]):
+                A ``Channel`` instance through which to make calls, or a Callable
+                that constructs and returns one. If set to None, ``self.create_channel``
+                is used to create the channel. If a Callable is given, it will be called
+                with the same arguments as used in ``self.create_channel``.
             api_mtls_endpoint (Optional[str]): Deprecated. The mutual TLS endpoint.
                 If provided, it overrides the ``host`` argument and tries to create
                 a mutual TLS channel with client SSL credentials from
                 ``client_cert_source`` or application default SSL credentials.
             client_cert_source (Optional[Callable[[], Tuple[bytes, bytes]]]):
                 Deprecated. A callback to provide client SSL certificate bytes and
                 private key bytes, both in PEM format. It is ignored if
                 ``api_mtls_endpoint`` is None.
             ssl_channel_credentials (grpc.ChannelCredentials): SSL credentials
-                for the grpc channel. It is ignored if ``channel`` is provided.
+                for the grpc channel. It is ignored if a ``channel`` instance is provided.
             client_cert_source_for_mtls (Optional[Callable[[], Tuple[bytes, bytes]]]):
                 A callback to provide client certificate bytes and private key bytes,
                 both in PEM format. It is used to configure a mutual TLS channel. It is
-                ignored if ``channel`` or ``ssl_channel_credentials`` is provided.
+                ignored if a ``channel`` instance or ``ssl_channel_credentials`` is provided.
             quota_project_id (Optional[str]): An optional project to use for billing
                 and quota.
             client_info (google.api_core.gapic_v1.client_info.ClientInfo):
                 The client info used to send a user-agent string along with
                 API requests. If ``None``, then default info will be used.
                 Generally, you only need to set this if you're developing
                 your own client library.
@@ -164,15 +168,15 @@
         self._stubs: Dict[str, Callable] = {}
 
         if api_mtls_endpoint:
             warnings.warn("api_mtls_endpoint is deprecated", DeprecationWarning)
         if client_cert_source:
             warnings.warn("client_cert_source is deprecated", DeprecationWarning)
 
-        if channel:
+        if isinstance(channel, aio.Channel):
             # Ignore credentials if a channel was passed.
             credentials = False
             # If a channel was explicitly provided, set it.
             self._grpc_channel = channel
             self._ssl_channel_credentials = None
         else:
             if api_mtls_endpoint:
@@ -204,15 +208,17 @@
             quota_project_id=quota_project_id,
             client_info=client_info,
             always_use_jwt_access=always_use_jwt_access,
             api_audience=api_audience,
         )
 
         if not self._grpc_channel:
-            self._grpc_channel = type(self).create_channel(
+            # initialize with the provided callable or the default channel
+            channel_init = channel or type(self).create_channel
+            self._grpc_channel = channel_init(
                 self._host,
                 # use the credentials which are saved
                 credentials=self._credentials,
                 # Set ``credentials_file`` to ``None`` here as
                 # the credentials that we saved earlier should be used.
                 credentials_file=None,
                 scopes=self._scopes,
@@ -472,14 +478,100 @@
             self._stubs["list_partitions"] = self.grpc_channel.unary_unary(
                 "/google.cloud.dataplex.v1.MetadataService/ListPartitions",
                 request_serializer=metadata_.ListPartitionsRequest.serialize,
                 response_deserializer=metadata_.ListPartitionsResponse.deserialize,
             )
         return self._stubs["list_partitions"]
 
+    def _prep_wrapped_messages(self, client_info):
+        """Precompute the wrapped methods, overriding the base class method to use async wrappers."""
+        self._wrapped_methods = {
+            self.create_entity: gapic_v1.method_async.wrap_method(
+                self.create_entity,
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.update_entity: gapic_v1.method_async.wrap_method(
+                self.update_entity,
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.delete_entity: gapic_v1.method_async.wrap_method(
+                self.delete_entity,
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.get_entity: gapic_v1.method_async.wrap_method(
+                self.get_entity,
+                default_retry=retries.AsyncRetry(
+                    initial=1.0,
+                    maximum=10.0,
+                    multiplier=1.3,
+                    predicate=retries.if_exception_type(
+                        core_exceptions.ServiceUnavailable,
+                    ),
+                    deadline=60.0,
+                ),
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.list_entities: gapic_v1.method_async.wrap_method(
+                self.list_entities,
+                default_retry=retries.AsyncRetry(
+                    initial=1.0,
+                    maximum=10.0,
+                    multiplier=1.3,
+                    predicate=retries.if_exception_type(
+                        core_exceptions.ServiceUnavailable,
+                    ),
+                    deadline=60.0,
+                ),
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.create_partition: gapic_v1.method_async.wrap_method(
+                self.create_partition,
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.delete_partition: gapic_v1.method_async.wrap_method(
+                self.delete_partition,
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.get_partition: gapic_v1.method_async.wrap_method(
+                self.get_partition,
+                default_retry=retries.AsyncRetry(
+                    initial=1.0,
+                    maximum=10.0,
+                    multiplier=1.3,
+                    predicate=retries.if_exception_type(
+                        core_exceptions.ServiceUnavailable,
+                    ),
+                    deadline=60.0,
+                ),
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+            self.list_partitions: gapic_v1.method_async.wrap_method(
+                self.list_partitions,
+                default_retry=retries.AsyncRetry(
+                    initial=1.0,
+                    maximum=10.0,
+                    multiplier=1.3,
+                    predicate=retries.if_exception_type(
+                        core_exceptions.ServiceUnavailable,
+                    ),
+                    deadline=60.0,
+                ),
+                default_timeout=60.0,
+                client_info=client_info,
+            ),
+        }
+
     def close(self):
         return self.grpc_channel.close()
 
     @property
     def delete_operation(
         self,
     ) -> Callable[[operations_pb2.DeleteOperationRequest], None]:
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/types/analyze.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/types/analyze.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/types/content.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/types/content.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/types/data_profile.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/types/data_profile.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/types/data_quality.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/types/data_quality.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -26,14 +26,15 @@
     manifest={
         "DataQualitySpec",
         "DataQualityResult",
         "DataQualityRuleResult",
         "DataQualityDimensionResult",
         "DataQualityDimension",
         "DataQualityRule",
+        "DataQualityColumnResult",
     },
 )
 
 
 class DataQualitySpec(proto.Message):
     r"""DataQualityScan related setting.
 
@@ -66,14 +67,17 @@
     class PostScanActions(proto.Message):
         r"""The configuration of post scan actions of DataQualityScan.
 
         Attributes:
             bigquery_export (google.cloud.dataplex_v1.types.DataQualitySpec.PostScanActions.BigQueryExport):
                 Optional. If set, results will be exported to
                 the provided BigQuery table.
+            notification_report (google.cloud.dataplex_v1.types.DataQualitySpec.PostScanActions.NotificationReport):
+                Optional. If set, results will be sent to the
+                provided notification receipts upon triggers.
         """
 
         class BigQueryExport(proto.Message):
             r"""The configuration of BigQuery export post scan action.
 
             Attributes:
                 results_table (str):
@@ -83,19 +87,110 @@
             """
 
             results_table: str = proto.Field(
                 proto.STRING,
                 number=1,
             )
 
+        class Recipients(proto.Message):
+            r"""The individuals or groups who are designated to receive
+            notifications upon triggers.
+
+            Attributes:
+                emails (MutableSequence[str]):
+                    Optional. The email recipients who will
+                    receive the DataQualityScan results report.
+            """
+
+            emails: MutableSequence[str] = proto.RepeatedField(
+                proto.STRING,
+                number=1,
+            )
+
+        class ScoreThresholdTrigger(proto.Message):
+            r"""This trigger is triggered when the DQ score in the job result
+            is less than a specified input score.
+
+            Attributes:
+                score_threshold (float):
+                    Optional. The score range is in [0,100].
+            """
+
+            score_threshold: float = proto.Field(
+                proto.FLOAT,
+                number=2,
+            )
+
+        class JobFailureTrigger(proto.Message):
+            r"""This trigger is triggered when the scan job itself fails,
+            regardless of the result.
+
+            """
+
+        class JobEndTrigger(proto.Message):
+            r"""This trigger is triggered whenever a scan job run ends,
+            regardless of the result.
+
+            """
+
+        class NotificationReport(proto.Message):
+            r"""The configuration of notification report post scan action.
+
+            Attributes:
+                recipients (google.cloud.dataplex_v1.types.DataQualitySpec.PostScanActions.Recipients):
+                    Required. The recipients who will receive the
+                    notification report.
+                score_threshold_trigger (google.cloud.dataplex_v1.types.DataQualitySpec.PostScanActions.ScoreThresholdTrigger):
+                    Optional. If set, report will be sent when
+                    score threshold is met.
+                job_failure_trigger (google.cloud.dataplex_v1.types.DataQualitySpec.PostScanActions.JobFailureTrigger):
+                    Optional. If set, report will be sent when a
+                    scan job fails.
+                job_end_trigger (google.cloud.dataplex_v1.types.DataQualitySpec.PostScanActions.JobEndTrigger):
+                    Optional. If set, report will be sent when a
+                    scan job ends.
+            """
+
+            recipients: "DataQualitySpec.PostScanActions.Recipients" = proto.Field(
+                proto.MESSAGE,
+                number=1,
+                message="DataQualitySpec.PostScanActions.Recipients",
+            )
+            score_threshold_trigger: "DataQualitySpec.PostScanActions.ScoreThresholdTrigger" = proto.Field(
+                proto.MESSAGE,
+                number=2,
+                message="DataQualitySpec.PostScanActions.ScoreThresholdTrigger",
+            )
+            job_failure_trigger: "DataQualitySpec.PostScanActions.JobFailureTrigger" = (
+                proto.Field(
+                    proto.MESSAGE,
+                    number=4,
+                    message="DataQualitySpec.PostScanActions.JobFailureTrigger",
+                )
+            )
+            job_end_trigger: "DataQualitySpec.PostScanActions.JobEndTrigger" = (
+                proto.Field(
+                    proto.MESSAGE,
+                    number=5,
+                    message="DataQualitySpec.PostScanActions.JobEndTrigger",
+                )
+            )
+
         bigquery_export: "DataQualitySpec.PostScanActions.BigQueryExport" = proto.Field(
             proto.MESSAGE,
             number=1,
             message="DataQualitySpec.PostScanActions.BigQueryExport",
         )
+        notification_report: "DataQualitySpec.PostScanActions.NotificationReport" = (
+            proto.Field(
+                proto.MESSAGE,
+                number=2,
+                message="DataQualitySpec.PostScanActions.NotificationReport",
+            )
+        )
 
     rules: MutableSequence["DataQualityRule"] = proto.RepeatedField(
         proto.MESSAGE,
         number=1,
         message="DataQualityRule",
     )
     sampling_percent: float = proto.Field(
@@ -112,23 +207,38 @@
         message=PostScanActions,
     )
 
 
 class DataQualityResult(proto.Message):
     r"""The output of a DataQualityScan.
 
+    .. _oneof: https://proto-plus-python.readthedocs.io/en/stable/fields.html#oneofs-mutually-exclusive-fields
+
     Attributes:
         passed (bool):
             Overall data quality result -- ``true`` if all rules passed.
+        score (float):
+            Output only. The overall data quality score.
+
+            The score ranges between [0, 100] (up to two decimal
+            points).
+
+            This field is a member of `oneof`_ ``_score``.
         dimensions (MutableSequence[google.cloud.dataplex_v1.types.DataQualityDimensionResult]):
             A list of results at the dimension level.
 
             A dimension will have a corresponding
             ``DataQualityDimensionResult`` if and only if there is at
             least one rule with the 'dimension' field set to it.
+        columns (MutableSequence[google.cloud.dataplex_v1.types.DataQualityColumnResult]):
+            Output only. A list of results at the column level.
+
+            A column will have a corresponding
+            ``DataQualityColumnResult`` if and only if there is at least
+            one rule with the 'column' field set to it.
         rules (MutableSequence[google.cloud.dataplex_v1.types.DataQualityRuleResult]):
             A list of all the rules in a job, and their
             results.
         row_count (int):
             The count of rows processed.
         scanned_data (google.cloud.dataplex_v1.types.ScannedData):
             The data scanned for this result.
@@ -194,19 +304,29 @@
             message="DataQualityResult.PostScanActionsResult.BigQueryExportResult",
         )
 
     passed: bool = proto.Field(
         proto.BOOL,
         number=5,
     )
+    score: float = proto.Field(
+        proto.FLOAT,
+        number=9,
+        optional=True,
+    )
     dimensions: MutableSequence["DataQualityDimensionResult"] = proto.RepeatedField(
         proto.MESSAGE,
         number=2,
         message="DataQualityDimensionResult",
     )
+    columns: MutableSequence["DataQualityColumnResult"] = proto.RepeatedField(
+        proto.MESSAGE,
+        number=10,
+        message="DataQualityColumnResult",
+    )
     rules: MutableSequence["DataQualityRuleResult"] = proto.RepeatedField(
         proto.MESSAGE,
         number=3,
         message="DataQualityRuleResult",
     )
     row_count: int = proto.Field(
         proto.INT64,
@@ -258,14 +378,19 @@
 
             This field is only valid for row-level type rules.
         failing_rows_query (str):
             The query to find rows that did not pass this
             rule.
             This field is only valid for row-level type
             rules.
+        assertion_row_count (int):
+            Output only. The number of rows returned by
+            the sql statement in the SqlAssertion rule.
+
+            This field is only valid for SqlAssertion rules.
     """
 
     rule: "DataQualityRule" = proto.Field(
         proto.MESSAGE,
         number=1,
         message="DataQualityRule",
     )
@@ -289,37 +414,57 @@
         proto.DOUBLE,
         number=6,
     )
     failing_rows_query: str = proto.Field(
         proto.STRING,
         number=10,
     )
+    assertion_row_count: int = proto.Field(
+        proto.INT64,
+        number=11,
+    )
 
 
 class DataQualityDimensionResult(proto.Message):
     r"""DataQualityDimensionResult provides a more detailed,
     per-dimension view of the results.
 
+
+    .. _oneof: https://proto-plus-python.readthedocs.io/en/stable/fields.html#oneofs-mutually-exclusive-fields
+
     Attributes:
         dimension (google.cloud.dataplex_v1.types.DataQualityDimension):
             Output only. The dimension config specified
             in the DataQualitySpec, as is.
         passed (bool):
             Whether the dimension passed or failed.
+        score (float):
+            Output only. The dimension-level data quality score for this
+            data scan job if and only if the 'dimension' field is set.
+
+            The score ranges between [0, 100] (up to two decimal
+            points).
+
+            This field is a member of `oneof`_ ``_score``.
     """
 
     dimension: "DataQualityDimension" = proto.Field(
         proto.MESSAGE,
         number=1,
         message="DataQualityDimension",
     )
     passed: bool = proto.Field(
         proto.BOOL,
         number=3,
     )
+    score: float = proto.Field(
+        proto.FLOAT,
+        number=4,
+        optional=True,
+    )
 
 
 class DataQualityDimension(proto.Message):
     r"""A dimension captures data quality intent about a defined
     subset of the rules specified.
 
     Attributes:
@@ -383,23 +528,33 @@
 
             This field is a member of `oneof`_ ``rule_type``.
         table_condition_expectation (google.cloud.dataplex_v1.types.DataQualityRule.TableConditionExpectation):
             Aggregate rule which evaluates whether the
             provided expression is true for a table.
 
             This field is a member of `oneof`_ ``rule_type``.
+        sql_assertion (google.cloud.dataplex_v1.types.DataQualityRule.SqlAssertion):
+            Aggregate rule which evaluates the number of
+            rows returned for the provided statement.
+
+            This field is a member of `oneof`_ ``rule_type``.
         column (str):
             Optional. The unnested column which this rule
             is evaluated against.
         ignore_null (bool):
             Optional. Rows with ``null`` values will automatically fail
             a rule, unless ``ignore_null`` is ``true``. In that case,
             such ``null`` rows are trivially considered passing.
 
-            This field is only valid for row-level type rules.
+            This field is only valid for the following type of rules:
+
+            -  RangeExpectation
+            -  RegexExpectation
+            -  SetExpectation
+            -  UniquenessExpectation
         dimension (str):
             Required. The dimension a rule belongs to. Results are also
             aggregated at the dimension level. Supported dimensions are
             **["COMPLETENESS", "ACCURACY", "CONSISTENCY", "VALIDITY",
             "UNIQUENESS", "INTEGRITY"]**
         threshold (float):
             Optional. The minimum ratio of **passing_rows / total_rows**
@@ -610,14 +765,37 @@
         """
 
         sql_expression: str = proto.Field(
             proto.STRING,
             number=1,
         )
 
+    class SqlAssertion(proto.Message):
+        r"""Queries for rows returned by the provided SQL statement. If any rows
+        are are returned, this rule fails.
+
+        The SQL statement needs to use BigQuery standard SQL syntax, and
+        must not contain any semicolons.
+
+        ${data()} can be used to reference the rows being evaluated, i.e.
+        the table after all additional filters (row filters, incremental
+        data filters, sampling) are applied.
+
+        Example: SELECT \* FROM ${data()} WHERE price < 0
+
+        Attributes:
+            sql_statement (str):
+                Optional. The SQL statement.
+        """
+
+        sql_statement: str = proto.Field(
+            proto.STRING,
+            number=1,
+        )
+
     range_expectation: RangeExpectation = proto.Field(
         proto.MESSAGE,
         number=1,
         oneof="rule_type",
         message=RangeExpectation,
     )
     non_null_expectation: NonNullExpectation = proto.Field(
@@ -658,14 +836,20 @@
     )
     table_condition_expectation: TableConditionExpectation = proto.Field(
         proto.MESSAGE,
         number=201,
         oneof="rule_type",
         message=TableConditionExpectation,
     )
+    sql_assertion: SqlAssertion = proto.Field(
+        proto.MESSAGE,
+        number=202,
+        oneof="rule_type",
+        message=SqlAssertion,
+    )
     column: str = proto.Field(
         proto.STRING,
         number=500,
     )
     ignore_null: bool = proto.Field(
         proto.BOOL,
         number=501,
@@ -684,8 +868,40 @@
     )
     description: str = proto.Field(
         proto.STRING,
         number=505,
     )
 
 
+class DataQualityColumnResult(proto.Message):
+    r"""DataQualityColumnResult provides a more detailed, per-column
+    view of the results.
+
+
+    .. _oneof: https://proto-plus-python.readthedocs.io/en/stable/fields.html#oneofs-mutually-exclusive-fields
+
+    Attributes:
+        column (str):
+            Output only. The column specified in the
+            DataQualityRule.
+        score (float):
+            Output only. The column-level data quality score for this
+            data scan job if and only if the 'column' field is set.
+
+            The score ranges between between [0, 100] (up to two decimal
+            points).
+
+            This field is a member of `oneof`_ ``_score``.
+    """
+
+    column: str = proto.Field(
+        proto.STRING,
+        number=1,
+    )
+    score: float = proto.Field(
+        proto.FLOAT,
+        number=2,
+        optional=True,
+    )
+
+
 __all__ = tuple(sorted(__protobuf__.manifest))
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/types/data_taxonomy.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/types/data_taxonomy.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/types/datascans.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/types/datascans.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -39,14 +39,16 @@
         "ListDataScansRequest",
         "ListDataScansResponse",
         "RunDataScanRequest",
         "RunDataScanResponse",
         "GetDataScanJobRequest",
         "ListDataScanJobsRequest",
         "ListDataScanJobsResponse",
+        "GenerateDataQualityRulesRequest",
+        "GenerateDataQualityRulesResponse",
         "DataScan",
         "DataScanJob",
     },
 )
 
 
 class DataScanType(proto.Enum):
@@ -438,14 +440,49 @@
     )
     next_page_token: str = proto.Field(
         proto.STRING,
         number=2,
     )
 
 
+class GenerateDataQualityRulesRequest(proto.Message):
+    r"""Generate recommended DataQualityRules request.
+
+    Attributes:
+        name (str):
+            Required. The name should be either
+
+            -  the name of a datascan with at least one successful
+               completed data profiling job, or
+            -  the name of a successful completed data profiling
+               datascan job.
+    """
+
+    name: str = proto.Field(
+        proto.STRING,
+        number=1,
+    )
+
+
+class GenerateDataQualityRulesResponse(proto.Message):
+    r"""Generate recommended DataQualityRules response.
+
+    Attributes:
+        rule (MutableSequence[google.cloud.dataplex_v1.types.DataQualityRule]):
+            Generated recommended {@link
+            DataQualityRule}s.
+    """
+
+    rule: MutableSequence[data_quality.DataQualityRule] = proto.RepeatedField(
+        proto.MESSAGE,
+        number=1,
+        message=data_quality.DataQualityRule,
+    )
+
+
 class DataScan(proto.Message):
     r"""Represents a user-visible job which provides the insights for the
     related data source.
 
     For example:
 
     -  Data Quality: generates queries based on the rules and runs
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/types/logs.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/types/logs.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -616,14 +616,16 @@
             GOVERNANCE_RULE_MATCHED_RESOURCES (15):
                 Number of resources matched with particular
                 Query.
             GOVERNANCE_RULE_SEARCH_LIMIT_EXCEEDS (16):
                 Rule processing exceeds the allowed limit.
             GOVERNANCE_RULE_ERRORS (17):
                 Rule processing errors.
+            GOVERNANCE_RULE_PROCESSING (18):
+                Governance rule processing Event.
         """
         EVENT_TYPE_UNSPECIFIED = 0
         RESOURCE_IAM_POLICY_UPDATE = 1
         BIGQUERY_TABLE_CREATE = 2
         BIGQUERY_TABLE_UPDATE = 3
         BIGQUERY_TABLE_DELETE = 4
         BIGQUERY_CONNECTION_CREATE = 5
@@ -633,14 +635,15 @@
         BIGQUERY_POLICY_TAG_CREATE = 11
         BIGQUERY_POLICY_TAG_DELETE = 12
         BIGQUERY_POLICY_TAG_SET_IAM_POLICY = 13
         ACCESS_POLICY_UPDATE = 14
         GOVERNANCE_RULE_MATCHED_RESOURCES = 15
         GOVERNANCE_RULE_SEARCH_LIMIT_EXCEEDS = 16
         GOVERNANCE_RULE_ERRORS = 17
+        GOVERNANCE_RULE_PROCESSING = 18
 
     class Entity(proto.Message):
         r"""Information about Entity resource that the log event is
         associated with.
 
         Attributes:
             entity (str):
@@ -1130,14 +1133,18 @@
             type.
         passed_row_count (int):
             The number of rows which passed a rule evaluation. This
             field is only valid for rules of PER_ROW evaluation type.
         null_row_count (int):
             The number of rows with null values in the
             specified column.
+        assertion_row_count (int):
+            The number of rows returned by the sql
+            statement in the SqlAssertion rule. This field
+            is only valid for SqlAssertion rules.
     """
 
     class RuleType(proto.Enum):
         r"""The type of the data quality rule.
 
         Values:
             RULE_TYPE_UNSPECIFIED (0):
@@ -1162,24 +1169,28 @@
                 https://cloud.google.com/dataplex/docs/reference/rest/v1/DataQualityRule#statisticrangeexpectation.
             TABLE_CONDITION_EXPECTATION (7):
                 Please see
                 https://cloud.google.com/dataplex/docs/reference/rest/v1/DataQualityRule#tableconditionexpectation.
             UNIQUENESS_EXPECTATION (8):
                 Please see
                 https://cloud.google.com/dataplex/docs/reference/rest/v1/DataQualityRule#uniquenessexpectation.
+            SQL_ASSERTION (9):
+                Please see
+                https://cloud.google.com/dataplex/docs/reference/rest/v1/DataQualityRule#sqlAssertion.
         """
         RULE_TYPE_UNSPECIFIED = 0
         NON_NULL_EXPECTATION = 1
         RANGE_EXPECTATION = 2
         REGEX_EXPECTATION = 3
         ROW_CONDITION_EXPECTATION = 4
         SET_EXPECTATION = 5
         STATISTIC_RANGE_EXPECTATION = 6
         TABLE_CONDITION_EXPECTATION = 7
         UNIQUENESS_EXPECTATION = 8
+        SQL_ASSERTION = 9
 
     class EvaluationType(proto.Enum):
         r"""The evaluation type of the data quality rule.
 
         Values:
             EVALUATION_TYPE_UNSPECIFIED (0):
                 An unspecified evaluation type.
@@ -1255,10 +1266,14 @@
         proto.INT64,
         number=11,
     )
     null_row_count: int = proto.Field(
         proto.INT64,
         number=12,
     )
+    assertion_row_count: int = proto.Field(
+        proto.INT64,
+        number=13,
+    )
 
 
 __all__ = tuple(sorted(__protobuf__.manifest))
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/types/metadata_.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/types/metadata_.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/types/processing.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/types/processing.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/types/resources.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/types/resources.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/types/security.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/types/security.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/types/service.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/types/service.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `google-cloud-dataplex-1.9.0/google/cloud/dataplex_v1/types/tasks.py` & `google-cloud-dataplex-2.0.0/google/cloud/dataplex_v1/types/tasks.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `google-cloud-dataplex-1.9.0/google_cloud_dataplex.egg-info/PKG-INFO` & `google-cloud-dataplex-2.0.0/google_cloud_dataplex.egg-info/PKG-INFO`

 * *Files 3% similar despite different names*

```diff
@@ -1,33 +1,34 @@
 Metadata-Version: 2.1
 Name: google-cloud-dataplex
-Version: 1.9.0
+Version: 2.0.0
 Summary: Google Cloud Dataplex API client library
-Home-page: https://github.com/googleapis/google-cloud-python
+Home-page: https://github.com/googleapis/google-cloud-python/tree/main/packages/google-cloud-dataplex
 Author: Google LLC
 Author-email: googleapis-packages@google.com
 License: Apache 2.0
 Platform: Posix; MacOS X; Windows
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Intended Audience :: Developers
 Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Programming Language :: Python
 Classifier: Programming Language :: Python :: 3
 Classifier: Programming Language :: Python :: 3.7
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11
+Classifier: Programming Language :: Python :: 3.12
 Classifier: Operating System :: OS Independent
 Classifier: Topic :: Internet
 Requires-Python: >=3.7
 License-File: LICENSE
-Requires-Dist: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0
-Requires-Dist: proto-plus<2.0.0dev,>=1.22.0
-Requires-Dist: proto-plus<2.0.0dev,>=1.22.2; python_version >= "3.11"
+Requires-Dist: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1
+Requires-Dist: google-auth!=2.24.0,!=2.25.0,<3.0.0dev,>=2.14.1
+Requires-Dist: proto-plus<2.0.0dev,>=1.22.3
 Requires-Dist: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5
 Requires-Dist: grpc-google-iam-v1<1.0.0dev,>=0.12.4
 
 Python Client for Cloud Dataplex
 ================================
 
 |stable| |pypi| |versions|
```

### Comparing `google-cloud-dataplex-1.9.0/google_cloud_dataplex.egg-info/SOURCES.txt` & `google-cloud-dataplex-2.0.0/google_cloud_dataplex.egg-info/SOURCES.txt`

 * *Files 3% similar despite different names*

```diff
@@ -7,14 +7,22 @@
 google/cloud/dataplex/gapic_version.py
 google/cloud/dataplex/py.typed
 google/cloud/dataplex_v1/__init__.py
 google/cloud/dataplex_v1/gapic_metadata.json
 google/cloud/dataplex_v1/gapic_version.py
 google/cloud/dataplex_v1/py.typed
 google/cloud/dataplex_v1/services/__init__.py
+google/cloud/dataplex_v1/services/catalog_service/__init__.py
+google/cloud/dataplex_v1/services/catalog_service/async_client.py
+google/cloud/dataplex_v1/services/catalog_service/client.py
+google/cloud/dataplex_v1/services/catalog_service/pagers.py
+google/cloud/dataplex_v1/services/catalog_service/transports/__init__.py
+google/cloud/dataplex_v1/services/catalog_service/transports/base.py
+google/cloud/dataplex_v1/services/catalog_service/transports/grpc.py
+google/cloud/dataplex_v1/services/catalog_service/transports/grpc_asyncio.py
 google/cloud/dataplex_v1/services/content_service/__init__.py
 google/cloud/dataplex_v1/services/content_service/async_client.py
 google/cloud/dataplex_v1/services/content_service/client.py
 google/cloud/dataplex_v1/services/content_service/pagers.py
 google/cloud/dataplex_v1/services/content_service/transports/__init__.py
 google/cloud/dataplex_v1/services/content_service/transports/base.py
 google/cloud/dataplex_v1/services/content_service/transports/grpc.py
@@ -49,14 +57,15 @@
 google/cloud/dataplex_v1/services/metadata_service/pagers.py
 google/cloud/dataplex_v1/services/metadata_service/transports/__init__.py
 google/cloud/dataplex_v1/services/metadata_service/transports/base.py
 google/cloud/dataplex_v1/services/metadata_service/transports/grpc.py
 google/cloud/dataplex_v1/services/metadata_service/transports/grpc_asyncio.py
 google/cloud/dataplex_v1/types/__init__.py
 google/cloud/dataplex_v1/types/analyze.py
+google/cloud/dataplex_v1/types/catalog.py
 google/cloud/dataplex_v1/types/content.py
 google/cloud/dataplex_v1/types/data_profile.py
 google/cloud/dataplex_v1/types/data_quality.py
 google/cloud/dataplex_v1/types/data_taxonomy.py
 google/cloud/dataplex_v1/types/datascans.py
 google/cloud/dataplex_v1/types/logs.py
 google/cloud/dataplex_v1/types/metadata_.py
@@ -64,20 +73,20 @@
 google/cloud/dataplex_v1/types/resources.py
 google/cloud/dataplex_v1/types/security.py
 google/cloud/dataplex_v1/types/service.py
 google/cloud/dataplex_v1/types/tasks.py
 google_cloud_dataplex.egg-info/PKG-INFO
 google_cloud_dataplex.egg-info/SOURCES.txt
 google_cloud_dataplex.egg-info/dependency_links.txt
-google_cloud_dataplex.egg-info/namespace_packages.txt
 google_cloud_dataplex.egg-info/not-zip-safe
 google_cloud_dataplex.egg-info/requires.txt
 google_cloud_dataplex.egg-info/top_level.txt
 tests/__init__.py
 tests/unit/__init__.py
 tests/unit/gapic/__init__.py
 tests/unit/gapic/dataplex_v1/__init__.py
+tests/unit/gapic/dataplex_v1/test_catalog_service.py
 tests/unit/gapic/dataplex_v1/test_content_service.py
 tests/unit/gapic/dataplex_v1/test_data_scan_service.py
 tests/unit/gapic/dataplex_v1/test_data_taxonomy_service.py
 tests/unit/gapic/dataplex_v1/test_dataplex_service.py
 tests/unit/gapic/dataplex_v1/test_metadata_service.py
```

### Comparing `google-cloud-dataplex-1.9.0/setup.py` & `google-cloud-dataplex-2.0.0/setup.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -11,57 +11,60 @@
 # distributed under the License is distributed on an "AS IS" BASIS,
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 #
 import io
 import os
+import re
 
 import setuptools  # type: ignore
 
 package_root = os.path.abspath(os.path.dirname(__file__))
 
 name = "google-cloud-dataplex"
 
 
 description = "Google Cloud Dataplex API client library"
 
-version = {}
+version = None
+
 with open(os.path.join(package_root, "google/cloud/dataplex/gapic_version.py")) as fp:
-    exec(fp.read(), version)
-version = version["__version__"]
+    version_candidates = re.findall(r"(?<=\")\d+.\d+.\d+(?=\")", fp.read())
+    assert len(version_candidates) == 1
+    version = version_candidates[0]
 
 if version[0] == "0":
     release_status = "Development Status :: 4 - Beta"
 else:
     release_status = "Development Status :: 5 - Production/Stable"
 
 dependencies = [
-    "google-api-core[grpc] >= 1.34.0, <3.0.0dev,!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,!=2.10.*",
-    "proto-plus >= 1.22.0, <2.0.0dev",
-    "proto-plus >= 1.22.2, <2.0.0dev; python_version>='3.11'",
+    "google-api-core[grpc] >= 1.34.1, <3.0.0dev,!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,!=2.10.*",
+    # Exclude incompatible versions of `google-auth`
+    # See https://github.com/googleapis/google-cloud-python/issues/12364
+    "google-auth >= 2.14.1, <3.0.0dev,!=2.24.0,!=2.25.0",
+    "proto-plus >= 1.22.3, <2.0.0dev",
     "protobuf>=3.19.5,<5.0.0dev,!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5",
     "grpc-google-iam-v1 >= 0.12.4, <1.0.0dev",
 ]
-url = "https://github.com/googleapis/google-cloud-python"
+url = "https://github.com/googleapis/google-cloud-python/tree/main/packages/google-cloud-dataplex"
 
 package_root = os.path.abspath(os.path.dirname(__file__))
 
 readme_filename = os.path.join(package_root, "README.rst")
 with io.open(readme_filename, encoding="utf-8") as readme_file:
     readme = readme_file.read()
 
 packages = [
     package
-    for package in setuptools.PEP420PackageFinder.find()
+    for package in setuptools.find_namespace_packages()
     if package.startswith("google")
 ]
 
-namespaces = ["google", "google.cloud"]
-
 setuptools.setup(
     name=name,
     version=version,
     description=description,
     long_description=readme,
     author="Google LLC",
     author_email="googleapis-packages@google.com",
@@ -74,18 +77,18 @@
         "Programming Language :: Python",
         "Programming Language :: Python :: 3",
         "Programming Language :: Python :: 3.7",
         "Programming Language :: Python :: 3.8",
         "Programming Language :: Python :: 3.9",
         "Programming Language :: Python :: 3.10",
         "Programming Language :: Python :: 3.11",
+        "Programming Language :: Python :: 3.12",
         "Operating System :: OS Independent",
         "Topic :: Internet",
     ],
     platforms="Posix; MacOS X; Windows",
     packages=packages,
     python_requires=">=3.7",
-    namespace_packages=namespaces,
     install_requires=dependencies,
     include_package_data=True,
     zip_safe=False,
 )
```

### Comparing `google-cloud-dataplex-1.9.0/tests/__init__.py` & `google-cloud-dataplex-2.0.0/tests/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `google-cloud-dataplex-1.9.0/tests/unit/__init__.py` & `google-cloud-dataplex-2.0.0/tests/unit/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `google-cloud-dataplex-1.9.0/tests/unit/gapic/__init__.py` & `google-cloud-dataplex-2.0.0/tests/unit/gapic/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `google-cloud-dataplex-1.9.0/tests/unit/gapic/dataplex_v1/__init__.py` & `google-cloud-dataplex-2.0.0/tests/unit/gapic/dataplex_v1/__init__.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
```

### Comparing `google-cloud-dataplex-1.9.0/tests/unit/gapic/dataplex_v1/test_content_service.py` & `google-cloud-dataplex-2.0.0/tests/unit/gapic/dataplex_v1/test_content_service.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -21,15 +21,15 @@
     from unittest.mock import AsyncMock  # pragma: NO COVER
 except ImportError:  # pragma: NO COVER
     import mock
 
 import math
 
 from google.api_core import gapic_v1, grpc_helpers, grpc_helpers_async, path_template
-from google.api_core import client_options
+from google.api_core import api_core_version, client_options
 from google.api_core import exceptions as core_exceptions
 import google.auth
 from google.auth import credentials as ga_credentials
 from google.auth.exceptions import MutualTLSChannelError
 from google.cloud.location import locations_pb2
 from google.iam.v1 import iam_policy_pb2  # type: ignore
 from google.iam.v1 import options_pb2  # type: ignore
@@ -67,14 +67,25 @@
     return (
         "foo.googleapis.com"
         if ("localhost" in client.DEFAULT_ENDPOINT)
         else client.DEFAULT_ENDPOINT
     )
 
 
+# If default endpoint template is localhost, then default mtls endpoint will be the same.
+# This method modifies the default endpoint template so the client can produce a different
+# mtls endpoint for endpoint testing purposes.
+def modify_default_endpoint_template(client):
+    return (
+        "test.{UNIVERSE_DOMAIN}"
+        if ("localhost" in client._DEFAULT_ENDPOINT_TEMPLATE)
+        else client._DEFAULT_ENDPOINT_TEMPLATE
+    )
+
+
 def test__get_default_mtls_endpoint():
     api_endpoint = "example.googleapis.com"
     api_mtls_endpoint = "example.mtls.googleapis.com"
     sandbox_endpoint = "example.sandbox.googleapis.com"
     sandbox_mtls_endpoint = "example.mtls.sandbox.googleapis.com"
     non_googleapi = "api.example.com"
 
@@ -96,14 +107,281 @@
         == sandbox_mtls_endpoint
     )
     assert (
         ContentServiceClient._get_default_mtls_endpoint(non_googleapi) == non_googleapi
     )
 
 
+def test__read_environment_variables():
+    assert ContentServiceClient._read_environment_variables() == (False, "auto", None)
+
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "true"}):
+        assert ContentServiceClient._read_environment_variables() == (
+            True,
+            "auto",
+            None,
+        )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "false"}):
+        assert ContentServiceClient._read_environment_variables() == (
+            False,
+            "auto",
+            None,
+        )
+
+    with mock.patch.dict(
+        os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "Unsupported"}
+    ):
+        with pytest.raises(ValueError) as excinfo:
+            ContentServiceClient._read_environment_variables()
+    assert (
+        str(excinfo.value)
+        == "Environment variable `GOOGLE_API_USE_CLIENT_CERTIFICATE` must be either `true` or `false`"
+    )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "never"}):
+        assert ContentServiceClient._read_environment_variables() == (
+            False,
+            "never",
+            None,
+        )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "always"}):
+        assert ContentServiceClient._read_environment_variables() == (
+            False,
+            "always",
+            None,
+        )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "auto"}):
+        assert ContentServiceClient._read_environment_variables() == (
+            False,
+            "auto",
+            None,
+        )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "Unsupported"}):
+        with pytest.raises(MutualTLSChannelError) as excinfo:
+            ContentServiceClient._read_environment_variables()
+    assert (
+        str(excinfo.value)
+        == "Environment variable `GOOGLE_API_USE_MTLS_ENDPOINT` must be `never`, `auto` or `always`"
+    )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_CLOUD_UNIVERSE_DOMAIN": "foo.com"}):
+        assert ContentServiceClient._read_environment_variables() == (
+            False,
+            "auto",
+            "foo.com",
+        )
+
+
+def test__get_client_cert_source():
+    mock_provided_cert_source = mock.Mock()
+    mock_default_cert_source = mock.Mock()
+
+    assert ContentServiceClient._get_client_cert_source(None, False) is None
+    assert (
+        ContentServiceClient._get_client_cert_source(mock_provided_cert_source, False)
+        is None
+    )
+    assert (
+        ContentServiceClient._get_client_cert_source(mock_provided_cert_source, True)
+        == mock_provided_cert_source
+    )
+
+    with mock.patch(
+        "google.auth.transport.mtls.has_default_client_cert_source", return_value=True
+    ):
+        with mock.patch(
+            "google.auth.transport.mtls.default_client_cert_source",
+            return_value=mock_default_cert_source,
+        ):
+            assert (
+                ContentServiceClient._get_client_cert_source(None, True)
+                is mock_default_cert_source
+            )
+            assert (
+                ContentServiceClient._get_client_cert_source(
+                    mock_provided_cert_source, "true"
+                )
+                is mock_provided_cert_source
+            )
+
+
+@mock.patch.object(
+    ContentServiceClient,
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(ContentServiceClient),
+)
+@mock.patch.object(
+    ContentServiceAsyncClient,
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(ContentServiceAsyncClient),
+)
+def test__get_api_endpoint():
+    api_override = "foo.com"
+    mock_client_cert_source = mock.Mock()
+    default_universe = ContentServiceClient._DEFAULT_UNIVERSE
+    default_endpoint = ContentServiceClient._DEFAULT_ENDPOINT_TEMPLATE.format(
+        UNIVERSE_DOMAIN=default_universe
+    )
+    mock_universe = "bar.com"
+    mock_endpoint = ContentServiceClient._DEFAULT_ENDPOINT_TEMPLATE.format(
+        UNIVERSE_DOMAIN=mock_universe
+    )
+
+    assert (
+        ContentServiceClient._get_api_endpoint(
+            api_override, mock_client_cert_source, default_universe, "always"
+        )
+        == api_override
+    )
+    assert (
+        ContentServiceClient._get_api_endpoint(
+            None, mock_client_cert_source, default_universe, "auto"
+        )
+        == ContentServiceClient.DEFAULT_MTLS_ENDPOINT
+    )
+    assert (
+        ContentServiceClient._get_api_endpoint(None, None, default_universe, "auto")
+        == default_endpoint
+    )
+    assert (
+        ContentServiceClient._get_api_endpoint(None, None, default_universe, "always")
+        == ContentServiceClient.DEFAULT_MTLS_ENDPOINT
+    )
+    assert (
+        ContentServiceClient._get_api_endpoint(
+            None, mock_client_cert_source, default_universe, "always"
+        )
+        == ContentServiceClient.DEFAULT_MTLS_ENDPOINT
+    )
+    assert (
+        ContentServiceClient._get_api_endpoint(None, None, mock_universe, "never")
+        == mock_endpoint
+    )
+    assert (
+        ContentServiceClient._get_api_endpoint(None, None, default_universe, "never")
+        == default_endpoint
+    )
+
+    with pytest.raises(MutualTLSChannelError) as excinfo:
+        ContentServiceClient._get_api_endpoint(
+            None, mock_client_cert_source, mock_universe, "auto"
+        )
+    assert (
+        str(excinfo.value)
+        == "mTLS is not supported in any universe other than googleapis.com."
+    )
+
+
+def test__get_universe_domain():
+    client_universe_domain = "foo.com"
+    universe_domain_env = "bar.com"
+
+    assert (
+        ContentServiceClient._get_universe_domain(
+            client_universe_domain, universe_domain_env
+        )
+        == client_universe_domain
+    )
+    assert (
+        ContentServiceClient._get_universe_domain(None, universe_domain_env)
+        == universe_domain_env
+    )
+    assert (
+        ContentServiceClient._get_universe_domain(None, None)
+        == ContentServiceClient._DEFAULT_UNIVERSE
+    )
+
+    with pytest.raises(ValueError) as excinfo:
+        ContentServiceClient._get_universe_domain("", None)
+    assert str(excinfo.value) == "Universe Domain cannot be an empty string."
+
+
+@pytest.mark.parametrize(
+    "client_class,transport_class,transport_name",
+    [
+        (ContentServiceClient, transports.ContentServiceGrpcTransport, "grpc"),
+    ],
+)
+def test__validate_universe_domain(client_class, transport_class, transport_name):
+    client = client_class(
+        transport=transport_class(credentials=ga_credentials.AnonymousCredentials())
+    )
+    assert client._validate_universe_domain() == True
+
+    # Test the case when universe is already validated.
+    assert client._validate_universe_domain() == True
+
+    if transport_name == "grpc":
+        # Test the case where credentials are provided by the
+        # `local_channel_credentials`. The default universes in both match.
+        channel = grpc.secure_channel(
+            "http://localhost/", grpc.local_channel_credentials()
+        )
+        client = client_class(transport=transport_class(channel=channel))
+        assert client._validate_universe_domain() == True
+
+        # Test the case where credentials do not exist: e.g. a transport is provided
+        # with no credentials. Validation should still succeed because there is no
+        # mismatch with non-existent credentials.
+        channel = grpc.secure_channel(
+            "http://localhost/", grpc.local_channel_credentials()
+        )
+        transport = transport_class(channel=channel)
+        transport._credentials = None
+        client = client_class(transport=transport)
+        assert client._validate_universe_domain() == True
+
+    # TODO: This is needed to cater for older versions of google-auth
+    # Make this test unconditional once the minimum supported version of
+    # google-auth becomes 2.23.0 or higher.
+    google_auth_major, google_auth_minor = [
+        int(part) for part in google.auth.__version__.split(".")[0:2]
+    ]
+    if google_auth_major > 2 or (google_auth_major == 2 and google_auth_minor >= 23):
+        credentials = ga_credentials.AnonymousCredentials()
+        credentials._universe_domain = "foo.com"
+        # Test the case when there is a universe mismatch from the credentials.
+        client = client_class(transport=transport_class(credentials=credentials))
+        with pytest.raises(ValueError) as excinfo:
+            client._validate_universe_domain()
+        assert (
+            str(excinfo.value)
+            == "The configured universe domain (googleapis.com) does not match the universe domain found in the credentials (foo.com). If you haven't configured the universe domain explicitly, `googleapis.com` is the default."
+        )
+
+        # Test the case when there is a universe mismatch from the client.
+        #
+        # TODO: Make this test unconditional once the minimum supported version of
+        # google-api-core becomes 2.15.0 or higher.
+        api_core_major, api_core_minor = [
+            int(part) for part in api_core_version.__version__.split(".")[0:2]
+        ]
+        if api_core_major > 2 or (api_core_major == 2 and api_core_minor >= 15):
+            client = client_class(
+                client_options={"universe_domain": "bar.com"},
+                transport=transport_class(
+                    credentials=ga_credentials.AnonymousCredentials(),
+                ),
+            )
+            with pytest.raises(ValueError) as excinfo:
+                client._validate_universe_domain()
+            assert (
+                str(excinfo.value)
+                == "The configured universe domain (bar.com) does not match the universe domain found in the credentials (googleapis.com). If you haven't configured the universe domain explicitly, `googleapis.com` is the default."
+            )
+
+    # Test that ValueError is raised if universe_domain is provided via client options and credentials is None
+    with pytest.raises(ValueError):
+        client._compare_universes("foo.bar", None)
+
+
 @pytest.mark.parametrize(
     "client_class,transport_name",
     [
         (ContentServiceClient, "grpc"),
         (ContentServiceAsyncClient, "grpc_asyncio"),
     ],
 )
@@ -194,21 +472,21 @@
             transports.ContentServiceGrpcAsyncIOTransport,
             "grpc_asyncio",
         ),
     ],
 )
 @mock.patch.object(
     ContentServiceClient,
-    "DEFAULT_ENDPOINT",
-    modify_default_endpoint(ContentServiceClient),
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(ContentServiceClient),
 )
 @mock.patch.object(
     ContentServiceAsyncClient,
-    "DEFAULT_ENDPOINT",
-    modify_default_endpoint(ContentServiceAsyncClient),
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(ContentServiceAsyncClient),
 )
 def test_content_service_client_client_options(
     client_class, transport_class, transport_name
 ):
     # Check that if channel is provided we won't create a new one.
     with mock.patch.object(ContentServiceClient, "get_transport_class") as gtc:
         transport = transport_class(credentials=ga_credentials.AnonymousCredentials())
@@ -242,15 +520,17 @@
     with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "never"}):
         with mock.patch.object(transport_class, "__init__") as patched:
             patched.return_value = None
             client = client_class(transport=transport_name)
             patched.assert_called_once_with(
                 credentials=None,
                 credentials_file=None,
-                host=client.DEFAULT_ENDPOINT,
+                host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                    UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+                ),
                 scopes=None,
                 client_cert_source_for_mtls=None,
                 quota_project_id=None,
                 client_info=transports.base.DEFAULT_CLIENT_INFO,
                 always_use_jwt_access=True,
                 api_audience=None,
             )
@@ -272,33 +552,43 @@
                 always_use_jwt_access=True,
                 api_audience=None,
             )
 
     # Check the case api_endpoint is not provided and GOOGLE_API_USE_MTLS_ENDPOINT has
     # unsupported value.
     with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "Unsupported"}):
-        with pytest.raises(MutualTLSChannelError):
+        with pytest.raises(MutualTLSChannelError) as excinfo:
             client = client_class(transport=transport_name)
+    assert (
+        str(excinfo.value)
+        == "Environment variable `GOOGLE_API_USE_MTLS_ENDPOINT` must be `never`, `auto` or `always`"
+    )
 
     # Check the case GOOGLE_API_USE_CLIENT_CERTIFICATE has unsupported value.
     with mock.patch.dict(
         os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "Unsupported"}
     ):
-        with pytest.raises(ValueError):
+        with pytest.raises(ValueError) as excinfo:
             client = client_class(transport=transport_name)
+    assert (
+        str(excinfo.value)
+        == "Environment variable `GOOGLE_API_USE_CLIENT_CERTIFICATE` must be either `true` or `false`"
+    )
 
     # Check the case quota_project_id is provided
     options = client_options.ClientOptions(quota_project_id="octopus")
     with mock.patch.object(transport_class, "__init__") as patched:
         patched.return_value = None
         client = client_class(client_options=options, transport=transport_name)
         patched.assert_called_once_with(
             credentials=None,
             credentials_file=None,
-            host=client.DEFAULT_ENDPOINT,
+            host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+            ),
             scopes=None,
             client_cert_source_for_mtls=None,
             quota_project_id="octopus",
             client_info=transports.base.DEFAULT_CLIENT_INFO,
             always_use_jwt_access=True,
             api_audience=None,
         )
@@ -308,15 +598,17 @@
     )
     with mock.patch.object(transport_class, "__init__") as patched:
         patched.return_value = None
         client = client_class(client_options=options, transport=transport_name)
         patched.assert_called_once_with(
             credentials=None,
             credentials_file=None,
-            host=client.DEFAULT_ENDPOINT,
+            host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+            ),
             scopes=None,
             client_cert_source_for_mtls=None,
             quota_project_id=None,
             client_info=transports.base.DEFAULT_CLIENT_INFO,
             always_use_jwt_access=True,
             api_audience="https://language.googleapis.com",
         )
@@ -339,21 +631,21 @@
             "grpc_asyncio",
             "false",
         ),
     ],
 )
 @mock.patch.object(
     ContentServiceClient,
-    "DEFAULT_ENDPOINT",
-    modify_default_endpoint(ContentServiceClient),
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(ContentServiceClient),
 )
 @mock.patch.object(
     ContentServiceAsyncClient,
-    "DEFAULT_ENDPOINT",
-    modify_default_endpoint(ContentServiceAsyncClient),
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(ContentServiceAsyncClient),
 )
 @mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "auto"})
 def test_content_service_client_mtls_env_auto(
     client_class, transport_class, transport_name, use_client_cert_env
 ):
     # This tests the endpoint autoswitch behavior. Endpoint is autoswitched to the default
     # mtls endpoint, if GOOGLE_API_USE_CLIENT_CERTIFICATE is "true" and client cert exists.
@@ -368,15 +660,17 @@
         )
         with mock.patch.object(transport_class, "__init__") as patched:
             patched.return_value = None
             client = client_class(client_options=options, transport=transport_name)
 
             if use_client_cert_env == "false":
                 expected_client_cert_source = None
-                expected_host = client.DEFAULT_ENDPOINT
+                expected_host = client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                    UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+                )
             else:
                 expected_client_cert_source = client_cert_source_callback
                 expected_host = client.DEFAULT_MTLS_ENDPOINT
 
             patched.assert_called_once_with(
                 credentials=None,
                 credentials_file=None,
@@ -400,15 +694,17 @@
                 return_value=True,
             ):
                 with mock.patch(
                     "google.auth.transport.mtls.default_client_cert_source",
                     return_value=client_cert_source_callback,
                 ):
                     if use_client_cert_env == "false":
-                        expected_host = client.DEFAULT_ENDPOINT
+                        expected_host = client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                            UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+                        )
                         expected_client_cert_source = None
                     else:
                         expected_host = client.DEFAULT_MTLS_ENDPOINT
                         expected_client_cert_source = client_cert_source_callback
 
                     patched.return_value = None
                     client = client_class(transport=transport_name)
@@ -434,15 +730,17 @@
                 return_value=False,
             ):
                 patched.return_value = None
                 client = client_class(transport=transport_name)
                 patched.assert_called_once_with(
                     credentials=None,
                     credentials_file=None,
-                    host=client.DEFAULT_ENDPOINT,
+                    host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                        UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+                    ),
                     scopes=None,
                     client_cert_source_for_mtls=None,
                     quota_project_id=None,
                     client_info=transports.base.DEFAULT_CLIENT_INFO,
                     always_use_jwt_access=True,
                     api_audience=None,
                 )
@@ -524,14 +822,123 @@
                 (
                     api_endpoint,
                     cert_source,
                 ) = client_class.get_mtls_endpoint_and_cert_source()
                 assert api_endpoint == client_class.DEFAULT_MTLS_ENDPOINT
                 assert cert_source == mock_client_cert_source
 
+    # Check the case api_endpoint is not provided and GOOGLE_API_USE_MTLS_ENDPOINT has
+    # unsupported value.
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "Unsupported"}):
+        with pytest.raises(MutualTLSChannelError) as excinfo:
+            client_class.get_mtls_endpoint_and_cert_source()
+
+        assert (
+            str(excinfo.value)
+            == "Environment variable `GOOGLE_API_USE_MTLS_ENDPOINT` must be `never`, `auto` or `always`"
+        )
+
+    # Check the case GOOGLE_API_USE_CLIENT_CERTIFICATE has unsupported value.
+    with mock.patch.dict(
+        os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "Unsupported"}
+    ):
+        with pytest.raises(ValueError) as excinfo:
+            client_class.get_mtls_endpoint_and_cert_source()
+
+        assert (
+            str(excinfo.value)
+            == "Environment variable `GOOGLE_API_USE_CLIENT_CERTIFICATE` must be either `true` or `false`"
+        )
+
+
+@pytest.mark.parametrize(
+    "client_class", [ContentServiceClient, ContentServiceAsyncClient]
+)
+@mock.patch.object(
+    ContentServiceClient,
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(ContentServiceClient),
+)
+@mock.patch.object(
+    ContentServiceAsyncClient,
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(ContentServiceAsyncClient),
+)
+def test_content_service_client_client_api_endpoint(client_class):
+    mock_client_cert_source = client_cert_source_callback
+    api_override = "foo.com"
+    default_universe = ContentServiceClient._DEFAULT_UNIVERSE
+    default_endpoint = ContentServiceClient._DEFAULT_ENDPOINT_TEMPLATE.format(
+        UNIVERSE_DOMAIN=default_universe
+    )
+    mock_universe = "bar.com"
+    mock_endpoint = ContentServiceClient._DEFAULT_ENDPOINT_TEMPLATE.format(
+        UNIVERSE_DOMAIN=mock_universe
+    )
+
+    # If ClientOptions.api_endpoint is set and GOOGLE_API_USE_CLIENT_CERTIFICATE="true",
+    # use ClientOptions.api_endpoint as the api endpoint regardless.
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "true"}):
+        with mock.patch(
+            "google.auth.transport.requests.AuthorizedSession.configure_mtls_channel"
+        ):
+            options = client_options.ClientOptions(
+                client_cert_source=mock_client_cert_source, api_endpoint=api_override
+            )
+            client = client_class(
+                client_options=options,
+                credentials=ga_credentials.AnonymousCredentials(),
+            )
+            assert client.api_endpoint == api_override
+
+    # If ClientOptions.api_endpoint is not set and GOOGLE_API_USE_MTLS_ENDPOINT="never",
+    # use the _DEFAULT_ENDPOINT_TEMPLATE populated with GDU as the api endpoint.
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "never"}):
+        client = client_class(credentials=ga_credentials.AnonymousCredentials())
+        assert client.api_endpoint == default_endpoint
+
+    # If ClientOptions.api_endpoint is not set and GOOGLE_API_USE_MTLS_ENDPOINT="always",
+    # use the DEFAULT_MTLS_ENDPOINT as the api endpoint.
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "always"}):
+        client = client_class(credentials=ga_credentials.AnonymousCredentials())
+        assert client.api_endpoint == client_class.DEFAULT_MTLS_ENDPOINT
+
+    # If ClientOptions.api_endpoint is not set, GOOGLE_API_USE_MTLS_ENDPOINT="auto" (default),
+    # GOOGLE_API_USE_CLIENT_CERTIFICATE="false" (default), default cert source doesn't exist,
+    # and ClientOptions.universe_domain="bar.com",
+    # use the _DEFAULT_ENDPOINT_TEMPLATE populated with universe domain as the api endpoint.
+    options = client_options.ClientOptions()
+    universe_exists = hasattr(options, "universe_domain")
+    if universe_exists:
+        options = client_options.ClientOptions(universe_domain=mock_universe)
+        client = client_class(
+            client_options=options, credentials=ga_credentials.AnonymousCredentials()
+        )
+    else:
+        client = client_class(
+            client_options=options, credentials=ga_credentials.AnonymousCredentials()
+        )
+    assert client.api_endpoint == (
+        mock_endpoint if universe_exists else default_endpoint
+    )
+    assert client.universe_domain == (
+        mock_universe if universe_exists else default_universe
+    )
+
+    # If ClientOptions does not have a universe domain attribute and GOOGLE_API_USE_MTLS_ENDPOINT="never",
+    # use the _DEFAULT_ENDPOINT_TEMPLATE populated with GDU as the api endpoint.
+    options = client_options.ClientOptions()
+    if hasattr(options, "universe_domain"):
+        delattr(options, "universe_domain")
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "never"}):
+        client = client_class(
+            client_options=options, credentials=ga_credentials.AnonymousCredentials()
+        )
+        assert client.api_endpoint == default_endpoint
+
 
 @pytest.mark.parametrize(
     "client_class,transport_class,transport_name",
     [
         (ContentServiceClient, transports.ContentServiceGrpcTransport, "grpc"),
         (
             ContentServiceAsyncClient,
@@ -549,15 +956,17 @@
     )
     with mock.patch.object(transport_class, "__init__") as patched:
         patched.return_value = None
         client = client_class(client_options=options, transport=transport_name)
         patched.assert_called_once_with(
             credentials=None,
             credentials_file=None,
-            host=client.DEFAULT_ENDPOINT,
+            host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+            ),
             scopes=["1", "2"],
             client_cert_source_for_mtls=None,
             quota_project_id=None,
             client_info=transports.base.DEFAULT_CLIENT_INFO,
             always_use_jwt_access=True,
             api_audience=None,
         )
@@ -588,15 +997,17 @@
 
     with mock.patch.object(transport_class, "__init__") as patched:
         patched.return_value = None
         client = client_class(client_options=options, transport=transport_name)
         patched.assert_called_once_with(
             credentials=None,
             credentials_file="credentials.json",
-            host=client.DEFAULT_ENDPOINT,
+            host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+            ),
             scopes=None,
             client_cert_source_for_mtls=None,
             quota_project_id=None,
             client_info=transports.base.DEFAULT_CLIENT_INFO,
             always_use_jwt_access=True,
             api_audience=None,
         )
@@ -648,15 +1059,17 @@
 
     with mock.patch.object(transport_class, "__init__") as patched:
         patched.return_value = None
         client = client_class(client_options=options, transport=transport_name)
         patched.assert_called_once_with(
             credentials=None,
             credentials_file="credentials.json",
-            host=client.DEFAULT_ENDPOINT,
+            host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+            ),
             scopes=None,
             client_cert_source_for_mtls=None,
             quota_project_id=None,
             client_info=transports.base.DEFAULT_CLIENT_INFO,
             always_use_jwt_access=True,
             api_audience=None,
         )
@@ -718,15 +1131,16 @@
             data_text="data_text_value",
         )
         response = client.create_content(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == gcd_content.CreateContentRequest()
+        request = gcd_content.CreateContentRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, analyze.Content)
     assert response.name == "name_value"
     assert response.uid == "uid_value"
     assert response.path == "path_value"
     assert response.description == "description_value"
@@ -738,20 +1152,158 @@
     client = ContentServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.create_content), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.create_content()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == gcd_content.CreateContentRequest()
 
 
+def test_create_content_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = ContentServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = gcd_content.CreateContentRequest(
+        parent="parent_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.create_content), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.create_content(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == gcd_content.CreateContentRequest(
+            parent="parent_value",
+        )
+
+
+def test_create_content_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = ContentServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.create_content in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[client._transport.create_content] = mock_rpc
+        request = {}
+        client.create_content(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.create_content(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_create_content_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = ContentServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.create_content), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            analyze.Content(
+                name="name_value",
+                uid="uid_value",
+                path="path_value",
+                description="description_value",
+            )
+        )
+        response = await client.create_content()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == gcd_content.CreateContentRequest()
+
+
+@pytest.mark.asyncio
+async def test_create_content_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = ContentServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.create_content
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.create_content
+        ] = mock_object
+
+        request = {}
+        await client.create_content(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.create_content(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_create_content_async(
     transport: str = "grpc_asyncio", request_type=gcd_content.CreateContentRequest
 ):
     client = ContentServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
@@ -773,15 +1325,16 @@
             )
         )
         response = await client.create_content(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == gcd_content.CreateContentRequest()
+        request = gcd_content.CreateContentRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, analyze.Content)
     assert response.name == "name_value"
     assert response.uid == "uid_value"
     assert response.path == "path_value"
     assert response.description == "description_value"
@@ -969,15 +1522,16 @@
             data_text="data_text_value",
         )
         response = client.update_content(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == gcd_content.UpdateContentRequest()
+        request = gcd_content.UpdateContentRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, analyze.Content)
     assert response.name == "name_value"
     assert response.uid == "uid_value"
     assert response.path == "path_value"
     assert response.description == "description_value"
@@ -989,20 +1543,154 @@
     client = ContentServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.update_content), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.update_content()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == gcd_content.UpdateContentRequest()
 
 
+def test_update_content_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = ContentServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = gcd_content.UpdateContentRequest()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.update_content), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.update_content(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == gcd_content.UpdateContentRequest()
+
+
+def test_update_content_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = ContentServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.update_content in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[client._transport.update_content] = mock_rpc
+        request = {}
+        client.update_content(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.update_content(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_update_content_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = ContentServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.update_content), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            analyze.Content(
+                name="name_value",
+                uid="uid_value",
+                path="path_value",
+                description="description_value",
+            )
+        )
+        response = await client.update_content()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == gcd_content.UpdateContentRequest()
+
+
+@pytest.mark.asyncio
+async def test_update_content_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = ContentServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.update_content
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.update_content
+        ] = mock_object
+
+        request = {}
+        await client.update_content(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.update_content(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_update_content_async(
     transport: str = "grpc_asyncio", request_type=gcd_content.UpdateContentRequest
 ):
     client = ContentServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
@@ -1024,15 +1712,16 @@
             )
         )
         response = await client.update_content(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == gcd_content.UpdateContentRequest()
+        request = gcd_content.UpdateContentRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, analyze.Content)
     assert response.name == "name_value"
     assert response.uid == "uid_value"
     assert response.path == "path_value"
     assert response.description == "description_value"
@@ -1214,15 +1903,16 @@
         # Designate an appropriate return value for the call.
         call.return_value = None
         response = client.delete_content(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == content.DeleteContentRequest()
+        request = content.DeleteContentRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert response is None
 
 
 def test_delete_content_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
@@ -1230,20 +1920,151 @@
     client = ContentServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.delete_content), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.delete_content()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == content.DeleteContentRequest()
 
 
+def test_delete_content_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = ContentServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = content.DeleteContentRequest(
+        name="name_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.delete_content), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.delete_content(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == content.DeleteContentRequest(
+            name="name_value",
+        )
+
+
+def test_delete_content_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = ContentServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.delete_content in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[client._transport.delete_content] = mock_rpc
+        request = {}
+        client.delete_content(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.delete_content(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_delete_content_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = ContentServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.delete_content), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(None)
+        response = await client.delete_content()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == content.DeleteContentRequest()
+
+
+@pytest.mark.asyncio
+async def test_delete_content_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = ContentServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.delete_content
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.delete_content
+        ] = mock_object
+
+        request = {}
+        await client.delete_content(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.delete_content(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_delete_content_async(
     transport: str = "grpc_asyncio", request_type=content.DeleteContentRequest
 ):
     client = ContentServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
@@ -1258,15 +2079,16 @@
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(None)
         response = await client.delete_content(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == content.DeleteContentRequest()
+        request = content.DeleteContentRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert response is None
 
 
 @pytest.mark.asyncio
 async def test_delete_content_async_from_dict():
@@ -1440,15 +2262,16 @@
             data_text="data_text_value",
         )
         response = client.get_content(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == content.GetContentRequest()
+        request = content.GetContentRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, analyze.Content)
     assert response.name == "name_value"
     assert response.uid == "uid_value"
     assert response.path == "path_value"
     assert response.description == "description_value"
@@ -1460,20 +2283,158 @@
     client = ContentServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.get_content), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.get_content()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == content.GetContentRequest()
 
 
+def test_get_content_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = ContentServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = content.GetContentRequest(
+        name="name_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_content), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.get_content(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == content.GetContentRequest(
+            name="name_value",
+        )
+
+
+def test_get_content_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = ContentServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.get_content in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[client._transport.get_content] = mock_rpc
+        request = {}
+        client.get_content(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.get_content(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_get_content_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = ContentServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_content), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            analyze.Content(
+                name="name_value",
+                uid="uid_value",
+                path="path_value",
+                description="description_value",
+            )
+        )
+        response = await client.get_content()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == content.GetContentRequest()
+
+
+@pytest.mark.asyncio
+async def test_get_content_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = ContentServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.get_content
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.get_content
+        ] = mock_object
+
+        request = {}
+        await client.get_content(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.get_content(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_get_content_async(
     transport: str = "grpc_asyncio", request_type=content.GetContentRequest
 ):
     client = ContentServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
@@ -1495,15 +2456,16 @@
             )
         )
         response = await client.get_content(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == content.GetContentRequest()
+        request = content.GetContentRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, analyze.Content)
     assert response.name == "name_value"
     assert response.uid == "uid_value"
     assert response.path == "path_value"
     assert response.description == "description_value"
@@ -1678,15 +2640,16 @@
             etag=b"etag_blob",
         )
         response = client.get_iam_policy(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == iam_policy_pb2.GetIamPolicyRequest()
+        request = iam_policy_pb2.GetIamPolicyRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, policy_pb2.Policy)
     assert response.version == 774
     assert response.etag == b"etag_blob"
 
 
@@ -1696,20 +2659,156 @@
     client = ContentServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.get_iam_policy), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.get_iam_policy()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == iam_policy_pb2.GetIamPolicyRequest()
 
 
+def test_get_iam_policy_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = ContentServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = iam_policy_pb2.GetIamPolicyRequest(
+        resource="resource_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_iam_policy), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.get_iam_policy(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == iam_policy_pb2.GetIamPolicyRequest(
+            resource="resource_value",
+        )
+
+
+def test_get_iam_policy_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = ContentServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.get_iam_policy in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[client._transport.get_iam_policy] = mock_rpc
+        request = {}
+        client.get_iam_policy(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.get_iam_policy(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_get_iam_policy_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = ContentServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_iam_policy), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            policy_pb2.Policy(
+                version=774,
+                etag=b"etag_blob",
+            )
+        )
+        response = await client.get_iam_policy()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == iam_policy_pb2.GetIamPolicyRequest()
+
+
+@pytest.mark.asyncio
+async def test_get_iam_policy_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = ContentServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.get_iam_policy
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.get_iam_policy
+        ] = mock_object
+
+        request = {}
+        await client.get_iam_policy(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.get_iam_policy(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_get_iam_policy_async(
     transport: str = "grpc_asyncio", request_type=iam_policy_pb2.GetIamPolicyRequest
 ):
     client = ContentServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
@@ -1729,15 +2828,16 @@
             )
         )
         response = await client.get_iam_policy(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == iam_policy_pb2.GetIamPolicyRequest()
+        request = iam_policy_pb2.GetIamPolicyRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, policy_pb2.Policy)
     assert response.version == 774
     assert response.etag == b"etag_blob"
 
 
@@ -1927,15 +3027,16 @@
             etag=b"etag_blob",
         )
         response = client.set_iam_policy(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == iam_policy_pb2.SetIamPolicyRequest()
+        request = iam_policy_pb2.SetIamPolicyRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, policy_pb2.Policy)
     assert response.version == 774
     assert response.etag == b"etag_blob"
 
 
@@ -1945,20 +3046,156 @@
     client = ContentServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.set_iam_policy), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.set_iam_policy()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == iam_policy_pb2.SetIamPolicyRequest()
 
 
+def test_set_iam_policy_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = ContentServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = iam_policy_pb2.SetIamPolicyRequest(
+        resource="resource_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.set_iam_policy), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.set_iam_policy(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == iam_policy_pb2.SetIamPolicyRequest(
+            resource="resource_value",
+        )
+
+
+def test_set_iam_policy_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = ContentServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.set_iam_policy in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[client._transport.set_iam_policy] = mock_rpc
+        request = {}
+        client.set_iam_policy(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.set_iam_policy(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_set_iam_policy_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = ContentServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.set_iam_policy), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            policy_pb2.Policy(
+                version=774,
+                etag=b"etag_blob",
+            )
+        )
+        response = await client.set_iam_policy()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == iam_policy_pb2.SetIamPolicyRequest()
+
+
+@pytest.mark.asyncio
+async def test_set_iam_policy_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = ContentServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.set_iam_policy
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.set_iam_policy
+        ] = mock_object
+
+        request = {}
+        await client.set_iam_policy(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.set_iam_policy(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_set_iam_policy_async(
     transport: str = "grpc_asyncio", request_type=iam_policy_pb2.SetIamPolicyRequest
 ):
     client = ContentServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
@@ -1978,15 +3215,16 @@
             )
         )
         response = await client.set_iam_policy(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == iam_policy_pb2.SetIamPolicyRequest()
+        request = iam_policy_pb2.SetIamPolicyRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, policy_pb2.Policy)
     assert response.version == 774
     assert response.etag == b"etag_blob"
 
 
@@ -2098,15 +3336,16 @@
             permissions=["permissions_value"],
         )
         response = client.test_iam_permissions(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == iam_policy_pb2.TestIamPermissionsRequest()
+        request = iam_policy_pb2.TestIamPermissionsRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, iam_policy_pb2.TestIamPermissionsResponse)
     assert response.permissions == ["permissions_value"]
 
 
 def test_test_iam_permissions_empty_call():
@@ -2117,20 +3356,163 @@
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.test_iam_permissions), "__call__"
     ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.test_iam_permissions()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == iam_policy_pb2.TestIamPermissionsRequest()
 
 
+def test_test_iam_permissions_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = ContentServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = iam_policy_pb2.TestIamPermissionsRequest(
+        resource="resource_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.test_iam_permissions), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.test_iam_permissions(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == iam_policy_pb2.TestIamPermissionsRequest(
+            resource="resource_value",
+        )
+
+
+def test_test_iam_permissions_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = ContentServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._transport.test_iam_permissions in client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.test_iam_permissions
+        ] = mock_rpc
+        request = {}
+        client.test_iam_permissions(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.test_iam_permissions(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_test_iam_permissions_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = ContentServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.test_iam_permissions), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            iam_policy_pb2.TestIamPermissionsResponse(
+                permissions=["permissions_value"],
+            )
+        )
+        response = await client.test_iam_permissions()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == iam_policy_pb2.TestIamPermissionsRequest()
+
+
+@pytest.mark.asyncio
+async def test_test_iam_permissions_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = ContentServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.test_iam_permissions
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.test_iam_permissions
+        ] = mock_object
+
+        request = {}
+        await client.test_iam_permissions(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.test_iam_permissions(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_test_iam_permissions_async(
     transport: str = "grpc_asyncio",
     request_type=iam_policy_pb2.TestIamPermissionsRequest,
 ):
     client = ContentServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -2152,15 +3534,16 @@
             )
         )
         response = await client.test_iam_permissions(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == iam_policy_pb2.TestIamPermissionsRequest()
+        request = iam_policy_pb2.TestIamPermissionsRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, iam_policy_pb2.TestIamPermissionsResponse)
     assert response.permissions == ["permissions_value"]
 
 
 @pytest.mark.asyncio
@@ -2276,15 +3659,16 @@
             next_page_token="next_page_token_value",
         )
         response = client.list_content(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == content.ListContentRequest()
+        request = content.ListContentRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, pagers.ListContentPager)
     assert response.next_page_token == "next_page_token_value"
 
 
 def test_list_content_empty_call():
@@ -2293,20 +3677,159 @@
     client = ContentServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.list_content), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.list_content()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == content.ListContentRequest()
 
 
+def test_list_content_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = ContentServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = content.ListContentRequest(
+        parent="parent_value",
+        page_token="page_token_value",
+        filter="filter_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_content), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.list_content(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == content.ListContentRequest(
+            parent="parent_value",
+            page_token="page_token_value",
+            filter="filter_value",
+        )
+
+
+def test_list_content_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = ContentServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.list_content in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[client._transport.list_content] = mock_rpc
+        request = {}
+        client.list_content(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.list_content(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_list_content_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = ContentServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_content), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            content.ListContentResponse(
+                next_page_token="next_page_token_value",
+            )
+        )
+        response = await client.list_content()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == content.ListContentRequest()
+
+
+@pytest.mark.asyncio
+async def test_list_content_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = ContentServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.list_content
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.list_content
+        ] = mock_object
+
+        request = {}
+        await client.list_content(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.list_content(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_list_content_async(
     transport: str = "grpc_asyncio", request_type=content.ListContentRequest
 ):
     client = ContentServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
@@ -2325,15 +3848,16 @@
             )
         )
         response = await client.list_content(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == content.ListContentRequest()
+        request = content.ListContentRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, pagers.ListContentAsyncPager)
     assert response.next_page_token == "next_page_token_value"
 
 
 @pytest.mark.asyncio
@@ -2482,15 +4006,15 @@
             content.ListContentRequest(),
             parent="parent_value",
         )
 
 
 def test_list_content_pager(transport_name: str = "grpc"):
     client = ContentServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
         transport=transport_name,
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.list_content), "__call__") as call:
         # Set the response to a series of pages.
         call.side_effect = (
@@ -2532,15 +4056,15 @@
         results = list(pager)
         assert len(results) == 6
         assert all(isinstance(i, analyze.Content) for i in results)
 
 
 def test_list_content_pages(transport_name: str = "grpc"):
     client = ContentServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
         transport=transport_name,
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.list_content), "__call__") as call:
         # Set the response to a series of pages.
         call.side_effect = (
@@ -2574,15 +4098,15 @@
         for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
             assert page_.raw_page.next_page_token == token
 
 
 @pytest.mark.asyncio
 async def test_list_content_async_pager():
     client = ContentServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.list_content), "__call__", new_callable=mock.AsyncMock
     ) as call:
         # Set the response to a series of pages.
@@ -2624,15 +4148,15 @@
         assert len(responses) == 6
         assert all(isinstance(i, analyze.Content) for i in responses)
 
 
 @pytest.mark.asyncio
 async def test_list_content_async_pages():
     client = ContentServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.list_content), "__call__", new_callable=mock.AsyncMock
     ) as call:
         # Set the response to a series of pages.
@@ -2704,15 +4228,15 @@
     with pytest.raises(ValueError):
         client = ContentServiceClient(
             client_options=options,
             transport=transport,
         )
 
     # It is an error to provide an api_key and a credential.
-    options = mock.Mock()
+    options = client_options.ClientOptions()
     options.api_key = "api_key"
     with pytest.raises(ValueError):
         client = ContentServiceClient(
             client_options=options, credentials=ga_credentials.AnonymousCredentials()
         )
 
     # It is an error to provide scopes and a transport instance.
@@ -3388,15 +4912,15 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert response is None
 
 
 @pytest.mark.asyncio
-async def test_delete_operation_async(transport: str = "grpc"):
+async def test_delete_operation_async(transport: str = "grpc_asyncio"):
     client = ContentServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
@@ -3527,15 +5051,15 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert response is None
 
 
 @pytest.mark.asyncio
-async def test_cancel_operation_async(transport: str = "grpc"):
+async def test_cancel_operation_async(transport: str = "grpc_asyncio"):
     client = ContentServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
@@ -3666,15 +5190,15 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, operations_pb2.Operation)
 
 
 @pytest.mark.asyncio
-async def test_get_operation_async(transport: str = "grpc"):
+async def test_get_operation_async(transport: str = "grpc_asyncio"):
     client = ContentServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
@@ -3811,15 +5335,15 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, operations_pb2.ListOperationsResponse)
 
 
 @pytest.mark.asyncio
-async def test_list_operations_async(transport: str = "grpc"):
+async def test_list_operations_async(transport: str = "grpc_asyncio"):
     client = ContentServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
@@ -3956,15 +5480,15 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, locations_pb2.ListLocationsResponse)
 
 
 @pytest.mark.asyncio
-async def test_list_locations_async(transport: str = "grpc"):
+async def test_list_locations_async(transport: str = "grpc_asyncio"):
     client = ContentServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
@@ -4273,15 +5797,17 @@
         options.api_key = "api_key"
         with mock.patch.object(transport_class, "__init__") as patched:
             patched.return_value = None
             client = client_class(client_options=options)
             patched.assert_called_once_with(
                 credentials=mock_cred,
                 credentials_file=None,
-                host=client.DEFAULT_ENDPOINT,
+                host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                    UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+                ),
                 scopes=None,
                 client_cert_source_for_mtls=None,
                 quota_project_id=None,
                 client_info=transports.base.DEFAULT_CLIENT_INFO,
                 always_use_jwt_access=True,
                 api_audience=None,
             )
```

### Comparing `google-cloud-dataplex-1.9.0/tests/unit/gapic/dataplex_v1/test_data_scan_service.py` & `google-cloud-dataplex-2.0.0/tests/unit/gapic/dataplex_v1/test_data_scan_service.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -29,15 +29,15 @@
     gapic_v1,
     grpc_helpers,
     grpc_helpers_async,
     operation,
     operations_v1,
     path_template,
 )
-from google.api_core import client_options
+from google.api_core import api_core_version, client_options
 from google.api_core import exceptions as core_exceptions
 from google.api_core import operation_async  # type: ignore
 import google.auth
 from google.auth import credentials as ga_credentials
 from google.auth.exceptions import MutualTLSChannelError
 from google.cloud.location import locations_pb2
 from google.iam.v1 import iam_policy_pb2  # type: ignore
@@ -81,14 +81,25 @@
     return (
         "foo.googleapis.com"
         if ("localhost" in client.DEFAULT_ENDPOINT)
         else client.DEFAULT_ENDPOINT
     )
 
 
+# If default endpoint template is localhost, then default mtls endpoint will be the same.
+# This method modifies the default endpoint template so the client can produce a different
+# mtls endpoint for endpoint testing purposes.
+def modify_default_endpoint_template(client):
+    return (
+        "test.{UNIVERSE_DOMAIN}"
+        if ("localhost" in client._DEFAULT_ENDPOINT_TEMPLATE)
+        else client._DEFAULT_ENDPOINT_TEMPLATE
+    )
+
+
 def test__get_default_mtls_endpoint():
     api_endpoint = "example.googleapis.com"
     api_mtls_endpoint = "example.mtls.googleapis.com"
     sandbox_endpoint = "example.sandbox.googleapis.com"
     sandbox_mtls_endpoint = "example.mtls.sandbox.googleapis.com"
     non_googleapi = "api.example.com"
 
@@ -110,14 +121,281 @@
         == sandbox_mtls_endpoint
     )
     assert (
         DataScanServiceClient._get_default_mtls_endpoint(non_googleapi) == non_googleapi
     )
 
 
+def test__read_environment_variables():
+    assert DataScanServiceClient._read_environment_variables() == (False, "auto", None)
+
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "true"}):
+        assert DataScanServiceClient._read_environment_variables() == (
+            True,
+            "auto",
+            None,
+        )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "false"}):
+        assert DataScanServiceClient._read_environment_variables() == (
+            False,
+            "auto",
+            None,
+        )
+
+    with mock.patch.dict(
+        os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "Unsupported"}
+    ):
+        with pytest.raises(ValueError) as excinfo:
+            DataScanServiceClient._read_environment_variables()
+    assert (
+        str(excinfo.value)
+        == "Environment variable `GOOGLE_API_USE_CLIENT_CERTIFICATE` must be either `true` or `false`"
+    )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "never"}):
+        assert DataScanServiceClient._read_environment_variables() == (
+            False,
+            "never",
+            None,
+        )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "always"}):
+        assert DataScanServiceClient._read_environment_variables() == (
+            False,
+            "always",
+            None,
+        )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "auto"}):
+        assert DataScanServiceClient._read_environment_variables() == (
+            False,
+            "auto",
+            None,
+        )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "Unsupported"}):
+        with pytest.raises(MutualTLSChannelError) as excinfo:
+            DataScanServiceClient._read_environment_variables()
+    assert (
+        str(excinfo.value)
+        == "Environment variable `GOOGLE_API_USE_MTLS_ENDPOINT` must be `never`, `auto` or `always`"
+    )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_CLOUD_UNIVERSE_DOMAIN": "foo.com"}):
+        assert DataScanServiceClient._read_environment_variables() == (
+            False,
+            "auto",
+            "foo.com",
+        )
+
+
+def test__get_client_cert_source():
+    mock_provided_cert_source = mock.Mock()
+    mock_default_cert_source = mock.Mock()
+
+    assert DataScanServiceClient._get_client_cert_source(None, False) is None
+    assert (
+        DataScanServiceClient._get_client_cert_source(mock_provided_cert_source, False)
+        is None
+    )
+    assert (
+        DataScanServiceClient._get_client_cert_source(mock_provided_cert_source, True)
+        == mock_provided_cert_source
+    )
+
+    with mock.patch(
+        "google.auth.transport.mtls.has_default_client_cert_source", return_value=True
+    ):
+        with mock.patch(
+            "google.auth.transport.mtls.default_client_cert_source",
+            return_value=mock_default_cert_source,
+        ):
+            assert (
+                DataScanServiceClient._get_client_cert_source(None, True)
+                is mock_default_cert_source
+            )
+            assert (
+                DataScanServiceClient._get_client_cert_source(
+                    mock_provided_cert_source, "true"
+                )
+                is mock_provided_cert_source
+            )
+
+
+@mock.patch.object(
+    DataScanServiceClient,
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(DataScanServiceClient),
+)
+@mock.patch.object(
+    DataScanServiceAsyncClient,
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(DataScanServiceAsyncClient),
+)
+def test__get_api_endpoint():
+    api_override = "foo.com"
+    mock_client_cert_source = mock.Mock()
+    default_universe = DataScanServiceClient._DEFAULT_UNIVERSE
+    default_endpoint = DataScanServiceClient._DEFAULT_ENDPOINT_TEMPLATE.format(
+        UNIVERSE_DOMAIN=default_universe
+    )
+    mock_universe = "bar.com"
+    mock_endpoint = DataScanServiceClient._DEFAULT_ENDPOINT_TEMPLATE.format(
+        UNIVERSE_DOMAIN=mock_universe
+    )
+
+    assert (
+        DataScanServiceClient._get_api_endpoint(
+            api_override, mock_client_cert_source, default_universe, "always"
+        )
+        == api_override
+    )
+    assert (
+        DataScanServiceClient._get_api_endpoint(
+            None, mock_client_cert_source, default_universe, "auto"
+        )
+        == DataScanServiceClient.DEFAULT_MTLS_ENDPOINT
+    )
+    assert (
+        DataScanServiceClient._get_api_endpoint(None, None, default_universe, "auto")
+        == default_endpoint
+    )
+    assert (
+        DataScanServiceClient._get_api_endpoint(None, None, default_universe, "always")
+        == DataScanServiceClient.DEFAULT_MTLS_ENDPOINT
+    )
+    assert (
+        DataScanServiceClient._get_api_endpoint(
+            None, mock_client_cert_source, default_universe, "always"
+        )
+        == DataScanServiceClient.DEFAULT_MTLS_ENDPOINT
+    )
+    assert (
+        DataScanServiceClient._get_api_endpoint(None, None, mock_universe, "never")
+        == mock_endpoint
+    )
+    assert (
+        DataScanServiceClient._get_api_endpoint(None, None, default_universe, "never")
+        == default_endpoint
+    )
+
+    with pytest.raises(MutualTLSChannelError) as excinfo:
+        DataScanServiceClient._get_api_endpoint(
+            None, mock_client_cert_source, mock_universe, "auto"
+        )
+    assert (
+        str(excinfo.value)
+        == "mTLS is not supported in any universe other than googleapis.com."
+    )
+
+
+def test__get_universe_domain():
+    client_universe_domain = "foo.com"
+    universe_domain_env = "bar.com"
+
+    assert (
+        DataScanServiceClient._get_universe_domain(
+            client_universe_domain, universe_domain_env
+        )
+        == client_universe_domain
+    )
+    assert (
+        DataScanServiceClient._get_universe_domain(None, universe_domain_env)
+        == universe_domain_env
+    )
+    assert (
+        DataScanServiceClient._get_universe_domain(None, None)
+        == DataScanServiceClient._DEFAULT_UNIVERSE
+    )
+
+    with pytest.raises(ValueError) as excinfo:
+        DataScanServiceClient._get_universe_domain("", None)
+    assert str(excinfo.value) == "Universe Domain cannot be an empty string."
+
+
+@pytest.mark.parametrize(
+    "client_class,transport_class,transport_name",
+    [
+        (DataScanServiceClient, transports.DataScanServiceGrpcTransport, "grpc"),
+    ],
+)
+def test__validate_universe_domain(client_class, transport_class, transport_name):
+    client = client_class(
+        transport=transport_class(credentials=ga_credentials.AnonymousCredentials())
+    )
+    assert client._validate_universe_domain() == True
+
+    # Test the case when universe is already validated.
+    assert client._validate_universe_domain() == True
+
+    if transport_name == "grpc":
+        # Test the case where credentials are provided by the
+        # `local_channel_credentials`. The default universes in both match.
+        channel = grpc.secure_channel(
+            "http://localhost/", grpc.local_channel_credentials()
+        )
+        client = client_class(transport=transport_class(channel=channel))
+        assert client._validate_universe_domain() == True
+
+        # Test the case where credentials do not exist: e.g. a transport is provided
+        # with no credentials. Validation should still succeed because there is no
+        # mismatch with non-existent credentials.
+        channel = grpc.secure_channel(
+            "http://localhost/", grpc.local_channel_credentials()
+        )
+        transport = transport_class(channel=channel)
+        transport._credentials = None
+        client = client_class(transport=transport)
+        assert client._validate_universe_domain() == True
+
+    # TODO: This is needed to cater for older versions of google-auth
+    # Make this test unconditional once the minimum supported version of
+    # google-auth becomes 2.23.0 or higher.
+    google_auth_major, google_auth_minor = [
+        int(part) for part in google.auth.__version__.split(".")[0:2]
+    ]
+    if google_auth_major > 2 or (google_auth_major == 2 and google_auth_minor >= 23):
+        credentials = ga_credentials.AnonymousCredentials()
+        credentials._universe_domain = "foo.com"
+        # Test the case when there is a universe mismatch from the credentials.
+        client = client_class(transport=transport_class(credentials=credentials))
+        with pytest.raises(ValueError) as excinfo:
+            client._validate_universe_domain()
+        assert (
+            str(excinfo.value)
+            == "The configured universe domain (googleapis.com) does not match the universe domain found in the credentials (foo.com). If you haven't configured the universe domain explicitly, `googleapis.com` is the default."
+        )
+
+        # Test the case when there is a universe mismatch from the client.
+        #
+        # TODO: Make this test unconditional once the minimum supported version of
+        # google-api-core becomes 2.15.0 or higher.
+        api_core_major, api_core_minor = [
+            int(part) for part in api_core_version.__version__.split(".")[0:2]
+        ]
+        if api_core_major > 2 or (api_core_major == 2 and api_core_minor >= 15):
+            client = client_class(
+                client_options={"universe_domain": "bar.com"},
+                transport=transport_class(
+                    credentials=ga_credentials.AnonymousCredentials(),
+                ),
+            )
+            with pytest.raises(ValueError) as excinfo:
+                client._validate_universe_domain()
+            assert (
+                str(excinfo.value)
+                == "The configured universe domain (bar.com) does not match the universe domain found in the credentials (googleapis.com). If you haven't configured the universe domain explicitly, `googleapis.com` is the default."
+            )
+
+    # Test that ValueError is raised if universe_domain is provided via client options and credentials is None
+    with pytest.raises(ValueError):
+        client._compare_universes("foo.bar", None)
+
+
 @pytest.mark.parametrize(
     "client_class,transport_name",
     [
         (DataScanServiceClient, "grpc"),
         (DataScanServiceAsyncClient, "grpc_asyncio"),
     ],
 )
@@ -212,21 +490,21 @@
             transports.DataScanServiceGrpcAsyncIOTransport,
             "grpc_asyncio",
         ),
     ],
 )
 @mock.patch.object(
     DataScanServiceClient,
-    "DEFAULT_ENDPOINT",
-    modify_default_endpoint(DataScanServiceClient),
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(DataScanServiceClient),
 )
 @mock.patch.object(
     DataScanServiceAsyncClient,
-    "DEFAULT_ENDPOINT",
-    modify_default_endpoint(DataScanServiceAsyncClient),
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(DataScanServiceAsyncClient),
 )
 def test_data_scan_service_client_client_options(
     client_class, transport_class, transport_name
 ):
     # Check that if channel is provided we won't create a new one.
     with mock.patch.object(DataScanServiceClient, "get_transport_class") as gtc:
         transport = transport_class(credentials=ga_credentials.AnonymousCredentials())
@@ -260,15 +538,17 @@
     with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "never"}):
         with mock.patch.object(transport_class, "__init__") as patched:
             patched.return_value = None
             client = client_class(transport=transport_name)
             patched.assert_called_once_with(
                 credentials=None,
                 credentials_file=None,
-                host=client.DEFAULT_ENDPOINT,
+                host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                    UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+                ),
                 scopes=None,
                 client_cert_source_for_mtls=None,
                 quota_project_id=None,
                 client_info=transports.base.DEFAULT_CLIENT_INFO,
                 always_use_jwt_access=True,
                 api_audience=None,
             )
@@ -290,33 +570,43 @@
                 always_use_jwt_access=True,
                 api_audience=None,
             )
 
     # Check the case api_endpoint is not provided and GOOGLE_API_USE_MTLS_ENDPOINT has
     # unsupported value.
     with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "Unsupported"}):
-        with pytest.raises(MutualTLSChannelError):
+        with pytest.raises(MutualTLSChannelError) as excinfo:
             client = client_class(transport=transport_name)
+    assert (
+        str(excinfo.value)
+        == "Environment variable `GOOGLE_API_USE_MTLS_ENDPOINT` must be `never`, `auto` or `always`"
+    )
 
     # Check the case GOOGLE_API_USE_CLIENT_CERTIFICATE has unsupported value.
     with mock.patch.dict(
         os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "Unsupported"}
     ):
-        with pytest.raises(ValueError):
+        with pytest.raises(ValueError) as excinfo:
             client = client_class(transport=transport_name)
+    assert (
+        str(excinfo.value)
+        == "Environment variable `GOOGLE_API_USE_CLIENT_CERTIFICATE` must be either `true` or `false`"
+    )
 
     # Check the case quota_project_id is provided
     options = client_options.ClientOptions(quota_project_id="octopus")
     with mock.patch.object(transport_class, "__init__") as patched:
         patched.return_value = None
         client = client_class(client_options=options, transport=transport_name)
         patched.assert_called_once_with(
             credentials=None,
             credentials_file=None,
-            host=client.DEFAULT_ENDPOINT,
+            host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+            ),
             scopes=None,
             client_cert_source_for_mtls=None,
             quota_project_id="octopus",
             client_info=transports.base.DEFAULT_CLIENT_INFO,
             always_use_jwt_access=True,
             api_audience=None,
         )
@@ -326,15 +616,17 @@
     )
     with mock.patch.object(transport_class, "__init__") as patched:
         patched.return_value = None
         client = client_class(client_options=options, transport=transport_name)
         patched.assert_called_once_with(
             credentials=None,
             credentials_file=None,
-            host=client.DEFAULT_ENDPOINT,
+            host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+            ),
             scopes=None,
             client_cert_source_for_mtls=None,
             quota_project_id=None,
             client_info=transports.base.DEFAULT_CLIENT_INFO,
             always_use_jwt_access=True,
             api_audience="https://language.googleapis.com",
         )
@@ -367,21 +659,21 @@
             "grpc_asyncio",
             "false",
         ),
     ],
 )
 @mock.patch.object(
     DataScanServiceClient,
-    "DEFAULT_ENDPOINT",
-    modify_default_endpoint(DataScanServiceClient),
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(DataScanServiceClient),
 )
 @mock.patch.object(
     DataScanServiceAsyncClient,
-    "DEFAULT_ENDPOINT",
-    modify_default_endpoint(DataScanServiceAsyncClient),
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(DataScanServiceAsyncClient),
 )
 @mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "auto"})
 def test_data_scan_service_client_mtls_env_auto(
     client_class, transport_class, transport_name, use_client_cert_env
 ):
     # This tests the endpoint autoswitch behavior. Endpoint is autoswitched to the default
     # mtls endpoint, if GOOGLE_API_USE_CLIENT_CERTIFICATE is "true" and client cert exists.
@@ -396,15 +688,17 @@
         )
         with mock.patch.object(transport_class, "__init__") as patched:
             patched.return_value = None
             client = client_class(client_options=options, transport=transport_name)
 
             if use_client_cert_env == "false":
                 expected_client_cert_source = None
-                expected_host = client.DEFAULT_ENDPOINT
+                expected_host = client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                    UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+                )
             else:
                 expected_client_cert_source = client_cert_source_callback
                 expected_host = client.DEFAULT_MTLS_ENDPOINT
 
             patched.assert_called_once_with(
                 credentials=None,
                 credentials_file=None,
@@ -428,15 +722,17 @@
                 return_value=True,
             ):
                 with mock.patch(
                     "google.auth.transport.mtls.default_client_cert_source",
                     return_value=client_cert_source_callback,
                 ):
                     if use_client_cert_env == "false":
-                        expected_host = client.DEFAULT_ENDPOINT
+                        expected_host = client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                            UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+                        )
                         expected_client_cert_source = None
                     else:
                         expected_host = client.DEFAULT_MTLS_ENDPOINT
                         expected_client_cert_source = client_cert_source_callback
 
                     patched.return_value = None
                     client = client_class(transport=transport_name)
@@ -462,15 +758,17 @@
                 return_value=False,
             ):
                 patched.return_value = None
                 client = client_class(transport=transport_name)
                 patched.assert_called_once_with(
                     credentials=None,
                     credentials_file=None,
-                    host=client.DEFAULT_ENDPOINT,
+                    host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                        UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+                    ),
                     scopes=None,
                     client_cert_source_for_mtls=None,
                     quota_project_id=None,
                     client_info=transports.base.DEFAULT_CLIENT_INFO,
                     always_use_jwt_access=True,
                     api_audience=None,
                 )
@@ -552,14 +850,123 @@
                 (
                     api_endpoint,
                     cert_source,
                 ) = client_class.get_mtls_endpoint_and_cert_source()
                 assert api_endpoint == client_class.DEFAULT_MTLS_ENDPOINT
                 assert cert_source == mock_client_cert_source
 
+    # Check the case api_endpoint is not provided and GOOGLE_API_USE_MTLS_ENDPOINT has
+    # unsupported value.
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "Unsupported"}):
+        with pytest.raises(MutualTLSChannelError) as excinfo:
+            client_class.get_mtls_endpoint_and_cert_source()
+
+        assert (
+            str(excinfo.value)
+            == "Environment variable `GOOGLE_API_USE_MTLS_ENDPOINT` must be `never`, `auto` or `always`"
+        )
+
+    # Check the case GOOGLE_API_USE_CLIENT_CERTIFICATE has unsupported value.
+    with mock.patch.dict(
+        os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "Unsupported"}
+    ):
+        with pytest.raises(ValueError) as excinfo:
+            client_class.get_mtls_endpoint_and_cert_source()
+
+        assert (
+            str(excinfo.value)
+            == "Environment variable `GOOGLE_API_USE_CLIENT_CERTIFICATE` must be either `true` or `false`"
+        )
+
+
+@pytest.mark.parametrize(
+    "client_class", [DataScanServiceClient, DataScanServiceAsyncClient]
+)
+@mock.patch.object(
+    DataScanServiceClient,
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(DataScanServiceClient),
+)
+@mock.patch.object(
+    DataScanServiceAsyncClient,
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(DataScanServiceAsyncClient),
+)
+def test_data_scan_service_client_client_api_endpoint(client_class):
+    mock_client_cert_source = client_cert_source_callback
+    api_override = "foo.com"
+    default_universe = DataScanServiceClient._DEFAULT_UNIVERSE
+    default_endpoint = DataScanServiceClient._DEFAULT_ENDPOINT_TEMPLATE.format(
+        UNIVERSE_DOMAIN=default_universe
+    )
+    mock_universe = "bar.com"
+    mock_endpoint = DataScanServiceClient._DEFAULT_ENDPOINT_TEMPLATE.format(
+        UNIVERSE_DOMAIN=mock_universe
+    )
+
+    # If ClientOptions.api_endpoint is set and GOOGLE_API_USE_CLIENT_CERTIFICATE="true",
+    # use ClientOptions.api_endpoint as the api endpoint regardless.
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "true"}):
+        with mock.patch(
+            "google.auth.transport.requests.AuthorizedSession.configure_mtls_channel"
+        ):
+            options = client_options.ClientOptions(
+                client_cert_source=mock_client_cert_source, api_endpoint=api_override
+            )
+            client = client_class(
+                client_options=options,
+                credentials=ga_credentials.AnonymousCredentials(),
+            )
+            assert client.api_endpoint == api_override
+
+    # If ClientOptions.api_endpoint is not set and GOOGLE_API_USE_MTLS_ENDPOINT="never",
+    # use the _DEFAULT_ENDPOINT_TEMPLATE populated with GDU as the api endpoint.
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "never"}):
+        client = client_class(credentials=ga_credentials.AnonymousCredentials())
+        assert client.api_endpoint == default_endpoint
+
+    # If ClientOptions.api_endpoint is not set and GOOGLE_API_USE_MTLS_ENDPOINT="always",
+    # use the DEFAULT_MTLS_ENDPOINT as the api endpoint.
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "always"}):
+        client = client_class(credentials=ga_credentials.AnonymousCredentials())
+        assert client.api_endpoint == client_class.DEFAULT_MTLS_ENDPOINT
+
+    # If ClientOptions.api_endpoint is not set, GOOGLE_API_USE_MTLS_ENDPOINT="auto" (default),
+    # GOOGLE_API_USE_CLIENT_CERTIFICATE="false" (default), default cert source doesn't exist,
+    # and ClientOptions.universe_domain="bar.com",
+    # use the _DEFAULT_ENDPOINT_TEMPLATE populated with universe domain as the api endpoint.
+    options = client_options.ClientOptions()
+    universe_exists = hasattr(options, "universe_domain")
+    if universe_exists:
+        options = client_options.ClientOptions(universe_domain=mock_universe)
+        client = client_class(
+            client_options=options, credentials=ga_credentials.AnonymousCredentials()
+        )
+    else:
+        client = client_class(
+            client_options=options, credentials=ga_credentials.AnonymousCredentials()
+        )
+    assert client.api_endpoint == (
+        mock_endpoint if universe_exists else default_endpoint
+    )
+    assert client.universe_domain == (
+        mock_universe if universe_exists else default_universe
+    )
+
+    # If ClientOptions does not have a universe domain attribute and GOOGLE_API_USE_MTLS_ENDPOINT="never",
+    # use the _DEFAULT_ENDPOINT_TEMPLATE populated with GDU as the api endpoint.
+    options = client_options.ClientOptions()
+    if hasattr(options, "universe_domain"):
+        delattr(options, "universe_domain")
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "never"}):
+        client = client_class(
+            client_options=options, credentials=ga_credentials.AnonymousCredentials()
+        )
+        assert client.api_endpoint == default_endpoint
+
 
 @pytest.mark.parametrize(
     "client_class,transport_class,transport_name",
     [
         (DataScanServiceClient, transports.DataScanServiceGrpcTransport, "grpc"),
         (
             DataScanServiceAsyncClient,
@@ -577,15 +984,17 @@
     )
     with mock.patch.object(transport_class, "__init__") as patched:
         patched.return_value = None
         client = client_class(client_options=options, transport=transport_name)
         patched.assert_called_once_with(
             credentials=None,
             credentials_file=None,
-            host=client.DEFAULT_ENDPOINT,
+            host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+            ),
             scopes=["1", "2"],
             client_cert_source_for_mtls=None,
             quota_project_id=None,
             client_info=transports.base.DEFAULT_CLIENT_INFO,
             always_use_jwt_access=True,
             api_audience=None,
         )
@@ -616,15 +1025,17 @@
 
     with mock.patch.object(transport_class, "__init__") as patched:
         patched.return_value = None
         client = client_class(client_options=options, transport=transport_name)
         patched.assert_called_once_with(
             credentials=None,
             credentials_file="credentials.json",
-            host=client.DEFAULT_ENDPOINT,
+            host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+            ),
             scopes=None,
             client_cert_source_for_mtls=None,
             quota_project_id=None,
             client_info=transports.base.DEFAULT_CLIENT_INFO,
             always_use_jwt_access=True,
             api_audience=None,
         )
@@ -676,15 +1087,17 @@
 
     with mock.patch.object(transport_class, "__init__") as patched:
         patched.return_value = None
         client = client_class(client_options=options, transport=transport_name)
         patched.assert_called_once_with(
             credentials=None,
             credentials_file="credentials.json",
-            host=client.DEFAULT_ENDPOINT,
+            host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+            ),
             scopes=None,
             client_cert_source_for_mtls=None,
             quota_project_id=None,
             client_info=transports.base.DEFAULT_CLIENT_INFO,
             always_use_jwt_access=True,
             api_audience=None,
         )
@@ -740,15 +1153,16 @@
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/spam")
         response = client.create_data_scan(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == datascans.CreateDataScanRequest()
+        request = datascans.CreateDataScanRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 def test_create_data_scan_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
@@ -756,20 +1170,165 @@
     client = DataScanServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.create_data_scan), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.create_data_scan()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == datascans.CreateDataScanRequest()
 
 
+def test_create_data_scan_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = DataScanServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = datascans.CreateDataScanRequest(
+        parent="parent_value",
+        data_scan_id="data_scan_id_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.create_data_scan), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.create_data_scan(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == datascans.CreateDataScanRequest(
+            parent="parent_value",
+            data_scan_id="data_scan_id_value",
+        )
+
+
+def test_create_data_scan_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = DataScanServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.create_data_scan in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.create_data_scan
+        ] = mock_rpc
+        request = {}
+        client.create_data_scan(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        client.create_data_scan(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_create_data_scan_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = DataScanServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.create_data_scan), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        response = await client.create_data_scan()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == datascans.CreateDataScanRequest()
+
+
+@pytest.mark.asyncio
+async def test_create_data_scan_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = DataScanServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.create_data_scan
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.create_data_scan
+        ] = mock_object
+
+        request = {}
+        await client.create_data_scan(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        await client.create_data_scan(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_create_data_scan_async(
     transport: str = "grpc_asyncio", request_type=datascans.CreateDataScanRequest
 ):
     client = DataScanServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
@@ -786,15 +1345,16 @@
             operations_pb2.Operation(name="operations/spam")
         )
         response = await client.create_data_scan(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == datascans.CreateDataScanRequest()
+        request = datascans.CreateDataScanRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 @pytest.mark.asyncio
 async def test_create_data_scan_async_from_dict():
@@ -986,15 +1546,16 @@
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/spam")
         response = client.update_data_scan(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == datascans.UpdateDataScanRequest()
+        request = datascans.UpdateDataScanRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 def test_update_data_scan_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
@@ -1002,20 +1563,159 @@
     client = DataScanServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.update_data_scan), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.update_data_scan()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == datascans.UpdateDataScanRequest()
 
 
+def test_update_data_scan_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = DataScanServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = datascans.UpdateDataScanRequest()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.update_data_scan), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.update_data_scan(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == datascans.UpdateDataScanRequest()
+
+
+def test_update_data_scan_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = DataScanServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.update_data_scan in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.update_data_scan
+        ] = mock_rpc
+        request = {}
+        client.update_data_scan(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        client.update_data_scan(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_update_data_scan_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = DataScanServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.update_data_scan), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        response = await client.update_data_scan()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == datascans.UpdateDataScanRequest()
+
+
+@pytest.mark.asyncio
+async def test_update_data_scan_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = DataScanServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.update_data_scan
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.update_data_scan
+        ] = mock_object
+
+        request = {}
+        await client.update_data_scan(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        await client.update_data_scan(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_update_data_scan_async(
     transport: str = "grpc_asyncio", request_type=datascans.UpdateDataScanRequest
 ):
     client = DataScanServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
@@ -1032,15 +1732,16 @@
             operations_pb2.Operation(name="operations/spam")
         )
         response = await client.update_data_scan(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == datascans.UpdateDataScanRequest()
+        request = datascans.UpdateDataScanRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 @pytest.mark.asyncio
 async def test_update_data_scan_async_from_dict():
@@ -1222,15 +1923,16 @@
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/spam")
         response = client.delete_data_scan(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == datascans.DeleteDataScanRequest()
+        request = datascans.DeleteDataScanRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 def test_delete_data_scan_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
@@ -1238,20 +1940,163 @@
     client = DataScanServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.delete_data_scan), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.delete_data_scan()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == datascans.DeleteDataScanRequest()
 
 
+def test_delete_data_scan_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = DataScanServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = datascans.DeleteDataScanRequest(
+        name="name_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.delete_data_scan), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.delete_data_scan(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == datascans.DeleteDataScanRequest(
+            name="name_value",
+        )
+
+
+def test_delete_data_scan_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = DataScanServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.delete_data_scan in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.delete_data_scan
+        ] = mock_rpc
+        request = {}
+        client.delete_data_scan(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        client.delete_data_scan(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_delete_data_scan_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = DataScanServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.delete_data_scan), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        response = await client.delete_data_scan()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == datascans.DeleteDataScanRequest()
+
+
+@pytest.mark.asyncio
+async def test_delete_data_scan_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = DataScanServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.delete_data_scan
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.delete_data_scan
+        ] = mock_object
+
+        request = {}
+        await client.delete_data_scan(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        await client.delete_data_scan(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_delete_data_scan_async(
     transport: str = "grpc_asyncio", request_type=datascans.DeleteDataScanRequest
 ):
     client = DataScanServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
@@ -1268,15 +2113,16 @@
             operations_pb2.Operation(name="operations/spam")
         )
         response = await client.delete_data_scan(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == datascans.DeleteDataScanRequest()
+        request = datascans.DeleteDataScanRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 @pytest.mark.asyncio
 async def test_delete_data_scan_async_from_dict():
@@ -1455,15 +2301,16 @@
             type_=datascans.DataScanType.DATA_QUALITY,
         )
         response = client.get_data_scan(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == datascans.GetDataScanRequest()
+        request = datascans.GetDataScanRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, datascans.DataScan)
     assert response.name == "name_value"
     assert response.uid == "uid_value"
     assert response.description == "description_value"
     assert response.display_name == "display_name_value"
@@ -1477,20 +2324,160 @@
     client = DataScanServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.get_data_scan), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.get_data_scan()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == datascans.GetDataScanRequest()
 
 
+def test_get_data_scan_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = DataScanServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = datascans.GetDataScanRequest(
+        name="name_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_data_scan), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.get_data_scan(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == datascans.GetDataScanRequest(
+            name="name_value",
+        )
+
+
+def test_get_data_scan_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = DataScanServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.get_data_scan in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[client._transport.get_data_scan] = mock_rpc
+        request = {}
+        client.get_data_scan(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.get_data_scan(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_get_data_scan_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = DataScanServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_data_scan), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            datascans.DataScan(
+                name="name_value",
+                uid="uid_value",
+                description="description_value",
+                display_name="display_name_value",
+                state=resources.State.ACTIVE,
+                type_=datascans.DataScanType.DATA_QUALITY,
+            )
+        )
+        response = await client.get_data_scan()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == datascans.GetDataScanRequest()
+
+
+@pytest.mark.asyncio
+async def test_get_data_scan_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = DataScanServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.get_data_scan
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.get_data_scan
+        ] = mock_object
+
+        request = {}
+        await client.get_data_scan(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.get_data_scan(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_get_data_scan_async(
     transport: str = "grpc_asyncio", request_type=datascans.GetDataScanRequest
 ):
     client = DataScanServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
@@ -1514,15 +2501,16 @@
             )
         )
         response = await client.get_data_scan(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == datascans.GetDataScanRequest()
+        request = datascans.GetDataScanRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, datascans.DataScan)
     assert response.name == "name_value"
     assert response.uid == "uid_value"
     assert response.description == "description_value"
     assert response.display_name == "display_name_value"
@@ -1699,15 +2687,16 @@
             unreachable=["unreachable_value"],
         )
         response = client.list_data_scans(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == datascans.ListDataScansRequest()
+        request = datascans.ListDataScansRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, pagers.ListDataScansPager)
     assert response.next_page_token == "next_page_token_value"
     assert response.unreachable == ["unreachable_value"]
 
 
@@ -1717,20 +2706,162 @@
     client = DataScanServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.list_data_scans), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.list_data_scans()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == datascans.ListDataScansRequest()
 
 
+def test_list_data_scans_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = DataScanServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = datascans.ListDataScansRequest(
+        parent="parent_value",
+        page_token="page_token_value",
+        filter="filter_value",
+        order_by="order_by_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_data_scans), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.list_data_scans(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == datascans.ListDataScansRequest(
+            parent="parent_value",
+            page_token="page_token_value",
+            filter="filter_value",
+            order_by="order_by_value",
+        )
+
+
+def test_list_data_scans_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = DataScanServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.list_data_scans in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[client._transport.list_data_scans] = mock_rpc
+        request = {}
+        client.list_data_scans(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.list_data_scans(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_list_data_scans_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = DataScanServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_data_scans), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            datascans.ListDataScansResponse(
+                next_page_token="next_page_token_value",
+                unreachable=["unreachable_value"],
+            )
+        )
+        response = await client.list_data_scans()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == datascans.ListDataScansRequest()
+
+
+@pytest.mark.asyncio
+async def test_list_data_scans_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = DataScanServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.list_data_scans
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.list_data_scans
+        ] = mock_object
+
+        request = {}
+        await client.list_data_scans(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.list_data_scans(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_list_data_scans_async(
     transport: str = "grpc_asyncio", request_type=datascans.ListDataScansRequest
 ):
     client = DataScanServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
@@ -1750,15 +2881,16 @@
             )
         )
         response = await client.list_data_scans(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == datascans.ListDataScansRequest()
+        request = datascans.ListDataScansRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, pagers.ListDataScansAsyncPager)
     assert response.next_page_token == "next_page_token_value"
     assert response.unreachable == ["unreachable_value"]
 
 
@@ -1908,15 +3040,15 @@
             datascans.ListDataScansRequest(),
             parent="parent_value",
         )
 
 
 def test_list_data_scans_pager(transport_name: str = "grpc"):
     client = DataScanServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
         transport=transport_name,
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.list_data_scans), "__call__") as call:
         # Set the response to a series of pages.
         call.side_effect = (
@@ -1958,15 +3090,15 @@
         results = list(pager)
         assert len(results) == 6
         assert all(isinstance(i, datascans.DataScan) for i in results)
 
 
 def test_list_data_scans_pages(transport_name: str = "grpc"):
     client = DataScanServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
         transport=transport_name,
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.list_data_scans), "__call__") as call:
         # Set the response to a series of pages.
         call.side_effect = (
@@ -2000,15 +3132,15 @@
         for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
             assert page_.raw_page.next_page_token == token
 
 
 @pytest.mark.asyncio
 async def test_list_data_scans_async_pager():
     client = DataScanServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.list_data_scans), "__call__", new_callable=mock.AsyncMock
     ) as call:
         # Set the response to a series of pages.
@@ -2050,15 +3182,15 @@
         assert len(responses) == 6
         assert all(isinstance(i, datascans.DataScan) for i in responses)
 
 
 @pytest.mark.asyncio
 async def test_list_data_scans_async_pages():
     client = DataScanServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.list_data_scans), "__call__", new_callable=mock.AsyncMock
     ) as call:
         # Set the response to a series of pages.
@@ -2122,15 +3254,16 @@
         # Designate an appropriate return value for the call.
         call.return_value = datascans.RunDataScanResponse()
         response = client.run_data_scan(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == datascans.RunDataScanRequest()
+        request = datascans.RunDataScanRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, datascans.RunDataScanResponse)
 
 
 def test_run_data_scan_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
@@ -2138,20 +3271,153 @@
     client = DataScanServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.run_data_scan), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.run_data_scan()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == datascans.RunDataScanRequest()
 
 
+def test_run_data_scan_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = DataScanServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = datascans.RunDataScanRequest(
+        name="name_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.run_data_scan), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.run_data_scan(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == datascans.RunDataScanRequest(
+            name="name_value",
+        )
+
+
+def test_run_data_scan_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = DataScanServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.run_data_scan in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[client._transport.run_data_scan] = mock_rpc
+        request = {}
+        client.run_data_scan(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.run_data_scan(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_run_data_scan_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = DataScanServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.run_data_scan), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            datascans.RunDataScanResponse()
+        )
+        response = await client.run_data_scan()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == datascans.RunDataScanRequest()
+
+
+@pytest.mark.asyncio
+async def test_run_data_scan_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = DataScanServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.run_data_scan
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.run_data_scan
+        ] = mock_object
+
+        request = {}
+        await client.run_data_scan(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.run_data_scan(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_run_data_scan_async(
     transport: str = "grpc_asyncio", request_type=datascans.RunDataScanRequest
 ):
     client = DataScanServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
@@ -2168,15 +3434,16 @@
             datascans.RunDataScanResponse()
         )
         response = await client.run_data_scan(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == datascans.RunDataScanRequest()
+        request = datascans.RunDataScanRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, datascans.RunDataScanResponse)
 
 
 @pytest.mark.asyncio
 async def test_run_data_scan_async_from_dict():
@@ -2356,15 +3623,16 @@
             type_=datascans.DataScanType.DATA_QUALITY,
         )
         response = client.get_data_scan_job(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == datascans.GetDataScanJobRequest()
+        request = datascans.GetDataScanJobRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, datascans.DataScanJob)
     assert response.name == "name_value"
     assert response.uid == "uid_value"
     assert response.state == datascans.DataScanJob.State.RUNNING
     assert response.message == "message_value"
@@ -2379,20 +3647,165 @@
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.get_data_scan_job), "__call__"
     ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.get_data_scan_job()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == datascans.GetDataScanJobRequest()
 
 
+def test_get_data_scan_job_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = DataScanServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = datascans.GetDataScanJobRequest(
+        name="name_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.get_data_scan_job), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.get_data_scan_job(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == datascans.GetDataScanJobRequest(
+            name="name_value",
+        )
+
+
+def test_get_data_scan_job_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = DataScanServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.get_data_scan_job in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.get_data_scan_job
+        ] = mock_rpc
+        request = {}
+        client.get_data_scan_job(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.get_data_scan_job(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_get_data_scan_job_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = DataScanServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.get_data_scan_job), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            datascans.DataScanJob(
+                name="name_value",
+                uid="uid_value",
+                state=datascans.DataScanJob.State.RUNNING,
+                message="message_value",
+                type_=datascans.DataScanType.DATA_QUALITY,
+            )
+        )
+        response = await client.get_data_scan_job()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == datascans.GetDataScanJobRequest()
+
+
+@pytest.mark.asyncio
+async def test_get_data_scan_job_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = DataScanServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.get_data_scan_job
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.get_data_scan_job
+        ] = mock_object
+
+        request = {}
+        await client.get_data_scan_job(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.get_data_scan_job(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_get_data_scan_job_async(
     transport: str = "grpc_asyncio", request_type=datascans.GetDataScanJobRequest
 ):
     client = DataScanServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
@@ -2417,15 +3830,16 @@
             )
         )
         response = await client.get_data_scan_job(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == datascans.GetDataScanJobRequest()
+        request = datascans.GetDataScanJobRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, datascans.DataScanJob)
     assert response.name == "name_value"
     assert response.uid == "uid_value"
     assert response.state == datascans.DataScanJob.State.RUNNING
     assert response.message == "message_value"
@@ -2614,15 +4028,16 @@
             next_page_token="next_page_token_value",
         )
         response = client.list_data_scan_jobs(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == datascans.ListDataScanJobsRequest()
+        request = datascans.ListDataScanJobsRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, pagers.ListDataScanJobsPager)
     assert response.next_page_token == "next_page_token_value"
 
 
 def test_list_data_scan_jobs_empty_call():
@@ -2633,20 +4048,167 @@
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.list_data_scan_jobs), "__call__"
     ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.list_data_scan_jobs()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == datascans.ListDataScanJobsRequest()
 
 
+def test_list_data_scan_jobs_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = DataScanServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = datascans.ListDataScanJobsRequest(
+        parent="parent_value",
+        page_token="page_token_value",
+        filter="filter_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.list_data_scan_jobs), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.list_data_scan_jobs(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == datascans.ListDataScanJobsRequest(
+            parent="parent_value",
+            page_token="page_token_value",
+            filter="filter_value",
+        )
+
+
+def test_list_data_scan_jobs_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = DataScanServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._transport.list_data_scan_jobs in client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.list_data_scan_jobs
+        ] = mock_rpc
+        request = {}
+        client.list_data_scan_jobs(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.list_data_scan_jobs(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_list_data_scan_jobs_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = DataScanServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.list_data_scan_jobs), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            datascans.ListDataScanJobsResponse(
+                next_page_token="next_page_token_value",
+            )
+        )
+        response = await client.list_data_scan_jobs()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == datascans.ListDataScanJobsRequest()
+
+
+@pytest.mark.asyncio
+async def test_list_data_scan_jobs_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = DataScanServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.list_data_scan_jobs
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.list_data_scan_jobs
+        ] = mock_object
+
+        request = {}
+        await client.list_data_scan_jobs(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.list_data_scan_jobs(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_list_data_scan_jobs_async(
     transport: str = "grpc_asyncio", request_type=datascans.ListDataScanJobsRequest
 ):
     client = DataScanServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
@@ -2667,15 +4229,16 @@
             )
         )
         response = await client.list_data_scan_jobs(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == datascans.ListDataScanJobsRequest()
+        request = datascans.ListDataScanJobsRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, pagers.ListDataScanJobsAsyncPager)
     assert response.next_page_token == "next_page_token_value"
 
 
 @pytest.mark.asyncio
@@ -2832,15 +4395,15 @@
             datascans.ListDataScanJobsRequest(),
             parent="parent_value",
         )
 
 
 def test_list_data_scan_jobs_pager(transport_name: str = "grpc"):
     client = DataScanServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
         transport=transport_name,
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.list_data_scan_jobs), "__call__"
     ) as call:
@@ -2884,15 +4447,15 @@
         results = list(pager)
         assert len(results) == 6
         assert all(isinstance(i, datascans.DataScanJob) for i in results)
 
 
 def test_list_data_scan_jobs_pages(transport_name: str = "grpc"):
     client = DataScanServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
         transport=transport_name,
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.list_data_scan_jobs), "__call__"
     ) as call:
@@ -2928,15 +4491,15 @@
         for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
             assert page_.raw_page.next_page_token == token
 
 
 @pytest.mark.asyncio
 async def test_list_data_scan_jobs_async_pager():
     client = DataScanServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.list_data_scan_jobs),
         "__call__",
         new_callable=mock.AsyncMock,
@@ -2980,15 +4543,15 @@
         assert len(responses) == 6
         assert all(isinstance(i, datascans.DataScanJob) for i in responses)
 
 
 @pytest.mark.asyncio
 async def test_list_data_scan_jobs_async_pages():
     client = DataScanServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.list_data_scan_jobs),
         "__call__",
         new_callable=mock.AsyncMock,
@@ -3028,14 +4591,399 @@
             await client.list_data_scan_jobs(request={})
         ).pages:
             pages.append(page_)
         for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
             assert page_.raw_page.next_page_token == token
 
 
+@pytest.mark.parametrize(
+    "request_type",
+    [
+        datascans.GenerateDataQualityRulesRequest,
+        dict,
+    ],
+)
+def test_generate_data_quality_rules(request_type, transport: str = "grpc"):
+    client = DataScanServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.generate_data_quality_rules), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = datascans.GenerateDataQualityRulesResponse()
+        response = client.generate_data_quality_rules(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        request = datascans.GenerateDataQualityRulesRequest()
+        assert args[0] == request
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, datascans.GenerateDataQualityRulesResponse)
+
+
+def test_generate_data_quality_rules_empty_call():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = DataScanServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.generate_data_quality_rules), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.generate_data_quality_rules()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == datascans.GenerateDataQualityRulesRequest()
+
+
+def test_generate_data_quality_rules_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = DataScanServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = datascans.GenerateDataQualityRulesRequest(
+        name="name_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.generate_data_quality_rules), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.generate_data_quality_rules(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == datascans.GenerateDataQualityRulesRequest(
+            name="name_value",
+        )
+
+
+def test_generate_data_quality_rules_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = DataScanServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._transport.generate_data_quality_rules
+            in client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.generate_data_quality_rules
+        ] = mock_rpc
+        request = {}
+        client.generate_data_quality_rules(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.generate_data_quality_rules(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_generate_data_quality_rules_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = DataScanServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.generate_data_quality_rules), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            datascans.GenerateDataQualityRulesResponse()
+        )
+        response = await client.generate_data_quality_rules()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == datascans.GenerateDataQualityRulesRequest()
+
+
+@pytest.mark.asyncio
+async def test_generate_data_quality_rules_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = DataScanServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.generate_data_quality_rules
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.generate_data_quality_rules
+        ] = mock_object
+
+        request = {}
+        await client.generate_data_quality_rules(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.generate_data_quality_rules(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_generate_data_quality_rules_async(
+    transport: str = "grpc_asyncio",
+    request_type=datascans.GenerateDataQualityRulesRequest,
+):
+    client = DataScanServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport=transport,
+    )
+
+    # Everything is optional in proto3 as far as the runtime is concerned,
+    # and we are mocking out the actual API, so just send an empty request.
+    request = request_type()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.generate_data_quality_rules), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            datascans.GenerateDataQualityRulesResponse()
+        )
+        response = await client.generate_data_quality_rules(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        request = datascans.GenerateDataQualityRulesRequest()
+        assert args[0] == request
+
+    # Establish that the response is the type that we expect.
+    assert isinstance(response, datascans.GenerateDataQualityRulesResponse)
+
+
+@pytest.mark.asyncio
+async def test_generate_data_quality_rules_async_from_dict():
+    await test_generate_data_quality_rules_async(request_type=dict)
+
+
+def test_generate_data_quality_rules_field_headers():
+    client = DataScanServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = datascans.GenerateDataQualityRulesRequest()
+
+    request.name = "name_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.generate_data_quality_rules), "__call__"
+    ) as call:
+        call.return_value = datascans.GenerateDataQualityRulesResponse()
+        client.generate_data_quality_rules(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "name=name_value",
+    ) in kw["metadata"]
+
+
+@pytest.mark.asyncio
+async def test_generate_data_quality_rules_field_headers_async():
+    client = DataScanServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Any value that is part of the HTTP/1.1 URI should be sent as
+    # a field header. Set these to a non-empty value.
+    request = datascans.GenerateDataQualityRulesRequest()
+
+    request.name = "name_value"
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.generate_data_quality_rules), "__call__"
+    ) as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            datascans.GenerateDataQualityRulesResponse()
+        )
+        await client.generate_data_quality_rules(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == request
+
+    # Establish that the field header was sent.
+    _, _, kw = call.mock_calls[0]
+    assert (
+        "x-goog-request-params",
+        "name=name_value",
+    ) in kw["metadata"]
+
+
+def test_generate_data_quality_rules_flattened():
+    client = DataScanServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.generate_data_quality_rules), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = datascans.GenerateDataQualityRulesResponse()
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        client.generate_data_quality_rules(
+            name="name_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls) == 1
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].name
+        mock_val = "name_value"
+        assert arg == mock_val
+
+
+def test_generate_data_quality_rules_flattened_error():
+    client = DataScanServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        client.generate_data_quality_rules(
+            datascans.GenerateDataQualityRulesRequest(),
+            name="name_value",
+        )
+
+
+@pytest.mark.asyncio
+async def test_generate_data_quality_rules_flattened_async():
+    client = DataScanServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.generate_data_quality_rules), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = datascans.GenerateDataQualityRulesResponse()
+
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            datascans.GenerateDataQualityRulesResponse()
+        )
+        # Call the method with a truthy value for each flattened field,
+        # using the keyword arguments to the method.
+        response = await client.generate_data_quality_rules(
+            name="name_value",
+        )
+
+        # Establish that the underlying call was made with the expected
+        # request object values.
+        assert len(call.mock_calls)
+        _, args, _ = call.mock_calls[0]
+        arg = args[0].name
+        mock_val = "name_value"
+        assert arg == mock_val
+
+
+@pytest.mark.asyncio
+async def test_generate_data_quality_rules_flattened_error_async():
+    client = DataScanServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+    )
+
+    # Attempting to call a method with both a request object and flattened
+    # fields is an error.
+    with pytest.raises(ValueError):
+        await client.generate_data_quality_rules(
+            datascans.GenerateDataQualityRulesRequest(),
+            name="name_value",
+        )
+
+
 def test_credentials_transport_error():
     # It is an error to provide credentials and a transport instance.
     transport = transports.DataScanServiceGrpcTransport(
         credentials=ga_credentials.AnonymousCredentials(),
     )
     with pytest.raises(ValueError):
         client = DataScanServiceClient(
@@ -3062,15 +5010,15 @@
     with pytest.raises(ValueError):
         client = DataScanServiceClient(
             client_options=options,
             transport=transport,
         )
 
     # It is an error to provide an api_key and a credential.
-    options = mock.Mock()
+    options = client_options.ClientOptions()
     options.api_key = "api_key"
     with pytest.raises(ValueError):
         client = DataScanServiceClient(
             client_options=options, credentials=ga_credentials.AnonymousCredentials()
         )
 
     # It is an error to provide scopes and a transport instance.
@@ -3173,14 +5121,15 @@
         "update_data_scan",
         "delete_data_scan",
         "get_data_scan",
         "list_data_scans",
         "run_data_scan",
         "get_data_scan_job",
         "list_data_scan_jobs",
+        "generate_data_quality_rules",
         "get_location",
         "list_locations",
         "get_operation",
         "cancel_operation",
         "delete_operation",
         "list_operations",
     )
@@ -3815,15 +5764,15 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert response is None
 
 
 @pytest.mark.asyncio
-async def test_delete_operation_async(transport: str = "grpc"):
+async def test_delete_operation_async(transport: str = "grpc_asyncio"):
     client = DataScanServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
@@ -3954,15 +5903,15 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert response is None
 
 
 @pytest.mark.asyncio
-async def test_cancel_operation_async(transport: str = "grpc"):
+async def test_cancel_operation_async(transport: str = "grpc_asyncio"):
     client = DataScanServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
@@ -4093,15 +6042,15 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, operations_pb2.Operation)
 
 
 @pytest.mark.asyncio
-async def test_get_operation_async(transport: str = "grpc"):
+async def test_get_operation_async(transport: str = "grpc_asyncio"):
     client = DataScanServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
@@ -4238,15 +6187,15 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, operations_pb2.ListOperationsResponse)
 
 
 @pytest.mark.asyncio
-async def test_list_operations_async(transport: str = "grpc"):
+async def test_list_operations_async(transport: str = "grpc_asyncio"):
     client = DataScanServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
@@ -4383,15 +6332,15 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, locations_pb2.ListLocationsResponse)
 
 
 @pytest.mark.asyncio
-async def test_list_locations_async(transport: str = "grpc"):
+async def test_list_locations_async(transport: str = "grpc_asyncio"):
     client = DataScanServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
@@ -4700,15 +6649,17 @@
         options.api_key = "api_key"
         with mock.patch.object(transport_class, "__init__") as patched:
             patched.return_value = None
             client = client_class(client_options=options)
             patched.assert_called_once_with(
                 credentials=mock_cred,
                 credentials_file=None,
-                host=client.DEFAULT_ENDPOINT,
+                host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                    UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+                ),
                 scopes=None,
                 client_cert_source_for_mtls=None,
                 quota_project_id=None,
                 client_info=transports.base.DEFAULT_CLIENT_INFO,
                 always_use_jwt_access=True,
                 api_audience=None,
             )
```

### Comparing `google-cloud-dataplex-1.9.0/tests/unit/gapic/dataplex_v1/test_data_taxonomy_service.py` & `google-cloud-dataplex-2.0.0/tests/unit/gapic/dataplex_v1/test_data_taxonomy_service.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -29,15 +29,15 @@
     gapic_v1,
     grpc_helpers,
     grpc_helpers_async,
     operation,
     operations_v1,
     path_template,
 )
-from google.api_core import client_options
+from google.api_core import api_core_version, client_options
 from google.api_core import exceptions as core_exceptions
 from google.api_core import operation_async  # type: ignore
 import google.auth
 from google.auth import credentials as ga_credentials
 from google.auth.exceptions import MutualTLSChannelError
 from google.cloud.location import locations_pb2
 from google.iam.v1 import iam_policy_pb2  # type: ignore
@@ -76,14 +76,25 @@
     return (
         "foo.googleapis.com"
         if ("localhost" in client.DEFAULT_ENDPOINT)
         else client.DEFAULT_ENDPOINT
     )
 
 
+# If default endpoint template is localhost, then default mtls endpoint will be the same.
+# This method modifies the default endpoint template so the client can produce a different
+# mtls endpoint for endpoint testing purposes.
+def modify_default_endpoint_template(client):
+    return (
+        "test.{UNIVERSE_DOMAIN}"
+        if ("localhost" in client._DEFAULT_ENDPOINT_TEMPLATE)
+        else client._DEFAULT_ENDPOINT_TEMPLATE
+    )
+
+
 def test__get_default_mtls_endpoint():
     api_endpoint = "example.googleapis.com"
     api_mtls_endpoint = "example.mtls.googleapis.com"
     sandbox_endpoint = "example.sandbox.googleapis.com"
     sandbox_mtls_endpoint = "example.mtls.sandbox.googleapis.com"
     non_googleapi = "api.example.com"
 
@@ -106,14 +117,299 @@
     )
     assert (
         DataTaxonomyServiceClient._get_default_mtls_endpoint(non_googleapi)
         == non_googleapi
     )
 
 
+def test__read_environment_variables():
+    assert DataTaxonomyServiceClient._read_environment_variables() == (
+        False,
+        "auto",
+        None,
+    )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "true"}):
+        assert DataTaxonomyServiceClient._read_environment_variables() == (
+            True,
+            "auto",
+            None,
+        )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "false"}):
+        assert DataTaxonomyServiceClient._read_environment_variables() == (
+            False,
+            "auto",
+            None,
+        )
+
+    with mock.patch.dict(
+        os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "Unsupported"}
+    ):
+        with pytest.raises(ValueError) as excinfo:
+            DataTaxonomyServiceClient._read_environment_variables()
+    assert (
+        str(excinfo.value)
+        == "Environment variable `GOOGLE_API_USE_CLIENT_CERTIFICATE` must be either `true` or `false`"
+    )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "never"}):
+        assert DataTaxonomyServiceClient._read_environment_variables() == (
+            False,
+            "never",
+            None,
+        )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "always"}):
+        assert DataTaxonomyServiceClient._read_environment_variables() == (
+            False,
+            "always",
+            None,
+        )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "auto"}):
+        assert DataTaxonomyServiceClient._read_environment_variables() == (
+            False,
+            "auto",
+            None,
+        )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "Unsupported"}):
+        with pytest.raises(MutualTLSChannelError) as excinfo:
+            DataTaxonomyServiceClient._read_environment_variables()
+    assert (
+        str(excinfo.value)
+        == "Environment variable `GOOGLE_API_USE_MTLS_ENDPOINT` must be `never`, `auto` or `always`"
+    )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_CLOUD_UNIVERSE_DOMAIN": "foo.com"}):
+        assert DataTaxonomyServiceClient._read_environment_variables() == (
+            False,
+            "auto",
+            "foo.com",
+        )
+
+
+def test__get_client_cert_source():
+    mock_provided_cert_source = mock.Mock()
+    mock_default_cert_source = mock.Mock()
+
+    assert DataTaxonomyServiceClient._get_client_cert_source(None, False) is None
+    assert (
+        DataTaxonomyServiceClient._get_client_cert_source(
+            mock_provided_cert_source, False
+        )
+        is None
+    )
+    assert (
+        DataTaxonomyServiceClient._get_client_cert_source(
+            mock_provided_cert_source, True
+        )
+        == mock_provided_cert_source
+    )
+
+    with mock.patch(
+        "google.auth.transport.mtls.has_default_client_cert_source", return_value=True
+    ):
+        with mock.patch(
+            "google.auth.transport.mtls.default_client_cert_source",
+            return_value=mock_default_cert_source,
+        ):
+            assert (
+                DataTaxonomyServiceClient._get_client_cert_source(None, True)
+                is mock_default_cert_source
+            )
+            assert (
+                DataTaxonomyServiceClient._get_client_cert_source(
+                    mock_provided_cert_source, "true"
+                )
+                is mock_provided_cert_source
+            )
+
+
+@mock.patch.object(
+    DataTaxonomyServiceClient,
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(DataTaxonomyServiceClient),
+)
+@mock.patch.object(
+    DataTaxonomyServiceAsyncClient,
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(DataTaxonomyServiceAsyncClient),
+)
+def test__get_api_endpoint():
+    api_override = "foo.com"
+    mock_client_cert_source = mock.Mock()
+    default_universe = DataTaxonomyServiceClient._DEFAULT_UNIVERSE
+    default_endpoint = DataTaxonomyServiceClient._DEFAULT_ENDPOINT_TEMPLATE.format(
+        UNIVERSE_DOMAIN=default_universe
+    )
+    mock_universe = "bar.com"
+    mock_endpoint = DataTaxonomyServiceClient._DEFAULT_ENDPOINT_TEMPLATE.format(
+        UNIVERSE_DOMAIN=mock_universe
+    )
+
+    assert (
+        DataTaxonomyServiceClient._get_api_endpoint(
+            api_override, mock_client_cert_source, default_universe, "always"
+        )
+        == api_override
+    )
+    assert (
+        DataTaxonomyServiceClient._get_api_endpoint(
+            None, mock_client_cert_source, default_universe, "auto"
+        )
+        == DataTaxonomyServiceClient.DEFAULT_MTLS_ENDPOINT
+    )
+    assert (
+        DataTaxonomyServiceClient._get_api_endpoint(
+            None, None, default_universe, "auto"
+        )
+        == default_endpoint
+    )
+    assert (
+        DataTaxonomyServiceClient._get_api_endpoint(
+            None, None, default_universe, "always"
+        )
+        == DataTaxonomyServiceClient.DEFAULT_MTLS_ENDPOINT
+    )
+    assert (
+        DataTaxonomyServiceClient._get_api_endpoint(
+            None, mock_client_cert_source, default_universe, "always"
+        )
+        == DataTaxonomyServiceClient.DEFAULT_MTLS_ENDPOINT
+    )
+    assert (
+        DataTaxonomyServiceClient._get_api_endpoint(None, None, mock_universe, "never")
+        == mock_endpoint
+    )
+    assert (
+        DataTaxonomyServiceClient._get_api_endpoint(
+            None, None, default_universe, "never"
+        )
+        == default_endpoint
+    )
+
+    with pytest.raises(MutualTLSChannelError) as excinfo:
+        DataTaxonomyServiceClient._get_api_endpoint(
+            None, mock_client_cert_source, mock_universe, "auto"
+        )
+    assert (
+        str(excinfo.value)
+        == "mTLS is not supported in any universe other than googleapis.com."
+    )
+
+
+def test__get_universe_domain():
+    client_universe_domain = "foo.com"
+    universe_domain_env = "bar.com"
+
+    assert (
+        DataTaxonomyServiceClient._get_universe_domain(
+            client_universe_domain, universe_domain_env
+        )
+        == client_universe_domain
+    )
+    assert (
+        DataTaxonomyServiceClient._get_universe_domain(None, universe_domain_env)
+        == universe_domain_env
+    )
+    assert (
+        DataTaxonomyServiceClient._get_universe_domain(None, None)
+        == DataTaxonomyServiceClient._DEFAULT_UNIVERSE
+    )
+
+    with pytest.raises(ValueError) as excinfo:
+        DataTaxonomyServiceClient._get_universe_domain("", None)
+    assert str(excinfo.value) == "Universe Domain cannot be an empty string."
+
+
+@pytest.mark.parametrize(
+    "client_class,transport_class,transport_name",
+    [
+        (
+            DataTaxonomyServiceClient,
+            transports.DataTaxonomyServiceGrpcTransport,
+            "grpc",
+        ),
+    ],
+)
+def test__validate_universe_domain(client_class, transport_class, transport_name):
+    client = client_class(
+        transport=transport_class(credentials=ga_credentials.AnonymousCredentials())
+    )
+    assert client._validate_universe_domain() == True
+
+    # Test the case when universe is already validated.
+    assert client._validate_universe_domain() == True
+
+    if transport_name == "grpc":
+        # Test the case where credentials are provided by the
+        # `local_channel_credentials`. The default universes in both match.
+        channel = grpc.secure_channel(
+            "http://localhost/", grpc.local_channel_credentials()
+        )
+        client = client_class(transport=transport_class(channel=channel))
+        assert client._validate_universe_domain() == True
+
+        # Test the case where credentials do not exist: e.g. a transport is provided
+        # with no credentials. Validation should still succeed because there is no
+        # mismatch with non-existent credentials.
+        channel = grpc.secure_channel(
+            "http://localhost/", grpc.local_channel_credentials()
+        )
+        transport = transport_class(channel=channel)
+        transport._credentials = None
+        client = client_class(transport=transport)
+        assert client._validate_universe_domain() == True
+
+    # TODO: This is needed to cater for older versions of google-auth
+    # Make this test unconditional once the minimum supported version of
+    # google-auth becomes 2.23.0 or higher.
+    google_auth_major, google_auth_minor = [
+        int(part) for part in google.auth.__version__.split(".")[0:2]
+    ]
+    if google_auth_major > 2 or (google_auth_major == 2 and google_auth_minor >= 23):
+        credentials = ga_credentials.AnonymousCredentials()
+        credentials._universe_domain = "foo.com"
+        # Test the case when there is a universe mismatch from the credentials.
+        client = client_class(transport=transport_class(credentials=credentials))
+        with pytest.raises(ValueError) as excinfo:
+            client._validate_universe_domain()
+        assert (
+            str(excinfo.value)
+            == "The configured universe domain (googleapis.com) does not match the universe domain found in the credentials (foo.com). If you haven't configured the universe domain explicitly, `googleapis.com` is the default."
+        )
+
+        # Test the case when there is a universe mismatch from the client.
+        #
+        # TODO: Make this test unconditional once the minimum supported version of
+        # google-api-core becomes 2.15.0 or higher.
+        api_core_major, api_core_minor = [
+            int(part) for part in api_core_version.__version__.split(".")[0:2]
+        ]
+        if api_core_major > 2 or (api_core_major == 2 and api_core_minor >= 15):
+            client = client_class(
+                client_options={"universe_domain": "bar.com"},
+                transport=transport_class(
+                    credentials=ga_credentials.AnonymousCredentials(),
+                ),
+            )
+            with pytest.raises(ValueError) as excinfo:
+                client._validate_universe_domain()
+            assert (
+                str(excinfo.value)
+                == "The configured universe domain (bar.com) does not match the universe domain found in the credentials (googleapis.com). If you haven't configured the universe domain explicitly, `googleapis.com` is the default."
+            )
+
+    # Test that ValueError is raised if universe_domain is provided via client options and credentials is None
+    with pytest.raises(ValueError):
+        client._compare_universes("foo.bar", None)
+
+
 @pytest.mark.parametrize(
     "client_class,transport_name",
     [
         (DataTaxonomyServiceClient, "grpc"),
         (DataTaxonomyServiceAsyncClient, "grpc_asyncio"),
     ],
 )
@@ -212,21 +508,21 @@
             transports.DataTaxonomyServiceGrpcAsyncIOTransport,
             "grpc_asyncio",
         ),
     ],
 )
 @mock.patch.object(
     DataTaxonomyServiceClient,
-    "DEFAULT_ENDPOINT",
-    modify_default_endpoint(DataTaxonomyServiceClient),
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(DataTaxonomyServiceClient),
 )
 @mock.patch.object(
     DataTaxonomyServiceAsyncClient,
-    "DEFAULT_ENDPOINT",
-    modify_default_endpoint(DataTaxonomyServiceAsyncClient),
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(DataTaxonomyServiceAsyncClient),
 )
 def test_data_taxonomy_service_client_client_options(
     client_class, transport_class, transport_name
 ):
     # Check that if channel is provided we won't create a new one.
     with mock.patch.object(DataTaxonomyServiceClient, "get_transport_class") as gtc:
         transport = transport_class(credentials=ga_credentials.AnonymousCredentials())
@@ -260,15 +556,17 @@
     with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "never"}):
         with mock.patch.object(transport_class, "__init__") as patched:
             patched.return_value = None
             client = client_class(transport=transport_name)
             patched.assert_called_once_with(
                 credentials=None,
                 credentials_file=None,
-                host=client.DEFAULT_ENDPOINT,
+                host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                    UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+                ),
                 scopes=None,
                 client_cert_source_for_mtls=None,
                 quota_project_id=None,
                 client_info=transports.base.DEFAULT_CLIENT_INFO,
                 always_use_jwt_access=True,
                 api_audience=None,
             )
@@ -290,33 +588,43 @@
                 always_use_jwt_access=True,
                 api_audience=None,
             )
 
     # Check the case api_endpoint is not provided and GOOGLE_API_USE_MTLS_ENDPOINT has
     # unsupported value.
     with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "Unsupported"}):
-        with pytest.raises(MutualTLSChannelError):
+        with pytest.raises(MutualTLSChannelError) as excinfo:
             client = client_class(transport=transport_name)
+    assert (
+        str(excinfo.value)
+        == "Environment variable `GOOGLE_API_USE_MTLS_ENDPOINT` must be `never`, `auto` or `always`"
+    )
 
     # Check the case GOOGLE_API_USE_CLIENT_CERTIFICATE has unsupported value.
     with mock.patch.dict(
         os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "Unsupported"}
     ):
-        with pytest.raises(ValueError):
+        with pytest.raises(ValueError) as excinfo:
             client = client_class(transport=transport_name)
+    assert (
+        str(excinfo.value)
+        == "Environment variable `GOOGLE_API_USE_CLIENT_CERTIFICATE` must be either `true` or `false`"
+    )
 
     # Check the case quota_project_id is provided
     options = client_options.ClientOptions(quota_project_id="octopus")
     with mock.patch.object(transport_class, "__init__") as patched:
         patched.return_value = None
         client = client_class(client_options=options, transport=transport_name)
         patched.assert_called_once_with(
             credentials=None,
             credentials_file=None,
-            host=client.DEFAULT_ENDPOINT,
+            host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+            ),
             scopes=None,
             client_cert_source_for_mtls=None,
             quota_project_id="octopus",
             client_info=transports.base.DEFAULT_CLIENT_INFO,
             always_use_jwt_access=True,
             api_audience=None,
         )
@@ -326,15 +634,17 @@
     )
     with mock.patch.object(transport_class, "__init__") as patched:
         patched.return_value = None
         client = client_class(client_options=options, transport=transport_name)
         patched.assert_called_once_with(
             credentials=None,
             credentials_file=None,
-            host=client.DEFAULT_ENDPOINT,
+            host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+            ),
             scopes=None,
             client_cert_source_for_mtls=None,
             quota_project_id=None,
             client_info=transports.base.DEFAULT_CLIENT_INFO,
             always_use_jwt_access=True,
             api_audience="https://language.googleapis.com",
         )
@@ -367,21 +677,21 @@
             "grpc_asyncio",
             "false",
         ),
     ],
 )
 @mock.patch.object(
     DataTaxonomyServiceClient,
-    "DEFAULT_ENDPOINT",
-    modify_default_endpoint(DataTaxonomyServiceClient),
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(DataTaxonomyServiceClient),
 )
 @mock.patch.object(
     DataTaxonomyServiceAsyncClient,
-    "DEFAULT_ENDPOINT",
-    modify_default_endpoint(DataTaxonomyServiceAsyncClient),
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(DataTaxonomyServiceAsyncClient),
 )
 @mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "auto"})
 def test_data_taxonomy_service_client_mtls_env_auto(
     client_class, transport_class, transport_name, use_client_cert_env
 ):
     # This tests the endpoint autoswitch behavior. Endpoint is autoswitched to the default
     # mtls endpoint, if GOOGLE_API_USE_CLIENT_CERTIFICATE is "true" and client cert exists.
@@ -396,15 +706,17 @@
         )
         with mock.patch.object(transport_class, "__init__") as patched:
             patched.return_value = None
             client = client_class(client_options=options, transport=transport_name)
 
             if use_client_cert_env == "false":
                 expected_client_cert_source = None
-                expected_host = client.DEFAULT_ENDPOINT
+                expected_host = client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                    UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+                )
             else:
                 expected_client_cert_source = client_cert_source_callback
                 expected_host = client.DEFAULT_MTLS_ENDPOINT
 
             patched.assert_called_once_with(
                 credentials=None,
                 credentials_file=None,
@@ -428,15 +740,17 @@
                 return_value=True,
             ):
                 with mock.patch(
                     "google.auth.transport.mtls.default_client_cert_source",
                     return_value=client_cert_source_callback,
                 ):
                     if use_client_cert_env == "false":
-                        expected_host = client.DEFAULT_ENDPOINT
+                        expected_host = client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                            UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+                        )
                         expected_client_cert_source = None
                     else:
                         expected_host = client.DEFAULT_MTLS_ENDPOINT
                         expected_client_cert_source = client_cert_source_callback
 
                     patched.return_value = None
                     client = client_class(transport=transport_name)
@@ -462,15 +776,17 @@
                 return_value=False,
             ):
                 patched.return_value = None
                 client = client_class(transport=transport_name)
                 patched.assert_called_once_with(
                     credentials=None,
                     credentials_file=None,
-                    host=client.DEFAULT_ENDPOINT,
+                    host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                        UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+                    ),
                     scopes=None,
                     client_cert_source_for_mtls=None,
                     quota_project_id=None,
                     client_info=transports.base.DEFAULT_CLIENT_INFO,
                     always_use_jwt_access=True,
                     api_audience=None,
                 )
@@ -552,14 +868,123 @@
                 (
                     api_endpoint,
                     cert_source,
                 ) = client_class.get_mtls_endpoint_and_cert_source()
                 assert api_endpoint == client_class.DEFAULT_MTLS_ENDPOINT
                 assert cert_source == mock_client_cert_source
 
+    # Check the case api_endpoint is not provided and GOOGLE_API_USE_MTLS_ENDPOINT has
+    # unsupported value.
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "Unsupported"}):
+        with pytest.raises(MutualTLSChannelError) as excinfo:
+            client_class.get_mtls_endpoint_and_cert_source()
+
+        assert (
+            str(excinfo.value)
+            == "Environment variable `GOOGLE_API_USE_MTLS_ENDPOINT` must be `never`, `auto` or `always`"
+        )
+
+    # Check the case GOOGLE_API_USE_CLIENT_CERTIFICATE has unsupported value.
+    with mock.patch.dict(
+        os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "Unsupported"}
+    ):
+        with pytest.raises(ValueError) as excinfo:
+            client_class.get_mtls_endpoint_and_cert_source()
+
+        assert (
+            str(excinfo.value)
+            == "Environment variable `GOOGLE_API_USE_CLIENT_CERTIFICATE` must be either `true` or `false`"
+        )
+
+
+@pytest.mark.parametrize(
+    "client_class", [DataTaxonomyServiceClient, DataTaxonomyServiceAsyncClient]
+)
+@mock.patch.object(
+    DataTaxonomyServiceClient,
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(DataTaxonomyServiceClient),
+)
+@mock.patch.object(
+    DataTaxonomyServiceAsyncClient,
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(DataTaxonomyServiceAsyncClient),
+)
+def test_data_taxonomy_service_client_client_api_endpoint(client_class):
+    mock_client_cert_source = client_cert_source_callback
+    api_override = "foo.com"
+    default_universe = DataTaxonomyServiceClient._DEFAULT_UNIVERSE
+    default_endpoint = DataTaxonomyServiceClient._DEFAULT_ENDPOINT_TEMPLATE.format(
+        UNIVERSE_DOMAIN=default_universe
+    )
+    mock_universe = "bar.com"
+    mock_endpoint = DataTaxonomyServiceClient._DEFAULT_ENDPOINT_TEMPLATE.format(
+        UNIVERSE_DOMAIN=mock_universe
+    )
+
+    # If ClientOptions.api_endpoint is set and GOOGLE_API_USE_CLIENT_CERTIFICATE="true",
+    # use ClientOptions.api_endpoint as the api endpoint regardless.
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "true"}):
+        with mock.patch(
+            "google.auth.transport.requests.AuthorizedSession.configure_mtls_channel"
+        ):
+            options = client_options.ClientOptions(
+                client_cert_source=mock_client_cert_source, api_endpoint=api_override
+            )
+            client = client_class(
+                client_options=options,
+                credentials=ga_credentials.AnonymousCredentials(),
+            )
+            assert client.api_endpoint == api_override
+
+    # If ClientOptions.api_endpoint is not set and GOOGLE_API_USE_MTLS_ENDPOINT="never",
+    # use the _DEFAULT_ENDPOINT_TEMPLATE populated with GDU as the api endpoint.
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "never"}):
+        client = client_class(credentials=ga_credentials.AnonymousCredentials())
+        assert client.api_endpoint == default_endpoint
+
+    # If ClientOptions.api_endpoint is not set and GOOGLE_API_USE_MTLS_ENDPOINT="always",
+    # use the DEFAULT_MTLS_ENDPOINT as the api endpoint.
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "always"}):
+        client = client_class(credentials=ga_credentials.AnonymousCredentials())
+        assert client.api_endpoint == client_class.DEFAULT_MTLS_ENDPOINT
+
+    # If ClientOptions.api_endpoint is not set, GOOGLE_API_USE_MTLS_ENDPOINT="auto" (default),
+    # GOOGLE_API_USE_CLIENT_CERTIFICATE="false" (default), default cert source doesn't exist,
+    # and ClientOptions.universe_domain="bar.com",
+    # use the _DEFAULT_ENDPOINT_TEMPLATE populated with universe domain as the api endpoint.
+    options = client_options.ClientOptions()
+    universe_exists = hasattr(options, "universe_domain")
+    if universe_exists:
+        options = client_options.ClientOptions(universe_domain=mock_universe)
+        client = client_class(
+            client_options=options, credentials=ga_credentials.AnonymousCredentials()
+        )
+    else:
+        client = client_class(
+            client_options=options, credentials=ga_credentials.AnonymousCredentials()
+        )
+    assert client.api_endpoint == (
+        mock_endpoint if universe_exists else default_endpoint
+    )
+    assert client.universe_domain == (
+        mock_universe if universe_exists else default_universe
+    )
+
+    # If ClientOptions does not have a universe domain attribute and GOOGLE_API_USE_MTLS_ENDPOINT="never",
+    # use the _DEFAULT_ENDPOINT_TEMPLATE populated with GDU as the api endpoint.
+    options = client_options.ClientOptions()
+    if hasattr(options, "universe_domain"):
+        delattr(options, "universe_domain")
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "never"}):
+        client = client_class(
+            client_options=options, credentials=ga_credentials.AnonymousCredentials()
+        )
+        assert client.api_endpoint == default_endpoint
+
 
 @pytest.mark.parametrize(
     "client_class,transport_class,transport_name",
     [
         (
             DataTaxonomyServiceClient,
             transports.DataTaxonomyServiceGrpcTransport,
@@ -581,15 +1006,17 @@
     )
     with mock.patch.object(transport_class, "__init__") as patched:
         patched.return_value = None
         client = client_class(client_options=options, transport=transport_name)
         patched.assert_called_once_with(
             credentials=None,
             credentials_file=None,
-            host=client.DEFAULT_ENDPOINT,
+            host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+            ),
             scopes=["1", "2"],
             client_cert_source_for_mtls=None,
             quota_project_id=None,
             client_info=transports.base.DEFAULT_CLIENT_INFO,
             always_use_jwt_access=True,
             api_audience=None,
         )
@@ -620,15 +1047,17 @@
 
     with mock.patch.object(transport_class, "__init__") as patched:
         patched.return_value = None
         client = client_class(client_options=options, transport=transport_name)
         patched.assert_called_once_with(
             credentials=None,
             credentials_file="credentials.json",
-            host=client.DEFAULT_ENDPOINT,
+            host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+            ),
             scopes=None,
             client_cert_source_for_mtls=None,
             quota_project_id=None,
             client_info=transports.base.DEFAULT_CLIENT_INFO,
             always_use_jwt_access=True,
             api_audience=None,
         )
@@ -680,15 +1109,17 @@
 
     with mock.patch.object(transport_class, "__init__") as patched:
         patched.return_value = None
         client = client_class(client_options=options, transport=transport_name)
         patched.assert_called_once_with(
             credentials=None,
             credentials_file="credentials.json",
-            host=client.DEFAULT_ENDPOINT,
+            host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+            ),
             scopes=None,
             client_cert_source_for_mtls=None,
             quota_project_id=None,
             client_info=transports.base.DEFAULT_CLIENT_INFO,
             always_use_jwt_access=True,
             api_audience=None,
         )
@@ -746,15 +1177,16 @@
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/spam")
         response = client.create_data_taxonomy(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == gcd_data_taxonomy.CreateDataTaxonomyRequest()
+        request = gcd_data_taxonomy.CreateDataTaxonomyRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 def test_create_data_taxonomy_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
@@ -764,20 +1196,171 @@
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.create_data_taxonomy), "__call__"
     ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.create_data_taxonomy()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == gcd_data_taxonomy.CreateDataTaxonomyRequest()
 
 
+def test_create_data_taxonomy_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = DataTaxonomyServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = gcd_data_taxonomy.CreateDataTaxonomyRequest(
+        parent="parent_value",
+        data_taxonomy_id="data_taxonomy_id_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.create_data_taxonomy), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.create_data_taxonomy(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == gcd_data_taxonomy.CreateDataTaxonomyRequest(
+            parent="parent_value",
+            data_taxonomy_id="data_taxonomy_id_value",
+        )
+
+
+def test_create_data_taxonomy_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = DataTaxonomyServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._transport.create_data_taxonomy in client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.create_data_taxonomy
+        ] = mock_rpc
+        request = {}
+        client.create_data_taxonomy(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        client.create_data_taxonomy(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_create_data_taxonomy_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = DataTaxonomyServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.create_data_taxonomy), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        response = await client.create_data_taxonomy()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == gcd_data_taxonomy.CreateDataTaxonomyRequest()
+
+
+@pytest.mark.asyncio
+async def test_create_data_taxonomy_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = DataTaxonomyServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.create_data_taxonomy
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.create_data_taxonomy
+        ] = mock_object
+
+        request = {}
+        await client.create_data_taxonomy(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        await client.create_data_taxonomy(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_create_data_taxonomy_async(
     transport: str = "grpc_asyncio",
     request_type=gcd_data_taxonomy.CreateDataTaxonomyRequest,
 ):
     client = DataTaxonomyServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -797,15 +1380,16 @@
             operations_pb2.Operation(name="operations/spam")
         )
         response = await client.create_data_taxonomy(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == gcd_data_taxonomy.CreateDataTaxonomyRequest()
+        request = gcd_data_taxonomy.CreateDataTaxonomyRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 @pytest.mark.asyncio
 async def test_create_data_taxonomy_async_from_dict():
@@ -1007,15 +1591,16 @@
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/spam")
         response = client.update_data_taxonomy(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == gcd_data_taxonomy.UpdateDataTaxonomyRequest()
+        request = gcd_data_taxonomy.UpdateDataTaxonomyRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 def test_update_data_taxonomy_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
@@ -1025,20 +1610,165 @@
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.update_data_taxonomy), "__call__"
     ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.update_data_taxonomy()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == gcd_data_taxonomy.UpdateDataTaxonomyRequest()
 
 
+def test_update_data_taxonomy_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = DataTaxonomyServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = gcd_data_taxonomy.UpdateDataTaxonomyRequest()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.update_data_taxonomy), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.update_data_taxonomy(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == gcd_data_taxonomy.UpdateDataTaxonomyRequest()
+
+
+def test_update_data_taxonomy_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = DataTaxonomyServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._transport.update_data_taxonomy in client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.update_data_taxonomy
+        ] = mock_rpc
+        request = {}
+        client.update_data_taxonomy(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        client.update_data_taxonomy(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_update_data_taxonomy_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = DataTaxonomyServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.update_data_taxonomy), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        response = await client.update_data_taxonomy()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == gcd_data_taxonomy.UpdateDataTaxonomyRequest()
+
+
+@pytest.mark.asyncio
+async def test_update_data_taxonomy_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = DataTaxonomyServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.update_data_taxonomy
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.update_data_taxonomy
+        ] = mock_object
+
+        request = {}
+        await client.update_data_taxonomy(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        await client.update_data_taxonomy(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_update_data_taxonomy_async(
     transport: str = "grpc_asyncio",
     request_type=gcd_data_taxonomy.UpdateDataTaxonomyRequest,
 ):
     client = DataTaxonomyServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -1058,15 +1788,16 @@
             operations_pb2.Operation(name="operations/spam")
         )
         response = await client.update_data_taxonomy(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == gcd_data_taxonomy.UpdateDataTaxonomyRequest()
+        request = gcd_data_taxonomy.UpdateDataTaxonomyRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 @pytest.mark.asyncio
 async def test_update_data_taxonomy_async_from_dict():
@@ -1258,15 +1989,16 @@
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/spam")
         response = client.delete_data_taxonomy(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == data_taxonomy.DeleteDataTaxonomyRequest()
+        request = data_taxonomy.DeleteDataTaxonomyRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 def test_delete_data_taxonomy_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
@@ -1276,20 +2008,171 @@
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.delete_data_taxonomy), "__call__"
     ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.delete_data_taxonomy()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == data_taxonomy.DeleteDataTaxonomyRequest()
 
 
+def test_delete_data_taxonomy_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = DataTaxonomyServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = data_taxonomy.DeleteDataTaxonomyRequest(
+        name="name_value",
+        etag="etag_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.delete_data_taxonomy), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.delete_data_taxonomy(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == data_taxonomy.DeleteDataTaxonomyRequest(
+            name="name_value",
+            etag="etag_value",
+        )
+
+
+def test_delete_data_taxonomy_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = DataTaxonomyServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._transport.delete_data_taxonomy in client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.delete_data_taxonomy
+        ] = mock_rpc
+        request = {}
+        client.delete_data_taxonomy(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        client.delete_data_taxonomy(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_delete_data_taxonomy_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = DataTaxonomyServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.delete_data_taxonomy), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        response = await client.delete_data_taxonomy()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == data_taxonomy.DeleteDataTaxonomyRequest()
+
+
+@pytest.mark.asyncio
+async def test_delete_data_taxonomy_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = DataTaxonomyServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.delete_data_taxonomy
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.delete_data_taxonomy
+        ] = mock_object
+
+        request = {}
+        await client.delete_data_taxonomy(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        await client.delete_data_taxonomy(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_delete_data_taxonomy_async(
     transport: str = "grpc_asyncio",
     request_type=data_taxonomy.DeleteDataTaxonomyRequest,
 ):
     client = DataTaxonomyServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -1309,15 +2192,16 @@
             operations_pb2.Operation(name="operations/spam")
         )
         response = await client.delete_data_taxonomy(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == data_taxonomy.DeleteDataTaxonomyRequest()
+        request = data_taxonomy.DeleteDataTaxonomyRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 @pytest.mark.asyncio
 async def test_delete_data_taxonomy_async_from_dict():
@@ -1502,15 +2386,16 @@
             unreachable_locations=["unreachable_locations_value"],
         )
         response = client.list_data_taxonomies(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == data_taxonomy.ListDataTaxonomiesRequest()
+        request = data_taxonomy.ListDataTaxonomiesRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, pagers.ListDataTaxonomiesPager)
     assert response.next_page_token == "next_page_token_value"
     assert response.unreachable_locations == ["unreachable_locations_value"]
 
 
@@ -1522,20 +2407,170 @@
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.list_data_taxonomies), "__call__"
     ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.list_data_taxonomies()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == data_taxonomy.ListDataTaxonomiesRequest()
 
 
+def test_list_data_taxonomies_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = DataTaxonomyServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = data_taxonomy.ListDataTaxonomiesRequest(
+        parent="parent_value",
+        page_token="page_token_value",
+        filter="filter_value",
+        order_by="order_by_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.list_data_taxonomies), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.list_data_taxonomies(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == data_taxonomy.ListDataTaxonomiesRequest(
+            parent="parent_value",
+            page_token="page_token_value",
+            filter="filter_value",
+            order_by="order_by_value",
+        )
+
+
+def test_list_data_taxonomies_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = DataTaxonomyServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._transport.list_data_taxonomies in client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.list_data_taxonomies
+        ] = mock_rpc
+        request = {}
+        client.list_data_taxonomies(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.list_data_taxonomies(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_list_data_taxonomies_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = DataTaxonomyServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.list_data_taxonomies), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            data_taxonomy.ListDataTaxonomiesResponse(
+                next_page_token="next_page_token_value",
+                unreachable_locations=["unreachable_locations_value"],
+            )
+        )
+        response = await client.list_data_taxonomies()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == data_taxonomy.ListDataTaxonomiesRequest()
+
+
+@pytest.mark.asyncio
+async def test_list_data_taxonomies_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = DataTaxonomyServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.list_data_taxonomies
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.list_data_taxonomies
+        ] = mock_object
+
+        request = {}
+        await client.list_data_taxonomies(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.list_data_taxonomies(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_list_data_taxonomies_async(
     transport: str = "grpc_asyncio",
     request_type=data_taxonomy.ListDataTaxonomiesRequest,
 ):
     client = DataTaxonomyServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -1558,15 +2593,16 @@
             )
         )
         response = await client.list_data_taxonomies(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == data_taxonomy.ListDataTaxonomiesRequest()
+        request = data_taxonomy.ListDataTaxonomiesRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, pagers.ListDataTaxonomiesAsyncPager)
     assert response.next_page_token == "next_page_token_value"
     assert response.unreachable_locations == ["unreachable_locations_value"]
 
 
@@ -1724,15 +2760,15 @@
             data_taxonomy.ListDataTaxonomiesRequest(),
             parent="parent_value",
         )
 
 
 def test_list_data_taxonomies_pager(transport_name: str = "grpc"):
     client = DataTaxonomyServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
         transport=transport_name,
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.list_data_taxonomies), "__call__"
     ) as call:
@@ -1776,15 +2812,15 @@
         results = list(pager)
         assert len(results) == 6
         assert all(isinstance(i, data_taxonomy.DataTaxonomy) for i in results)
 
 
 def test_list_data_taxonomies_pages(transport_name: str = "grpc"):
     client = DataTaxonomyServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
         transport=transport_name,
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.list_data_taxonomies), "__call__"
     ) as call:
@@ -1820,15 +2856,15 @@
         for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
             assert page_.raw_page.next_page_token == token
 
 
 @pytest.mark.asyncio
 async def test_list_data_taxonomies_async_pager():
     client = DataTaxonomyServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.list_data_taxonomies),
         "__call__",
         new_callable=mock.AsyncMock,
@@ -1872,15 +2908,15 @@
         assert len(responses) == 6
         assert all(isinstance(i, data_taxonomy.DataTaxonomy) for i in responses)
 
 
 @pytest.mark.asyncio
 async def test_list_data_taxonomies_async_pages():
     client = DataTaxonomyServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.list_data_taxonomies),
         "__call__",
         new_callable=mock.AsyncMock,
@@ -1956,15 +2992,16 @@
             class_count=1182,
         )
         response = client.get_data_taxonomy(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == data_taxonomy.GetDataTaxonomyRequest()
+        request = data_taxonomy.GetDataTaxonomyRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, data_taxonomy.DataTaxonomy)
     assert response.name == "name_value"
     assert response.uid == "uid_value"
     assert response.description == "description_value"
     assert response.display_name == "display_name_value"
@@ -1981,20 +3018,167 @@
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.get_data_taxonomy), "__call__"
     ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.get_data_taxonomy()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == data_taxonomy.GetDataTaxonomyRequest()
 
 
+def test_get_data_taxonomy_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = DataTaxonomyServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = data_taxonomy.GetDataTaxonomyRequest(
+        name="name_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.get_data_taxonomy), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.get_data_taxonomy(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == data_taxonomy.GetDataTaxonomyRequest(
+            name="name_value",
+        )
+
+
+def test_get_data_taxonomy_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = DataTaxonomyServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.get_data_taxonomy in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.get_data_taxonomy
+        ] = mock_rpc
+        request = {}
+        client.get_data_taxonomy(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.get_data_taxonomy(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_get_data_taxonomy_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = DataTaxonomyServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.get_data_taxonomy), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            data_taxonomy.DataTaxonomy(
+                name="name_value",
+                uid="uid_value",
+                description="description_value",
+                display_name="display_name_value",
+                attribute_count=1628,
+                etag="etag_value",
+                class_count=1182,
+            )
+        )
+        response = await client.get_data_taxonomy()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == data_taxonomy.GetDataTaxonomyRequest()
+
+
+@pytest.mark.asyncio
+async def test_get_data_taxonomy_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = DataTaxonomyServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.get_data_taxonomy
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.get_data_taxonomy
+        ] = mock_object
+
+        request = {}
+        await client.get_data_taxonomy(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.get_data_taxonomy(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_get_data_taxonomy_async(
     transport: str = "grpc_asyncio", request_type=data_taxonomy.GetDataTaxonomyRequest
 ):
     client = DataTaxonomyServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
@@ -2021,15 +3205,16 @@
             )
         )
         response = await client.get_data_taxonomy(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == data_taxonomy.GetDataTaxonomyRequest()
+        request = data_taxonomy.GetDataTaxonomyRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, data_taxonomy.DataTaxonomy)
     assert response.name == "name_value"
     assert response.uid == "uid_value"
     assert response.description == "description_value"
     assert response.display_name == "display_name_value"
@@ -2218,15 +3403,16 @@
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/spam")
         response = client.create_data_attribute_binding(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == data_taxonomy.CreateDataAttributeBindingRequest()
+        request = data_taxonomy.CreateDataAttributeBindingRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 def test_create_data_attribute_binding_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
@@ -2236,20 +3422,172 @@
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.create_data_attribute_binding), "__call__"
     ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.create_data_attribute_binding()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == data_taxonomy.CreateDataAttributeBindingRequest()
 
 
+def test_create_data_attribute_binding_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = DataTaxonomyServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = data_taxonomy.CreateDataAttributeBindingRequest(
+        parent="parent_value",
+        data_attribute_binding_id="data_attribute_binding_id_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.create_data_attribute_binding), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.create_data_attribute_binding(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == data_taxonomy.CreateDataAttributeBindingRequest(
+            parent="parent_value",
+            data_attribute_binding_id="data_attribute_binding_id_value",
+        )
+
+
+def test_create_data_attribute_binding_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = DataTaxonomyServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._transport.create_data_attribute_binding
+            in client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.create_data_attribute_binding
+        ] = mock_rpc
+        request = {}
+        client.create_data_attribute_binding(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        client.create_data_attribute_binding(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_create_data_attribute_binding_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = DataTaxonomyServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.create_data_attribute_binding), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        response = await client.create_data_attribute_binding()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == data_taxonomy.CreateDataAttributeBindingRequest()
+
+
+@pytest.mark.asyncio
+async def test_create_data_attribute_binding_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = DataTaxonomyServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.create_data_attribute_binding
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.create_data_attribute_binding
+        ] = mock_object
+
+        request = {}
+        await client.create_data_attribute_binding(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        await client.create_data_attribute_binding(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_create_data_attribute_binding_async(
     transport: str = "grpc_asyncio",
     request_type=data_taxonomy.CreateDataAttributeBindingRequest,
 ):
     client = DataTaxonomyServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -2269,15 +3607,16 @@
             operations_pb2.Operation(name="operations/spam")
         )
         response = await client.create_data_attribute_binding(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == data_taxonomy.CreateDataAttributeBindingRequest()
+        request = data_taxonomy.CreateDataAttributeBindingRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 @pytest.mark.asyncio
 async def test_create_data_attribute_binding_async_from_dict():
@@ -2487,15 +3826,16 @@
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/spam")
         response = client.update_data_attribute_binding(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == data_taxonomy.UpdateDataAttributeBindingRequest()
+        request = data_taxonomy.UpdateDataAttributeBindingRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 def test_update_data_attribute_binding_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
@@ -2505,20 +3845,166 @@
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.update_data_attribute_binding), "__call__"
     ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.update_data_attribute_binding()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == data_taxonomy.UpdateDataAttributeBindingRequest()
 
 
+def test_update_data_attribute_binding_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = DataTaxonomyServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = data_taxonomy.UpdateDataAttributeBindingRequest()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.update_data_attribute_binding), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.update_data_attribute_binding(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == data_taxonomy.UpdateDataAttributeBindingRequest()
+
+
+def test_update_data_attribute_binding_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = DataTaxonomyServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._transport.update_data_attribute_binding
+            in client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.update_data_attribute_binding
+        ] = mock_rpc
+        request = {}
+        client.update_data_attribute_binding(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        client.update_data_attribute_binding(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_update_data_attribute_binding_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = DataTaxonomyServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.update_data_attribute_binding), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        response = await client.update_data_attribute_binding()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == data_taxonomy.UpdateDataAttributeBindingRequest()
+
+
+@pytest.mark.asyncio
+async def test_update_data_attribute_binding_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = DataTaxonomyServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.update_data_attribute_binding
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.update_data_attribute_binding
+        ] = mock_object
+
+        request = {}
+        await client.update_data_attribute_binding(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        await client.update_data_attribute_binding(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_update_data_attribute_binding_async(
     transport: str = "grpc_asyncio",
     request_type=data_taxonomy.UpdateDataAttributeBindingRequest,
 ):
     client = DataTaxonomyServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -2538,15 +4024,16 @@
             operations_pb2.Operation(name="operations/spam")
         )
         response = await client.update_data_attribute_binding(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == data_taxonomy.UpdateDataAttributeBindingRequest()
+        request = data_taxonomy.UpdateDataAttributeBindingRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 @pytest.mark.asyncio
 async def test_update_data_attribute_binding_async_from_dict():
@@ -2746,15 +4233,16 @@
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/spam")
         response = client.delete_data_attribute_binding(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == data_taxonomy.DeleteDataAttributeBindingRequest()
+        request = data_taxonomy.DeleteDataAttributeBindingRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 def test_delete_data_attribute_binding_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
@@ -2764,20 +4252,172 @@
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.delete_data_attribute_binding), "__call__"
     ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.delete_data_attribute_binding()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == data_taxonomy.DeleteDataAttributeBindingRequest()
 
 
+def test_delete_data_attribute_binding_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = DataTaxonomyServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = data_taxonomy.DeleteDataAttributeBindingRequest(
+        name="name_value",
+        etag="etag_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.delete_data_attribute_binding), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.delete_data_attribute_binding(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == data_taxonomy.DeleteDataAttributeBindingRequest(
+            name="name_value",
+            etag="etag_value",
+        )
+
+
+def test_delete_data_attribute_binding_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = DataTaxonomyServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._transport.delete_data_attribute_binding
+            in client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.delete_data_attribute_binding
+        ] = mock_rpc
+        request = {}
+        client.delete_data_attribute_binding(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        client.delete_data_attribute_binding(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_delete_data_attribute_binding_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = DataTaxonomyServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.delete_data_attribute_binding), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        response = await client.delete_data_attribute_binding()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == data_taxonomy.DeleteDataAttributeBindingRequest()
+
+
+@pytest.mark.asyncio
+async def test_delete_data_attribute_binding_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = DataTaxonomyServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.delete_data_attribute_binding
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.delete_data_attribute_binding
+        ] = mock_object
+
+        request = {}
+        await client.delete_data_attribute_binding(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        await client.delete_data_attribute_binding(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_delete_data_attribute_binding_async(
     transport: str = "grpc_asyncio",
     request_type=data_taxonomy.DeleteDataAttributeBindingRequest,
 ):
     client = DataTaxonomyServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -2797,15 +4437,16 @@
             operations_pb2.Operation(name="operations/spam")
         )
         response = await client.delete_data_attribute_binding(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == data_taxonomy.DeleteDataAttributeBindingRequest()
+        request = data_taxonomy.DeleteDataAttributeBindingRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 @pytest.mark.asyncio
 async def test_delete_data_attribute_binding_async_from_dict():
@@ -2990,15 +4631,16 @@
             unreachable_locations=["unreachable_locations_value"],
         )
         response = client.list_data_attribute_bindings(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == data_taxonomy.ListDataAttributeBindingsRequest()
+        request = data_taxonomy.ListDataAttributeBindingsRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, pagers.ListDataAttributeBindingsPager)
     assert response.next_page_token == "next_page_token_value"
     assert response.unreachable_locations == ["unreachable_locations_value"]
 
 
@@ -3010,20 +4652,171 @@
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.list_data_attribute_bindings), "__call__"
     ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.list_data_attribute_bindings()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == data_taxonomy.ListDataAttributeBindingsRequest()
 
 
+def test_list_data_attribute_bindings_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = DataTaxonomyServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = data_taxonomy.ListDataAttributeBindingsRequest(
+        parent="parent_value",
+        page_token="page_token_value",
+        filter="filter_value",
+        order_by="order_by_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.list_data_attribute_bindings), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.list_data_attribute_bindings(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == data_taxonomy.ListDataAttributeBindingsRequest(
+            parent="parent_value",
+            page_token="page_token_value",
+            filter="filter_value",
+            order_by="order_by_value",
+        )
+
+
+def test_list_data_attribute_bindings_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = DataTaxonomyServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._transport.list_data_attribute_bindings
+            in client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.list_data_attribute_bindings
+        ] = mock_rpc
+        request = {}
+        client.list_data_attribute_bindings(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.list_data_attribute_bindings(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_list_data_attribute_bindings_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = DataTaxonomyServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.list_data_attribute_bindings), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            data_taxonomy.ListDataAttributeBindingsResponse(
+                next_page_token="next_page_token_value",
+                unreachable_locations=["unreachable_locations_value"],
+            )
+        )
+        response = await client.list_data_attribute_bindings()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == data_taxonomy.ListDataAttributeBindingsRequest()
+
+
+@pytest.mark.asyncio
+async def test_list_data_attribute_bindings_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = DataTaxonomyServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.list_data_attribute_bindings
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.list_data_attribute_bindings
+        ] = mock_object
+
+        request = {}
+        await client.list_data_attribute_bindings(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.list_data_attribute_bindings(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_list_data_attribute_bindings_async(
     transport: str = "grpc_asyncio",
     request_type=data_taxonomy.ListDataAttributeBindingsRequest,
 ):
     client = DataTaxonomyServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -3046,15 +4839,16 @@
             )
         )
         response = await client.list_data_attribute_bindings(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == data_taxonomy.ListDataAttributeBindingsRequest()
+        request = data_taxonomy.ListDataAttributeBindingsRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, pagers.ListDataAttributeBindingsAsyncPager)
     assert response.next_page_token == "next_page_token_value"
     assert response.unreachable_locations == ["unreachable_locations_value"]
 
 
@@ -3212,15 +5006,15 @@
             data_taxonomy.ListDataAttributeBindingsRequest(),
             parent="parent_value",
         )
 
 
 def test_list_data_attribute_bindings_pager(transport_name: str = "grpc"):
     client = DataTaxonomyServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
         transport=transport_name,
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.list_data_attribute_bindings), "__call__"
     ) as call:
@@ -3264,15 +5058,15 @@
         results = list(pager)
         assert len(results) == 6
         assert all(isinstance(i, data_taxonomy.DataAttributeBinding) for i in results)
 
 
 def test_list_data_attribute_bindings_pages(transport_name: str = "grpc"):
     client = DataTaxonomyServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
         transport=transport_name,
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.list_data_attribute_bindings), "__call__"
     ) as call:
@@ -3308,15 +5102,15 @@
         for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
             assert page_.raw_page.next_page_token == token
 
 
 @pytest.mark.asyncio
 async def test_list_data_attribute_bindings_async_pager():
     client = DataTaxonomyServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.list_data_attribute_bindings),
         "__call__",
         new_callable=mock.AsyncMock,
@@ -3360,15 +5154,15 @@
         assert len(responses) == 6
         assert all(isinstance(i, data_taxonomy.DataAttributeBinding) for i in responses)
 
 
 @pytest.mark.asyncio
 async def test_list_data_attribute_bindings_async_pages():
     client = DataTaxonomyServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.list_data_attribute_bindings),
         "__call__",
         new_callable=mock.AsyncMock,
@@ -3444,15 +5238,16 @@
             resource="resource_value",
         )
         response = client.get_data_attribute_binding(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == data_taxonomy.GetDataAttributeBindingRequest()
+        request = data_taxonomy.GetDataAttributeBindingRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, data_taxonomy.DataAttributeBinding)
     assert response.name == "name_value"
     assert response.uid == "uid_value"
     assert response.description == "description_value"
     assert response.display_name == "display_name_value"
@@ -3468,20 +5263,169 @@
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.get_data_attribute_binding), "__call__"
     ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.get_data_attribute_binding()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == data_taxonomy.GetDataAttributeBindingRequest()
 
 
+def test_get_data_attribute_binding_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = DataTaxonomyServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = data_taxonomy.GetDataAttributeBindingRequest(
+        name="name_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.get_data_attribute_binding), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.get_data_attribute_binding(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == data_taxonomy.GetDataAttributeBindingRequest(
+            name="name_value",
+        )
+
+
+def test_get_data_attribute_binding_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = DataTaxonomyServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._transport.get_data_attribute_binding
+            in client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.get_data_attribute_binding
+        ] = mock_rpc
+        request = {}
+        client.get_data_attribute_binding(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.get_data_attribute_binding(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_get_data_attribute_binding_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = DataTaxonomyServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.get_data_attribute_binding), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            data_taxonomy.DataAttributeBinding(
+                name="name_value",
+                uid="uid_value",
+                description="description_value",
+                display_name="display_name_value",
+                etag="etag_value",
+                attributes=["attributes_value"],
+            )
+        )
+        response = await client.get_data_attribute_binding()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == data_taxonomy.GetDataAttributeBindingRequest()
+
+
+@pytest.mark.asyncio
+async def test_get_data_attribute_binding_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = DataTaxonomyServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.get_data_attribute_binding
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.get_data_attribute_binding
+        ] = mock_object
+
+        request = {}
+        await client.get_data_attribute_binding(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.get_data_attribute_binding(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_get_data_attribute_binding_async(
     transport: str = "grpc_asyncio",
     request_type=data_taxonomy.GetDataAttributeBindingRequest,
 ):
     client = DataTaxonomyServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -3508,15 +5452,16 @@
             )
         )
         response = await client.get_data_attribute_binding(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == data_taxonomy.GetDataAttributeBindingRequest()
+        request = data_taxonomy.GetDataAttributeBindingRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, data_taxonomy.DataAttributeBinding)
     assert response.name == "name_value"
     assert response.uid == "uid_value"
     assert response.description == "description_value"
     assert response.display_name == "display_name_value"
@@ -3704,15 +5649,16 @@
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/spam")
         response = client.create_data_attribute(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == data_taxonomy.CreateDataAttributeRequest()
+        request = data_taxonomy.CreateDataAttributeRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 def test_create_data_attribute_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
@@ -3722,20 +5668,172 @@
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.create_data_attribute), "__call__"
     ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.create_data_attribute()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == data_taxonomy.CreateDataAttributeRequest()
 
 
+def test_create_data_attribute_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = DataTaxonomyServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = data_taxonomy.CreateDataAttributeRequest(
+        parent="parent_value",
+        data_attribute_id="data_attribute_id_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.create_data_attribute), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.create_data_attribute(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == data_taxonomy.CreateDataAttributeRequest(
+            parent="parent_value",
+            data_attribute_id="data_attribute_id_value",
+        )
+
+
+def test_create_data_attribute_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = DataTaxonomyServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._transport.create_data_attribute
+            in client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.create_data_attribute
+        ] = mock_rpc
+        request = {}
+        client.create_data_attribute(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        client.create_data_attribute(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_create_data_attribute_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = DataTaxonomyServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.create_data_attribute), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        response = await client.create_data_attribute()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == data_taxonomy.CreateDataAttributeRequest()
+
+
+@pytest.mark.asyncio
+async def test_create_data_attribute_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = DataTaxonomyServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.create_data_attribute
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.create_data_attribute
+        ] = mock_object
+
+        request = {}
+        await client.create_data_attribute(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        await client.create_data_attribute(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_create_data_attribute_async(
     transport: str = "grpc_asyncio",
     request_type=data_taxonomy.CreateDataAttributeRequest,
 ):
     client = DataTaxonomyServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -3755,15 +5853,16 @@
             operations_pb2.Operation(name="operations/spam")
         )
         response = await client.create_data_attribute(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == data_taxonomy.CreateDataAttributeRequest()
+        request = data_taxonomy.CreateDataAttributeRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 @pytest.mark.asyncio
 async def test_create_data_attribute_async_from_dict():
@@ -3965,15 +6064,16 @@
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/spam")
         response = client.update_data_attribute(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == data_taxonomy.UpdateDataAttributeRequest()
+        request = data_taxonomy.UpdateDataAttributeRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 def test_update_data_attribute_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
@@ -3983,20 +6083,166 @@
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.update_data_attribute), "__call__"
     ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.update_data_attribute()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == data_taxonomy.UpdateDataAttributeRequest()
 
 
+def test_update_data_attribute_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = DataTaxonomyServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = data_taxonomy.UpdateDataAttributeRequest()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.update_data_attribute), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.update_data_attribute(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == data_taxonomy.UpdateDataAttributeRequest()
+
+
+def test_update_data_attribute_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = DataTaxonomyServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._transport.update_data_attribute
+            in client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.update_data_attribute
+        ] = mock_rpc
+        request = {}
+        client.update_data_attribute(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        client.update_data_attribute(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_update_data_attribute_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = DataTaxonomyServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.update_data_attribute), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        response = await client.update_data_attribute()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == data_taxonomy.UpdateDataAttributeRequest()
+
+
+@pytest.mark.asyncio
+async def test_update_data_attribute_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = DataTaxonomyServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.update_data_attribute
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.update_data_attribute
+        ] = mock_object
+
+        request = {}
+        await client.update_data_attribute(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        await client.update_data_attribute(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_update_data_attribute_async(
     transport: str = "grpc_asyncio",
     request_type=data_taxonomy.UpdateDataAttributeRequest,
 ):
     client = DataTaxonomyServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -4016,15 +6262,16 @@
             operations_pb2.Operation(name="operations/spam")
         )
         response = await client.update_data_attribute(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == data_taxonomy.UpdateDataAttributeRequest()
+        request = data_taxonomy.UpdateDataAttributeRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 @pytest.mark.asyncio
 async def test_update_data_attribute_async_from_dict():
@@ -4216,15 +6463,16 @@
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/spam")
         response = client.delete_data_attribute(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == data_taxonomy.DeleteDataAttributeRequest()
+        request = data_taxonomy.DeleteDataAttributeRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 def test_delete_data_attribute_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
@@ -4234,20 +6482,172 @@
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.delete_data_attribute), "__call__"
     ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.delete_data_attribute()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == data_taxonomy.DeleteDataAttributeRequest()
 
 
+def test_delete_data_attribute_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = DataTaxonomyServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = data_taxonomy.DeleteDataAttributeRequest(
+        name="name_value",
+        etag="etag_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.delete_data_attribute), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.delete_data_attribute(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == data_taxonomy.DeleteDataAttributeRequest(
+            name="name_value",
+            etag="etag_value",
+        )
+
+
+def test_delete_data_attribute_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = DataTaxonomyServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._transport.delete_data_attribute
+            in client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.delete_data_attribute
+        ] = mock_rpc
+        request = {}
+        client.delete_data_attribute(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        client.delete_data_attribute(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_delete_data_attribute_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = DataTaxonomyServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.delete_data_attribute), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        response = await client.delete_data_attribute()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == data_taxonomy.DeleteDataAttributeRequest()
+
+
+@pytest.mark.asyncio
+async def test_delete_data_attribute_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = DataTaxonomyServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.delete_data_attribute
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.delete_data_attribute
+        ] = mock_object
+
+        request = {}
+        await client.delete_data_attribute(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        await client.delete_data_attribute(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_delete_data_attribute_async(
     transport: str = "grpc_asyncio",
     request_type=data_taxonomy.DeleteDataAttributeRequest,
 ):
     client = DataTaxonomyServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -4267,15 +6667,16 @@
             operations_pb2.Operation(name="operations/spam")
         )
         response = await client.delete_data_attribute(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == data_taxonomy.DeleteDataAttributeRequest()
+        request = data_taxonomy.DeleteDataAttributeRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 @pytest.mark.asyncio
 async def test_delete_data_attribute_async_from_dict():
@@ -4460,15 +6861,16 @@
             unreachable_locations=["unreachable_locations_value"],
         )
         response = client.list_data_attributes(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == data_taxonomy.ListDataAttributesRequest()
+        request = data_taxonomy.ListDataAttributesRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, pagers.ListDataAttributesPager)
     assert response.next_page_token == "next_page_token_value"
     assert response.unreachable_locations == ["unreachable_locations_value"]
 
 
@@ -4480,20 +6882,170 @@
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.list_data_attributes), "__call__"
     ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.list_data_attributes()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == data_taxonomy.ListDataAttributesRequest()
 
 
+def test_list_data_attributes_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = DataTaxonomyServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = data_taxonomy.ListDataAttributesRequest(
+        parent="parent_value",
+        page_token="page_token_value",
+        filter="filter_value",
+        order_by="order_by_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.list_data_attributes), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.list_data_attributes(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == data_taxonomy.ListDataAttributesRequest(
+            parent="parent_value",
+            page_token="page_token_value",
+            filter="filter_value",
+            order_by="order_by_value",
+        )
+
+
+def test_list_data_attributes_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = DataTaxonomyServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._transport.list_data_attributes in client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.list_data_attributes
+        ] = mock_rpc
+        request = {}
+        client.list_data_attributes(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.list_data_attributes(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_list_data_attributes_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = DataTaxonomyServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.list_data_attributes), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            data_taxonomy.ListDataAttributesResponse(
+                next_page_token="next_page_token_value",
+                unreachable_locations=["unreachable_locations_value"],
+            )
+        )
+        response = await client.list_data_attributes()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == data_taxonomy.ListDataAttributesRequest()
+
+
+@pytest.mark.asyncio
+async def test_list_data_attributes_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = DataTaxonomyServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.list_data_attributes
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.list_data_attributes
+        ] = mock_object
+
+        request = {}
+        await client.list_data_attributes(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.list_data_attributes(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_list_data_attributes_async(
     transport: str = "grpc_asyncio",
     request_type=data_taxonomy.ListDataAttributesRequest,
 ):
     client = DataTaxonomyServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
@@ -4516,15 +7068,16 @@
             )
         )
         response = await client.list_data_attributes(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == data_taxonomy.ListDataAttributesRequest()
+        request = data_taxonomy.ListDataAttributesRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, pagers.ListDataAttributesAsyncPager)
     assert response.next_page_token == "next_page_token_value"
     assert response.unreachable_locations == ["unreachable_locations_value"]
 
 
@@ -4682,15 +7235,15 @@
             data_taxonomy.ListDataAttributesRequest(),
             parent="parent_value",
         )
 
 
 def test_list_data_attributes_pager(transport_name: str = "grpc"):
     client = DataTaxonomyServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
         transport=transport_name,
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.list_data_attributes), "__call__"
     ) as call:
@@ -4734,15 +7287,15 @@
         results = list(pager)
         assert len(results) == 6
         assert all(isinstance(i, data_taxonomy.DataAttribute) for i in results)
 
 
 def test_list_data_attributes_pages(transport_name: str = "grpc"):
     client = DataTaxonomyServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
         transport=transport_name,
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.list_data_attributes), "__call__"
     ) as call:
@@ -4778,15 +7331,15 @@
         for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
             assert page_.raw_page.next_page_token == token
 
 
 @pytest.mark.asyncio
 async def test_list_data_attributes_async_pager():
     client = DataTaxonomyServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.list_data_attributes),
         "__call__",
         new_callable=mock.AsyncMock,
@@ -4830,15 +7383,15 @@
         assert len(responses) == 6
         assert all(isinstance(i, data_taxonomy.DataAttribute) for i in responses)
 
 
 @pytest.mark.asyncio
 async def test_list_data_attributes_async_pages():
     client = DataTaxonomyServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.list_data_attributes),
         "__call__",
         new_callable=mock.AsyncMock,
@@ -4914,15 +7467,16 @@
             etag="etag_value",
         )
         response = client.get_data_attribute(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == data_taxonomy.GetDataAttributeRequest()
+        request = data_taxonomy.GetDataAttributeRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, data_taxonomy.DataAttribute)
     assert response.name == "name_value"
     assert response.uid == "uid_value"
     assert response.description == "description_value"
     assert response.display_name == "display_name_value"
@@ -4939,20 +7493,169 @@
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.get_data_attribute), "__call__"
     ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.get_data_attribute()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == data_taxonomy.GetDataAttributeRequest()
 
 
+def test_get_data_attribute_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = DataTaxonomyServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = data_taxonomy.GetDataAttributeRequest(
+        name="name_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.get_data_attribute), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.get_data_attribute(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == data_taxonomy.GetDataAttributeRequest(
+            name="name_value",
+        )
+
+
+def test_get_data_attribute_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = DataTaxonomyServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._transport.get_data_attribute in client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.get_data_attribute
+        ] = mock_rpc
+        request = {}
+        client.get_data_attribute(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.get_data_attribute(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_get_data_attribute_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = DataTaxonomyServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.get_data_attribute), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            data_taxonomy.DataAttribute(
+                name="name_value",
+                uid="uid_value",
+                description="description_value",
+                display_name="display_name_value",
+                parent_id="parent_id_value",
+                attribute_count=1628,
+                etag="etag_value",
+            )
+        )
+        response = await client.get_data_attribute()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == data_taxonomy.GetDataAttributeRequest()
+
+
+@pytest.mark.asyncio
+async def test_get_data_attribute_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = DataTaxonomyServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.get_data_attribute
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.get_data_attribute
+        ] = mock_object
+
+        request = {}
+        await client.get_data_attribute(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.get_data_attribute(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_get_data_attribute_async(
     transport: str = "grpc_asyncio", request_type=data_taxonomy.GetDataAttributeRequest
 ):
     client = DataTaxonomyServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
@@ -4979,15 +7682,16 @@
             )
         )
         response = await client.get_data_attribute(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == data_taxonomy.GetDataAttributeRequest()
+        request = data_taxonomy.GetDataAttributeRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, data_taxonomy.DataAttribute)
     assert response.name == "name_value"
     assert response.uid == "uid_value"
     assert response.description == "description_value"
     assert response.display_name == "display_name_value"
@@ -5182,15 +7886,15 @@
     with pytest.raises(ValueError):
         client = DataTaxonomyServiceClient(
             client_options=options,
             transport=transport,
         )
 
     # It is an error to provide an api_key and a credential.
-    options = mock.Mock()
+    options = client_options.ClientOptions()
     options.api_key = "api_key"
     with pytest.raises(ValueError):
         client = DataTaxonomyServiceClient(
             client_options=options, credentials=ga_credentials.AnonymousCredentials()
         )
 
     # It is an error to provide scopes and a transport instance.
@@ -5944,15 +8648,15 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert response is None
 
 
 @pytest.mark.asyncio
-async def test_delete_operation_async(transport: str = "grpc"):
+async def test_delete_operation_async(transport: str = "grpc_asyncio"):
     client = DataTaxonomyServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
@@ -6083,15 +8787,15 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert response is None
 
 
 @pytest.mark.asyncio
-async def test_cancel_operation_async(transport: str = "grpc"):
+async def test_cancel_operation_async(transport: str = "grpc_asyncio"):
     client = DataTaxonomyServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
@@ -6222,15 +8926,15 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, operations_pb2.Operation)
 
 
 @pytest.mark.asyncio
-async def test_get_operation_async(transport: str = "grpc"):
+async def test_get_operation_async(transport: str = "grpc_asyncio"):
     client = DataTaxonomyServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
@@ -6367,15 +9071,15 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, operations_pb2.ListOperationsResponse)
 
 
 @pytest.mark.asyncio
-async def test_list_operations_async(transport: str = "grpc"):
+async def test_list_operations_async(transport: str = "grpc_asyncio"):
     client = DataTaxonomyServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
@@ -6512,15 +9216,15 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, locations_pb2.ListLocationsResponse)
 
 
 @pytest.mark.asyncio
-async def test_list_locations_async(transport: str = "grpc"):
+async def test_list_locations_async(transport: str = "grpc_asyncio"):
     client = DataTaxonomyServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
@@ -6834,15 +9538,17 @@
         options.api_key = "api_key"
         with mock.patch.object(transport_class, "__init__") as patched:
             patched.return_value = None
             client = client_class(client_options=options)
             patched.assert_called_once_with(
                 credentials=mock_cred,
                 credentials_file=None,
-                host=client.DEFAULT_ENDPOINT,
+                host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                    UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+                ),
                 scopes=None,
                 client_cert_source_for_mtls=None,
                 quota_project_id=None,
                 client_info=transports.base.DEFAULT_CLIENT_INFO,
                 always_use_jwt_access=True,
                 api_audience=None,
             )
```

### Comparing `google-cloud-dataplex-1.9.0/tests/unit/gapic/dataplex_v1/test_dataplex_service.py` & `google-cloud-dataplex-2.0.0/tests/unit/gapic/dataplex_v1/test_catalog_service.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -29,43 +29,43 @@
     gapic_v1,
     grpc_helpers,
     grpc_helpers_async,
     operation,
     operations_v1,
     path_template,
 )
-from google.api_core import client_options
+from google.api_core import api_core_version, client_options
 from google.api_core import exceptions as core_exceptions
 from google.api_core import operation_async  # type: ignore
 import google.auth
 from google.auth import credentials as ga_credentials
 from google.auth.exceptions import MutualTLSChannelError
 from google.cloud.location import locations_pb2
 from google.iam.v1 import iam_policy_pb2  # type: ignore
 from google.iam.v1 import options_pb2  # type: ignore
 from google.iam.v1 import policy_pb2  # type: ignore
 from google.longrunning import operations_pb2  # type: ignore
 from google.oauth2 import service_account
-from google.protobuf import duration_pb2  # type: ignore
 from google.protobuf import empty_pb2  # type: ignore
 from google.protobuf import field_mask_pb2  # type: ignore
+from google.protobuf import struct_pb2  # type: ignore
 from google.protobuf import timestamp_pb2  # type: ignore
 import grpc
 from grpc.experimental import aio
 from proto.marshal.rules import wrappers
 from proto.marshal.rules.dates import DurationRule, TimestampRule
 import pytest
 
-from google.cloud.dataplex_v1.services.dataplex_service import (
-    DataplexServiceAsyncClient,
-    DataplexServiceClient,
+from google.cloud.dataplex_v1.services.catalog_service import (
+    CatalogServiceAsyncClient,
+    CatalogServiceClient,
     pagers,
     transports,
 )
-from google.cloud.dataplex_v1.types import analyze, resources, service, tasks
+from google.cloud.dataplex_v1.types import catalog, service
 
 
 def client_cert_source_callback():
     return b"cert bytes", b"key bytes"
 
 
 # If default endpoint is localhost, then default mtls endpoint will be the same.
@@ -75,53 +75,329 @@
     return (
         "foo.googleapis.com"
         if ("localhost" in client.DEFAULT_ENDPOINT)
         else client.DEFAULT_ENDPOINT
     )
 
 
+# If default endpoint template is localhost, then default mtls endpoint will be the same.
+# This method modifies the default endpoint template so the client can produce a different
+# mtls endpoint for endpoint testing purposes.
+def modify_default_endpoint_template(client):
+    return (
+        "test.{UNIVERSE_DOMAIN}"
+        if ("localhost" in client._DEFAULT_ENDPOINT_TEMPLATE)
+        else client._DEFAULT_ENDPOINT_TEMPLATE
+    )
+
+
 def test__get_default_mtls_endpoint():
     api_endpoint = "example.googleapis.com"
     api_mtls_endpoint = "example.mtls.googleapis.com"
     sandbox_endpoint = "example.sandbox.googleapis.com"
     sandbox_mtls_endpoint = "example.mtls.sandbox.googleapis.com"
     non_googleapi = "api.example.com"
 
-    assert DataplexServiceClient._get_default_mtls_endpoint(None) is None
+    assert CatalogServiceClient._get_default_mtls_endpoint(None) is None
     assert (
-        DataplexServiceClient._get_default_mtls_endpoint(api_endpoint)
+        CatalogServiceClient._get_default_mtls_endpoint(api_endpoint)
         == api_mtls_endpoint
     )
     assert (
-        DataplexServiceClient._get_default_mtls_endpoint(api_mtls_endpoint)
+        CatalogServiceClient._get_default_mtls_endpoint(api_mtls_endpoint)
         == api_mtls_endpoint
     )
     assert (
-        DataplexServiceClient._get_default_mtls_endpoint(sandbox_endpoint)
+        CatalogServiceClient._get_default_mtls_endpoint(sandbox_endpoint)
         == sandbox_mtls_endpoint
     )
     assert (
-        DataplexServiceClient._get_default_mtls_endpoint(sandbox_mtls_endpoint)
+        CatalogServiceClient._get_default_mtls_endpoint(sandbox_mtls_endpoint)
         == sandbox_mtls_endpoint
     )
     assert (
-        DataplexServiceClient._get_default_mtls_endpoint(non_googleapi) == non_googleapi
+        CatalogServiceClient._get_default_mtls_endpoint(non_googleapi) == non_googleapi
+    )
+
+
+def test__read_environment_variables():
+    assert CatalogServiceClient._read_environment_variables() == (False, "auto", None)
+
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "true"}):
+        assert CatalogServiceClient._read_environment_variables() == (
+            True,
+            "auto",
+            None,
+        )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "false"}):
+        assert CatalogServiceClient._read_environment_variables() == (
+            False,
+            "auto",
+            None,
+        )
+
+    with mock.patch.dict(
+        os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "Unsupported"}
+    ):
+        with pytest.raises(ValueError) as excinfo:
+            CatalogServiceClient._read_environment_variables()
+    assert (
+        str(excinfo.value)
+        == "Environment variable `GOOGLE_API_USE_CLIENT_CERTIFICATE` must be either `true` or `false`"
+    )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "never"}):
+        assert CatalogServiceClient._read_environment_variables() == (
+            False,
+            "never",
+            None,
+        )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "always"}):
+        assert CatalogServiceClient._read_environment_variables() == (
+            False,
+            "always",
+            None,
+        )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "auto"}):
+        assert CatalogServiceClient._read_environment_variables() == (
+            False,
+            "auto",
+            None,
+        )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "Unsupported"}):
+        with pytest.raises(MutualTLSChannelError) as excinfo:
+            CatalogServiceClient._read_environment_variables()
+    assert (
+        str(excinfo.value)
+        == "Environment variable `GOOGLE_API_USE_MTLS_ENDPOINT` must be `never`, `auto` or `always`"
+    )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_CLOUD_UNIVERSE_DOMAIN": "foo.com"}):
+        assert CatalogServiceClient._read_environment_variables() == (
+            False,
+            "auto",
+            "foo.com",
+        )
+
+
+def test__get_client_cert_source():
+    mock_provided_cert_source = mock.Mock()
+    mock_default_cert_source = mock.Mock()
+
+    assert CatalogServiceClient._get_client_cert_source(None, False) is None
+    assert (
+        CatalogServiceClient._get_client_cert_source(mock_provided_cert_source, False)
+        is None
+    )
+    assert (
+        CatalogServiceClient._get_client_cert_source(mock_provided_cert_source, True)
+        == mock_provided_cert_source
+    )
+
+    with mock.patch(
+        "google.auth.transport.mtls.has_default_client_cert_source", return_value=True
+    ):
+        with mock.patch(
+            "google.auth.transport.mtls.default_client_cert_source",
+            return_value=mock_default_cert_source,
+        ):
+            assert (
+                CatalogServiceClient._get_client_cert_source(None, True)
+                is mock_default_cert_source
+            )
+            assert (
+                CatalogServiceClient._get_client_cert_source(
+                    mock_provided_cert_source, "true"
+                )
+                is mock_provided_cert_source
+            )
+
+
+@mock.patch.object(
+    CatalogServiceClient,
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(CatalogServiceClient),
+)
+@mock.patch.object(
+    CatalogServiceAsyncClient,
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(CatalogServiceAsyncClient),
+)
+def test__get_api_endpoint():
+    api_override = "foo.com"
+    mock_client_cert_source = mock.Mock()
+    default_universe = CatalogServiceClient._DEFAULT_UNIVERSE
+    default_endpoint = CatalogServiceClient._DEFAULT_ENDPOINT_TEMPLATE.format(
+        UNIVERSE_DOMAIN=default_universe
+    )
+    mock_universe = "bar.com"
+    mock_endpoint = CatalogServiceClient._DEFAULT_ENDPOINT_TEMPLATE.format(
+        UNIVERSE_DOMAIN=mock_universe
+    )
+
+    assert (
+        CatalogServiceClient._get_api_endpoint(
+            api_override, mock_client_cert_source, default_universe, "always"
+        )
+        == api_override
+    )
+    assert (
+        CatalogServiceClient._get_api_endpoint(
+            None, mock_client_cert_source, default_universe, "auto"
+        )
+        == CatalogServiceClient.DEFAULT_MTLS_ENDPOINT
+    )
+    assert (
+        CatalogServiceClient._get_api_endpoint(None, None, default_universe, "auto")
+        == default_endpoint
+    )
+    assert (
+        CatalogServiceClient._get_api_endpoint(None, None, default_universe, "always")
+        == CatalogServiceClient.DEFAULT_MTLS_ENDPOINT
+    )
+    assert (
+        CatalogServiceClient._get_api_endpoint(
+            None, mock_client_cert_source, default_universe, "always"
+        )
+        == CatalogServiceClient.DEFAULT_MTLS_ENDPOINT
+    )
+    assert (
+        CatalogServiceClient._get_api_endpoint(None, None, mock_universe, "never")
+        == mock_endpoint
+    )
+    assert (
+        CatalogServiceClient._get_api_endpoint(None, None, default_universe, "never")
+        == default_endpoint
+    )
+
+    with pytest.raises(MutualTLSChannelError) as excinfo:
+        CatalogServiceClient._get_api_endpoint(
+            None, mock_client_cert_source, mock_universe, "auto"
+        )
+    assert (
+        str(excinfo.value)
+        == "mTLS is not supported in any universe other than googleapis.com."
     )
 
 
+def test__get_universe_domain():
+    client_universe_domain = "foo.com"
+    universe_domain_env = "bar.com"
+
+    assert (
+        CatalogServiceClient._get_universe_domain(
+            client_universe_domain, universe_domain_env
+        )
+        == client_universe_domain
+    )
+    assert (
+        CatalogServiceClient._get_universe_domain(None, universe_domain_env)
+        == universe_domain_env
+    )
+    assert (
+        CatalogServiceClient._get_universe_domain(None, None)
+        == CatalogServiceClient._DEFAULT_UNIVERSE
+    )
+
+    with pytest.raises(ValueError) as excinfo:
+        CatalogServiceClient._get_universe_domain("", None)
+    assert str(excinfo.value) == "Universe Domain cannot be an empty string."
+
+
+@pytest.mark.parametrize(
+    "client_class,transport_class,transport_name",
+    [
+        (CatalogServiceClient, transports.CatalogServiceGrpcTransport, "grpc"),
+    ],
+)
+def test__validate_universe_domain(client_class, transport_class, transport_name):
+    client = client_class(
+        transport=transport_class(credentials=ga_credentials.AnonymousCredentials())
+    )
+    assert client._validate_universe_domain() == True
+
+    # Test the case when universe is already validated.
+    assert client._validate_universe_domain() == True
+
+    if transport_name == "grpc":
+        # Test the case where credentials are provided by the
+        # `local_channel_credentials`. The default universes in both match.
+        channel = grpc.secure_channel(
+            "http://localhost/", grpc.local_channel_credentials()
+        )
+        client = client_class(transport=transport_class(channel=channel))
+        assert client._validate_universe_domain() == True
+
+        # Test the case where credentials do not exist: e.g. a transport is provided
+        # with no credentials. Validation should still succeed because there is no
+        # mismatch with non-existent credentials.
+        channel = grpc.secure_channel(
+            "http://localhost/", grpc.local_channel_credentials()
+        )
+        transport = transport_class(channel=channel)
+        transport._credentials = None
+        client = client_class(transport=transport)
+        assert client._validate_universe_domain() == True
+
+    # TODO: This is needed to cater for older versions of google-auth
+    # Make this test unconditional once the minimum supported version of
+    # google-auth becomes 2.23.0 or higher.
+    google_auth_major, google_auth_minor = [
+        int(part) for part in google.auth.__version__.split(".")[0:2]
+    ]
+    if google_auth_major > 2 or (google_auth_major == 2 and google_auth_minor >= 23):
+        credentials = ga_credentials.AnonymousCredentials()
+        credentials._universe_domain = "foo.com"
+        # Test the case when there is a universe mismatch from the credentials.
+        client = client_class(transport=transport_class(credentials=credentials))
+        with pytest.raises(ValueError) as excinfo:
+            client._validate_universe_domain()
+        assert (
+            str(excinfo.value)
+            == "The configured universe domain (googleapis.com) does not match the universe domain found in the credentials (foo.com). If you haven't configured the universe domain explicitly, `googleapis.com` is the default."
+        )
+
+        # Test the case when there is a universe mismatch from the client.
+        #
+        # TODO: Make this test unconditional once the minimum supported version of
+        # google-api-core becomes 2.15.0 or higher.
+        api_core_major, api_core_minor = [
+            int(part) for part in api_core_version.__version__.split(".")[0:2]
+        ]
+        if api_core_major > 2 or (api_core_major == 2 and api_core_minor >= 15):
+            client = client_class(
+                client_options={"universe_domain": "bar.com"},
+                transport=transport_class(
+                    credentials=ga_credentials.AnonymousCredentials(),
+                ),
+            )
+            with pytest.raises(ValueError) as excinfo:
+                client._validate_universe_domain()
+            assert (
+                str(excinfo.value)
+                == "The configured universe domain (bar.com) does not match the universe domain found in the credentials (googleapis.com). If you haven't configured the universe domain explicitly, `googleapis.com` is the default."
+            )
+
+    # Test that ValueError is raised if universe_domain is provided via client options and credentials is None
+    with pytest.raises(ValueError):
+        client._compare_universes("foo.bar", None)
+
+
 @pytest.mark.parametrize(
     "client_class,transport_name",
     [
-        (DataplexServiceClient, "grpc"),
-        (DataplexServiceAsyncClient, "grpc_asyncio"),
+        (CatalogServiceClient, "grpc"),
+        (CatalogServiceAsyncClient, "grpc_asyncio"),
     ],
 )
-def test_dataplex_service_client_from_service_account_info(
-    client_class, transport_name
-):
+def test_catalog_service_client_from_service_account_info(client_class, transport_name):
     creds = ga_credentials.AnonymousCredentials()
     with mock.patch.object(
         service_account.Credentials, "from_service_account_info"
     ) as factory:
         factory.return_value = creds
         info = {"valid": True}
         client = client_class.from_service_account_info(info, transport=transport_name)
@@ -130,19 +406,19 @@
 
         assert client.transport._host == ("dataplex.googleapis.com:443")
 
 
 @pytest.mark.parametrize(
     "transport_class,transport_name",
     [
-        (transports.DataplexServiceGrpcTransport, "grpc"),
-        (transports.DataplexServiceGrpcAsyncIOTransport, "grpc_asyncio"),
+        (transports.CatalogServiceGrpcTransport, "grpc"),
+        (transports.CatalogServiceGrpcAsyncIOTransport, "grpc_asyncio"),
     ],
 )
-def test_dataplex_service_client_service_account_always_use_jwt(
+def test_catalog_service_client_service_account_always_use_jwt(
     transport_class, transport_name
 ):
     with mock.patch.object(
         service_account.Credentials, "with_always_use_jwt_access", create=True
     ) as use_jwt:
         creds = service_account.Credentials(None, None, None)
         transport = transport_class(credentials=creds, always_use_jwt_access=True)
@@ -155,21 +431,19 @@
         transport = transport_class(credentials=creds, always_use_jwt_access=False)
         use_jwt.assert_not_called()
 
 
 @pytest.mark.parametrize(
     "client_class,transport_name",
     [
-        (DataplexServiceClient, "grpc"),
-        (DataplexServiceAsyncClient, "grpc_asyncio"),
+        (CatalogServiceClient, "grpc"),
+        (CatalogServiceAsyncClient, "grpc_asyncio"),
     ],
 )
-def test_dataplex_service_client_from_service_account_file(
-    client_class, transport_name
-):
+def test_catalog_service_client_from_service_account_file(client_class, transport_name):
     creds = ga_credentials.AnonymousCredentials()
     with mock.patch.object(
         service_account.Credentials, "from_service_account_file"
     ) as factory:
         factory.return_value = creds
         client = client_class.from_service_account_file(
             "dummy/file/path.json", transport=transport_name
@@ -182,57 +456,57 @@
         )
         assert client.transport._credentials == creds
         assert isinstance(client, client_class)
 
         assert client.transport._host == ("dataplex.googleapis.com:443")
 
 
-def test_dataplex_service_client_get_transport_class():
-    transport = DataplexServiceClient.get_transport_class()
+def test_catalog_service_client_get_transport_class():
+    transport = CatalogServiceClient.get_transport_class()
     available_transports = [
-        transports.DataplexServiceGrpcTransport,
+        transports.CatalogServiceGrpcTransport,
     ]
     assert transport in available_transports
 
-    transport = DataplexServiceClient.get_transport_class("grpc")
-    assert transport == transports.DataplexServiceGrpcTransport
+    transport = CatalogServiceClient.get_transport_class("grpc")
+    assert transport == transports.CatalogServiceGrpcTransport
 
 
 @pytest.mark.parametrize(
     "client_class,transport_class,transport_name",
     [
-        (DataplexServiceClient, transports.DataplexServiceGrpcTransport, "grpc"),
+        (CatalogServiceClient, transports.CatalogServiceGrpcTransport, "grpc"),
         (
-            DataplexServiceAsyncClient,
-            transports.DataplexServiceGrpcAsyncIOTransport,
+            CatalogServiceAsyncClient,
+            transports.CatalogServiceGrpcAsyncIOTransport,
             "grpc_asyncio",
         ),
     ],
 )
 @mock.patch.object(
-    DataplexServiceClient,
-    "DEFAULT_ENDPOINT",
-    modify_default_endpoint(DataplexServiceClient),
+    CatalogServiceClient,
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(CatalogServiceClient),
 )
 @mock.patch.object(
-    DataplexServiceAsyncClient,
-    "DEFAULT_ENDPOINT",
-    modify_default_endpoint(DataplexServiceAsyncClient),
+    CatalogServiceAsyncClient,
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(CatalogServiceAsyncClient),
 )
-def test_dataplex_service_client_client_options(
+def test_catalog_service_client_client_options(
     client_class, transport_class, transport_name
 ):
     # Check that if channel is provided we won't create a new one.
-    with mock.patch.object(DataplexServiceClient, "get_transport_class") as gtc:
+    with mock.patch.object(CatalogServiceClient, "get_transport_class") as gtc:
         transport = transport_class(credentials=ga_credentials.AnonymousCredentials())
         client = client_class(transport=transport)
         gtc.assert_not_called()
 
     # Check that if channel is provided via str we will create a new one.
-    with mock.patch.object(DataplexServiceClient, "get_transport_class") as gtc:
+    with mock.patch.object(CatalogServiceClient, "get_transport_class") as gtc:
         client = client_class(transport=transport_name)
         gtc.assert_called()
 
     # Check the case api_endpoint is provided.
     options = client_options.ClientOptions(api_endpoint="squid.clam.whelk")
     with mock.patch.object(transport_class, "__init__") as patched:
         patched.return_value = None
@@ -254,15 +528,17 @@
     with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "never"}):
         with mock.patch.object(transport_class, "__init__") as patched:
             patched.return_value = None
             client = client_class(transport=transport_name)
             patched.assert_called_once_with(
                 credentials=None,
                 credentials_file=None,
-                host=client.DEFAULT_ENDPOINT,
+                host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                    UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+                ),
                 scopes=None,
                 client_cert_source_for_mtls=None,
                 quota_project_id=None,
                 client_info=transports.base.DEFAULT_CLIENT_INFO,
                 always_use_jwt_access=True,
                 api_audience=None,
             )
@@ -284,33 +560,43 @@
                 always_use_jwt_access=True,
                 api_audience=None,
             )
 
     # Check the case api_endpoint is not provided and GOOGLE_API_USE_MTLS_ENDPOINT has
     # unsupported value.
     with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "Unsupported"}):
-        with pytest.raises(MutualTLSChannelError):
+        with pytest.raises(MutualTLSChannelError) as excinfo:
             client = client_class(transport=transport_name)
+    assert (
+        str(excinfo.value)
+        == "Environment variable `GOOGLE_API_USE_MTLS_ENDPOINT` must be `never`, `auto` or `always`"
+    )
 
     # Check the case GOOGLE_API_USE_CLIENT_CERTIFICATE has unsupported value.
     with mock.patch.dict(
         os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "Unsupported"}
     ):
-        with pytest.raises(ValueError):
+        with pytest.raises(ValueError) as excinfo:
             client = client_class(transport=transport_name)
+    assert (
+        str(excinfo.value)
+        == "Environment variable `GOOGLE_API_USE_CLIENT_CERTIFICATE` must be either `true` or `false`"
+    )
 
     # Check the case quota_project_id is provided
     options = client_options.ClientOptions(quota_project_id="octopus")
     with mock.patch.object(transport_class, "__init__") as patched:
         patched.return_value = None
         client = client_class(client_options=options, transport=transport_name)
         patched.assert_called_once_with(
             credentials=None,
             credentials_file=None,
-            host=client.DEFAULT_ENDPOINT,
+            host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+            ),
             scopes=None,
             client_cert_source_for_mtls=None,
             quota_project_id="octopus",
             client_info=transports.base.DEFAULT_CLIENT_INFO,
             always_use_jwt_access=True,
             api_audience=None,
         )
@@ -320,65 +606,57 @@
     )
     with mock.patch.object(transport_class, "__init__") as patched:
         patched.return_value = None
         client = client_class(client_options=options, transport=transport_name)
         patched.assert_called_once_with(
             credentials=None,
             credentials_file=None,
-            host=client.DEFAULT_ENDPOINT,
+            host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+            ),
             scopes=None,
             client_cert_source_for_mtls=None,
             quota_project_id=None,
             client_info=transports.base.DEFAULT_CLIENT_INFO,
             always_use_jwt_access=True,
             api_audience="https://language.googleapis.com",
         )
 
 
 @pytest.mark.parametrize(
     "client_class,transport_class,transport_name,use_client_cert_env",
     [
+        (CatalogServiceClient, transports.CatalogServiceGrpcTransport, "grpc", "true"),
         (
-            DataplexServiceClient,
-            transports.DataplexServiceGrpcTransport,
-            "grpc",
-            "true",
-        ),
-        (
-            DataplexServiceAsyncClient,
-            transports.DataplexServiceGrpcAsyncIOTransport,
+            CatalogServiceAsyncClient,
+            transports.CatalogServiceGrpcAsyncIOTransport,
             "grpc_asyncio",
             "true",
         ),
+        (CatalogServiceClient, transports.CatalogServiceGrpcTransport, "grpc", "false"),
         (
-            DataplexServiceClient,
-            transports.DataplexServiceGrpcTransport,
-            "grpc",
-            "false",
-        ),
-        (
-            DataplexServiceAsyncClient,
-            transports.DataplexServiceGrpcAsyncIOTransport,
+            CatalogServiceAsyncClient,
+            transports.CatalogServiceGrpcAsyncIOTransport,
             "grpc_asyncio",
             "false",
         ),
     ],
 )
 @mock.patch.object(
-    DataplexServiceClient,
-    "DEFAULT_ENDPOINT",
-    modify_default_endpoint(DataplexServiceClient),
+    CatalogServiceClient,
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(CatalogServiceClient),
 )
 @mock.patch.object(
-    DataplexServiceAsyncClient,
-    "DEFAULT_ENDPOINT",
-    modify_default_endpoint(DataplexServiceAsyncClient),
+    CatalogServiceAsyncClient,
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(CatalogServiceAsyncClient),
 )
 @mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "auto"})
-def test_dataplex_service_client_mtls_env_auto(
+def test_catalog_service_client_mtls_env_auto(
     client_class, transport_class, transport_name, use_client_cert_env
 ):
     # This tests the endpoint autoswitch behavior. Endpoint is autoswitched to the default
     # mtls endpoint, if GOOGLE_API_USE_CLIENT_CERTIFICATE is "true" and client cert exists.
 
     # Check the case client_cert_source is provided. Whether client cert is used depends on
     # GOOGLE_API_USE_CLIENT_CERTIFICATE value.
@@ -390,15 +668,17 @@
         )
         with mock.patch.object(transport_class, "__init__") as patched:
             patched.return_value = None
             client = client_class(client_options=options, transport=transport_name)
 
             if use_client_cert_env == "false":
                 expected_client_cert_source = None
-                expected_host = client.DEFAULT_ENDPOINT
+                expected_host = client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                    UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+                )
             else:
                 expected_client_cert_source = client_cert_source_callback
                 expected_host = client.DEFAULT_MTLS_ENDPOINT
 
             patched.assert_called_once_with(
                 credentials=None,
                 credentials_file=None,
@@ -422,15 +702,17 @@
                 return_value=True,
             ):
                 with mock.patch(
                     "google.auth.transport.mtls.default_client_cert_source",
                     return_value=client_cert_source_callback,
                 ):
                     if use_client_cert_env == "false":
-                        expected_host = client.DEFAULT_ENDPOINT
+                        expected_host = client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                            UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+                        )
                         expected_client_cert_source = None
                     else:
                         expected_host = client.DEFAULT_MTLS_ENDPOINT
                         expected_client_cert_source = client_cert_source_callback
 
                     patched.return_value = None
                     client = client_class(transport=transport_name)
@@ -456,38 +738,40 @@
                 return_value=False,
             ):
                 patched.return_value = None
                 client = client_class(transport=transport_name)
                 patched.assert_called_once_with(
                     credentials=None,
                     credentials_file=None,
-                    host=client.DEFAULT_ENDPOINT,
+                    host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                        UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+                    ),
                     scopes=None,
                     client_cert_source_for_mtls=None,
                     quota_project_id=None,
                     client_info=transports.base.DEFAULT_CLIENT_INFO,
                     always_use_jwt_access=True,
                     api_audience=None,
                 )
 
 
 @pytest.mark.parametrize(
-    "client_class", [DataplexServiceClient, DataplexServiceAsyncClient]
+    "client_class", [CatalogServiceClient, CatalogServiceAsyncClient]
 )
 @mock.patch.object(
-    DataplexServiceClient,
+    CatalogServiceClient,
     "DEFAULT_ENDPOINT",
-    modify_default_endpoint(DataplexServiceClient),
+    modify_default_endpoint(CatalogServiceClient),
 )
 @mock.patch.object(
-    DataplexServiceAsyncClient,
+    CatalogServiceAsyncClient,
     "DEFAULT_ENDPOINT",
-    modify_default_endpoint(DataplexServiceAsyncClient),
+    modify_default_endpoint(CatalogServiceAsyncClient),
 )
-def test_dataplex_service_client_get_mtls_endpoint_and_cert_source(client_class):
+def test_catalog_service_client_get_mtls_endpoint_and_cert_source(client_class):
     mock_client_cert_source = mock.Mock()
 
     # Test the case GOOGLE_API_USE_CLIENT_CERTIFICATE is "true".
     with mock.patch.dict(os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "true"}):
         mock_api_endpoint = "foo"
         options = client_options.ClientOptions(
             client_cert_source=mock_client_cert_source, api_endpoint=mock_api_endpoint
@@ -546,94 +830,207 @@
                 (
                     api_endpoint,
                     cert_source,
                 ) = client_class.get_mtls_endpoint_and_cert_source()
                 assert api_endpoint == client_class.DEFAULT_MTLS_ENDPOINT
                 assert cert_source == mock_client_cert_source
 
+    # Check the case api_endpoint is not provided and GOOGLE_API_USE_MTLS_ENDPOINT has
+    # unsupported value.
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "Unsupported"}):
+        with pytest.raises(MutualTLSChannelError) as excinfo:
+            client_class.get_mtls_endpoint_and_cert_source()
+
+        assert (
+            str(excinfo.value)
+            == "Environment variable `GOOGLE_API_USE_MTLS_ENDPOINT` must be `never`, `auto` or `always`"
+        )
+
+    # Check the case GOOGLE_API_USE_CLIENT_CERTIFICATE has unsupported value.
+    with mock.patch.dict(
+        os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "Unsupported"}
+    ):
+        with pytest.raises(ValueError) as excinfo:
+            client_class.get_mtls_endpoint_and_cert_source()
+
+        assert (
+            str(excinfo.value)
+            == "Environment variable `GOOGLE_API_USE_CLIENT_CERTIFICATE` must be either `true` or `false`"
+        )
+
+
+@pytest.mark.parametrize(
+    "client_class", [CatalogServiceClient, CatalogServiceAsyncClient]
+)
+@mock.patch.object(
+    CatalogServiceClient,
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(CatalogServiceClient),
+)
+@mock.patch.object(
+    CatalogServiceAsyncClient,
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(CatalogServiceAsyncClient),
+)
+def test_catalog_service_client_client_api_endpoint(client_class):
+    mock_client_cert_source = client_cert_source_callback
+    api_override = "foo.com"
+    default_universe = CatalogServiceClient._DEFAULT_UNIVERSE
+    default_endpoint = CatalogServiceClient._DEFAULT_ENDPOINT_TEMPLATE.format(
+        UNIVERSE_DOMAIN=default_universe
+    )
+    mock_universe = "bar.com"
+    mock_endpoint = CatalogServiceClient._DEFAULT_ENDPOINT_TEMPLATE.format(
+        UNIVERSE_DOMAIN=mock_universe
+    )
+
+    # If ClientOptions.api_endpoint is set and GOOGLE_API_USE_CLIENT_CERTIFICATE="true",
+    # use ClientOptions.api_endpoint as the api endpoint regardless.
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "true"}):
+        with mock.patch(
+            "google.auth.transport.requests.AuthorizedSession.configure_mtls_channel"
+        ):
+            options = client_options.ClientOptions(
+                client_cert_source=mock_client_cert_source, api_endpoint=api_override
+            )
+            client = client_class(
+                client_options=options,
+                credentials=ga_credentials.AnonymousCredentials(),
+            )
+            assert client.api_endpoint == api_override
+
+    # If ClientOptions.api_endpoint is not set and GOOGLE_API_USE_MTLS_ENDPOINT="never",
+    # use the _DEFAULT_ENDPOINT_TEMPLATE populated with GDU as the api endpoint.
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "never"}):
+        client = client_class(credentials=ga_credentials.AnonymousCredentials())
+        assert client.api_endpoint == default_endpoint
+
+    # If ClientOptions.api_endpoint is not set and GOOGLE_API_USE_MTLS_ENDPOINT="always",
+    # use the DEFAULT_MTLS_ENDPOINT as the api endpoint.
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "always"}):
+        client = client_class(credentials=ga_credentials.AnonymousCredentials())
+        assert client.api_endpoint == client_class.DEFAULT_MTLS_ENDPOINT
+
+    # If ClientOptions.api_endpoint is not set, GOOGLE_API_USE_MTLS_ENDPOINT="auto" (default),
+    # GOOGLE_API_USE_CLIENT_CERTIFICATE="false" (default), default cert source doesn't exist,
+    # and ClientOptions.universe_domain="bar.com",
+    # use the _DEFAULT_ENDPOINT_TEMPLATE populated with universe domain as the api endpoint.
+    options = client_options.ClientOptions()
+    universe_exists = hasattr(options, "universe_domain")
+    if universe_exists:
+        options = client_options.ClientOptions(universe_domain=mock_universe)
+        client = client_class(
+            client_options=options, credentials=ga_credentials.AnonymousCredentials()
+        )
+    else:
+        client = client_class(
+            client_options=options, credentials=ga_credentials.AnonymousCredentials()
+        )
+    assert client.api_endpoint == (
+        mock_endpoint if universe_exists else default_endpoint
+    )
+    assert client.universe_domain == (
+        mock_universe if universe_exists else default_universe
+    )
+
+    # If ClientOptions does not have a universe domain attribute and GOOGLE_API_USE_MTLS_ENDPOINT="never",
+    # use the _DEFAULT_ENDPOINT_TEMPLATE populated with GDU as the api endpoint.
+    options = client_options.ClientOptions()
+    if hasattr(options, "universe_domain"):
+        delattr(options, "universe_domain")
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "never"}):
+        client = client_class(
+            client_options=options, credentials=ga_credentials.AnonymousCredentials()
+        )
+        assert client.api_endpoint == default_endpoint
+
 
 @pytest.mark.parametrize(
     "client_class,transport_class,transport_name",
     [
-        (DataplexServiceClient, transports.DataplexServiceGrpcTransport, "grpc"),
+        (CatalogServiceClient, transports.CatalogServiceGrpcTransport, "grpc"),
         (
-            DataplexServiceAsyncClient,
-            transports.DataplexServiceGrpcAsyncIOTransport,
+            CatalogServiceAsyncClient,
+            transports.CatalogServiceGrpcAsyncIOTransport,
             "grpc_asyncio",
         ),
     ],
 )
-def test_dataplex_service_client_client_options_scopes(
+def test_catalog_service_client_client_options_scopes(
     client_class, transport_class, transport_name
 ):
     # Check the case scopes are provided.
     options = client_options.ClientOptions(
         scopes=["1", "2"],
     )
     with mock.patch.object(transport_class, "__init__") as patched:
         patched.return_value = None
         client = client_class(client_options=options, transport=transport_name)
         patched.assert_called_once_with(
             credentials=None,
             credentials_file=None,
-            host=client.DEFAULT_ENDPOINT,
+            host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+            ),
             scopes=["1", "2"],
             client_cert_source_for_mtls=None,
             quota_project_id=None,
             client_info=transports.base.DEFAULT_CLIENT_INFO,
             always_use_jwt_access=True,
             api_audience=None,
         )
 
 
 @pytest.mark.parametrize(
     "client_class,transport_class,transport_name,grpc_helpers",
     [
         (
-            DataplexServiceClient,
-            transports.DataplexServiceGrpcTransport,
+            CatalogServiceClient,
+            transports.CatalogServiceGrpcTransport,
             "grpc",
             grpc_helpers,
         ),
         (
-            DataplexServiceAsyncClient,
-            transports.DataplexServiceGrpcAsyncIOTransport,
+            CatalogServiceAsyncClient,
+            transports.CatalogServiceGrpcAsyncIOTransport,
             "grpc_asyncio",
             grpc_helpers_async,
         ),
     ],
 )
-def test_dataplex_service_client_client_options_credentials_file(
+def test_catalog_service_client_client_options_credentials_file(
     client_class, transport_class, transport_name, grpc_helpers
 ):
     # Check the case credentials file is provided.
     options = client_options.ClientOptions(credentials_file="credentials.json")
 
     with mock.patch.object(transport_class, "__init__") as patched:
         patched.return_value = None
         client = client_class(client_options=options, transport=transport_name)
         patched.assert_called_once_with(
             credentials=None,
             credentials_file="credentials.json",
-            host=client.DEFAULT_ENDPOINT,
+            host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+            ),
             scopes=None,
             client_cert_source_for_mtls=None,
             quota_project_id=None,
             client_info=transports.base.DEFAULT_CLIENT_INFO,
             always_use_jwt_access=True,
             api_audience=None,
         )
 
 
-def test_dataplex_service_client_client_options_from_dict():
+def test_catalog_service_client_client_options_from_dict():
     with mock.patch(
-        "google.cloud.dataplex_v1.services.dataplex_service.transports.DataplexServiceGrpcTransport.__init__"
+        "google.cloud.dataplex_v1.services.catalog_service.transports.CatalogServiceGrpcTransport.__init__"
     ) as grpc_transport:
         grpc_transport.return_value = None
-        client = DataplexServiceClient(
+        client = CatalogServiceClient(
             client_options={"api_endpoint": "squid.clam.whelk"}
         )
         grpc_transport.assert_called_once_with(
             credentials=None,
             credentials_file=None,
             host="squid.clam.whelk",
             scopes=None,
@@ -645,40 +1042,42 @@
         )
 
 
 @pytest.mark.parametrize(
     "client_class,transport_class,transport_name,grpc_helpers",
     [
         (
-            DataplexServiceClient,
-            transports.DataplexServiceGrpcTransport,
+            CatalogServiceClient,
+            transports.CatalogServiceGrpcTransport,
             "grpc",
             grpc_helpers,
         ),
         (
-            DataplexServiceAsyncClient,
-            transports.DataplexServiceGrpcAsyncIOTransport,
+            CatalogServiceAsyncClient,
+            transports.CatalogServiceGrpcAsyncIOTransport,
             "grpc_asyncio",
             grpc_helpers_async,
         ),
     ],
 )
-def test_dataplex_service_client_create_channel_credentials_file(
+def test_catalog_service_client_create_channel_credentials_file(
     client_class, transport_class, transport_name, grpc_helpers
 ):
     # Check the case credentials file is provided.
     options = client_options.ClientOptions(credentials_file="credentials.json")
 
     with mock.patch.object(transport_class, "__init__") as patched:
         patched.return_value = None
         client = client_class(client_options=options, transport=transport_name)
         patched.assert_called_once_with(
             credentials=None,
             credentials_file="credentials.json",
-            host=client.DEFAULT_ENDPOINT,
+            host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+            ),
             scopes=None,
             client_cert_source_for_mtls=None,
             quota_project_id=None,
             client_info=transports.base.DEFAULT_CLIENT_INFO,
             always_use_jwt_access=True,
             api_audience=None,
         )
@@ -711,109 +1110,268 @@
             ],
         )
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
-        service.CreateLakeRequest,
+        catalog.CreateEntryTypeRequest,
         dict,
     ],
 )
-def test_create_lake(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
+def test_create_entry_type(request_type, transport: str = "grpc"):
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.create_lake), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.create_entry_type), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/spam")
-        response = client.create_lake(request)
+        response = client.create_entry_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.CreateLakeRequest()
+        request = catalog.CreateEntryTypeRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
-def test_create_lake_empty_call():
+def test_create_entry_type_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
     # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.create_entry_type), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.create_entry_type()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == catalog.CreateEntryTypeRequest()
+
+
+def test_create_entry_type_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = catalog.CreateEntryTypeRequest(
+        parent="parent_value",
+        entry_type_id="entry_type_id_value",
+    )
+
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.create_lake), "__call__") as call:
-        client.create_lake()
+    with mock.patch.object(
+        type(client.transport.create_entry_type), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.create_entry_type(request=request)
         call.assert_called()
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.CreateLakeRequest()
+        assert args[0] == catalog.CreateEntryTypeRequest(
+            parent="parent_value",
+            entry_type_id="entry_type_id_value",
+        )
+
+
+def test_create_entry_type_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = CatalogServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.create_entry_type in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.create_entry_type
+        ] = mock_rpc
+        request = {}
+        client.create_entry_type(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        client.create_entry_type(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
 
 
 @pytest.mark.asyncio
-async def test_create_lake_async(
-    transport: str = "grpc_asyncio", request_type=service.CreateLakeRequest
+async def test_create_entry_type_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = CatalogServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.create_entry_type), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        response = await client.create_entry_type()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == catalog.CreateEntryTypeRequest()
+
+
+@pytest.mark.asyncio
+async def test_create_entry_type_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
 ):
-    client = DataplexServiceAsyncClient(
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = CatalogServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.create_entry_type
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.create_entry_type
+        ] = mock_object
+
+        request = {}
+        await client.create_entry_type(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        await client.create_entry_type(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_create_entry_type_async(
+    transport: str = "grpc_asyncio", request_type=catalog.CreateEntryTypeRequest
+):
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.create_lake), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.create_entry_type), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             operations_pb2.Operation(name="operations/spam")
         )
-        response = await client.create_lake(request)
+        response = await client.create_entry_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.CreateLakeRequest()
+        request = catalog.CreateEntryTypeRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 @pytest.mark.asyncio
-async def test_create_lake_async_from_dict():
-    await test_create_lake_async(request_type=dict)
+async def test_create_entry_type_async_from_dict():
+    await test_create_entry_type_async(request_type=dict)
 
 
-def test_create_lake_field_headers():
-    client = DataplexServiceClient(
+def test_create_entry_type_field_headers():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.CreateLakeRequest()
+    request = catalog.CreateEntryTypeRequest()
 
     request.parent = "parent_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.create_lake), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.create_entry_type), "__call__"
+    ) as call:
         call.return_value = operations_pb2.Operation(name="operations/op")
-        client.create_lake(request)
+        client.create_entry_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
@@ -821,481 +1379,805 @@
     assert (
         "x-goog-request-params",
         "parent=parent_value",
     ) in kw["metadata"]
 
 
 @pytest.mark.asyncio
-async def test_create_lake_field_headers_async():
-    client = DataplexServiceAsyncClient(
+async def test_create_entry_type_field_headers_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.CreateLakeRequest()
+    request = catalog.CreateEntryTypeRequest()
 
     request.parent = "parent_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.create_lake), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.create_entry_type), "__call__"
+    ) as call:
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             operations_pb2.Operation(name="operations/op")
         )
-        await client.create_lake(request)
+        await client.create_entry_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
     _, _, kw = call.mock_calls[0]
     assert (
         "x-goog-request-params",
         "parent=parent_value",
     ) in kw["metadata"]
 
 
-def test_create_lake_flattened():
-    client = DataplexServiceClient(
+def test_create_entry_type_flattened():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.create_lake), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.create_entry_type), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/op")
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        client.create_lake(
+        client.create_entry_type(
             parent="parent_value",
-            lake=resources.Lake(name="name_value"),
-            lake_id="lake_id_value",
+            entry_type=catalog.EntryType(name="name_value"),
+            entry_type_id="entry_type_id_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         arg = args[0].parent
         mock_val = "parent_value"
         assert arg == mock_val
-        arg = args[0].lake
-        mock_val = resources.Lake(name="name_value")
+        arg = args[0].entry_type
+        mock_val = catalog.EntryType(name="name_value")
         assert arg == mock_val
-        arg = args[0].lake_id
-        mock_val = "lake_id_value"
+        arg = args[0].entry_type_id
+        mock_val = "entry_type_id_value"
         assert arg == mock_val
 
 
-def test_create_lake_flattened_error():
-    client = DataplexServiceClient(
+def test_create_entry_type_flattened_error():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        client.create_lake(
-            service.CreateLakeRequest(),
+        client.create_entry_type(
+            catalog.CreateEntryTypeRequest(),
             parent="parent_value",
-            lake=resources.Lake(name="name_value"),
-            lake_id="lake_id_value",
+            entry_type=catalog.EntryType(name="name_value"),
+            entry_type_id="entry_type_id_value",
         )
 
 
 @pytest.mark.asyncio
-async def test_create_lake_flattened_async():
-    client = DataplexServiceAsyncClient(
+async def test_create_entry_type_flattened_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.create_lake), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.create_entry_type), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/op")
 
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             operations_pb2.Operation(name="operations/spam")
         )
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        response = await client.create_lake(
+        response = await client.create_entry_type(
             parent="parent_value",
-            lake=resources.Lake(name="name_value"),
-            lake_id="lake_id_value",
+            entry_type=catalog.EntryType(name="name_value"),
+            entry_type_id="entry_type_id_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         arg = args[0].parent
         mock_val = "parent_value"
         assert arg == mock_val
-        arg = args[0].lake
-        mock_val = resources.Lake(name="name_value")
+        arg = args[0].entry_type
+        mock_val = catalog.EntryType(name="name_value")
         assert arg == mock_val
-        arg = args[0].lake_id
-        mock_val = "lake_id_value"
+        arg = args[0].entry_type_id
+        mock_val = "entry_type_id_value"
         assert arg == mock_val
 
 
 @pytest.mark.asyncio
-async def test_create_lake_flattened_error_async():
-    client = DataplexServiceAsyncClient(
+async def test_create_entry_type_flattened_error_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        await client.create_lake(
-            service.CreateLakeRequest(),
+        await client.create_entry_type(
+            catalog.CreateEntryTypeRequest(),
             parent="parent_value",
-            lake=resources.Lake(name="name_value"),
-            lake_id="lake_id_value",
+            entry_type=catalog.EntryType(name="name_value"),
+            entry_type_id="entry_type_id_value",
         )
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
-        service.UpdateLakeRequest,
+        catalog.UpdateEntryTypeRequest,
         dict,
     ],
 )
-def test_update_lake(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
+def test_update_entry_type(request_type, transport: str = "grpc"):
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.update_lake), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.update_entry_type), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/spam")
-        response = client.update_lake(request)
+        response = client.update_entry_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.UpdateLakeRequest()
+        request = catalog.UpdateEntryTypeRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
-def test_update_lake_empty_call():
+def test_update_entry_type_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
     # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.update_entry_type), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.update_entry_type()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == catalog.UpdateEntryTypeRequest()
+
+
+def test_update_entry_type_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = catalog.UpdateEntryTypeRequest()
+
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.update_lake), "__call__") as call:
-        client.update_lake()
+    with mock.patch.object(
+        type(client.transport.update_entry_type), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.update_entry_type(request=request)
         call.assert_called()
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.UpdateLakeRequest()
+        assert args[0] == catalog.UpdateEntryTypeRequest()
+
+
+def test_update_entry_type_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = CatalogServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.update_entry_type in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.update_entry_type
+        ] = mock_rpc
+        request = {}
+        client.update_entry_type(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        client.update_entry_type(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_update_entry_type_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = CatalogServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.update_entry_type), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        response = await client.update_entry_type()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == catalog.UpdateEntryTypeRequest()
+
+
+@pytest.mark.asyncio
+async def test_update_entry_type_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = CatalogServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.update_entry_type
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.update_entry_type
+        ] = mock_object
+
+        request = {}
+        await client.update_entry_type(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        await client.update_entry_type(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
 
 
 @pytest.mark.asyncio
-async def test_update_lake_async(
-    transport: str = "grpc_asyncio", request_type=service.UpdateLakeRequest
+async def test_update_entry_type_async(
+    transport: str = "grpc_asyncio", request_type=catalog.UpdateEntryTypeRequest
 ):
-    client = DataplexServiceAsyncClient(
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.update_lake), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.update_entry_type), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             operations_pb2.Operation(name="operations/spam")
         )
-        response = await client.update_lake(request)
+        response = await client.update_entry_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.UpdateLakeRequest()
+        request = catalog.UpdateEntryTypeRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 @pytest.mark.asyncio
-async def test_update_lake_async_from_dict():
-    await test_update_lake_async(request_type=dict)
+async def test_update_entry_type_async_from_dict():
+    await test_update_entry_type_async(request_type=dict)
 
 
-def test_update_lake_field_headers():
-    client = DataplexServiceClient(
+def test_update_entry_type_field_headers():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.UpdateLakeRequest()
+    request = catalog.UpdateEntryTypeRequest()
 
-    request.lake.name = "name_value"
+    request.entry_type.name = "name_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.update_lake), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.update_entry_type), "__call__"
+    ) as call:
         call.return_value = operations_pb2.Operation(name="operations/op")
-        client.update_lake(request)
+        client.update_entry_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
     _, _, kw = call.mock_calls[0]
     assert (
         "x-goog-request-params",
-        "lake.name=name_value",
+        "entry_type.name=name_value",
     ) in kw["metadata"]
 
 
 @pytest.mark.asyncio
-async def test_update_lake_field_headers_async():
-    client = DataplexServiceAsyncClient(
+async def test_update_entry_type_field_headers_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.UpdateLakeRequest()
+    request = catalog.UpdateEntryTypeRequest()
 
-    request.lake.name = "name_value"
+    request.entry_type.name = "name_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.update_lake), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.update_entry_type), "__call__"
+    ) as call:
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             operations_pb2.Operation(name="operations/op")
         )
-        await client.update_lake(request)
+        await client.update_entry_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
     _, _, kw = call.mock_calls[0]
     assert (
         "x-goog-request-params",
-        "lake.name=name_value",
+        "entry_type.name=name_value",
     ) in kw["metadata"]
 
 
-def test_update_lake_flattened():
-    client = DataplexServiceClient(
+def test_update_entry_type_flattened():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.update_lake), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.update_entry_type), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/op")
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        client.update_lake(
-            lake=resources.Lake(name="name_value"),
+        client.update_entry_type(
+            entry_type=catalog.EntryType(name="name_value"),
             update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        arg = args[0].lake
-        mock_val = resources.Lake(name="name_value")
+        arg = args[0].entry_type
+        mock_val = catalog.EntryType(name="name_value")
         assert arg == mock_val
         arg = args[0].update_mask
         mock_val = field_mask_pb2.FieldMask(paths=["paths_value"])
         assert arg == mock_val
 
 
-def test_update_lake_flattened_error():
-    client = DataplexServiceClient(
+def test_update_entry_type_flattened_error():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        client.update_lake(
-            service.UpdateLakeRequest(),
-            lake=resources.Lake(name="name_value"),
+        client.update_entry_type(
+            catalog.UpdateEntryTypeRequest(),
+            entry_type=catalog.EntryType(name="name_value"),
             update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
         )
 
 
 @pytest.mark.asyncio
-async def test_update_lake_flattened_async():
-    client = DataplexServiceAsyncClient(
+async def test_update_entry_type_flattened_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.update_lake), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.update_entry_type), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/op")
 
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             operations_pb2.Operation(name="operations/spam")
         )
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        response = await client.update_lake(
-            lake=resources.Lake(name="name_value"),
+        response = await client.update_entry_type(
+            entry_type=catalog.EntryType(name="name_value"),
             update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        arg = args[0].lake
-        mock_val = resources.Lake(name="name_value")
+        arg = args[0].entry_type
+        mock_val = catalog.EntryType(name="name_value")
         assert arg == mock_val
         arg = args[0].update_mask
         mock_val = field_mask_pb2.FieldMask(paths=["paths_value"])
         assert arg == mock_val
 
 
 @pytest.mark.asyncio
-async def test_update_lake_flattened_error_async():
-    client = DataplexServiceAsyncClient(
+async def test_update_entry_type_flattened_error_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        await client.update_lake(
-            service.UpdateLakeRequest(),
-            lake=resources.Lake(name="name_value"),
+        await client.update_entry_type(
+            catalog.UpdateEntryTypeRequest(),
+            entry_type=catalog.EntryType(name="name_value"),
             update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
         )
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
-        service.DeleteLakeRequest,
+        catalog.DeleteEntryTypeRequest,
         dict,
     ],
 )
-def test_delete_lake(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
+def test_delete_entry_type(request_type, transport: str = "grpc"):
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.delete_lake), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.delete_entry_type), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/spam")
-        response = client.delete_lake(request)
+        response = client.delete_entry_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.DeleteLakeRequest()
+        request = catalog.DeleteEntryTypeRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
-def test_delete_lake_empty_call():
+def test_delete_entry_type_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
     # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.delete_lake), "__call__") as call:
-        client.delete_lake()
+    with mock.patch.object(
+        type(client.transport.delete_entry_type), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.delete_entry_type()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.DeleteLakeRequest()
+        assert args[0] == catalog.DeleteEntryTypeRequest()
+
+
+def test_delete_entry_type_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = CatalogServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = catalog.DeleteEntryTypeRequest(
+        name="name_value",
+        etag="etag_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.delete_entry_type), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.delete_entry_type(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == catalog.DeleteEntryTypeRequest(
+            name="name_value",
+            etag="etag_value",
+        )
+
+
+def test_delete_entry_type_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = CatalogServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.delete_entry_type in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.delete_entry_type
+        ] = mock_rpc
+        request = {}
+        client.delete_entry_type(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        client.delete_entry_type(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
 
 
 @pytest.mark.asyncio
-async def test_delete_lake_async(
-    transport: str = "grpc_asyncio", request_type=service.DeleteLakeRequest
+async def test_delete_entry_type_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = CatalogServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.delete_entry_type), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        response = await client.delete_entry_type()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == catalog.DeleteEntryTypeRequest()
+
+
+@pytest.mark.asyncio
+async def test_delete_entry_type_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = CatalogServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.delete_entry_type
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.delete_entry_type
+        ] = mock_object
+
+        request = {}
+        await client.delete_entry_type(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        await client.delete_entry_type(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_delete_entry_type_async(
+    transport: str = "grpc_asyncio", request_type=catalog.DeleteEntryTypeRequest
 ):
-    client = DataplexServiceAsyncClient(
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.delete_lake), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.delete_entry_type), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             operations_pb2.Operation(name="operations/spam")
         )
-        response = await client.delete_lake(request)
+        response = await client.delete_entry_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.DeleteLakeRequest()
+        request = catalog.DeleteEntryTypeRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 @pytest.mark.asyncio
-async def test_delete_lake_async_from_dict():
-    await test_delete_lake_async(request_type=dict)
+async def test_delete_entry_type_async_from_dict():
+    await test_delete_entry_type_async(request_type=dict)
 
 
-def test_delete_lake_field_headers():
-    client = DataplexServiceClient(
+def test_delete_entry_type_field_headers():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.DeleteLakeRequest()
+    request = catalog.DeleteEntryTypeRequest()
 
     request.name = "name_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.delete_lake), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.delete_entry_type), "__call__"
+    ) as call:
         call.return_value = operations_pb2.Operation(name="operations/op")
-        client.delete_lake(request)
+        client.delete_entry_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
@@ -1303,235 +2185,387 @@
     assert (
         "x-goog-request-params",
         "name=name_value",
     ) in kw["metadata"]
 
 
 @pytest.mark.asyncio
-async def test_delete_lake_field_headers_async():
-    client = DataplexServiceAsyncClient(
+async def test_delete_entry_type_field_headers_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.DeleteLakeRequest()
+    request = catalog.DeleteEntryTypeRequest()
 
     request.name = "name_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.delete_lake), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.delete_entry_type), "__call__"
+    ) as call:
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             operations_pb2.Operation(name="operations/op")
         )
-        await client.delete_lake(request)
+        await client.delete_entry_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
     _, _, kw = call.mock_calls[0]
     assert (
         "x-goog-request-params",
         "name=name_value",
     ) in kw["metadata"]
 
 
-def test_delete_lake_flattened():
-    client = DataplexServiceClient(
+def test_delete_entry_type_flattened():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.delete_lake), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.delete_entry_type), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/op")
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        client.delete_lake(
+        client.delete_entry_type(
             name="name_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         arg = args[0].name
         mock_val = "name_value"
         assert arg == mock_val
 
 
-def test_delete_lake_flattened_error():
-    client = DataplexServiceClient(
+def test_delete_entry_type_flattened_error():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        client.delete_lake(
-            service.DeleteLakeRequest(),
+        client.delete_entry_type(
+            catalog.DeleteEntryTypeRequest(),
             name="name_value",
         )
 
 
 @pytest.mark.asyncio
-async def test_delete_lake_flattened_async():
-    client = DataplexServiceAsyncClient(
+async def test_delete_entry_type_flattened_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.delete_lake), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.delete_entry_type), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/op")
 
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             operations_pb2.Operation(name="operations/spam")
         )
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        response = await client.delete_lake(
+        response = await client.delete_entry_type(
             name="name_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         arg = args[0].name
         mock_val = "name_value"
         assert arg == mock_val
 
 
 @pytest.mark.asyncio
-async def test_delete_lake_flattened_error_async():
-    client = DataplexServiceAsyncClient(
+async def test_delete_entry_type_flattened_error_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        await client.delete_lake(
-            service.DeleteLakeRequest(),
+        await client.delete_entry_type(
+            catalog.DeleteEntryTypeRequest(),
             name="name_value",
         )
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
-        service.ListLakesRequest,
+        catalog.ListEntryTypesRequest,
         dict,
     ],
 )
-def test_list_lakes(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
+def test_list_entry_types(request_type, transport: str = "grpc"):
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_lakes), "__call__") as call:
+    with mock.patch.object(type(client.transport.list_entry_types), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = service.ListLakesResponse(
+        call.return_value = catalog.ListEntryTypesResponse(
             next_page_token="next_page_token_value",
             unreachable_locations=["unreachable_locations_value"],
         )
-        response = client.list_lakes(request)
+        response = client.list_entry_types(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.ListLakesRequest()
+        request = catalog.ListEntryTypesRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
-    assert isinstance(response, pagers.ListLakesPager)
+    assert isinstance(response, pagers.ListEntryTypesPager)
     assert response.next_page_token == "next_page_token_value"
     assert response.unreachable_locations == ["unreachable_locations_value"]
 
 
-def test_list_lakes_empty_call():
+def test_list_entry_types_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
     # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_lakes), "__call__") as call:
-        client.list_lakes()
+    with mock.patch.object(type(client.transport.list_entry_types), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.list_entry_types()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.ListLakesRequest()
+        assert args[0] == catalog.ListEntryTypesRequest()
+
+
+def test_list_entry_types_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = CatalogServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = catalog.ListEntryTypesRequest(
+        parent="parent_value",
+        page_token="page_token_value",
+        filter="filter_value",
+        order_by="order_by_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_entry_types), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.list_entry_types(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == catalog.ListEntryTypesRequest(
+            parent="parent_value",
+            page_token="page_token_value",
+            filter="filter_value",
+            order_by="order_by_value",
+        )
+
+
+def test_list_entry_types_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = CatalogServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.list_entry_types in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.list_entry_types
+        ] = mock_rpc
+        request = {}
+        client.list_entry_types(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.list_entry_types(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_list_entry_types_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = CatalogServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_entry_types), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            catalog.ListEntryTypesResponse(
+                next_page_token="next_page_token_value",
+                unreachable_locations=["unreachable_locations_value"],
+            )
+        )
+        response = await client.list_entry_types()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == catalog.ListEntryTypesRequest()
+
+
+@pytest.mark.asyncio
+async def test_list_entry_types_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = CatalogServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.list_entry_types
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.list_entry_types
+        ] = mock_object
+
+        request = {}
+        await client.list_entry_types(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.list_entry_types(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
 
 
 @pytest.mark.asyncio
-async def test_list_lakes_async(
-    transport: str = "grpc_asyncio", request_type=service.ListLakesRequest
+async def test_list_entry_types_async(
+    transport: str = "grpc_asyncio", request_type=catalog.ListEntryTypesRequest
 ):
-    client = DataplexServiceAsyncClient(
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_lakes), "__call__") as call:
+    with mock.patch.object(type(client.transport.list_entry_types), "__call__") as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.ListLakesResponse(
+            catalog.ListEntryTypesResponse(
                 next_page_token="next_page_token_value",
                 unreachable_locations=["unreachable_locations_value"],
             )
         )
-        response = await client.list_lakes(request)
+        response = await client.list_entry_types(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.ListLakesRequest()
+        request = catalog.ListEntryTypesRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
-    assert isinstance(response, pagers.ListLakesAsyncPager)
+    assert isinstance(response, pagers.ListEntryTypesAsyncPager)
     assert response.next_page_token == "next_page_token_value"
     assert response.unreachable_locations == ["unreachable_locations_value"]
 
 
 @pytest.mark.asyncio
-async def test_list_lakes_async_from_dict():
-    await test_list_lakes_async(request_type=dict)
+async def test_list_entry_types_async_from_dict():
+    await test_list_entry_types_async(request_type=dict)
 
 
-def test_list_lakes_field_headers():
-    client = DataplexServiceClient(
+def test_list_entry_types_field_headers():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.ListLakesRequest()
+    request = catalog.ListEntryTypesRequest()
 
     request.parent = "parent_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_lakes), "__call__") as call:
-        call.return_value = service.ListLakesResponse()
-        client.list_lakes(request)
+    with mock.patch.object(type(client.transport.list_entry_types), "__call__") as call:
+        call.return_value = catalog.ListEntryTypesResponse()
+        client.list_entry_types(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
@@ -1539,441 +2573,593 @@
     assert (
         "x-goog-request-params",
         "parent=parent_value",
     ) in kw["metadata"]
 
 
 @pytest.mark.asyncio
-async def test_list_lakes_field_headers_async():
-    client = DataplexServiceAsyncClient(
+async def test_list_entry_types_field_headers_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.ListLakesRequest()
+    request = catalog.ListEntryTypesRequest()
 
     request.parent = "parent_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_lakes), "__call__") as call:
+    with mock.patch.object(type(client.transport.list_entry_types), "__call__") as call:
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.ListLakesResponse()
+            catalog.ListEntryTypesResponse()
         )
-        await client.list_lakes(request)
+        await client.list_entry_types(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
     _, _, kw = call.mock_calls[0]
     assert (
         "x-goog-request-params",
         "parent=parent_value",
     ) in kw["metadata"]
 
 
-def test_list_lakes_flattened():
-    client = DataplexServiceClient(
+def test_list_entry_types_flattened():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_lakes), "__call__") as call:
+    with mock.patch.object(type(client.transport.list_entry_types), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = service.ListLakesResponse()
+        call.return_value = catalog.ListEntryTypesResponse()
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        client.list_lakes(
+        client.list_entry_types(
             parent="parent_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         arg = args[0].parent
         mock_val = "parent_value"
         assert arg == mock_val
 
 
-def test_list_lakes_flattened_error():
-    client = DataplexServiceClient(
+def test_list_entry_types_flattened_error():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        client.list_lakes(
-            service.ListLakesRequest(),
+        client.list_entry_types(
+            catalog.ListEntryTypesRequest(),
             parent="parent_value",
         )
 
 
 @pytest.mark.asyncio
-async def test_list_lakes_flattened_async():
-    client = DataplexServiceAsyncClient(
+async def test_list_entry_types_flattened_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_lakes), "__call__") as call:
+    with mock.patch.object(type(client.transport.list_entry_types), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = service.ListLakesResponse()
+        call.return_value = catalog.ListEntryTypesResponse()
 
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.ListLakesResponse()
+            catalog.ListEntryTypesResponse()
         )
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        response = await client.list_lakes(
+        response = await client.list_entry_types(
             parent="parent_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         arg = args[0].parent
         mock_val = "parent_value"
         assert arg == mock_val
 
 
 @pytest.mark.asyncio
-async def test_list_lakes_flattened_error_async():
-    client = DataplexServiceAsyncClient(
+async def test_list_entry_types_flattened_error_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        await client.list_lakes(
-            service.ListLakesRequest(),
+        await client.list_entry_types(
+            catalog.ListEntryTypesRequest(),
             parent="parent_value",
         )
 
 
-def test_list_lakes_pager(transport_name: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
+def test_list_entry_types_pager(transport_name: str = "grpc"):
+    client = CatalogServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
         transport=transport_name,
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_lakes), "__call__") as call:
+    with mock.patch.object(type(client.transport.list_entry_types), "__call__") as call:
         # Set the response to a series of pages.
         call.side_effect = (
-            service.ListLakesResponse(
-                lakes=[
-                    resources.Lake(),
-                    resources.Lake(),
-                    resources.Lake(),
+            catalog.ListEntryTypesResponse(
+                entry_types=[
+                    catalog.EntryType(),
+                    catalog.EntryType(),
+                    catalog.EntryType(),
                 ],
                 next_page_token="abc",
             ),
-            service.ListLakesResponse(
-                lakes=[],
+            catalog.ListEntryTypesResponse(
+                entry_types=[],
                 next_page_token="def",
             ),
-            service.ListLakesResponse(
-                lakes=[
-                    resources.Lake(),
+            catalog.ListEntryTypesResponse(
+                entry_types=[
+                    catalog.EntryType(),
                 ],
                 next_page_token="ghi",
             ),
-            service.ListLakesResponse(
-                lakes=[
-                    resources.Lake(),
-                    resources.Lake(),
+            catalog.ListEntryTypesResponse(
+                entry_types=[
+                    catalog.EntryType(),
+                    catalog.EntryType(),
                 ],
             ),
             RuntimeError,
         )
 
         metadata = ()
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", ""),)),
         )
-        pager = client.list_lakes(request={})
+        pager = client.list_entry_types(request={})
 
         assert pager._metadata == metadata
 
         results = list(pager)
         assert len(results) == 6
-        assert all(isinstance(i, resources.Lake) for i in results)
+        assert all(isinstance(i, catalog.EntryType) for i in results)
 
 
-def test_list_lakes_pages(transport_name: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
+def test_list_entry_types_pages(transport_name: str = "grpc"):
+    client = CatalogServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
         transport=transport_name,
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_lakes), "__call__") as call:
+    with mock.patch.object(type(client.transport.list_entry_types), "__call__") as call:
         # Set the response to a series of pages.
         call.side_effect = (
-            service.ListLakesResponse(
-                lakes=[
-                    resources.Lake(),
-                    resources.Lake(),
-                    resources.Lake(),
+            catalog.ListEntryTypesResponse(
+                entry_types=[
+                    catalog.EntryType(),
+                    catalog.EntryType(),
+                    catalog.EntryType(),
                 ],
                 next_page_token="abc",
             ),
-            service.ListLakesResponse(
-                lakes=[],
+            catalog.ListEntryTypesResponse(
+                entry_types=[],
                 next_page_token="def",
             ),
-            service.ListLakesResponse(
-                lakes=[
-                    resources.Lake(),
+            catalog.ListEntryTypesResponse(
+                entry_types=[
+                    catalog.EntryType(),
                 ],
                 next_page_token="ghi",
             ),
-            service.ListLakesResponse(
-                lakes=[
-                    resources.Lake(),
-                    resources.Lake(),
+            catalog.ListEntryTypesResponse(
+                entry_types=[
+                    catalog.EntryType(),
+                    catalog.EntryType(),
                 ],
             ),
             RuntimeError,
         )
-        pages = list(client.list_lakes(request={}).pages)
+        pages = list(client.list_entry_types(request={}).pages)
         for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
             assert page_.raw_page.next_page_token == token
 
 
 @pytest.mark.asyncio
-async def test_list_lakes_async_pager():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
+async def test_list_entry_types_async_pager():
+    client = CatalogServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
-        type(client.transport.list_lakes), "__call__", new_callable=mock.AsyncMock
+        type(client.transport.list_entry_types), "__call__", new_callable=mock.AsyncMock
     ) as call:
         # Set the response to a series of pages.
         call.side_effect = (
-            service.ListLakesResponse(
-                lakes=[
-                    resources.Lake(),
-                    resources.Lake(),
-                    resources.Lake(),
+            catalog.ListEntryTypesResponse(
+                entry_types=[
+                    catalog.EntryType(),
+                    catalog.EntryType(),
+                    catalog.EntryType(),
                 ],
                 next_page_token="abc",
             ),
-            service.ListLakesResponse(
-                lakes=[],
+            catalog.ListEntryTypesResponse(
+                entry_types=[],
                 next_page_token="def",
             ),
-            service.ListLakesResponse(
-                lakes=[
-                    resources.Lake(),
+            catalog.ListEntryTypesResponse(
+                entry_types=[
+                    catalog.EntryType(),
                 ],
                 next_page_token="ghi",
             ),
-            service.ListLakesResponse(
-                lakes=[
-                    resources.Lake(),
-                    resources.Lake(),
+            catalog.ListEntryTypesResponse(
+                entry_types=[
+                    catalog.EntryType(),
+                    catalog.EntryType(),
                 ],
             ),
             RuntimeError,
         )
-        async_pager = await client.list_lakes(
+        async_pager = await client.list_entry_types(
             request={},
         )
         assert async_pager.next_page_token == "abc"
         responses = []
         async for response in async_pager:  # pragma: no branch
             responses.append(response)
 
         assert len(responses) == 6
-        assert all(isinstance(i, resources.Lake) for i in responses)
+        assert all(isinstance(i, catalog.EntryType) for i in responses)
 
 
 @pytest.mark.asyncio
-async def test_list_lakes_async_pages():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
+async def test_list_entry_types_async_pages():
+    client = CatalogServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
-        type(client.transport.list_lakes), "__call__", new_callable=mock.AsyncMock
+        type(client.transport.list_entry_types), "__call__", new_callable=mock.AsyncMock
     ) as call:
         # Set the response to a series of pages.
         call.side_effect = (
-            service.ListLakesResponse(
-                lakes=[
-                    resources.Lake(),
-                    resources.Lake(),
-                    resources.Lake(),
+            catalog.ListEntryTypesResponse(
+                entry_types=[
+                    catalog.EntryType(),
+                    catalog.EntryType(),
+                    catalog.EntryType(),
                 ],
                 next_page_token="abc",
             ),
-            service.ListLakesResponse(
-                lakes=[],
+            catalog.ListEntryTypesResponse(
+                entry_types=[],
                 next_page_token="def",
             ),
-            service.ListLakesResponse(
-                lakes=[
-                    resources.Lake(),
+            catalog.ListEntryTypesResponse(
+                entry_types=[
+                    catalog.EntryType(),
                 ],
                 next_page_token="ghi",
             ),
-            service.ListLakesResponse(
-                lakes=[
-                    resources.Lake(),
-                    resources.Lake(),
+            catalog.ListEntryTypesResponse(
+                entry_types=[
+                    catalog.EntryType(),
+                    catalog.EntryType(),
                 ],
             ),
             RuntimeError,
         )
         pages = []
         # Workaround issue in python 3.9 related to code coverage by adding `# pragma: no branch`
         # See https://github.com/googleapis/gapic-generator-python/pull/1174#issuecomment-1025132372
         async for page_ in (  # pragma: no branch
-            await client.list_lakes(request={})
+            await client.list_entry_types(request={})
         ).pages:
             pages.append(page_)
         for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
             assert page_.raw_page.next_page_token == token
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
-        service.GetLakeRequest,
+        catalog.GetEntryTypeRequest,
         dict,
     ],
 )
-def test_get_lake(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
+def test_get_entry_type(request_type, transport: str = "grpc"):
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_lake), "__call__") as call:
+    with mock.patch.object(type(client.transport.get_entry_type), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = resources.Lake(
+        call.return_value = catalog.EntryType(
             name="name_value",
-            display_name="display_name_value",
             uid="uid_value",
             description="description_value",
-            state=resources.State.ACTIVE,
-            service_account="service_account_value",
+            display_name="display_name_value",
+            etag="etag_value",
+            type_aliases=["type_aliases_value"],
+            platform="platform_value",
+            system="system_value",
         )
-        response = client.get_lake(request)
+        response = client.get_entry_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.GetLakeRequest()
+        request = catalog.GetEntryTypeRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
-    assert isinstance(response, resources.Lake)
+    assert isinstance(response, catalog.EntryType)
     assert response.name == "name_value"
-    assert response.display_name == "display_name_value"
     assert response.uid == "uid_value"
     assert response.description == "description_value"
-    assert response.state == resources.State.ACTIVE
-    assert response.service_account == "service_account_value"
+    assert response.display_name == "display_name_value"
+    assert response.etag == "etag_value"
+    assert response.type_aliases == ["type_aliases_value"]
+    assert response.platform == "platform_value"
+    assert response.system == "system_value"
 
 
-def test_get_lake_empty_call():
+def test_get_entry_type_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
     # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_entry_type), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.get_entry_type()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == catalog.GetEntryTypeRequest()
+
+
+def test_get_entry_type_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = catalog.GetEntryTypeRequest(
+        name="name_value",
+    )
+
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_lake), "__call__") as call:
-        client.get_lake()
+    with mock.patch.object(type(client.transport.get_entry_type), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.get_entry_type(request=request)
         call.assert_called()
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.GetLakeRequest()
+        assert args[0] == catalog.GetEntryTypeRequest(
+            name="name_value",
+        )
+
+
+def test_get_entry_type_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = CatalogServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.get_entry_type in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[client._transport.get_entry_type] = mock_rpc
+        request = {}
+        client.get_entry_type(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.get_entry_type(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
 
 
 @pytest.mark.asyncio
-async def test_get_lake_async(
-    transport: str = "grpc_asyncio", request_type=service.GetLakeRequest
+async def test_get_entry_type_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = CatalogServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_entry_type), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            catalog.EntryType(
+                name="name_value",
+                uid="uid_value",
+                description="description_value",
+                display_name="display_name_value",
+                etag="etag_value",
+                type_aliases=["type_aliases_value"],
+                platform="platform_value",
+                system="system_value",
+            )
+        )
+        response = await client.get_entry_type()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == catalog.GetEntryTypeRequest()
+
+
+@pytest.mark.asyncio
+async def test_get_entry_type_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
 ):
-    client = DataplexServiceAsyncClient(
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = CatalogServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.get_entry_type
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.get_entry_type
+        ] = mock_object
+
+        request = {}
+        await client.get_entry_type(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.get_entry_type(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_get_entry_type_async(
+    transport: str = "grpc_asyncio", request_type=catalog.GetEntryTypeRequest
+):
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_lake), "__call__") as call:
+    with mock.patch.object(type(client.transport.get_entry_type), "__call__") as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            resources.Lake(
+            catalog.EntryType(
                 name="name_value",
-                display_name="display_name_value",
                 uid="uid_value",
                 description="description_value",
-                state=resources.State.ACTIVE,
-                service_account="service_account_value",
+                display_name="display_name_value",
+                etag="etag_value",
+                type_aliases=["type_aliases_value"],
+                platform="platform_value",
+                system="system_value",
             )
         )
-        response = await client.get_lake(request)
+        response = await client.get_entry_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.GetLakeRequest()
+        request = catalog.GetEntryTypeRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
-    assert isinstance(response, resources.Lake)
+    assert isinstance(response, catalog.EntryType)
     assert response.name == "name_value"
-    assert response.display_name == "display_name_value"
     assert response.uid == "uid_value"
     assert response.description == "description_value"
-    assert response.state == resources.State.ACTIVE
-    assert response.service_account == "service_account_value"
+    assert response.display_name == "display_name_value"
+    assert response.etag == "etag_value"
+    assert response.type_aliases == ["type_aliases_value"]
+    assert response.platform == "platform_value"
+    assert response.system == "system_value"
 
 
 @pytest.mark.asyncio
-async def test_get_lake_async_from_dict():
-    await test_get_lake_async(request_type=dict)
+async def test_get_entry_type_async_from_dict():
+    await test_get_entry_type_async(request_type=dict)
 
 
-def test_get_lake_field_headers():
-    client = DataplexServiceClient(
+def test_get_entry_type_field_headers():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.GetLakeRequest()
+    request = catalog.GetEntryTypeRequest()
 
     request.name = "name_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_lake), "__call__") as call:
-        call.return_value = resources.Lake()
-        client.get_lake(request)
+    with mock.patch.object(type(client.transport.get_entry_type), "__call__") as call:
+        call.return_value = catalog.EntryType()
+        client.get_entry_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
@@ -1981,665 +3167,382 @@
     assert (
         "x-goog-request-params",
         "name=name_value",
     ) in kw["metadata"]
 
 
 @pytest.mark.asyncio
-async def test_get_lake_field_headers_async():
-    client = DataplexServiceAsyncClient(
+async def test_get_entry_type_field_headers_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.GetLakeRequest()
+    request = catalog.GetEntryTypeRequest()
 
     request.name = "name_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_lake), "__call__") as call:
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(resources.Lake())
-        await client.get_lake(request)
+    with mock.patch.object(type(client.transport.get_entry_type), "__call__") as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(catalog.EntryType())
+        await client.get_entry_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
     _, _, kw = call.mock_calls[0]
     assert (
         "x-goog-request-params",
         "name=name_value",
     ) in kw["metadata"]
 
 
-def test_get_lake_flattened():
-    client = DataplexServiceClient(
+def test_get_entry_type_flattened():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_lake), "__call__") as call:
+    with mock.patch.object(type(client.transport.get_entry_type), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = resources.Lake()
+        call.return_value = catalog.EntryType()
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        client.get_lake(
+        client.get_entry_type(
             name="name_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         arg = args[0].name
         mock_val = "name_value"
         assert arg == mock_val
 
 
-def test_get_lake_flattened_error():
-    client = DataplexServiceClient(
+def test_get_entry_type_flattened_error():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        client.get_lake(
-            service.GetLakeRequest(),
+        client.get_entry_type(
+            catalog.GetEntryTypeRequest(),
             name="name_value",
         )
 
 
 @pytest.mark.asyncio
-async def test_get_lake_flattened_async():
-    client = DataplexServiceAsyncClient(
+async def test_get_entry_type_flattened_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_lake), "__call__") as call:
+    with mock.patch.object(type(client.transport.get_entry_type), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = resources.Lake()
+        call.return_value = catalog.EntryType()
 
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(resources.Lake())
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(catalog.EntryType())
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        response = await client.get_lake(
+        response = await client.get_entry_type(
             name="name_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         arg = args[0].name
         mock_val = "name_value"
         assert arg == mock_val
 
 
 @pytest.mark.asyncio
-async def test_get_lake_flattened_error_async():
-    client = DataplexServiceAsyncClient(
+async def test_get_entry_type_flattened_error_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        await client.get_lake(
-            service.GetLakeRequest(),
+        await client.get_entry_type(
+            catalog.GetEntryTypeRequest(),
             name="name_value",
         )
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
-        service.ListLakeActionsRequest,
+        catalog.CreateAspectTypeRequest,
         dict,
     ],
 )
-def test_list_lake_actions(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
+def test_create_aspect_type(request_type, transport: str = "grpc"):
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
-        type(client.transport.list_lake_actions), "__call__"
+        type(client.transport.create_aspect_type), "__call__"
     ) as call:
         # Designate an appropriate return value for the call.
-        call.return_value = service.ListActionsResponse(
-            next_page_token="next_page_token_value",
-        )
-        response = client.list_lake_actions(request)
+        call.return_value = operations_pb2.Operation(name="operations/spam")
+        response = client.create_aspect_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.ListLakeActionsRequest()
+        request = catalog.CreateAspectTypeRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
-    assert isinstance(response, pagers.ListLakeActionsPager)
-    assert response.next_page_token == "next_page_token_value"
+    assert isinstance(response, future.Future)
 
 
-def test_list_lake_actions_empty_call():
+def test_create_aspect_type_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
     # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
-        type(client.transport.list_lake_actions), "__call__"
+        type(client.transport.create_aspect_type), "__call__"
     ) as call:
-        client.list_lake_actions()
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.create_aspect_type()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.ListLakeActionsRequest()
+        assert args[0] == catalog.CreateAspectTypeRequest()
 
 
-@pytest.mark.asyncio
-async def test_list_lake_actions_async(
-    transport: str = "grpc_asyncio", request_type=service.ListLakeActionsRequest
-):
-    client = DataplexServiceAsyncClient(
+def test_create_aspect_type_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
-        transport=transport,
+        transport="grpc",
     )
 
-    # Everything is optional in proto3 as far as the runtime is concerned,
-    # and we are mocking out the actual API, so just send an empty request.
-    request = request_type()
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_lake_actions), "__call__"
-    ) as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.ListActionsResponse(
-                next_page_token="next_page_token_value",
-            )
-        )
-        response = await client.list_lake_actions(request)
-
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls)
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.ListLakeActionsRequest()
-
-    # Establish that the response is the type that we expect.
-    assert isinstance(response, pagers.ListLakeActionsAsyncPager)
-    assert response.next_page_token == "next_page_token_value"
-
-
-@pytest.mark.asyncio
-async def test_list_lake_actions_async_from_dict():
-    await test_list_lake_actions_async(request_type=dict)
-
-
-def test_list_lake_actions_field_headers():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = catalog.CreateAspectTypeRequest(
+        parent="parent_value",
+        aspect_type_id="aspect_type_id_value",
     )
 
-    # Any value that is part of the HTTP/1.1 URI should be sent as
-    # a field header. Set these to a non-empty value.
-    request = service.ListLakeActionsRequest()
-
-    request.parent = "parent_value"
-
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
-        type(client.transport.list_lake_actions), "__call__"
+        type(client.transport.create_aspect_type), "__call__"
     ) as call:
-        call.return_value = service.ListActionsResponse()
-        client.list_lake_actions(request)
-
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls) == 1
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.create_aspect_type(request=request)
+        call.assert_called()
         _, args, _ = call.mock_calls[0]
-        assert args[0] == request
-
-    # Establish that the field header was sent.
-    _, _, kw = call.mock_calls[0]
-    assert (
-        "x-goog-request-params",
-        "parent=parent_value",
-    ) in kw["metadata"]
-
-
-@pytest.mark.asyncio
-async def test_list_lake_actions_field_headers_async():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Any value that is part of the HTTP/1.1 URI should be sent as
-    # a field header. Set these to a non-empty value.
-    request = service.ListLakeActionsRequest()
-
-    request.parent = "parent_value"
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_lake_actions), "__call__"
-    ) as call:
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.ListActionsResponse()
+        assert args[0] == catalog.CreateAspectTypeRequest(
+            parent="parent_value",
+            aspect_type_id="aspect_type_id_value",
         )
-        await client.list_lake_actions(request)
 
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls)
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == request
 
-    # Establish that the field header was sent.
-    _, _, kw = call.mock_calls[0]
-    assert (
-        "x-goog-request-params",
-        "parent=parent_value",
-    ) in kw["metadata"]
+def test_create_aspect_type_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = CatalogServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
 
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
 
-def test_list_lake_actions_flattened():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
+        # Ensure method has been cached
+        assert (
+            client._transport.create_aspect_type in client._transport._wrapped_methods
+        )
 
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_lake_actions), "__call__"
-    ) as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = service.ListActionsResponse()
-        # Call the method with a truthy value for each flattened field,
-        # using the keyword arguments to the method.
-        client.list_lake_actions(
-            parent="parent_value",
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
         )
+        client._transport._wrapped_methods[
+            client._transport.create_aspect_type
+        ] = mock_rpc
+        request = {}
+        client.create_aspect_type(request)
 
-        # Establish that the underlying call was made with the expected
-        # request object values.
-        assert len(call.mock_calls) == 1
-        _, args, _ = call.mock_calls[0]
-        arg = args[0].parent
-        mock_val = "parent_value"
-        assert arg == mock_val
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
 
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
 
-def test_list_lake_actions_flattened_error():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
+        client.create_aspect_type(request)
 
-    # Attempting to call a method with both a request object and flattened
-    # fields is an error.
-    with pytest.raises(ValueError):
-        client.list_lake_actions(
-            service.ListLakeActionsRequest(),
-            parent="parent_value",
-        )
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
 
 
 @pytest.mark.asyncio
-async def test_list_lake_actions_flattened_async():
-    client = DataplexServiceAsyncClient(
+async def test_create_aspect_type_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
-        type(client.transport.list_lake_actions), "__call__"
+        type(client.transport.create_aspect_type), "__call__"
     ) as call:
         # Designate an appropriate return value for the call.
-        call.return_value = service.ListActionsResponse()
-
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.ListActionsResponse()
-        )
-        # Call the method with a truthy value for each flattened field,
-        # using the keyword arguments to the method.
-        response = await client.list_lake_actions(
-            parent="parent_value",
+            operations_pb2.Operation(name="operations/spam")
         )
-
-        # Establish that the underlying call was made with the expected
-        # request object values.
-        assert len(call.mock_calls)
+        response = await client.create_aspect_type()
+        call.assert_called()
         _, args, _ = call.mock_calls[0]
-        arg = args[0].parent
-        mock_val = "parent_value"
-        assert arg == mock_val
-
-
-@pytest.mark.asyncio
-async def test_list_lake_actions_flattened_error_async():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Attempting to call a method with both a request object and flattened
-    # fields is an error.
-    with pytest.raises(ValueError):
-        await client.list_lake_actions(
-            service.ListLakeActionsRequest(),
-            parent="parent_value",
-        )
-
-
-def test_list_lake_actions_pager(transport_name: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
-        transport=transport_name,
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_lake_actions), "__call__"
-    ) as call:
-        # Set the response to a series of pages.
-        call.side_effect = (
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                    resources.Action(),
-                    resources.Action(),
-                ],
-                next_page_token="abc",
-            ),
-            service.ListActionsResponse(
-                actions=[],
-                next_page_token="def",
-            ),
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                ],
-                next_page_token="ghi",
-            ),
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                    resources.Action(),
-                ],
-            ),
-            RuntimeError,
-        )
-
-        metadata = ()
-        metadata = tuple(metadata) + (
-            gapic_v1.routing_header.to_grpc_metadata((("parent", ""),)),
-        )
-        pager = client.list_lake_actions(request={})
-
-        assert pager._metadata == metadata
-
-        results = list(pager)
-        assert len(results) == 6
-        assert all(isinstance(i, resources.Action) for i in results)
-
-
-def test_list_lake_actions_pages(transport_name: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
-        transport=transport_name,
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_lake_actions), "__call__"
-    ) as call:
-        # Set the response to a series of pages.
-        call.side_effect = (
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                    resources.Action(),
-                    resources.Action(),
-                ],
-                next_page_token="abc",
-            ),
-            service.ListActionsResponse(
-                actions=[],
-                next_page_token="def",
-            ),
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                ],
-                next_page_token="ghi",
-            ),
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                    resources.Action(),
-                ],
-            ),
-            RuntimeError,
-        )
-        pages = list(client.list_lake_actions(request={}).pages)
-        for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
-            assert page_.raw_page.next_page_token == token
+        assert args[0] == catalog.CreateAspectTypeRequest()
 
 
 @pytest.mark.asyncio
-async def test_list_lake_actions_async_pager():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_lake_actions),
-        "__call__",
-        new_callable=mock.AsyncMock,
-    ) as call:
-        # Set the response to a series of pages.
-        call.side_effect = (
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                    resources.Action(),
-                    resources.Action(),
-                ],
-                next_page_token="abc",
-            ),
-            service.ListActionsResponse(
-                actions=[],
-                next_page_token="def",
-            ),
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                ],
-                next_page_token="ghi",
-            ),
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                    resources.Action(),
-                ],
-            ),
-            RuntimeError,
-        )
-        async_pager = await client.list_lake_actions(
-            request={},
+async def test_create_aspect_type_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = CatalogServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
         )
-        assert async_pager.next_page_token == "abc"
-        responses = []
-        async for response in async_pager:  # pragma: no branch
-            responses.append(response)
-
-        assert len(responses) == 6
-        assert all(isinstance(i, resources.Action) for i in responses)
 
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
 
-@pytest.mark.asyncio
-async def test_list_lake_actions_async_pages():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_lake_actions),
-        "__call__",
-        new_callable=mock.AsyncMock,
-    ) as call:
-        # Set the response to a series of pages.
-        call.side_effect = (
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                    resources.Action(),
-                    resources.Action(),
-                ],
-                next_page_token="abc",
-            ),
-            service.ListActionsResponse(
-                actions=[],
-                next_page_token="def",
-            ),
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                ],
-                next_page_token="ghi",
-            ),
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                    resources.Action(),
-                ],
-            ),
-            RuntimeError,
+        # Ensure method has been cached
+        assert (
+            client._client._transport.create_aspect_type
+            in client._client._transport._wrapped_methods
         )
-        pages = []
-        # Workaround issue in python 3.9 related to code coverage by adding `# pragma: no branch`
-        # See https://github.com/googleapis/gapic-generator-python/pull/1174#issuecomment-1025132372
-        async for page_ in (  # pragma: no branch
-            await client.list_lake_actions(request={})
-        ).pages:
-            pages.append(page_)
-        for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
-            assert page_.raw_page.next_page_token == token
-
 
-@pytest.mark.parametrize(
-    "request_type",
-    [
-        service.CreateZoneRequest,
-        dict,
-    ],
-)
-def test_create_zone(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-        transport=transport,
-    )
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
 
-    # Everything is optional in proto3 as far as the runtime is concerned,
-    # and we are mocking out the actual API, so just send an empty request.
-    request = request_type()
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.create_aspect_type
+        ] = mock_object
 
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.create_zone), "__call__") as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = operations_pb2.Operation(name="operations/spam")
-        response = client.create_zone(request)
+        request = {}
+        await client.create_aspect_type(request)
 
         # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls) == 1
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.CreateZoneRequest()
-
-    # Establish that the response is the type that we expect.
-    assert isinstance(response, future.Future)
+        assert mock_object.call_count == 1
 
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
 
-def test_create_zone_empty_call():
-    # This test is a coverage failsafe to make sure that totally empty calls,
-    # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-        transport="grpc",
-    )
+        await client.create_aspect_type(request)
 
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.create_zone), "__call__") as call:
-        client.create_zone()
-        call.assert_called()
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.CreateZoneRequest()
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
 
 
 @pytest.mark.asyncio
-async def test_create_zone_async(
-    transport: str = "grpc_asyncio", request_type=service.CreateZoneRequest
+async def test_create_aspect_type_async(
+    transport: str = "grpc_asyncio", request_type=catalog.CreateAspectTypeRequest
 ):
-    client = DataplexServiceAsyncClient(
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.create_zone), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.create_aspect_type), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             operations_pb2.Operation(name="operations/spam")
         )
-        response = await client.create_zone(request)
+        response = await client.create_aspect_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.CreateZoneRequest()
+        request = catalog.CreateAspectTypeRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 @pytest.mark.asyncio
-async def test_create_zone_async_from_dict():
-    await test_create_zone_async(request_type=dict)
+async def test_create_aspect_type_async_from_dict():
+    await test_create_aspect_type_async(request_type=dict)
 
 
-def test_create_zone_field_headers():
-    client = DataplexServiceClient(
+def test_create_aspect_type_field_headers():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.CreateZoneRequest()
+    request = catalog.CreateAspectTypeRequest()
 
     request.parent = "parent_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.create_zone), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.create_aspect_type), "__call__"
+    ) as call:
         call.return_value = operations_pb2.Operation(name="operations/op")
-        client.create_zone(request)
+        client.create_aspect_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
@@ -2647,481 +3550,809 @@
     assert (
         "x-goog-request-params",
         "parent=parent_value",
     ) in kw["metadata"]
 
 
 @pytest.mark.asyncio
-async def test_create_zone_field_headers_async():
-    client = DataplexServiceAsyncClient(
+async def test_create_aspect_type_field_headers_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.CreateZoneRequest()
+    request = catalog.CreateAspectTypeRequest()
 
     request.parent = "parent_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.create_zone), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.create_aspect_type), "__call__"
+    ) as call:
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             operations_pb2.Operation(name="operations/op")
         )
-        await client.create_zone(request)
+        await client.create_aspect_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
     _, _, kw = call.mock_calls[0]
     assert (
         "x-goog-request-params",
         "parent=parent_value",
     ) in kw["metadata"]
 
 
-def test_create_zone_flattened():
-    client = DataplexServiceClient(
+def test_create_aspect_type_flattened():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.create_zone), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.create_aspect_type), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/op")
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        client.create_zone(
+        client.create_aspect_type(
             parent="parent_value",
-            zone=resources.Zone(name="name_value"),
-            zone_id="zone_id_value",
+            aspect_type=catalog.AspectType(name="name_value"),
+            aspect_type_id="aspect_type_id_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         arg = args[0].parent
         mock_val = "parent_value"
         assert arg == mock_val
-        arg = args[0].zone
-        mock_val = resources.Zone(name="name_value")
+        arg = args[0].aspect_type
+        mock_val = catalog.AspectType(name="name_value")
         assert arg == mock_val
-        arg = args[0].zone_id
-        mock_val = "zone_id_value"
+        arg = args[0].aspect_type_id
+        mock_val = "aspect_type_id_value"
         assert arg == mock_val
 
 
-def test_create_zone_flattened_error():
-    client = DataplexServiceClient(
+def test_create_aspect_type_flattened_error():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        client.create_zone(
-            service.CreateZoneRequest(),
+        client.create_aspect_type(
+            catalog.CreateAspectTypeRequest(),
             parent="parent_value",
-            zone=resources.Zone(name="name_value"),
-            zone_id="zone_id_value",
+            aspect_type=catalog.AspectType(name="name_value"),
+            aspect_type_id="aspect_type_id_value",
         )
 
 
 @pytest.mark.asyncio
-async def test_create_zone_flattened_async():
-    client = DataplexServiceAsyncClient(
+async def test_create_aspect_type_flattened_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.create_zone), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.create_aspect_type), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/op")
 
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             operations_pb2.Operation(name="operations/spam")
         )
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        response = await client.create_zone(
+        response = await client.create_aspect_type(
             parent="parent_value",
-            zone=resources.Zone(name="name_value"),
-            zone_id="zone_id_value",
+            aspect_type=catalog.AspectType(name="name_value"),
+            aspect_type_id="aspect_type_id_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         arg = args[0].parent
         mock_val = "parent_value"
         assert arg == mock_val
-        arg = args[0].zone
-        mock_val = resources.Zone(name="name_value")
+        arg = args[0].aspect_type
+        mock_val = catalog.AspectType(name="name_value")
         assert arg == mock_val
-        arg = args[0].zone_id
-        mock_val = "zone_id_value"
+        arg = args[0].aspect_type_id
+        mock_val = "aspect_type_id_value"
         assert arg == mock_val
 
 
 @pytest.mark.asyncio
-async def test_create_zone_flattened_error_async():
-    client = DataplexServiceAsyncClient(
+async def test_create_aspect_type_flattened_error_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        await client.create_zone(
-            service.CreateZoneRequest(),
+        await client.create_aspect_type(
+            catalog.CreateAspectTypeRequest(),
             parent="parent_value",
-            zone=resources.Zone(name="name_value"),
-            zone_id="zone_id_value",
+            aspect_type=catalog.AspectType(name="name_value"),
+            aspect_type_id="aspect_type_id_value",
         )
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
-        service.UpdateZoneRequest,
+        catalog.UpdateAspectTypeRequest,
         dict,
     ],
 )
-def test_update_zone(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
+def test_update_aspect_type(request_type, transport: str = "grpc"):
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.update_zone), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.update_aspect_type), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/spam")
-        response = client.update_zone(request)
+        response = client.update_aspect_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.UpdateZoneRequest()
+        request = catalog.UpdateAspectTypeRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
-def test_update_zone_empty_call():
+def test_update_aspect_type_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
     # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.update_zone), "__call__") as call:
-        client.update_zone()
+    with mock.patch.object(
+        type(client.transport.update_aspect_type), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.update_aspect_type()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.UpdateZoneRequest()
+        assert args[0] == catalog.UpdateAspectTypeRequest()
+
+
+def test_update_aspect_type_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = CatalogServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = catalog.UpdateAspectTypeRequest()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.update_aspect_type), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.update_aspect_type(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == catalog.UpdateAspectTypeRequest()
+
+
+def test_update_aspect_type_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = CatalogServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._transport.update_aspect_type in client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.update_aspect_type
+        ] = mock_rpc
+        request = {}
+        client.update_aspect_type(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        client.update_aspect_type(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_update_aspect_type_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = CatalogServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.update_aspect_type), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        response = await client.update_aspect_type()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == catalog.UpdateAspectTypeRequest()
 
 
 @pytest.mark.asyncio
-async def test_update_zone_async(
-    transport: str = "grpc_asyncio", request_type=service.UpdateZoneRequest
+async def test_update_aspect_type_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
 ):
-    client = DataplexServiceAsyncClient(
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = CatalogServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.update_aspect_type
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.update_aspect_type
+        ] = mock_object
+
+        request = {}
+        await client.update_aspect_type(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        await client.update_aspect_type(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_update_aspect_type_async(
+    transport: str = "grpc_asyncio", request_type=catalog.UpdateAspectTypeRequest
+):
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.update_zone), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.update_aspect_type), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             operations_pb2.Operation(name="operations/spam")
         )
-        response = await client.update_zone(request)
+        response = await client.update_aspect_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.UpdateZoneRequest()
+        request = catalog.UpdateAspectTypeRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 @pytest.mark.asyncio
-async def test_update_zone_async_from_dict():
-    await test_update_zone_async(request_type=dict)
+async def test_update_aspect_type_async_from_dict():
+    await test_update_aspect_type_async(request_type=dict)
 
 
-def test_update_zone_field_headers():
-    client = DataplexServiceClient(
+def test_update_aspect_type_field_headers():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.UpdateZoneRequest()
+    request = catalog.UpdateAspectTypeRequest()
 
-    request.zone.name = "name_value"
+    request.aspect_type.name = "name_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.update_zone), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.update_aspect_type), "__call__"
+    ) as call:
         call.return_value = operations_pb2.Operation(name="operations/op")
-        client.update_zone(request)
+        client.update_aspect_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
     _, _, kw = call.mock_calls[0]
     assert (
         "x-goog-request-params",
-        "zone.name=name_value",
+        "aspect_type.name=name_value",
     ) in kw["metadata"]
 
 
 @pytest.mark.asyncio
-async def test_update_zone_field_headers_async():
-    client = DataplexServiceAsyncClient(
+async def test_update_aspect_type_field_headers_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.UpdateZoneRequest()
+    request = catalog.UpdateAspectTypeRequest()
 
-    request.zone.name = "name_value"
+    request.aspect_type.name = "name_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.update_zone), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.update_aspect_type), "__call__"
+    ) as call:
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             operations_pb2.Operation(name="operations/op")
         )
-        await client.update_zone(request)
+        await client.update_aspect_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
     _, _, kw = call.mock_calls[0]
     assert (
         "x-goog-request-params",
-        "zone.name=name_value",
+        "aspect_type.name=name_value",
     ) in kw["metadata"]
 
 
-def test_update_zone_flattened():
-    client = DataplexServiceClient(
+def test_update_aspect_type_flattened():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.update_zone), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.update_aspect_type), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/op")
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        client.update_zone(
-            zone=resources.Zone(name="name_value"),
+        client.update_aspect_type(
+            aspect_type=catalog.AspectType(name="name_value"),
             update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        arg = args[0].zone
-        mock_val = resources.Zone(name="name_value")
+        arg = args[0].aspect_type
+        mock_val = catalog.AspectType(name="name_value")
         assert arg == mock_val
         arg = args[0].update_mask
         mock_val = field_mask_pb2.FieldMask(paths=["paths_value"])
         assert arg == mock_val
 
 
-def test_update_zone_flattened_error():
-    client = DataplexServiceClient(
+def test_update_aspect_type_flattened_error():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        client.update_zone(
-            service.UpdateZoneRequest(),
-            zone=resources.Zone(name="name_value"),
+        client.update_aspect_type(
+            catalog.UpdateAspectTypeRequest(),
+            aspect_type=catalog.AspectType(name="name_value"),
             update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
         )
 
 
 @pytest.mark.asyncio
-async def test_update_zone_flattened_async():
-    client = DataplexServiceAsyncClient(
+async def test_update_aspect_type_flattened_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.update_zone), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.update_aspect_type), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/op")
 
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             operations_pb2.Operation(name="operations/spam")
         )
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        response = await client.update_zone(
-            zone=resources.Zone(name="name_value"),
+        response = await client.update_aspect_type(
+            aspect_type=catalog.AspectType(name="name_value"),
             update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        arg = args[0].zone
-        mock_val = resources.Zone(name="name_value")
+        arg = args[0].aspect_type
+        mock_val = catalog.AspectType(name="name_value")
         assert arg == mock_val
         arg = args[0].update_mask
         mock_val = field_mask_pb2.FieldMask(paths=["paths_value"])
         assert arg == mock_val
 
 
 @pytest.mark.asyncio
-async def test_update_zone_flattened_error_async():
-    client = DataplexServiceAsyncClient(
+async def test_update_aspect_type_flattened_error_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        await client.update_zone(
-            service.UpdateZoneRequest(),
-            zone=resources.Zone(name="name_value"),
+        await client.update_aspect_type(
+            catalog.UpdateAspectTypeRequest(),
+            aspect_type=catalog.AspectType(name="name_value"),
             update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
         )
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
-        service.DeleteZoneRequest,
+        catalog.DeleteAspectTypeRequest,
         dict,
     ],
 )
-def test_delete_zone(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
+def test_delete_aspect_type(request_type, transport: str = "grpc"):
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.delete_zone), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.delete_aspect_type), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/spam")
-        response = client.delete_zone(request)
+        response = client.delete_aspect_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.DeleteZoneRequest()
+        request = catalog.DeleteAspectTypeRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
-def test_delete_zone_empty_call():
+def test_delete_aspect_type_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
     # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.delete_zone), "__call__") as call:
-        client.delete_zone()
+    with mock.patch.object(
+        type(client.transport.delete_aspect_type), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.delete_aspect_type()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.DeleteZoneRequest()
+        assert args[0] == catalog.DeleteAspectTypeRequest()
+
+
+def test_delete_aspect_type_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = CatalogServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = catalog.DeleteAspectTypeRequest(
+        name="name_value",
+        etag="etag_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.delete_aspect_type), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.delete_aspect_type(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == catalog.DeleteAspectTypeRequest(
+            name="name_value",
+            etag="etag_value",
+        )
+
+
+def test_delete_aspect_type_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = CatalogServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._transport.delete_aspect_type in client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.delete_aspect_type
+        ] = mock_rpc
+        request = {}
+        client.delete_aspect_type(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        client.delete_aspect_type(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_delete_aspect_type_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = CatalogServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.delete_aspect_type), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        response = await client.delete_aspect_type()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == catalog.DeleteAspectTypeRequest()
+
+
+@pytest.mark.asyncio
+async def test_delete_aspect_type_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = CatalogServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.delete_aspect_type
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.delete_aspect_type
+        ] = mock_object
+
+        request = {}
+        await client.delete_aspect_type(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        await client.delete_aspect_type(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
 
 
 @pytest.mark.asyncio
-async def test_delete_zone_async(
-    transport: str = "grpc_asyncio", request_type=service.DeleteZoneRequest
+async def test_delete_aspect_type_async(
+    transport: str = "grpc_asyncio", request_type=catalog.DeleteAspectTypeRequest
 ):
-    client = DataplexServiceAsyncClient(
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.delete_zone), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.delete_aspect_type), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             operations_pb2.Operation(name="operations/spam")
         )
-        response = await client.delete_zone(request)
+        response = await client.delete_aspect_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.DeleteZoneRequest()
+        request = catalog.DeleteAspectTypeRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 @pytest.mark.asyncio
-async def test_delete_zone_async_from_dict():
-    await test_delete_zone_async(request_type=dict)
+async def test_delete_aspect_type_async_from_dict():
+    await test_delete_aspect_type_async(request_type=dict)
 
 
-def test_delete_zone_field_headers():
-    client = DataplexServiceClient(
+def test_delete_aspect_type_field_headers():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.DeleteZoneRequest()
+    request = catalog.DeleteAspectTypeRequest()
 
     request.name = "name_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.delete_zone), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.delete_aspect_type), "__call__"
+    ) as call:
         call.return_value = operations_pb2.Operation(name="operations/op")
-        client.delete_zone(request)
+        client.delete_aspect_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
@@ -3129,231 +4360,399 @@
     assert (
         "x-goog-request-params",
         "name=name_value",
     ) in kw["metadata"]
 
 
 @pytest.mark.asyncio
-async def test_delete_zone_field_headers_async():
-    client = DataplexServiceAsyncClient(
+async def test_delete_aspect_type_field_headers_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.DeleteZoneRequest()
+    request = catalog.DeleteAspectTypeRequest()
 
     request.name = "name_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.delete_zone), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.delete_aspect_type), "__call__"
+    ) as call:
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             operations_pb2.Operation(name="operations/op")
         )
-        await client.delete_zone(request)
+        await client.delete_aspect_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
     _, _, kw = call.mock_calls[0]
     assert (
         "x-goog-request-params",
         "name=name_value",
     ) in kw["metadata"]
 
 
-def test_delete_zone_flattened():
-    client = DataplexServiceClient(
+def test_delete_aspect_type_flattened():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.delete_zone), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.delete_aspect_type), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/op")
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        client.delete_zone(
+        client.delete_aspect_type(
             name="name_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         arg = args[0].name
         mock_val = "name_value"
         assert arg == mock_val
 
 
-def test_delete_zone_flattened_error():
-    client = DataplexServiceClient(
+def test_delete_aspect_type_flattened_error():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        client.delete_zone(
-            service.DeleteZoneRequest(),
+        client.delete_aspect_type(
+            catalog.DeleteAspectTypeRequest(),
             name="name_value",
         )
 
 
 @pytest.mark.asyncio
-async def test_delete_zone_flattened_async():
-    client = DataplexServiceAsyncClient(
+async def test_delete_aspect_type_flattened_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.delete_zone), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.delete_aspect_type), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/op")
 
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             operations_pb2.Operation(name="operations/spam")
         )
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        response = await client.delete_zone(
+        response = await client.delete_aspect_type(
             name="name_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         arg = args[0].name
         mock_val = "name_value"
         assert arg == mock_val
 
 
 @pytest.mark.asyncio
-async def test_delete_zone_flattened_error_async():
-    client = DataplexServiceAsyncClient(
+async def test_delete_aspect_type_flattened_error_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        await client.delete_zone(
-            service.DeleteZoneRequest(),
+        await client.delete_aspect_type(
+            catalog.DeleteAspectTypeRequest(),
             name="name_value",
         )
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
-        service.ListZonesRequest,
+        catalog.ListAspectTypesRequest,
         dict,
     ],
 )
-def test_list_zones(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
+def test_list_aspect_types(request_type, transport: str = "grpc"):
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_zones), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.list_aspect_types), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
-        call.return_value = service.ListZonesResponse(
+        call.return_value = catalog.ListAspectTypesResponse(
             next_page_token="next_page_token_value",
+            unreachable_locations=["unreachable_locations_value"],
         )
-        response = client.list_zones(request)
+        response = client.list_aspect_types(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.ListZonesRequest()
+        request = catalog.ListAspectTypesRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
-    assert isinstance(response, pagers.ListZonesPager)
+    assert isinstance(response, pagers.ListAspectTypesPager)
     assert response.next_page_token == "next_page_token_value"
+    assert response.unreachable_locations == ["unreachable_locations_value"]
 
 
-def test_list_zones_empty_call():
+def test_list_aspect_types_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
     # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_zones), "__call__") as call:
-        client.list_zones()
+    with mock.patch.object(
+        type(client.transport.list_aspect_types), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.list_aspect_types()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == catalog.ListAspectTypesRequest()
+
+
+def test_list_aspect_types_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = CatalogServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = catalog.ListAspectTypesRequest(
+        parent="parent_value",
+        page_token="page_token_value",
+        filter="filter_value",
+        order_by="order_by_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.list_aspect_types), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.list_aspect_types(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == catalog.ListAspectTypesRequest(
+            parent="parent_value",
+            page_token="page_token_value",
+            filter="filter_value",
+            order_by="order_by_value",
+        )
+
+
+def test_list_aspect_types_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = CatalogServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.list_aspect_types in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.list_aspect_types
+        ] = mock_rpc
+        request = {}
+        client.list_aspect_types(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.list_aspect_types(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_list_aspect_types_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = CatalogServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.list_aspect_types), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            catalog.ListAspectTypesResponse(
+                next_page_token="next_page_token_value",
+                unreachable_locations=["unreachable_locations_value"],
+            )
+        )
+        response = await client.list_aspect_types()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.ListZonesRequest()
+        assert args[0] == catalog.ListAspectTypesRequest()
+
+
+@pytest.mark.asyncio
+async def test_list_aspect_types_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = CatalogServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.list_aspect_types
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.list_aspect_types
+        ] = mock_object
+
+        request = {}
+        await client.list_aspect_types(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.list_aspect_types(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
 
 
 @pytest.mark.asyncio
-async def test_list_zones_async(
-    transport: str = "grpc_asyncio", request_type=service.ListZonesRequest
+async def test_list_aspect_types_async(
+    transport: str = "grpc_asyncio", request_type=catalog.ListAspectTypesRequest
 ):
-    client = DataplexServiceAsyncClient(
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_zones), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.list_aspect_types), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.ListZonesResponse(
+            catalog.ListAspectTypesResponse(
                 next_page_token="next_page_token_value",
+                unreachable_locations=["unreachable_locations_value"],
             )
         )
-        response = await client.list_zones(request)
+        response = await client.list_aspect_types(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.ListZonesRequest()
+        request = catalog.ListAspectTypesRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
-    assert isinstance(response, pagers.ListZonesAsyncPager)
+    assert isinstance(response, pagers.ListAspectTypesAsyncPager)
     assert response.next_page_token == "next_page_token_value"
+    assert response.unreachable_locations == ["unreachable_locations_value"]
 
 
 @pytest.mark.asyncio
-async def test_list_zones_async_from_dict():
-    await test_list_zones_async(request_type=dict)
+async def test_list_aspect_types_async_from_dict():
+    await test_list_aspect_types_async(request_type=dict)
 
 
-def test_list_zones_field_headers():
-    client = DataplexServiceClient(
+def test_list_aspect_types_field_headers():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.ListZonesRequest()
+    request = catalog.ListAspectTypesRequest()
 
     request.parent = "parent_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_zones), "__call__") as call:
-        call.return_value = service.ListZonesResponse()
-        client.list_zones(request)
+    with mock.patch.object(
+        type(client.transport.list_aspect_types), "__call__"
+    ) as call:
+        call.return_value = catalog.ListAspectTypesResponse()
+        client.list_aspect_types(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
@@ -3361,441 +4760,597 @@
     assert (
         "x-goog-request-params",
         "parent=parent_value",
     ) in kw["metadata"]
 
 
 @pytest.mark.asyncio
-async def test_list_zones_field_headers_async():
-    client = DataplexServiceAsyncClient(
+async def test_list_aspect_types_field_headers_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.ListZonesRequest()
+    request = catalog.ListAspectTypesRequest()
 
     request.parent = "parent_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_zones), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.list_aspect_types), "__call__"
+    ) as call:
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.ListZonesResponse()
+            catalog.ListAspectTypesResponse()
         )
-        await client.list_zones(request)
+        await client.list_aspect_types(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
     _, _, kw = call.mock_calls[0]
     assert (
         "x-goog-request-params",
         "parent=parent_value",
     ) in kw["metadata"]
 
 
-def test_list_zones_flattened():
-    client = DataplexServiceClient(
+def test_list_aspect_types_flattened():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_zones), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.list_aspect_types), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
-        call.return_value = service.ListZonesResponse()
+        call.return_value = catalog.ListAspectTypesResponse()
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        client.list_zones(
+        client.list_aspect_types(
             parent="parent_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         arg = args[0].parent
         mock_val = "parent_value"
         assert arg == mock_val
 
 
-def test_list_zones_flattened_error():
-    client = DataplexServiceClient(
+def test_list_aspect_types_flattened_error():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        client.list_zones(
-            service.ListZonesRequest(),
+        client.list_aspect_types(
+            catalog.ListAspectTypesRequest(),
             parent="parent_value",
         )
 
 
 @pytest.mark.asyncio
-async def test_list_zones_flattened_async():
-    client = DataplexServiceAsyncClient(
+async def test_list_aspect_types_flattened_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_zones), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.list_aspect_types), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
-        call.return_value = service.ListZonesResponse()
+        call.return_value = catalog.ListAspectTypesResponse()
 
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.ListZonesResponse()
+            catalog.ListAspectTypesResponse()
         )
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        response = await client.list_zones(
+        response = await client.list_aspect_types(
             parent="parent_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         arg = args[0].parent
         mock_val = "parent_value"
         assert arg == mock_val
 
 
 @pytest.mark.asyncio
-async def test_list_zones_flattened_error_async():
-    client = DataplexServiceAsyncClient(
+async def test_list_aspect_types_flattened_error_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        await client.list_zones(
-            service.ListZonesRequest(),
+        await client.list_aspect_types(
+            catalog.ListAspectTypesRequest(),
             parent="parent_value",
         )
 
 
-def test_list_zones_pager(transport_name: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
+def test_list_aspect_types_pager(transport_name: str = "grpc"):
+    client = CatalogServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
         transport=transport_name,
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_zones), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.list_aspect_types), "__call__"
+    ) as call:
         # Set the response to a series of pages.
         call.side_effect = (
-            service.ListZonesResponse(
-                zones=[
-                    resources.Zone(),
-                    resources.Zone(),
-                    resources.Zone(),
+            catalog.ListAspectTypesResponse(
+                aspect_types=[
+                    catalog.AspectType(),
+                    catalog.AspectType(),
+                    catalog.AspectType(),
                 ],
                 next_page_token="abc",
             ),
-            service.ListZonesResponse(
-                zones=[],
+            catalog.ListAspectTypesResponse(
+                aspect_types=[],
                 next_page_token="def",
             ),
-            service.ListZonesResponse(
-                zones=[
-                    resources.Zone(),
+            catalog.ListAspectTypesResponse(
+                aspect_types=[
+                    catalog.AspectType(),
                 ],
                 next_page_token="ghi",
             ),
-            service.ListZonesResponse(
-                zones=[
-                    resources.Zone(),
-                    resources.Zone(),
+            catalog.ListAspectTypesResponse(
+                aspect_types=[
+                    catalog.AspectType(),
+                    catalog.AspectType(),
                 ],
             ),
             RuntimeError,
         )
 
         metadata = ()
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", ""),)),
         )
-        pager = client.list_zones(request={})
+        pager = client.list_aspect_types(request={})
 
         assert pager._metadata == metadata
 
         results = list(pager)
         assert len(results) == 6
-        assert all(isinstance(i, resources.Zone) for i in results)
+        assert all(isinstance(i, catalog.AspectType) for i in results)
 
 
-def test_list_zones_pages(transport_name: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
+def test_list_aspect_types_pages(transport_name: str = "grpc"):
+    client = CatalogServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
         transport=transport_name,
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_zones), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.list_aspect_types), "__call__"
+    ) as call:
         # Set the response to a series of pages.
         call.side_effect = (
-            service.ListZonesResponse(
-                zones=[
-                    resources.Zone(),
-                    resources.Zone(),
-                    resources.Zone(),
+            catalog.ListAspectTypesResponse(
+                aspect_types=[
+                    catalog.AspectType(),
+                    catalog.AspectType(),
+                    catalog.AspectType(),
                 ],
                 next_page_token="abc",
             ),
-            service.ListZonesResponse(
-                zones=[],
+            catalog.ListAspectTypesResponse(
+                aspect_types=[],
                 next_page_token="def",
             ),
-            service.ListZonesResponse(
-                zones=[
-                    resources.Zone(),
+            catalog.ListAspectTypesResponse(
+                aspect_types=[
+                    catalog.AspectType(),
                 ],
                 next_page_token="ghi",
             ),
-            service.ListZonesResponse(
-                zones=[
-                    resources.Zone(),
-                    resources.Zone(),
+            catalog.ListAspectTypesResponse(
+                aspect_types=[
+                    catalog.AspectType(),
+                    catalog.AspectType(),
                 ],
             ),
             RuntimeError,
         )
-        pages = list(client.list_zones(request={}).pages)
+        pages = list(client.list_aspect_types(request={}).pages)
         for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
             assert page_.raw_page.next_page_token == token
 
 
 @pytest.mark.asyncio
-async def test_list_zones_async_pager():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
+async def test_list_aspect_types_async_pager():
+    client = CatalogServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
-        type(client.transport.list_zones), "__call__", new_callable=mock.AsyncMock
+        type(client.transport.list_aspect_types),
+        "__call__",
+        new_callable=mock.AsyncMock,
     ) as call:
         # Set the response to a series of pages.
         call.side_effect = (
-            service.ListZonesResponse(
-                zones=[
-                    resources.Zone(),
-                    resources.Zone(),
-                    resources.Zone(),
+            catalog.ListAspectTypesResponse(
+                aspect_types=[
+                    catalog.AspectType(),
+                    catalog.AspectType(),
+                    catalog.AspectType(),
                 ],
                 next_page_token="abc",
             ),
-            service.ListZonesResponse(
-                zones=[],
+            catalog.ListAspectTypesResponse(
+                aspect_types=[],
                 next_page_token="def",
             ),
-            service.ListZonesResponse(
-                zones=[
-                    resources.Zone(),
+            catalog.ListAspectTypesResponse(
+                aspect_types=[
+                    catalog.AspectType(),
                 ],
                 next_page_token="ghi",
             ),
-            service.ListZonesResponse(
-                zones=[
-                    resources.Zone(),
-                    resources.Zone(),
+            catalog.ListAspectTypesResponse(
+                aspect_types=[
+                    catalog.AspectType(),
+                    catalog.AspectType(),
                 ],
             ),
             RuntimeError,
         )
-        async_pager = await client.list_zones(
+        async_pager = await client.list_aspect_types(
             request={},
         )
         assert async_pager.next_page_token == "abc"
         responses = []
         async for response in async_pager:  # pragma: no branch
             responses.append(response)
 
         assert len(responses) == 6
-        assert all(isinstance(i, resources.Zone) for i in responses)
+        assert all(isinstance(i, catalog.AspectType) for i in responses)
 
 
 @pytest.mark.asyncio
-async def test_list_zones_async_pages():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
+async def test_list_aspect_types_async_pages():
+    client = CatalogServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
-        type(client.transport.list_zones), "__call__", new_callable=mock.AsyncMock
+        type(client.transport.list_aspect_types),
+        "__call__",
+        new_callable=mock.AsyncMock,
     ) as call:
         # Set the response to a series of pages.
         call.side_effect = (
-            service.ListZonesResponse(
-                zones=[
-                    resources.Zone(),
-                    resources.Zone(),
-                    resources.Zone(),
+            catalog.ListAspectTypesResponse(
+                aspect_types=[
+                    catalog.AspectType(),
+                    catalog.AspectType(),
+                    catalog.AspectType(),
                 ],
                 next_page_token="abc",
             ),
-            service.ListZonesResponse(
-                zones=[],
+            catalog.ListAspectTypesResponse(
+                aspect_types=[],
                 next_page_token="def",
             ),
-            service.ListZonesResponse(
-                zones=[
-                    resources.Zone(),
+            catalog.ListAspectTypesResponse(
+                aspect_types=[
+                    catalog.AspectType(),
                 ],
                 next_page_token="ghi",
             ),
-            service.ListZonesResponse(
-                zones=[
-                    resources.Zone(),
-                    resources.Zone(),
+            catalog.ListAspectTypesResponse(
+                aspect_types=[
+                    catalog.AspectType(),
+                    catalog.AspectType(),
                 ],
             ),
             RuntimeError,
         )
         pages = []
         # Workaround issue in python 3.9 related to code coverage by adding `# pragma: no branch`
         # See https://github.com/googleapis/gapic-generator-python/pull/1174#issuecomment-1025132372
         async for page_ in (  # pragma: no branch
-            await client.list_zones(request={})
+            await client.list_aspect_types(request={})
         ).pages:
             pages.append(page_)
         for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
             assert page_.raw_page.next_page_token == token
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
-        service.GetZoneRequest,
+        catalog.GetAspectTypeRequest,
         dict,
     ],
 )
-def test_get_zone(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
+def test_get_aspect_type(request_type, transport: str = "grpc"):
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_zone), "__call__") as call:
+    with mock.patch.object(type(client.transport.get_aspect_type), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = resources.Zone(
+        call.return_value = catalog.AspectType(
             name="name_value",
-            display_name="display_name_value",
             uid="uid_value",
             description="description_value",
-            state=resources.State.ACTIVE,
-            type_=resources.Zone.Type.RAW,
+            display_name="display_name_value",
+            etag="etag_value",
+            transfer_status=catalog.TransferStatus.TRANSFER_STATUS_MIGRATED,
         )
-        response = client.get_zone(request)
+        response = client.get_aspect_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.GetZoneRequest()
+        request = catalog.GetAspectTypeRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
-    assert isinstance(response, resources.Zone)
+    assert isinstance(response, catalog.AspectType)
     assert response.name == "name_value"
-    assert response.display_name == "display_name_value"
     assert response.uid == "uid_value"
     assert response.description == "description_value"
-    assert response.state == resources.State.ACTIVE
-    assert response.type_ == resources.Zone.Type.RAW
+    assert response.display_name == "display_name_value"
+    assert response.etag == "etag_value"
+    assert response.transfer_status == catalog.TransferStatus.TRANSFER_STATUS_MIGRATED
 
 
-def test_get_zone_empty_call():
+def test_get_aspect_type_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
     # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_zone), "__call__") as call:
-        client.get_zone()
+    with mock.patch.object(type(client.transport.get_aspect_type), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.get_aspect_type()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == catalog.GetAspectTypeRequest()
+
+
+def test_get_aspect_type_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = CatalogServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = catalog.GetAspectTypeRequest(
+        name="name_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_aspect_type), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.get_aspect_type(request=request)
         call.assert_called()
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.GetZoneRequest()
+        assert args[0] == catalog.GetAspectTypeRequest(
+            name="name_value",
+        )
+
+
+def test_get_aspect_type_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = CatalogServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.get_aspect_type in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[client._transport.get_aspect_type] = mock_rpc
+        request = {}
+        client.get_aspect_type(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.get_aspect_type(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
 
 
 @pytest.mark.asyncio
-async def test_get_zone_async(
-    transport: str = "grpc_asyncio", request_type=service.GetZoneRequest
+async def test_get_aspect_type_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = CatalogServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_aspect_type), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            catalog.AspectType(
+                name="name_value",
+                uid="uid_value",
+                description="description_value",
+                display_name="display_name_value",
+                etag="etag_value",
+                transfer_status=catalog.TransferStatus.TRANSFER_STATUS_MIGRATED,
+            )
+        )
+        response = await client.get_aspect_type()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == catalog.GetAspectTypeRequest()
+
+
+@pytest.mark.asyncio
+async def test_get_aspect_type_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
 ):
-    client = DataplexServiceAsyncClient(
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = CatalogServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.get_aspect_type
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.get_aspect_type
+        ] = mock_object
+
+        request = {}
+        await client.get_aspect_type(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.get_aspect_type(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_get_aspect_type_async(
+    transport: str = "grpc_asyncio", request_type=catalog.GetAspectTypeRequest
+):
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_zone), "__call__") as call:
+    with mock.patch.object(type(client.transport.get_aspect_type), "__call__") as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            resources.Zone(
+            catalog.AspectType(
                 name="name_value",
-                display_name="display_name_value",
                 uid="uid_value",
                 description="description_value",
-                state=resources.State.ACTIVE,
-                type_=resources.Zone.Type.RAW,
+                display_name="display_name_value",
+                etag="etag_value",
+                transfer_status=catalog.TransferStatus.TRANSFER_STATUS_MIGRATED,
             )
         )
-        response = await client.get_zone(request)
+        response = await client.get_aspect_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.GetZoneRequest()
+        request = catalog.GetAspectTypeRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
-    assert isinstance(response, resources.Zone)
+    assert isinstance(response, catalog.AspectType)
     assert response.name == "name_value"
-    assert response.display_name == "display_name_value"
     assert response.uid == "uid_value"
     assert response.description == "description_value"
-    assert response.state == resources.State.ACTIVE
-    assert response.type_ == resources.Zone.Type.RAW
+    assert response.display_name == "display_name_value"
+    assert response.etag == "etag_value"
+    assert response.transfer_status == catalog.TransferStatus.TRANSFER_STATUS_MIGRATED
 
 
 @pytest.mark.asyncio
-async def test_get_zone_async_from_dict():
-    await test_get_zone_async(request_type=dict)
+async def test_get_aspect_type_async_from_dict():
+    await test_get_aspect_type_async(request_type=dict)
 
 
-def test_get_zone_field_headers():
-    client = DataplexServiceClient(
+def test_get_aspect_type_field_headers():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.GetZoneRequest()
+    request = catalog.GetAspectTypeRequest()
 
     request.name = "name_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_zone), "__call__") as call:
-        call.return_value = resources.Zone()
-        client.get_zone(request)
+    with mock.patch.object(type(client.transport.get_aspect_type), "__call__") as call:
+        call.return_value = catalog.AspectType()
+        client.get_aspect_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
@@ -3803,665 +5358,382 @@
     assert (
         "x-goog-request-params",
         "name=name_value",
     ) in kw["metadata"]
 
 
 @pytest.mark.asyncio
-async def test_get_zone_field_headers_async():
-    client = DataplexServiceAsyncClient(
+async def test_get_aspect_type_field_headers_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.GetZoneRequest()
+    request = catalog.GetAspectTypeRequest()
 
     request.name = "name_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_zone), "__call__") as call:
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(resources.Zone())
-        await client.get_zone(request)
+    with mock.patch.object(type(client.transport.get_aspect_type), "__call__") as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(catalog.AspectType())
+        await client.get_aspect_type(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
     _, _, kw = call.mock_calls[0]
     assert (
         "x-goog-request-params",
         "name=name_value",
     ) in kw["metadata"]
 
 
-def test_get_zone_flattened():
-    client = DataplexServiceClient(
+def test_get_aspect_type_flattened():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_zone), "__call__") as call:
+    with mock.patch.object(type(client.transport.get_aspect_type), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = resources.Zone()
+        call.return_value = catalog.AspectType()
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        client.get_zone(
+        client.get_aspect_type(
             name="name_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         arg = args[0].name
         mock_val = "name_value"
         assert arg == mock_val
 
 
-def test_get_zone_flattened_error():
-    client = DataplexServiceClient(
+def test_get_aspect_type_flattened_error():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        client.get_zone(
-            service.GetZoneRequest(),
+        client.get_aspect_type(
+            catalog.GetAspectTypeRequest(),
             name="name_value",
         )
 
 
 @pytest.mark.asyncio
-async def test_get_zone_flattened_async():
-    client = DataplexServiceAsyncClient(
+async def test_get_aspect_type_flattened_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_zone), "__call__") as call:
+    with mock.patch.object(type(client.transport.get_aspect_type), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = resources.Zone()
+        call.return_value = catalog.AspectType()
 
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(resources.Zone())
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(catalog.AspectType())
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        response = await client.get_zone(
+        response = await client.get_aspect_type(
             name="name_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         arg = args[0].name
         mock_val = "name_value"
         assert arg == mock_val
 
 
 @pytest.mark.asyncio
-async def test_get_zone_flattened_error_async():
-    client = DataplexServiceAsyncClient(
+async def test_get_aspect_type_flattened_error_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        await client.get_zone(
-            service.GetZoneRequest(),
+        await client.get_aspect_type(
+            catalog.GetAspectTypeRequest(),
             name="name_value",
         )
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
-        service.ListZoneActionsRequest,
+        catalog.CreateEntryGroupRequest,
         dict,
     ],
 )
-def test_list_zone_actions(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
+def test_create_entry_group(request_type, transport: str = "grpc"):
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
-        type(client.transport.list_zone_actions), "__call__"
+        type(client.transport.create_entry_group), "__call__"
     ) as call:
         # Designate an appropriate return value for the call.
-        call.return_value = service.ListActionsResponse(
-            next_page_token="next_page_token_value",
-        )
-        response = client.list_zone_actions(request)
+        call.return_value = operations_pb2.Operation(name="operations/spam")
+        response = client.create_entry_group(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.ListZoneActionsRequest()
+        request = catalog.CreateEntryGroupRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
-    assert isinstance(response, pagers.ListZoneActionsPager)
-    assert response.next_page_token == "next_page_token_value"
+    assert isinstance(response, future.Future)
 
 
-def test_list_zone_actions_empty_call():
+def test_create_entry_group_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
     # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
-        type(client.transport.list_zone_actions), "__call__"
+        type(client.transport.create_entry_group), "__call__"
     ) as call:
-        client.list_zone_actions()
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.create_entry_group()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.ListZoneActionsRequest()
+        assert args[0] == catalog.CreateEntryGroupRequest()
 
 
-@pytest.mark.asyncio
-async def test_list_zone_actions_async(
-    transport: str = "grpc_asyncio", request_type=service.ListZoneActionsRequest
-):
-    client = DataplexServiceAsyncClient(
+def test_create_entry_group_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
-        transport=transport,
+        transport="grpc",
     )
 
-    # Everything is optional in proto3 as far as the runtime is concerned,
-    # and we are mocking out the actual API, so just send an empty request.
-    request = request_type()
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_zone_actions), "__call__"
-    ) as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.ListActionsResponse(
-                next_page_token="next_page_token_value",
-            )
-        )
-        response = await client.list_zone_actions(request)
-
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls)
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.ListZoneActionsRequest()
-
-    # Establish that the response is the type that we expect.
-    assert isinstance(response, pagers.ListZoneActionsAsyncPager)
-    assert response.next_page_token == "next_page_token_value"
-
-
-@pytest.mark.asyncio
-async def test_list_zone_actions_async_from_dict():
-    await test_list_zone_actions_async(request_type=dict)
-
-
-def test_list_zone_actions_field_headers():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = catalog.CreateEntryGroupRequest(
+        parent="parent_value",
+        entry_group_id="entry_group_id_value",
     )
 
-    # Any value that is part of the HTTP/1.1 URI should be sent as
-    # a field header. Set these to a non-empty value.
-    request = service.ListZoneActionsRequest()
-
-    request.parent = "parent_value"
-
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
-        type(client.transport.list_zone_actions), "__call__"
+        type(client.transport.create_entry_group), "__call__"
     ) as call:
-        call.return_value = service.ListActionsResponse()
-        client.list_zone_actions(request)
-
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls) == 1
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.create_entry_group(request=request)
+        call.assert_called()
         _, args, _ = call.mock_calls[0]
-        assert args[0] == request
-
-    # Establish that the field header was sent.
-    _, _, kw = call.mock_calls[0]
-    assert (
-        "x-goog-request-params",
-        "parent=parent_value",
-    ) in kw["metadata"]
-
-
-@pytest.mark.asyncio
-async def test_list_zone_actions_field_headers_async():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Any value that is part of the HTTP/1.1 URI should be sent as
-    # a field header. Set these to a non-empty value.
-    request = service.ListZoneActionsRequest()
-
-    request.parent = "parent_value"
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_zone_actions), "__call__"
-    ) as call:
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.ListActionsResponse()
+        assert args[0] == catalog.CreateEntryGroupRequest(
+            parent="parent_value",
+            entry_group_id="entry_group_id_value",
         )
-        await client.list_zone_actions(request)
 
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls)
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == request
 
-    # Establish that the field header was sent.
-    _, _, kw = call.mock_calls[0]
-    assert (
-        "x-goog-request-params",
-        "parent=parent_value",
-    ) in kw["metadata"]
+def test_create_entry_group_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = CatalogServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
 
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
 
-def test_list_zone_actions_flattened():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
+        # Ensure method has been cached
+        assert (
+            client._transport.create_entry_group in client._transport._wrapped_methods
+        )
 
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_zone_actions), "__call__"
-    ) as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = service.ListActionsResponse()
-        # Call the method with a truthy value for each flattened field,
-        # using the keyword arguments to the method.
-        client.list_zone_actions(
-            parent="parent_value",
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
         )
+        client._transport._wrapped_methods[
+            client._transport.create_entry_group
+        ] = mock_rpc
+        request = {}
+        client.create_entry_group(request)
 
-        # Establish that the underlying call was made with the expected
-        # request object values.
-        assert len(call.mock_calls) == 1
-        _, args, _ = call.mock_calls[0]
-        arg = args[0].parent
-        mock_val = "parent_value"
-        assert arg == mock_val
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
 
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
 
-def test_list_zone_actions_flattened_error():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
+        client.create_entry_group(request)
 
-    # Attempting to call a method with both a request object and flattened
-    # fields is an error.
-    with pytest.raises(ValueError):
-        client.list_zone_actions(
-            service.ListZoneActionsRequest(),
-            parent="parent_value",
-        )
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
 
 
 @pytest.mark.asyncio
-async def test_list_zone_actions_flattened_async():
-    client = DataplexServiceAsyncClient(
+async def test_create_entry_group_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
-        type(client.transport.list_zone_actions), "__call__"
+        type(client.transport.create_entry_group), "__call__"
     ) as call:
         # Designate an appropriate return value for the call.
-        call.return_value = service.ListActionsResponse()
-
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.ListActionsResponse()
-        )
-        # Call the method with a truthy value for each flattened field,
-        # using the keyword arguments to the method.
-        response = await client.list_zone_actions(
-            parent="parent_value",
+            operations_pb2.Operation(name="operations/spam")
         )
-
-        # Establish that the underlying call was made with the expected
-        # request object values.
-        assert len(call.mock_calls)
+        response = await client.create_entry_group()
+        call.assert_called()
         _, args, _ = call.mock_calls[0]
-        arg = args[0].parent
-        mock_val = "parent_value"
-        assert arg == mock_val
-
-
-@pytest.mark.asyncio
-async def test_list_zone_actions_flattened_error_async():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Attempting to call a method with both a request object and flattened
-    # fields is an error.
-    with pytest.raises(ValueError):
-        await client.list_zone_actions(
-            service.ListZoneActionsRequest(),
-            parent="parent_value",
-        )
-
-
-def test_list_zone_actions_pager(transport_name: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
-        transport=transport_name,
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_zone_actions), "__call__"
-    ) as call:
-        # Set the response to a series of pages.
-        call.side_effect = (
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                    resources.Action(),
-                    resources.Action(),
-                ],
-                next_page_token="abc",
-            ),
-            service.ListActionsResponse(
-                actions=[],
-                next_page_token="def",
-            ),
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                ],
-                next_page_token="ghi",
-            ),
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                    resources.Action(),
-                ],
-            ),
-            RuntimeError,
-        )
-
-        metadata = ()
-        metadata = tuple(metadata) + (
-            gapic_v1.routing_header.to_grpc_metadata((("parent", ""),)),
-        )
-        pager = client.list_zone_actions(request={})
-
-        assert pager._metadata == metadata
-
-        results = list(pager)
-        assert len(results) == 6
-        assert all(isinstance(i, resources.Action) for i in results)
-
-
-def test_list_zone_actions_pages(transport_name: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
-        transport=transport_name,
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_zone_actions), "__call__"
-    ) as call:
-        # Set the response to a series of pages.
-        call.side_effect = (
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                    resources.Action(),
-                    resources.Action(),
-                ],
-                next_page_token="abc",
-            ),
-            service.ListActionsResponse(
-                actions=[],
-                next_page_token="def",
-            ),
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                ],
-                next_page_token="ghi",
-            ),
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                    resources.Action(),
-                ],
-            ),
-            RuntimeError,
-        )
-        pages = list(client.list_zone_actions(request={}).pages)
-        for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
-            assert page_.raw_page.next_page_token == token
+        assert args[0] == catalog.CreateEntryGroupRequest()
 
 
 @pytest.mark.asyncio
-async def test_list_zone_actions_async_pager():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_zone_actions),
-        "__call__",
-        new_callable=mock.AsyncMock,
-    ) as call:
-        # Set the response to a series of pages.
-        call.side_effect = (
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                    resources.Action(),
-                    resources.Action(),
-                ],
-                next_page_token="abc",
-            ),
-            service.ListActionsResponse(
-                actions=[],
-                next_page_token="def",
-            ),
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                ],
-                next_page_token="ghi",
-            ),
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                    resources.Action(),
-                ],
-            ),
-            RuntimeError,
-        )
-        async_pager = await client.list_zone_actions(
-            request={},
+async def test_create_entry_group_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = CatalogServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
         )
-        assert async_pager.next_page_token == "abc"
-        responses = []
-        async for response in async_pager:  # pragma: no branch
-            responses.append(response)
-
-        assert len(responses) == 6
-        assert all(isinstance(i, resources.Action) for i in responses)
-
 
-@pytest.mark.asyncio
-async def test_list_zone_actions_async_pages():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
-    )
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
 
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_zone_actions),
-        "__call__",
-        new_callable=mock.AsyncMock,
-    ) as call:
-        # Set the response to a series of pages.
-        call.side_effect = (
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                    resources.Action(),
-                    resources.Action(),
-                ],
-                next_page_token="abc",
-            ),
-            service.ListActionsResponse(
-                actions=[],
-                next_page_token="def",
-            ),
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                ],
-                next_page_token="ghi",
-            ),
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                    resources.Action(),
-                ],
-            ),
-            RuntimeError,
+        # Ensure method has been cached
+        assert (
+            client._client._transport.create_entry_group
+            in client._client._transport._wrapped_methods
         )
-        pages = []
-        # Workaround issue in python 3.9 related to code coverage by adding `# pragma: no branch`
-        # See https://github.com/googleapis/gapic-generator-python/pull/1174#issuecomment-1025132372
-        async for page_ in (  # pragma: no branch
-            await client.list_zone_actions(request={})
-        ).pages:
-            pages.append(page_)
-        for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
-            assert page_.raw_page.next_page_token == token
 
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
 
-@pytest.mark.parametrize(
-    "request_type",
-    [
-        service.CreateAssetRequest,
-        dict,
-    ],
-)
-def test_create_asset(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-        transport=transport,
-    )
-
-    # Everything is optional in proto3 as far as the runtime is concerned,
-    # and we are mocking out the actual API, so just send an empty request.
-    request = request_type()
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.create_entry_group
+        ] = mock_object
 
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.create_asset), "__call__") as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = operations_pb2.Operation(name="operations/spam")
-        response = client.create_asset(request)
+        request = {}
+        await client.create_entry_group(request)
 
         # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls) == 1
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.CreateAssetRequest()
+        assert mock_object.call_count == 1
 
-    # Establish that the response is the type that we expect.
-    assert isinstance(response, future.Future)
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
 
+        await client.create_entry_group(request)
 
-def test_create_asset_empty_call():
-    # This test is a coverage failsafe to make sure that totally empty calls,
-    # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-        transport="grpc",
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.create_asset), "__call__") as call:
-        client.create_asset()
-        call.assert_called()
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.CreateAssetRequest()
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
 
 
 @pytest.mark.asyncio
-async def test_create_asset_async(
-    transport: str = "grpc_asyncio", request_type=service.CreateAssetRequest
+async def test_create_entry_group_async(
+    transport: str = "grpc_asyncio", request_type=catalog.CreateEntryGroupRequest
 ):
-    client = DataplexServiceAsyncClient(
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.create_asset), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.create_entry_group), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             operations_pb2.Operation(name="operations/spam")
         )
-        response = await client.create_asset(request)
+        response = await client.create_entry_group(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.CreateAssetRequest()
+        request = catalog.CreateEntryGroupRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 @pytest.mark.asyncio
-async def test_create_asset_async_from_dict():
-    await test_create_asset_async(request_type=dict)
+async def test_create_entry_group_async_from_dict():
+    await test_create_entry_group_async(request_type=dict)
 
 
-def test_create_asset_field_headers():
-    client = DataplexServiceClient(
+def test_create_entry_group_field_headers():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.CreateAssetRequest()
+    request = catalog.CreateEntryGroupRequest()
 
     request.parent = "parent_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.create_asset), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.create_entry_group), "__call__"
+    ) as call:
         call.return_value = operations_pb2.Operation(name="operations/op")
-        client.create_asset(request)
+        client.create_entry_group(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
@@ -4469,481 +5741,809 @@
     assert (
         "x-goog-request-params",
         "parent=parent_value",
     ) in kw["metadata"]
 
 
 @pytest.mark.asyncio
-async def test_create_asset_field_headers_async():
-    client = DataplexServiceAsyncClient(
+async def test_create_entry_group_field_headers_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.CreateAssetRequest()
+    request = catalog.CreateEntryGroupRequest()
 
     request.parent = "parent_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.create_asset), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.create_entry_group), "__call__"
+    ) as call:
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             operations_pb2.Operation(name="operations/op")
         )
-        await client.create_asset(request)
+        await client.create_entry_group(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
     _, _, kw = call.mock_calls[0]
     assert (
         "x-goog-request-params",
         "parent=parent_value",
     ) in kw["metadata"]
 
 
-def test_create_asset_flattened():
-    client = DataplexServiceClient(
+def test_create_entry_group_flattened():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.create_asset), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.create_entry_group), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/op")
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        client.create_asset(
+        client.create_entry_group(
             parent="parent_value",
-            asset=resources.Asset(name="name_value"),
-            asset_id="asset_id_value",
+            entry_group=catalog.EntryGroup(name="name_value"),
+            entry_group_id="entry_group_id_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         arg = args[0].parent
         mock_val = "parent_value"
         assert arg == mock_val
-        arg = args[0].asset
-        mock_val = resources.Asset(name="name_value")
+        arg = args[0].entry_group
+        mock_val = catalog.EntryGroup(name="name_value")
         assert arg == mock_val
-        arg = args[0].asset_id
-        mock_val = "asset_id_value"
+        arg = args[0].entry_group_id
+        mock_val = "entry_group_id_value"
         assert arg == mock_val
 
 
-def test_create_asset_flattened_error():
-    client = DataplexServiceClient(
+def test_create_entry_group_flattened_error():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        client.create_asset(
-            service.CreateAssetRequest(),
+        client.create_entry_group(
+            catalog.CreateEntryGroupRequest(),
             parent="parent_value",
-            asset=resources.Asset(name="name_value"),
-            asset_id="asset_id_value",
+            entry_group=catalog.EntryGroup(name="name_value"),
+            entry_group_id="entry_group_id_value",
         )
 
 
 @pytest.mark.asyncio
-async def test_create_asset_flattened_async():
-    client = DataplexServiceAsyncClient(
+async def test_create_entry_group_flattened_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.create_asset), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.create_entry_group), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/op")
 
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             operations_pb2.Operation(name="operations/spam")
         )
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        response = await client.create_asset(
+        response = await client.create_entry_group(
             parent="parent_value",
-            asset=resources.Asset(name="name_value"),
-            asset_id="asset_id_value",
+            entry_group=catalog.EntryGroup(name="name_value"),
+            entry_group_id="entry_group_id_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         arg = args[0].parent
         mock_val = "parent_value"
         assert arg == mock_val
-        arg = args[0].asset
-        mock_val = resources.Asset(name="name_value")
+        arg = args[0].entry_group
+        mock_val = catalog.EntryGroup(name="name_value")
         assert arg == mock_val
-        arg = args[0].asset_id
-        mock_val = "asset_id_value"
+        arg = args[0].entry_group_id
+        mock_val = "entry_group_id_value"
         assert arg == mock_val
 
 
 @pytest.mark.asyncio
-async def test_create_asset_flattened_error_async():
-    client = DataplexServiceAsyncClient(
+async def test_create_entry_group_flattened_error_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        await client.create_asset(
-            service.CreateAssetRequest(),
+        await client.create_entry_group(
+            catalog.CreateEntryGroupRequest(),
             parent="parent_value",
-            asset=resources.Asset(name="name_value"),
-            asset_id="asset_id_value",
+            entry_group=catalog.EntryGroup(name="name_value"),
+            entry_group_id="entry_group_id_value",
         )
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
-        service.UpdateAssetRequest,
+        catalog.UpdateEntryGroupRequest,
         dict,
     ],
 )
-def test_update_asset(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
+def test_update_entry_group(request_type, transport: str = "grpc"):
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.update_asset), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.update_entry_group), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/spam")
-        response = client.update_asset(request)
+        response = client.update_entry_group(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.UpdateAssetRequest()
+        request = catalog.UpdateEntryGroupRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
-def test_update_asset_empty_call():
+def test_update_entry_group_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
     # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.update_asset), "__call__") as call:
-        client.update_asset()
+    with mock.patch.object(
+        type(client.transport.update_entry_group), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.update_entry_group()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == catalog.UpdateEntryGroupRequest()
+
+
+def test_update_entry_group_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = CatalogServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = catalog.UpdateEntryGroupRequest()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.update_entry_group), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.update_entry_group(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == catalog.UpdateEntryGroupRequest()
+
+
+def test_update_entry_group_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = CatalogServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._transport.update_entry_group in client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.update_entry_group
+        ] = mock_rpc
+        request = {}
+        client.update_entry_group(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        client.update_entry_group(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_update_entry_group_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = CatalogServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.update_entry_group), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        response = await client.update_entry_group()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.UpdateAssetRequest()
+        assert args[0] == catalog.UpdateEntryGroupRequest()
 
 
 @pytest.mark.asyncio
-async def test_update_asset_async(
-    transport: str = "grpc_asyncio", request_type=service.UpdateAssetRequest
+async def test_update_entry_group_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
 ):
-    client = DataplexServiceAsyncClient(
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = CatalogServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.update_entry_group
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.update_entry_group
+        ] = mock_object
+
+        request = {}
+        await client.update_entry_group(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        await client.update_entry_group(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_update_entry_group_async(
+    transport: str = "grpc_asyncio", request_type=catalog.UpdateEntryGroupRequest
+):
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.update_asset), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.update_entry_group), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             operations_pb2.Operation(name="operations/spam")
         )
-        response = await client.update_asset(request)
+        response = await client.update_entry_group(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.UpdateAssetRequest()
+        request = catalog.UpdateEntryGroupRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 @pytest.mark.asyncio
-async def test_update_asset_async_from_dict():
-    await test_update_asset_async(request_type=dict)
+async def test_update_entry_group_async_from_dict():
+    await test_update_entry_group_async(request_type=dict)
 
 
-def test_update_asset_field_headers():
-    client = DataplexServiceClient(
+def test_update_entry_group_field_headers():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.UpdateAssetRequest()
+    request = catalog.UpdateEntryGroupRequest()
 
-    request.asset.name = "name_value"
+    request.entry_group.name = "name_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.update_asset), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.update_entry_group), "__call__"
+    ) as call:
         call.return_value = operations_pb2.Operation(name="operations/op")
-        client.update_asset(request)
+        client.update_entry_group(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
     _, _, kw = call.mock_calls[0]
     assert (
         "x-goog-request-params",
-        "asset.name=name_value",
+        "entry_group.name=name_value",
     ) in kw["metadata"]
 
 
 @pytest.mark.asyncio
-async def test_update_asset_field_headers_async():
-    client = DataplexServiceAsyncClient(
+async def test_update_entry_group_field_headers_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.UpdateAssetRequest()
+    request = catalog.UpdateEntryGroupRequest()
 
-    request.asset.name = "name_value"
+    request.entry_group.name = "name_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.update_asset), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.update_entry_group), "__call__"
+    ) as call:
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             operations_pb2.Operation(name="operations/op")
         )
-        await client.update_asset(request)
+        await client.update_entry_group(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
     _, _, kw = call.mock_calls[0]
     assert (
         "x-goog-request-params",
-        "asset.name=name_value",
+        "entry_group.name=name_value",
     ) in kw["metadata"]
 
 
-def test_update_asset_flattened():
-    client = DataplexServiceClient(
+def test_update_entry_group_flattened():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.update_asset), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.update_entry_group), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/op")
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        client.update_asset(
-            asset=resources.Asset(name="name_value"),
+        client.update_entry_group(
+            entry_group=catalog.EntryGroup(name="name_value"),
             update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        arg = args[0].asset
-        mock_val = resources.Asset(name="name_value")
+        arg = args[0].entry_group
+        mock_val = catalog.EntryGroup(name="name_value")
         assert arg == mock_val
         arg = args[0].update_mask
         mock_val = field_mask_pb2.FieldMask(paths=["paths_value"])
         assert arg == mock_val
 
 
-def test_update_asset_flattened_error():
-    client = DataplexServiceClient(
+def test_update_entry_group_flattened_error():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        client.update_asset(
-            service.UpdateAssetRequest(),
-            asset=resources.Asset(name="name_value"),
+        client.update_entry_group(
+            catalog.UpdateEntryGroupRequest(),
+            entry_group=catalog.EntryGroup(name="name_value"),
             update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
         )
 
 
 @pytest.mark.asyncio
-async def test_update_asset_flattened_async():
-    client = DataplexServiceAsyncClient(
+async def test_update_entry_group_flattened_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.update_asset), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.update_entry_group), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/op")
 
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             operations_pb2.Operation(name="operations/spam")
         )
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        response = await client.update_asset(
-            asset=resources.Asset(name="name_value"),
+        response = await client.update_entry_group(
+            entry_group=catalog.EntryGroup(name="name_value"),
             update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        arg = args[0].asset
-        mock_val = resources.Asset(name="name_value")
+        arg = args[0].entry_group
+        mock_val = catalog.EntryGroup(name="name_value")
         assert arg == mock_val
         arg = args[0].update_mask
         mock_val = field_mask_pb2.FieldMask(paths=["paths_value"])
         assert arg == mock_val
 
 
 @pytest.mark.asyncio
-async def test_update_asset_flattened_error_async():
-    client = DataplexServiceAsyncClient(
+async def test_update_entry_group_flattened_error_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        await client.update_asset(
-            service.UpdateAssetRequest(),
-            asset=resources.Asset(name="name_value"),
+        await client.update_entry_group(
+            catalog.UpdateEntryGroupRequest(),
+            entry_group=catalog.EntryGroup(name="name_value"),
             update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
         )
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
-        service.DeleteAssetRequest,
+        catalog.DeleteEntryGroupRequest,
         dict,
     ],
 )
-def test_delete_asset(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
+def test_delete_entry_group(request_type, transport: str = "grpc"):
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.delete_asset), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.delete_entry_group), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/spam")
-        response = client.delete_asset(request)
+        response = client.delete_entry_group(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.DeleteAssetRequest()
+        request = catalog.DeleteEntryGroupRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
-def test_delete_asset_empty_call():
+def test_delete_entry_group_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
     # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.delete_entry_group), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.delete_entry_group()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == catalog.DeleteEntryGroupRequest()
+
+
+def test_delete_entry_group_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = catalog.DeleteEntryGroupRequest(
+        name="name_value",
+        etag="etag_value",
+    )
+
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.delete_asset), "__call__") as call:
-        client.delete_asset()
+    with mock.patch.object(
+        type(client.transport.delete_entry_group), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.delete_entry_group(request=request)
         call.assert_called()
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.DeleteAssetRequest()
+        assert args[0] == catalog.DeleteEntryGroupRequest(
+            name="name_value",
+            etag="etag_value",
+        )
+
+
+def test_delete_entry_group_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = CatalogServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._transport.delete_entry_group in client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.delete_entry_group
+        ] = mock_rpc
+        request = {}
+        client.delete_entry_group(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        client.delete_entry_group(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
 
 
 @pytest.mark.asyncio
-async def test_delete_asset_async(
-    transport: str = "grpc_asyncio", request_type=service.DeleteAssetRequest
+async def test_delete_entry_group_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = CatalogServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.delete_entry_group), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            operations_pb2.Operation(name="operations/spam")
+        )
+        response = await client.delete_entry_group()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == catalog.DeleteEntryGroupRequest()
+
+
+@pytest.mark.asyncio
+async def test_delete_entry_group_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
 ):
-    client = DataplexServiceAsyncClient(
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = CatalogServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.delete_entry_group
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.delete_entry_group
+        ] = mock_object
+
+        request = {}
+        await client.delete_entry_group(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        # Operation methods build a cached wrapper on first rpc call
+        # subsequent calls should use the cached wrapper
+        wrapper_fn.reset_mock()
+
+        await client.delete_entry_group(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_delete_entry_group_async(
+    transport: str = "grpc_asyncio", request_type=catalog.DeleteEntryGroupRequest
+):
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.delete_asset), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.delete_entry_group), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             operations_pb2.Operation(name="operations/spam")
         )
-        response = await client.delete_asset(request)
+        response = await client.delete_entry_group(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.DeleteAssetRequest()
+        request = catalog.DeleteEntryGroupRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, future.Future)
 
 
 @pytest.mark.asyncio
-async def test_delete_asset_async_from_dict():
-    await test_delete_asset_async(request_type=dict)
+async def test_delete_entry_group_async_from_dict():
+    await test_delete_entry_group_async(request_type=dict)
 
 
-def test_delete_asset_field_headers():
-    client = DataplexServiceClient(
+def test_delete_entry_group_field_headers():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.DeleteAssetRequest()
+    request = catalog.DeleteEntryGroupRequest()
 
     request.name = "name_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.delete_asset), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.delete_entry_group), "__call__"
+    ) as call:
         call.return_value = operations_pb2.Operation(name="operations/op")
-        client.delete_asset(request)
+        client.delete_entry_group(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
@@ -4951,231 +6551,399 @@
     assert (
         "x-goog-request-params",
         "name=name_value",
     ) in kw["metadata"]
 
 
 @pytest.mark.asyncio
-async def test_delete_asset_field_headers_async():
-    client = DataplexServiceAsyncClient(
+async def test_delete_entry_group_field_headers_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.DeleteAssetRequest()
+    request = catalog.DeleteEntryGroupRequest()
 
     request.name = "name_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.delete_asset), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.delete_entry_group), "__call__"
+    ) as call:
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             operations_pb2.Operation(name="operations/op")
         )
-        await client.delete_asset(request)
+        await client.delete_entry_group(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
     _, _, kw = call.mock_calls[0]
     assert (
         "x-goog-request-params",
         "name=name_value",
     ) in kw["metadata"]
 
 
-def test_delete_asset_flattened():
-    client = DataplexServiceClient(
+def test_delete_entry_group_flattened():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.delete_asset), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.delete_entry_group), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/op")
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        client.delete_asset(
+        client.delete_entry_group(
             name="name_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         arg = args[0].name
         mock_val = "name_value"
         assert arg == mock_val
 
 
-def test_delete_asset_flattened_error():
-    client = DataplexServiceClient(
+def test_delete_entry_group_flattened_error():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        client.delete_asset(
-            service.DeleteAssetRequest(),
+        client.delete_entry_group(
+            catalog.DeleteEntryGroupRequest(),
             name="name_value",
         )
 
 
 @pytest.mark.asyncio
-async def test_delete_asset_flattened_async():
-    client = DataplexServiceAsyncClient(
+async def test_delete_entry_group_flattened_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.delete_asset), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.delete_entry_group), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation(name="operations/op")
 
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             operations_pb2.Operation(name="operations/spam")
         )
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        response = await client.delete_asset(
+        response = await client.delete_entry_group(
             name="name_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         arg = args[0].name
         mock_val = "name_value"
         assert arg == mock_val
 
 
 @pytest.mark.asyncio
-async def test_delete_asset_flattened_error_async():
-    client = DataplexServiceAsyncClient(
+async def test_delete_entry_group_flattened_error_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        await client.delete_asset(
-            service.DeleteAssetRequest(),
+        await client.delete_entry_group(
+            catalog.DeleteEntryGroupRequest(),
             name="name_value",
         )
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
-        service.ListAssetsRequest,
+        catalog.ListEntryGroupsRequest,
         dict,
     ],
 )
-def test_list_assets(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
+def test_list_entry_groups(request_type, transport: str = "grpc"):
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_assets), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.list_entry_groups), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
-        call.return_value = service.ListAssetsResponse(
+        call.return_value = catalog.ListEntryGroupsResponse(
             next_page_token="next_page_token_value",
+            unreachable_locations=["unreachable_locations_value"],
         )
-        response = client.list_assets(request)
+        response = client.list_entry_groups(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.ListAssetsRequest()
+        request = catalog.ListEntryGroupsRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
-    assert isinstance(response, pagers.ListAssetsPager)
+    assert isinstance(response, pagers.ListEntryGroupsPager)
     assert response.next_page_token == "next_page_token_value"
+    assert response.unreachable_locations == ["unreachable_locations_value"]
 
 
-def test_list_assets_empty_call():
+def test_list_entry_groups_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
     # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.list_entry_groups), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.list_entry_groups()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == catalog.ListEntryGroupsRequest()
+
+
+def test_list_entry_groups_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = catalog.ListEntryGroupsRequest(
+        parent="parent_value",
+        page_token="page_token_value",
+        filter="filter_value",
+        order_by="order_by_value",
+    )
+
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_assets), "__call__") as call:
-        client.list_assets()
+    with mock.patch.object(
+        type(client.transport.list_entry_groups), "__call__"
+    ) as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.list_entry_groups(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == catalog.ListEntryGroupsRequest(
+            parent="parent_value",
+            page_token="page_token_value",
+            filter="filter_value",
+            order_by="order_by_value",
+        )
+
+
+def test_list_entry_groups_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = CatalogServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.list_entry_groups in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.list_entry_groups
+        ] = mock_rpc
+        request = {}
+        client.list_entry_groups(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.list_entry_groups(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_list_entry_groups_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = CatalogServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(
+        type(client.transport.list_entry_groups), "__call__"
+    ) as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            catalog.ListEntryGroupsResponse(
+                next_page_token="next_page_token_value",
+                unreachable_locations=["unreachable_locations_value"],
+            )
+        )
+        response = await client.list_entry_groups()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.ListAssetsRequest()
+        assert args[0] == catalog.ListEntryGroupsRequest()
+
+
+@pytest.mark.asyncio
+async def test_list_entry_groups_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = CatalogServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.list_entry_groups
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.list_entry_groups
+        ] = mock_object
+
+        request = {}
+        await client.list_entry_groups(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.list_entry_groups(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
 
 
 @pytest.mark.asyncio
-async def test_list_assets_async(
-    transport: str = "grpc_asyncio", request_type=service.ListAssetsRequest
+async def test_list_entry_groups_async(
+    transport: str = "grpc_asyncio", request_type=catalog.ListEntryGroupsRequest
 ):
-    client = DataplexServiceAsyncClient(
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_assets), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.list_entry_groups), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.ListAssetsResponse(
+            catalog.ListEntryGroupsResponse(
                 next_page_token="next_page_token_value",
+                unreachable_locations=["unreachable_locations_value"],
             )
         )
-        response = await client.list_assets(request)
+        response = await client.list_entry_groups(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.ListAssetsRequest()
+        request = catalog.ListEntryGroupsRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
-    assert isinstance(response, pagers.ListAssetsAsyncPager)
+    assert isinstance(response, pagers.ListEntryGroupsAsyncPager)
     assert response.next_page_token == "next_page_token_value"
+    assert response.unreachable_locations == ["unreachable_locations_value"]
 
 
 @pytest.mark.asyncio
-async def test_list_assets_async_from_dict():
-    await test_list_assets_async(request_type=dict)
+async def test_list_entry_groups_async_from_dict():
+    await test_list_entry_groups_async(request_type=dict)
 
 
-def test_list_assets_field_headers():
-    client = DataplexServiceClient(
+def test_list_entry_groups_field_headers():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.ListAssetsRequest()
+    request = catalog.ListEntryGroupsRequest()
 
     request.parent = "parent_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_assets), "__call__") as call:
-        call.return_value = service.ListAssetsResponse()
-        client.list_assets(request)
+    with mock.patch.object(
+        type(client.transport.list_entry_groups), "__call__"
+    ) as call:
+        call.return_value = catalog.ListEntryGroupsResponse()
+        client.list_entry_groups(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
@@ -5183,437 +6951,597 @@
     assert (
         "x-goog-request-params",
         "parent=parent_value",
     ) in kw["metadata"]
 
 
 @pytest.mark.asyncio
-async def test_list_assets_field_headers_async():
-    client = DataplexServiceAsyncClient(
+async def test_list_entry_groups_field_headers_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.ListAssetsRequest()
+    request = catalog.ListEntryGroupsRequest()
 
     request.parent = "parent_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_assets), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.list_entry_groups), "__call__"
+    ) as call:
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.ListAssetsResponse()
+            catalog.ListEntryGroupsResponse()
         )
-        await client.list_assets(request)
+        await client.list_entry_groups(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
     _, _, kw = call.mock_calls[0]
     assert (
         "x-goog-request-params",
         "parent=parent_value",
     ) in kw["metadata"]
 
 
-def test_list_assets_flattened():
-    client = DataplexServiceClient(
+def test_list_entry_groups_flattened():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_assets), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.list_entry_groups), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
-        call.return_value = service.ListAssetsResponse()
+        call.return_value = catalog.ListEntryGroupsResponse()
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        client.list_assets(
+        client.list_entry_groups(
             parent="parent_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         arg = args[0].parent
         mock_val = "parent_value"
         assert arg == mock_val
 
 
-def test_list_assets_flattened_error():
-    client = DataplexServiceClient(
+def test_list_entry_groups_flattened_error():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        client.list_assets(
-            service.ListAssetsRequest(),
+        client.list_entry_groups(
+            catalog.ListEntryGroupsRequest(),
             parent="parent_value",
         )
 
 
 @pytest.mark.asyncio
-async def test_list_assets_flattened_async():
-    client = DataplexServiceAsyncClient(
+async def test_list_entry_groups_flattened_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_assets), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.list_entry_groups), "__call__"
+    ) as call:
         # Designate an appropriate return value for the call.
-        call.return_value = service.ListAssetsResponse()
+        call.return_value = catalog.ListEntryGroupsResponse()
 
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.ListAssetsResponse()
+            catalog.ListEntryGroupsResponse()
         )
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        response = await client.list_assets(
+        response = await client.list_entry_groups(
             parent="parent_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         arg = args[0].parent
         mock_val = "parent_value"
         assert arg == mock_val
 
 
 @pytest.mark.asyncio
-async def test_list_assets_flattened_error_async():
-    client = DataplexServiceAsyncClient(
+async def test_list_entry_groups_flattened_error_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        await client.list_assets(
-            service.ListAssetsRequest(),
+        await client.list_entry_groups(
+            catalog.ListEntryGroupsRequest(),
             parent="parent_value",
         )
 
 
-def test_list_assets_pager(transport_name: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
+def test_list_entry_groups_pager(transport_name: str = "grpc"):
+    client = CatalogServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
         transport=transport_name,
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_assets), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.list_entry_groups), "__call__"
+    ) as call:
         # Set the response to a series of pages.
         call.side_effect = (
-            service.ListAssetsResponse(
-                assets=[
-                    resources.Asset(),
-                    resources.Asset(),
-                    resources.Asset(),
+            catalog.ListEntryGroupsResponse(
+                entry_groups=[
+                    catalog.EntryGroup(),
+                    catalog.EntryGroup(),
+                    catalog.EntryGroup(),
                 ],
                 next_page_token="abc",
             ),
-            service.ListAssetsResponse(
-                assets=[],
+            catalog.ListEntryGroupsResponse(
+                entry_groups=[],
                 next_page_token="def",
             ),
-            service.ListAssetsResponse(
-                assets=[
-                    resources.Asset(),
+            catalog.ListEntryGroupsResponse(
+                entry_groups=[
+                    catalog.EntryGroup(),
                 ],
                 next_page_token="ghi",
             ),
-            service.ListAssetsResponse(
-                assets=[
-                    resources.Asset(),
-                    resources.Asset(),
+            catalog.ListEntryGroupsResponse(
+                entry_groups=[
+                    catalog.EntryGroup(),
+                    catalog.EntryGroup(),
                 ],
             ),
             RuntimeError,
         )
 
         metadata = ()
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", ""),)),
         )
-        pager = client.list_assets(request={})
+        pager = client.list_entry_groups(request={})
 
         assert pager._metadata == metadata
 
         results = list(pager)
         assert len(results) == 6
-        assert all(isinstance(i, resources.Asset) for i in results)
+        assert all(isinstance(i, catalog.EntryGroup) for i in results)
 
 
-def test_list_assets_pages(transport_name: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
+def test_list_entry_groups_pages(transport_name: str = "grpc"):
+    client = CatalogServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
         transport=transport_name,
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_assets), "__call__") as call:
+    with mock.patch.object(
+        type(client.transport.list_entry_groups), "__call__"
+    ) as call:
         # Set the response to a series of pages.
         call.side_effect = (
-            service.ListAssetsResponse(
-                assets=[
-                    resources.Asset(),
-                    resources.Asset(),
-                    resources.Asset(),
+            catalog.ListEntryGroupsResponse(
+                entry_groups=[
+                    catalog.EntryGroup(),
+                    catalog.EntryGroup(),
+                    catalog.EntryGroup(),
                 ],
                 next_page_token="abc",
             ),
-            service.ListAssetsResponse(
-                assets=[],
+            catalog.ListEntryGroupsResponse(
+                entry_groups=[],
                 next_page_token="def",
             ),
-            service.ListAssetsResponse(
-                assets=[
-                    resources.Asset(),
+            catalog.ListEntryGroupsResponse(
+                entry_groups=[
+                    catalog.EntryGroup(),
                 ],
                 next_page_token="ghi",
             ),
-            service.ListAssetsResponse(
-                assets=[
-                    resources.Asset(),
-                    resources.Asset(),
+            catalog.ListEntryGroupsResponse(
+                entry_groups=[
+                    catalog.EntryGroup(),
+                    catalog.EntryGroup(),
                 ],
             ),
             RuntimeError,
         )
-        pages = list(client.list_assets(request={}).pages)
+        pages = list(client.list_entry_groups(request={}).pages)
         for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
             assert page_.raw_page.next_page_token == token
 
 
 @pytest.mark.asyncio
-async def test_list_assets_async_pager():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
+async def test_list_entry_groups_async_pager():
+    client = CatalogServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
-        type(client.transport.list_assets), "__call__", new_callable=mock.AsyncMock
+        type(client.transport.list_entry_groups),
+        "__call__",
+        new_callable=mock.AsyncMock,
     ) as call:
         # Set the response to a series of pages.
         call.side_effect = (
-            service.ListAssetsResponse(
-                assets=[
-                    resources.Asset(),
-                    resources.Asset(),
-                    resources.Asset(),
+            catalog.ListEntryGroupsResponse(
+                entry_groups=[
+                    catalog.EntryGroup(),
+                    catalog.EntryGroup(),
+                    catalog.EntryGroup(),
                 ],
                 next_page_token="abc",
             ),
-            service.ListAssetsResponse(
-                assets=[],
+            catalog.ListEntryGroupsResponse(
+                entry_groups=[],
                 next_page_token="def",
             ),
-            service.ListAssetsResponse(
-                assets=[
-                    resources.Asset(),
+            catalog.ListEntryGroupsResponse(
+                entry_groups=[
+                    catalog.EntryGroup(),
                 ],
                 next_page_token="ghi",
             ),
-            service.ListAssetsResponse(
-                assets=[
-                    resources.Asset(),
-                    resources.Asset(),
+            catalog.ListEntryGroupsResponse(
+                entry_groups=[
+                    catalog.EntryGroup(),
+                    catalog.EntryGroup(),
                 ],
             ),
             RuntimeError,
         )
-        async_pager = await client.list_assets(
+        async_pager = await client.list_entry_groups(
             request={},
         )
         assert async_pager.next_page_token == "abc"
         responses = []
         async for response in async_pager:  # pragma: no branch
             responses.append(response)
 
         assert len(responses) == 6
-        assert all(isinstance(i, resources.Asset) for i in responses)
+        assert all(isinstance(i, catalog.EntryGroup) for i in responses)
 
 
 @pytest.mark.asyncio
-async def test_list_assets_async_pages():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
+async def test_list_entry_groups_async_pages():
+    client = CatalogServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
-        type(client.transport.list_assets), "__call__", new_callable=mock.AsyncMock
+        type(client.transport.list_entry_groups),
+        "__call__",
+        new_callable=mock.AsyncMock,
     ) as call:
         # Set the response to a series of pages.
         call.side_effect = (
-            service.ListAssetsResponse(
-                assets=[
-                    resources.Asset(),
-                    resources.Asset(),
-                    resources.Asset(),
+            catalog.ListEntryGroupsResponse(
+                entry_groups=[
+                    catalog.EntryGroup(),
+                    catalog.EntryGroup(),
+                    catalog.EntryGroup(),
                 ],
                 next_page_token="abc",
             ),
-            service.ListAssetsResponse(
-                assets=[],
+            catalog.ListEntryGroupsResponse(
+                entry_groups=[],
                 next_page_token="def",
             ),
-            service.ListAssetsResponse(
-                assets=[
-                    resources.Asset(),
+            catalog.ListEntryGroupsResponse(
+                entry_groups=[
+                    catalog.EntryGroup(),
                 ],
                 next_page_token="ghi",
             ),
-            service.ListAssetsResponse(
-                assets=[
-                    resources.Asset(),
-                    resources.Asset(),
+            catalog.ListEntryGroupsResponse(
+                entry_groups=[
+                    catalog.EntryGroup(),
+                    catalog.EntryGroup(),
                 ],
             ),
             RuntimeError,
         )
         pages = []
         # Workaround issue in python 3.9 related to code coverage by adding `# pragma: no branch`
         # See https://github.com/googleapis/gapic-generator-python/pull/1174#issuecomment-1025132372
         async for page_ in (  # pragma: no branch
-            await client.list_assets(request={})
+            await client.list_entry_groups(request={})
         ).pages:
             pages.append(page_)
         for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
             assert page_.raw_page.next_page_token == token
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
-        service.GetAssetRequest,
+        catalog.GetEntryGroupRequest,
         dict,
     ],
 )
-def test_get_asset(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
+def test_get_entry_group(request_type, transport: str = "grpc"):
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_asset), "__call__") as call:
+    with mock.patch.object(type(client.transport.get_entry_group), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = resources.Asset(
+        call.return_value = catalog.EntryGroup(
             name="name_value",
-            display_name="display_name_value",
             uid="uid_value",
             description="description_value",
-            state=resources.State.ACTIVE,
+            display_name="display_name_value",
+            etag="etag_value",
+            transfer_status=catalog.TransferStatus.TRANSFER_STATUS_MIGRATED,
         )
-        response = client.get_asset(request)
+        response = client.get_entry_group(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.GetAssetRequest()
+        request = catalog.GetEntryGroupRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
-    assert isinstance(response, resources.Asset)
+    assert isinstance(response, catalog.EntryGroup)
     assert response.name == "name_value"
-    assert response.display_name == "display_name_value"
     assert response.uid == "uid_value"
     assert response.description == "description_value"
-    assert response.state == resources.State.ACTIVE
+    assert response.display_name == "display_name_value"
+    assert response.etag == "etag_value"
+    assert response.transfer_status == catalog.TransferStatus.TRANSFER_STATUS_MIGRATED
 
 
-def test_get_asset_empty_call():
+def test_get_entry_group_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
     # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_asset), "__call__") as call:
-        client.get_asset()
+    with mock.patch.object(type(client.transport.get_entry_group), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.get_entry_group()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.GetAssetRequest()
+        assert args[0] == catalog.GetEntryGroupRequest()
+
+
+def test_get_entry_group_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = CatalogServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = catalog.GetEntryGroupRequest(
+        name="name_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_entry_group), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.get_entry_group(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == catalog.GetEntryGroupRequest(
+            name="name_value",
+        )
+
+
+def test_get_entry_group_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = CatalogServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.get_entry_group in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[client._transport.get_entry_group] = mock_rpc
+        request = {}
+        client.get_entry_group(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.get_entry_group(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_get_entry_group_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = CatalogServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_entry_group), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            catalog.EntryGroup(
+                name="name_value",
+                uid="uid_value",
+                description="description_value",
+                display_name="display_name_value",
+                etag="etag_value",
+                transfer_status=catalog.TransferStatus.TRANSFER_STATUS_MIGRATED,
+            )
+        )
+        response = await client.get_entry_group()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == catalog.GetEntryGroupRequest()
 
 
 @pytest.mark.asyncio
-async def test_get_asset_async(
-    transport: str = "grpc_asyncio", request_type=service.GetAssetRequest
+async def test_get_entry_group_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
 ):
-    client = DataplexServiceAsyncClient(
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = CatalogServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.get_entry_group
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.get_entry_group
+        ] = mock_object
+
+        request = {}
+        await client.get_entry_group(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.get_entry_group(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_get_entry_group_async(
+    transport: str = "grpc_asyncio", request_type=catalog.GetEntryGroupRequest
+):
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_asset), "__call__") as call:
+    with mock.patch.object(type(client.transport.get_entry_group), "__call__") as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            resources.Asset(
+            catalog.EntryGroup(
                 name="name_value",
-                display_name="display_name_value",
                 uid="uid_value",
                 description="description_value",
-                state=resources.State.ACTIVE,
+                display_name="display_name_value",
+                etag="etag_value",
+                transfer_status=catalog.TransferStatus.TRANSFER_STATUS_MIGRATED,
             )
         )
-        response = await client.get_asset(request)
+        response = await client.get_entry_group(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.GetAssetRequest()
+        request = catalog.GetEntryGroupRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
-    assert isinstance(response, resources.Asset)
+    assert isinstance(response, catalog.EntryGroup)
     assert response.name == "name_value"
-    assert response.display_name == "display_name_value"
     assert response.uid == "uid_value"
     assert response.description == "description_value"
-    assert response.state == resources.State.ACTIVE
+    assert response.display_name == "display_name_value"
+    assert response.etag == "etag_value"
+    assert response.transfer_status == catalog.TransferStatus.TRANSFER_STATUS_MIGRATED
 
 
 @pytest.mark.asyncio
-async def test_get_asset_async_from_dict():
-    await test_get_asset_async(request_type=dict)
+async def test_get_entry_group_async_from_dict():
+    await test_get_entry_group_async(request_type=dict)
 
 
-def test_get_asset_field_headers():
-    client = DataplexServiceClient(
+def test_get_entry_group_field_headers():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.GetAssetRequest()
+    request = catalog.GetEntryGroupRequest()
 
     request.name = "name_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_asset), "__call__") as call:
-        call.return_value = resources.Asset()
-        client.get_asset(request)
+    with mock.patch.object(type(client.transport.get_entry_group), "__call__") as call:
+        call.return_value = catalog.EntryGroup()
+        client.get_entry_group(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
@@ -5621,665 +7549,381 @@
     assert (
         "x-goog-request-params",
         "name=name_value",
     ) in kw["metadata"]
 
 
 @pytest.mark.asyncio
-async def test_get_asset_field_headers_async():
-    client = DataplexServiceAsyncClient(
+async def test_get_entry_group_field_headers_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.GetAssetRequest()
+    request = catalog.GetEntryGroupRequest()
 
     request.name = "name_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_asset), "__call__") as call:
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(resources.Asset())
-        await client.get_asset(request)
+    with mock.patch.object(type(client.transport.get_entry_group), "__call__") as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(catalog.EntryGroup())
+        await client.get_entry_group(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
     _, _, kw = call.mock_calls[0]
     assert (
         "x-goog-request-params",
         "name=name_value",
     ) in kw["metadata"]
 
 
-def test_get_asset_flattened():
-    client = DataplexServiceClient(
+def test_get_entry_group_flattened():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_asset), "__call__") as call:
+    with mock.patch.object(type(client.transport.get_entry_group), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = resources.Asset()
+        call.return_value = catalog.EntryGroup()
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        client.get_asset(
+        client.get_entry_group(
             name="name_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         arg = args[0].name
         mock_val = "name_value"
         assert arg == mock_val
 
 
-def test_get_asset_flattened_error():
-    client = DataplexServiceClient(
+def test_get_entry_group_flattened_error():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        client.get_asset(
-            service.GetAssetRequest(),
+        client.get_entry_group(
+            catalog.GetEntryGroupRequest(),
             name="name_value",
         )
 
 
 @pytest.mark.asyncio
-async def test_get_asset_flattened_async():
-    client = DataplexServiceAsyncClient(
+async def test_get_entry_group_flattened_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_asset), "__call__") as call:
+    with mock.patch.object(type(client.transport.get_entry_group), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = resources.Asset()
+        call.return_value = catalog.EntryGroup()
 
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(resources.Asset())
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(catalog.EntryGroup())
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        response = await client.get_asset(
+        response = await client.get_entry_group(
             name="name_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         arg = args[0].name
         mock_val = "name_value"
         assert arg == mock_val
 
 
 @pytest.mark.asyncio
-async def test_get_asset_flattened_error_async():
-    client = DataplexServiceAsyncClient(
+async def test_get_entry_group_flattened_error_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        await client.get_asset(
-            service.GetAssetRequest(),
+        await client.get_entry_group(
+            catalog.GetEntryGroupRequest(),
             name="name_value",
         )
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
-        service.ListAssetActionsRequest,
+        catalog.CreateEntryRequest,
         dict,
     ],
 )
-def test_list_asset_actions(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
+def test_create_entry(request_type, transport: str = "grpc"):
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_asset_actions), "__call__"
-    ) as call:
+    with mock.patch.object(type(client.transport.create_entry), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = service.ListActionsResponse(
-            next_page_token="next_page_token_value",
+        call.return_value = catalog.Entry(
+            name="name_value",
+            entry_type="entry_type_value",
+            parent_entry="parent_entry_value",
+            fully_qualified_name="fully_qualified_name_value",
         )
-        response = client.list_asset_actions(request)
+        response = client.create_entry(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.ListAssetActionsRequest()
+        request = catalog.CreateEntryRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
-    assert isinstance(response, pagers.ListAssetActionsPager)
-    assert response.next_page_token == "next_page_token_value"
+    assert isinstance(response, catalog.Entry)
+    assert response.name == "name_value"
+    assert response.entry_type == "entry_type_value"
+    assert response.parent_entry == "parent_entry_value"
+    assert response.fully_qualified_name == "fully_qualified_name_value"
 
 
-def test_list_asset_actions_empty_call():
+def test_create_entry_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
     # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_asset_actions), "__call__"
-    ) as call:
-        client.list_asset_actions()
+    with mock.patch.object(type(client.transport.create_entry), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.create_entry()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.ListAssetActionsRequest()
+        assert args[0] == catalog.CreateEntryRequest()
 
 
-@pytest.mark.asyncio
-async def test_list_asset_actions_async(
-    transport: str = "grpc_asyncio", request_type=service.ListAssetActionsRequest
-):
-    client = DataplexServiceAsyncClient(
+def test_create_entry_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
-        transport=transport,
+        transport="grpc",
     )
 
-    # Everything is optional in proto3 as far as the runtime is concerned,
-    # and we are mocking out the actual API, so just send an empty request.
-    request = request_type()
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_asset_actions), "__call__"
-    ) as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.ListActionsResponse(
-                next_page_token="next_page_token_value",
-            )
-        )
-        response = await client.list_asset_actions(request)
-
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls)
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.ListAssetActionsRequest()
-
-    # Establish that the response is the type that we expect.
-    assert isinstance(response, pagers.ListAssetActionsAsyncPager)
-    assert response.next_page_token == "next_page_token_value"
-
-
-@pytest.mark.asyncio
-async def test_list_asset_actions_async_from_dict():
-    await test_list_asset_actions_async(request_type=dict)
-
-
-def test_list_asset_actions_field_headers():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = catalog.CreateEntryRequest(
+        parent="parent_value",
+        entry_id="entry_id_value",
     )
 
-    # Any value that is part of the HTTP/1.1 URI should be sent as
-    # a field header. Set these to a non-empty value.
-    request = service.ListAssetActionsRequest()
-
-    request.parent = "parent_value"
-
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_asset_actions), "__call__"
-    ) as call:
-        call.return_value = service.ListActionsResponse()
-        client.list_asset_actions(request)
-
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls) == 1
+    with mock.patch.object(type(client.transport.create_entry), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.create_entry(request=request)
+        call.assert_called()
         _, args, _ = call.mock_calls[0]
-        assert args[0] == request
-
-    # Establish that the field header was sent.
-    _, _, kw = call.mock_calls[0]
-    assert (
-        "x-goog-request-params",
-        "parent=parent_value",
-    ) in kw["metadata"]
-
-
-@pytest.mark.asyncio
-async def test_list_asset_actions_field_headers_async():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Any value that is part of the HTTP/1.1 URI should be sent as
-    # a field header. Set these to a non-empty value.
-    request = service.ListAssetActionsRequest()
-
-    request.parent = "parent_value"
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_asset_actions), "__call__"
-    ) as call:
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.ListActionsResponse()
+        assert args[0] == catalog.CreateEntryRequest(
+            parent="parent_value",
+            entry_id="entry_id_value",
         )
-        await client.list_asset_actions(request)
 
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls)
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == request
 
-    # Establish that the field header was sent.
-    _, _, kw = call.mock_calls[0]
-    assert (
-        "x-goog-request-params",
-        "parent=parent_value",
-    ) in kw["metadata"]
+def test_create_entry_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = CatalogServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
 
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
 
-def test_list_asset_actions_flattened():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
+        # Ensure method has been cached
+        assert client._transport.create_entry in client._transport._wrapped_methods
 
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_asset_actions), "__call__"
-    ) as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = service.ListActionsResponse()
-        # Call the method with a truthy value for each flattened field,
-        # using the keyword arguments to the method.
-        client.list_asset_actions(
-            parent="parent_value",
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
         )
+        client._transport._wrapped_methods[client._transport.create_entry] = mock_rpc
+        request = {}
+        client.create_entry(request)
 
-        # Establish that the underlying call was made with the expected
-        # request object values.
-        assert len(call.mock_calls) == 1
-        _, args, _ = call.mock_calls[0]
-        arg = args[0].parent
-        mock_val = "parent_value"
-        assert arg == mock_val
-
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
 
-def test_list_asset_actions_flattened_error():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
+        client.create_entry(request)
 
-    # Attempting to call a method with both a request object and flattened
-    # fields is an error.
-    with pytest.raises(ValueError):
-        client.list_asset_actions(
-            service.ListAssetActionsRequest(),
-            parent="parent_value",
-        )
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
 
 
 @pytest.mark.asyncio
-async def test_list_asset_actions_flattened_async():
-    client = DataplexServiceAsyncClient(
+async def test_create_entry_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_asset_actions), "__call__"
-    ) as call:
+    with mock.patch.object(type(client.transport.create_entry), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = service.ListActionsResponse()
-
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.ListActionsResponse()
-        )
-        # Call the method with a truthy value for each flattened field,
-        # using the keyword arguments to the method.
-        response = await client.list_asset_actions(
-            parent="parent_value",
+            catalog.Entry(
+                name="name_value",
+                entry_type="entry_type_value",
+                parent_entry="parent_entry_value",
+                fully_qualified_name="fully_qualified_name_value",
+            )
         )
-
-        # Establish that the underlying call was made with the expected
-        # request object values.
-        assert len(call.mock_calls)
+        response = await client.create_entry()
+        call.assert_called()
         _, args, _ = call.mock_calls[0]
-        arg = args[0].parent
-        mock_val = "parent_value"
-        assert arg == mock_val
+        assert args[0] == catalog.CreateEntryRequest()
 
 
 @pytest.mark.asyncio
-async def test_list_asset_actions_flattened_error_async():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Attempting to call a method with both a request object and flattened
-    # fields is an error.
-    with pytest.raises(ValueError):
-        await client.list_asset_actions(
-            service.ListAssetActionsRequest(),
-            parent="parent_value",
-        )
-
-
-def test_list_asset_actions_pager(transport_name: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
-        transport=transport_name,
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_asset_actions), "__call__"
-    ) as call:
-        # Set the response to a series of pages.
-        call.side_effect = (
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                    resources.Action(),
-                    resources.Action(),
-                ],
-                next_page_token="abc",
-            ),
-            service.ListActionsResponse(
-                actions=[],
-                next_page_token="def",
-            ),
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                ],
-                next_page_token="ghi",
-            ),
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                    resources.Action(),
-                ],
-            ),
-            RuntimeError,
-        )
-
-        metadata = ()
-        metadata = tuple(metadata) + (
-            gapic_v1.routing_header.to_grpc_metadata((("parent", ""),)),
-        )
-        pager = client.list_asset_actions(request={})
-
-        assert pager._metadata == metadata
-
-        results = list(pager)
-        assert len(results) == 6
-        assert all(isinstance(i, resources.Action) for i in results)
-
-
-def test_list_asset_actions_pages(transport_name: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
-        transport=transport_name,
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_asset_actions), "__call__"
-    ) as call:
-        # Set the response to a series of pages.
-        call.side_effect = (
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                    resources.Action(),
-                    resources.Action(),
-                ],
-                next_page_token="abc",
-            ),
-            service.ListActionsResponse(
-                actions=[],
-                next_page_token="def",
-            ),
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                ],
-                next_page_token="ghi",
-            ),
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                    resources.Action(),
-                ],
-            ),
-            RuntimeError,
-        )
-        pages = list(client.list_asset_actions(request={}).pages)
-        for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
-            assert page_.raw_page.next_page_token == token
-
-
-@pytest.mark.asyncio
-async def test_list_asset_actions_async_pager():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_asset_actions),
-        "__call__",
-        new_callable=mock.AsyncMock,
-    ) as call:
-        # Set the response to a series of pages.
-        call.side_effect = (
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                    resources.Action(),
-                    resources.Action(),
-                ],
-                next_page_token="abc",
-            ),
-            service.ListActionsResponse(
-                actions=[],
-                next_page_token="def",
-            ),
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                ],
-                next_page_token="ghi",
-            ),
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                    resources.Action(),
-                ],
-            ),
-            RuntimeError,
-        )
-        async_pager = await client.list_asset_actions(
-            request={},
+async def test_create_entry_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = CatalogServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
         )
-        assert async_pager.next_page_token == "abc"
-        responses = []
-        async for response in async_pager:  # pragma: no branch
-            responses.append(response)
 
-        assert len(responses) == 6
-        assert all(isinstance(i, resources.Action) for i in responses)
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
 
-
-@pytest.mark.asyncio
-async def test_list_asset_actions_async_pages():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_asset_actions),
-        "__call__",
-        new_callable=mock.AsyncMock,
-    ) as call:
-        # Set the response to a series of pages.
-        call.side_effect = (
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                    resources.Action(),
-                    resources.Action(),
-                ],
-                next_page_token="abc",
-            ),
-            service.ListActionsResponse(
-                actions=[],
-                next_page_token="def",
-            ),
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                ],
-                next_page_token="ghi",
-            ),
-            service.ListActionsResponse(
-                actions=[
-                    resources.Action(),
-                    resources.Action(),
-                ],
-            ),
-            RuntimeError,
+        # Ensure method has been cached
+        assert (
+            client._client._transport.create_entry
+            in client._client._transport._wrapped_methods
         )
-        pages = []
-        # Workaround issue in python 3.9 related to code coverage by adding `# pragma: no branch`
-        # See https://github.com/googleapis/gapic-generator-python/pull/1174#issuecomment-1025132372
-        async for page_ in (  # pragma: no branch
-            await client.list_asset_actions(request={})
-        ).pages:
-            pages.append(page_)
-        for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
-            assert page_.raw_page.next_page_token == token
-
 
-@pytest.mark.parametrize(
-    "request_type",
-    [
-        service.CreateTaskRequest,
-        dict,
-    ],
-)
-def test_create_task(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-        transport=transport,
-    )
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
 
-    # Everything is optional in proto3 as far as the runtime is concerned,
-    # and we are mocking out the actual API, so just send an empty request.
-    request = request_type()
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.create_entry
+        ] = mock_object
 
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.create_task), "__call__") as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = operations_pb2.Operation(name="operations/spam")
-        response = client.create_task(request)
+        request = {}
+        await client.create_entry(request)
 
         # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls) == 1
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.CreateTaskRequest()
-
-    # Establish that the response is the type that we expect.
-    assert isinstance(response, future.Future)
+        assert mock_object.call_count == 1
 
+        await client.create_entry(request)
 
-def test_create_task_empty_call():
-    # This test is a coverage failsafe to make sure that totally empty calls,
-    # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-        transport="grpc",
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.create_task), "__call__") as call:
-        client.create_task()
-        call.assert_called()
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.CreateTaskRequest()
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
 
 
 @pytest.mark.asyncio
-async def test_create_task_async(
-    transport: str = "grpc_asyncio", request_type=service.CreateTaskRequest
+async def test_create_entry_async(
+    transport: str = "grpc_asyncio", request_type=catalog.CreateEntryRequest
 ):
-    client = DataplexServiceAsyncClient(
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.create_task), "__call__") as call:
+    with mock.patch.object(type(client.transport.create_entry), "__call__") as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            operations_pb2.Operation(name="operations/spam")
+            catalog.Entry(
+                name="name_value",
+                entry_type="entry_type_value",
+                parent_entry="parent_entry_value",
+                fully_qualified_name="fully_qualified_name_value",
+            )
         )
-        response = await client.create_task(request)
+        response = await client.create_entry(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.CreateTaskRequest()
+        request = catalog.CreateEntryRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
-    assert isinstance(response, future.Future)
+    assert isinstance(response, catalog.Entry)
+    assert response.name == "name_value"
+    assert response.entry_type == "entry_type_value"
+    assert response.parent_entry == "parent_entry_value"
+    assert response.fully_qualified_name == "fully_qualified_name_value"
 
 
 @pytest.mark.asyncio
-async def test_create_task_async_from_dict():
-    await test_create_task_async(request_type=dict)
+async def test_create_entry_async_from_dict():
+    await test_create_entry_async(request_type=dict)
 
 
-def test_create_task_field_headers():
-    client = DataplexServiceClient(
+def test_create_entry_field_headers():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.CreateTaskRequest()
+    request = catalog.CreateEntryRequest()
 
     request.parent = "parent_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.create_task), "__call__") as call:
-        call.return_value = operations_pb2.Operation(name="operations/op")
-        client.create_task(request)
+    with mock.patch.object(type(client.transport.create_entry), "__call__") as call:
+        call.return_value = catalog.Entry()
+        client.create_entry(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
@@ -6287,1155 +7931,785 @@
     assert (
         "x-goog-request-params",
         "parent=parent_value",
     ) in kw["metadata"]
 
 
 @pytest.mark.asyncio
-async def test_create_task_field_headers_async():
-    client = DataplexServiceAsyncClient(
+async def test_create_entry_field_headers_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.CreateTaskRequest()
+    request = catalog.CreateEntryRequest()
 
     request.parent = "parent_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.create_task), "__call__") as call:
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            operations_pb2.Operation(name="operations/op")
-        )
-        await client.create_task(request)
+    with mock.patch.object(type(client.transport.create_entry), "__call__") as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(catalog.Entry())
+        await client.create_entry(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
     _, _, kw = call.mock_calls[0]
     assert (
         "x-goog-request-params",
         "parent=parent_value",
     ) in kw["metadata"]
 
 
-def test_create_task_flattened():
-    client = DataplexServiceClient(
+def test_create_entry_flattened():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.create_task), "__call__") as call:
+    with mock.patch.object(type(client.transport.create_entry), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = operations_pb2.Operation(name="operations/op")
+        call.return_value = catalog.Entry()
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        client.create_task(
+        client.create_entry(
             parent="parent_value",
-            task=tasks.Task(name="name_value"),
-            task_id="task_id_value",
+            entry=catalog.Entry(name="name_value"),
+            entry_id="entry_id_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         arg = args[0].parent
         mock_val = "parent_value"
         assert arg == mock_val
-        arg = args[0].task
-        mock_val = tasks.Task(name="name_value")
+        arg = args[0].entry
+        mock_val = catalog.Entry(name="name_value")
         assert arg == mock_val
-        arg = args[0].task_id
-        mock_val = "task_id_value"
+        arg = args[0].entry_id
+        mock_val = "entry_id_value"
         assert arg == mock_val
 
 
-def test_create_task_flattened_error():
-    client = DataplexServiceClient(
+def test_create_entry_flattened_error():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        client.create_task(
-            service.CreateTaskRequest(),
+        client.create_entry(
+            catalog.CreateEntryRequest(),
             parent="parent_value",
-            task=tasks.Task(name="name_value"),
-            task_id="task_id_value",
+            entry=catalog.Entry(name="name_value"),
+            entry_id="entry_id_value",
         )
 
 
 @pytest.mark.asyncio
-async def test_create_task_flattened_async():
-    client = DataplexServiceAsyncClient(
+async def test_create_entry_flattened_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.create_task), "__call__") as call:
+    with mock.patch.object(type(client.transport.create_entry), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = operations_pb2.Operation(name="operations/op")
+        call.return_value = catalog.Entry()
 
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            operations_pb2.Operation(name="operations/spam")
-        )
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(catalog.Entry())
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        response = await client.create_task(
+        response = await client.create_entry(
             parent="parent_value",
-            task=tasks.Task(name="name_value"),
-            task_id="task_id_value",
+            entry=catalog.Entry(name="name_value"),
+            entry_id="entry_id_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         arg = args[0].parent
         mock_val = "parent_value"
         assert arg == mock_val
-        arg = args[0].task
-        mock_val = tasks.Task(name="name_value")
+        arg = args[0].entry
+        mock_val = catalog.Entry(name="name_value")
         assert arg == mock_val
-        arg = args[0].task_id
-        mock_val = "task_id_value"
+        arg = args[0].entry_id
+        mock_val = "entry_id_value"
         assert arg == mock_val
 
 
 @pytest.mark.asyncio
-async def test_create_task_flattened_error_async():
-    client = DataplexServiceAsyncClient(
+async def test_create_entry_flattened_error_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        await client.create_task(
-            service.CreateTaskRequest(),
+        await client.create_entry(
+            catalog.CreateEntryRequest(),
             parent="parent_value",
-            task=tasks.Task(name="name_value"),
-            task_id="task_id_value",
+            entry=catalog.Entry(name="name_value"),
+            entry_id="entry_id_value",
         )
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
-        service.UpdateTaskRequest,
+        catalog.UpdateEntryRequest,
         dict,
     ],
 )
-def test_update_task(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
+def test_update_entry(request_type, transport: str = "grpc"):
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.update_task), "__call__") as call:
+    with mock.patch.object(type(client.transport.update_entry), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = operations_pb2.Operation(name="operations/spam")
-        response = client.update_task(request)
+        call.return_value = catalog.Entry(
+            name="name_value",
+            entry_type="entry_type_value",
+            parent_entry="parent_entry_value",
+            fully_qualified_name="fully_qualified_name_value",
+        )
+        response = client.update_entry(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.UpdateTaskRequest()
+        request = catalog.UpdateEntryRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
-    assert isinstance(response, future.Future)
+    assert isinstance(response, catalog.Entry)
+    assert response.name == "name_value"
+    assert response.entry_type == "entry_type_value"
+    assert response.parent_entry == "parent_entry_value"
+    assert response.fully_qualified_name == "fully_qualified_name_value"
 
 
-def test_update_task_empty_call():
+def test_update_entry_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
     # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.update_task), "__call__") as call:
-        client.update_task()
+    with mock.patch.object(type(client.transport.update_entry), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.update_entry()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.UpdateTaskRequest()
+        assert args[0] == catalog.UpdateEntryRequest()
 
 
-@pytest.mark.asyncio
-async def test_update_task_async(
-    transport: str = "grpc_asyncio", request_type=service.UpdateTaskRequest
-):
-    client = DataplexServiceAsyncClient(
+def test_update_entry_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
-        transport=transport,
+        transport="grpc",
     )
 
-    # Everything is optional in proto3 as far as the runtime is concerned,
-    # and we are mocking out the actual API, so just send an empty request.
-    request = request_type()
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = catalog.UpdateEntryRequest()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.update_task), "__call__") as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            operations_pb2.Operation(name="operations/spam")
+    with mock.patch.object(type(client.transport.update_entry), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
         )
-        response = await client.update_task(request)
-
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls)
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.UpdateTaskRequest()
-
-    # Establish that the response is the type that we expect.
-    assert isinstance(response, future.Future)
-
-
-@pytest.mark.asyncio
-async def test_update_task_async_from_dict():
-    await test_update_task_async(request_type=dict)
-
-
-def test_update_task_field_headers():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Any value that is part of the HTTP/1.1 URI should be sent as
-    # a field header. Set these to a non-empty value.
-    request = service.UpdateTaskRequest()
-
-    request.task.name = "name_value"
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.update_task), "__call__") as call:
-        call.return_value = operations_pb2.Operation(name="operations/op")
-        client.update_task(request)
-
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls) == 1
+        client.update_entry(request=request)
+        call.assert_called()
         _, args, _ = call.mock_calls[0]
-        assert args[0] == request
-
-    # Establish that the field header was sent.
-    _, _, kw = call.mock_calls[0]
-    assert (
-        "x-goog-request-params",
-        "task.name=name_value",
-    ) in kw["metadata"]
+        assert args[0] == catalog.UpdateEntryRequest()
 
 
-@pytest.mark.asyncio
-async def test_update_task_field_headers_async():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Any value that is part of the HTTP/1.1 URI should be sent as
-    # a field header. Set these to a non-empty value.
-    request = service.UpdateTaskRequest()
-
-    request.task.name = "name_value"
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.update_task), "__call__") as call:
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            operations_pb2.Operation(name="operations/op")
+def test_update_entry_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = CatalogServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
         )
-        await client.update_task(request)
 
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls)
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == request
-
-    # Establish that the field header was sent.
-    _, _, kw = call.mock_calls[0]
-    assert (
-        "x-goog-request-params",
-        "task.name=name_value",
-    ) in kw["metadata"]
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
 
+        # Ensure method has been cached
+        assert client._transport.update_entry in client._transport._wrapped_methods
 
-def test_update_task_flattened():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.update_task), "__call__") as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = operations_pb2.Operation(name="operations/op")
-        # Call the method with a truthy value for each flattened field,
-        # using the keyword arguments to the method.
-        client.update_task(
-            task=tasks.Task(name="name_value"),
-            update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
         )
+        client._transport._wrapped_methods[client._transport.update_entry] = mock_rpc
+        request = {}
+        client.update_entry(request)
 
-        # Establish that the underlying call was made with the expected
-        # request object values.
-        assert len(call.mock_calls) == 1
-        _, args, _ = call.mock_calls[0]
-        arg = args[0].task
-        mock_val = tasks.Task(name="name_value")
-        assert arg == mock_val
-        arg = args[0].update_mask
-        mock_val = field_mask_pb2.FieldMask(paths=["paths_value"])
-        assert arg == mock_val
-
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
 
-def test_update_task_flattened_error():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
+        client.update_entry(request)
 
-    # Attempting to call a method with both a request object and flattened
-    # fields is an error.
-    with pytest.raises(ValueError):
-        client.update_task(
-            service.UpdateTaskRequest(),
-            task=tasks.Task(name="name_value"),
-            update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
-        )
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
 
 
 @pytest.mark.asyncio
-async def test_update_task_flattened_async():
-    client = DataplexServiceAsyncClient(
+async def test_update_entry_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.update_task), "__call__") as call:
+    with mock.patch.object(type(client.transport.update_entry), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = operations_pb2.Operation(name="operations/op")
-
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            operations_pb2.Operation(name="operations/spam")
-        )
-        # Call the method with a truthy value for each flattened field,
-        # using the keyword arguments to the method.
-        response = await client.update_task(
-            task=tasks.Task(name="name_value"),
-            update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
+            catalog.Entry(
+                name="name_value",
+                entry_type="entry_type_value",
+                parent_entry="parent_entry_value",
+                fully_qualified_name="fully_qualified_name_value",
+            )
         )
-
-        # Establish that the underlying call was made with the expected
-        # request object values.
-        assert len(call.mock_calls)
+        response = await client.update_entry()
+        call.assert_called()
         _, args, _ = call.mock_calls[0]
-        arg = args[0].task
-        mock_val = tasks.Task(name="name_value")
-        assert arg == mock_val
-        arg = args[0].update_mask
-        mock_val = field_mask_pb2.FieldMask(paths=["paths_value"])
-        assert arg == mock_val
+        assert args[0] == catalog.UpdateEntryRequest()
 
 
 @pytest.mark.asyncio
-async def test_update_task_flattened_error_async():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Attempting to call a method with both a request object and flattened
-    # fields is an error.
-    with pytest.raises(ValueError):
-        await client.update_task(
-            service.UpdateTaskRequest(),
-            task=tasks.Task(name="name_value"),
-            update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
+async def test_update_entry_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = CatalogServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
         )
 
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
 
-@pytest.mark.parametrize(
-    "request_type",
-    [
-        service.DeleteTaskRequest,
-        dict,
-    ],
-)
-def test_delete_task(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-        transport=transport,
-    )
+        # Ensure method has been cached
+        assert (
+            client._client._transport.update_entry
+            in client._client._transport._wrapped_methods
+        )
 
-    # Everything is optional in proto3 as far as the runtime is concerned,
-    # and we are mocking out the actual API, so just send an empty request.
-    request = request_type()
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
 
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.delete_task), "__call__") as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = operations_pb2.Operation(name="operations/spam")
-        response = client.delete_task(request)
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.update_entry
+        ] = mock_object
 
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls) == 1
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.DeleteTaskRequest()
-
-    # Establish that the response is the type that we expect.
-    assert isinstance(response, future.Future)
+        request = {}
+        await client.update_entry(request)
 
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
 
-def test_delete_task_empty_call():
-    # This test is a coverage failsafe to make sure that totally empty calls,
-    # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-        transport="grpc",
-    )
+        await client.update_entry(request)
 
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.delete_task), "__call__") as call:
-        client.delete_task()
-        call.assert_called()
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.DeleteTaskRequest()
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
 
 
 @pytest.mark.asyncio
-async def test_delete_task_async(
-    transport: str = "grpc_asyncio", request_type=service.DeleteTaskRequest
+async def test_update_entry_async(
+    transport: str = "grpc_asyncio", request_type=catalog.UpdateEntryRequest
 ):
-    client = DataplexServiceAsyncClient(
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.delete_task), "__call__") as call:
+    with mock.patch.object(type(client.transport.update_entry), "__call__") as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            operations_pb2.Operation(name="operations/spam")
+            catalog.Entry(
+                name="name_value",
+                entry_type="entry_type_value",
+                parent_entry="parent_entry_value",
+                fully_qualified_name="fully_qualified_name_value",
+            )
         )
-        response = await client.delete_task(request)
+        response = await client.update_entry(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.DeleteTaskRequest()
+        request = catalog.UpdateEntryRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
-    assert isinstance(response, future.Future)
+    assert isinstance(response, catalog.Entry)
+    assert response.name == "name_value"
+    assert response.entry_type == "entry_type_value"
+    assert response.parent_entry == "parent_entry_value"
+    assert response.fully_qualified_name == "fully_qualified_name_value"
 
 
 @pytest.mark.asyncio
-async def test_delete_task_async_from_dict():
-    await test_delete_task_async(request_type=dict)
+async def test_update_entry_async_from_dict():
+    await test_update_entry_async(request_type=dict)
 
 
-def test_delete_task_field_headers():
-    client = DataplexServiceClient(
+def test_update_entry_field_headers():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.DeleteTaskRequest()
+    request = catalog.UpdateEntryRequest()
 
-    request.name = "name_value"
+    request.entry.name = "name_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.delete_task), "__call__") as call:
-        call.return_value = operations_pb2.Operation(name="operations/op")
-        client.delete_task(request)
+    with mock.patch.object(type(client.transport.update_entry), "__call__") as call:
+        call.return_value = catalog.Entry()
+        client.update_entry(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
     _, _, kw = call.mock_calls[0]
     assert (
         "x-goog-request-params",
-        "name=name_value",
+        "entry.name=name_value",
     ) in kw["metadata"]
 
 
 @pytest.mark.asyncio
-async def test_delete_task_field_headers_async():
-    client = DataplexServiceAsyncClient(
+async def test_update_entry_field_headers_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.DeleteTaskRequest()
+    request = catalog.UpdateEntryRequest()
 
-    request.name = "name_value"
+    request.entry.name = "name_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.delete_task), "__call__") as call:
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            operations_pb2.Operation(name="operations/op")
-        )
-        await client.delete_task(request)
+    with mock.patch.object(type(client.transport.update_entry), "__call__") as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(catalog.Entry())
+        await client.update_entry(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
     _, _, kw = call.mock_calls[0]
     assert (
         "x-goog-request-params",
-        "name=name_value",
+        "entry.name=name_value",
     ) in kw["metadata"]
 
 
-def test_delete_task_flattened():
-    client = DataplexServiceClient(
+def test_update_entry_flattened():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.delete_task), "__call__") as call:
+    with mock.patch.object(type(client.transport.update_entry), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = operations_pb2.Operation(name="operations/op")
+        call.return_value = catalog.Entry()
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        client.delete_task(
-            name="name_value",
+        client.update_entry(
+            entry=catalog.Entry(name="name_value"),
+            update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        arg = args[0].name
-        mock_val = "name_value"
+        arg = args[0].entry
+        mock_val = catalog.Entry(name="name_value")
+        assert arg == mock_val
+        arg = args[0].update_mask
+        mock_val = field_mask_pb2.FieldMask(paths=["paths_value"])
         assert arg == mock_val
 
 
-def test_delete_task_flattened_error():
-    client = DataplexServiceClient(
+def test_update_entry_flattened_error():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        client.delete_task(
-            service.DeleteTaskRequest(),
-            name="name_value",
+        client.update_entry(
+            catalog.UpdateEntryRequest(),
+            entry=catalog.Entry(name="name_value"),
+            update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
         )
 
 
 @pytest.mark.asyncio
-async def test_delete_task_flattened_async():
-    client = DataplexServiceAsyncClient(
+async def test_update_entry_flattened_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.delete_task), "__call__") as call:
+    with mock.patch.object(type(client.transport.update_entry), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = operations_pb2.Operation(name="operations/op")
+        call.return_value = catalog.Entry()
 
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            operations_pb2.Operation(name="operations/spam")
-        )
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(catalog.Entry())
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        response = await client.delete_task(
-            name="name_value",
+        response = await client.update_entry(
+            entry=catalog.Entry(name="name_value"),
+            update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        arg = args[0].name
-        mock_val = "name_value"
+        arg = args[0].entry
+        mock_val = catalog.Entry(name="name_value")
+        assert arg == mock_val
+        arg = args[0].update_mask
+        mock_val = field_mask_pb2.FieldMask(paths=["paths_value"])
         assert arg == mock_val
 
 
 @pytest.mark.asyncio
-async def test_delete_task_flattened_error_async():
-    client = DataplexServiceAsyncClient(
+async def test_update_entry_flattened_error_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        await client.delete_task(
-            service.DeleteTaskRequest(),
-            name="name_value",
+        await client.update_entry(
+            catalog.UpdateEntryRequest(),
+            entry=catalog.Entry(name="name_value"),
+            update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
         )
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
-        service.ListTasksRequest,
+        catalog.DeleteEntryRequest,
         dict,
     ],
 )
-def test_list_tasks(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
+def test_delete_entry(request_type, transport: str = "grpc"):
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_tasks), "__call__") as call:
+    with mock.patch.object(type(client.transport.delete_entry), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = service.ListTasksResponse(
-            next_page_token="next_page_token_value",
-            unreachable_locations=["unreachable_locations_value"],
+        call.return_value = catalog.Entry(
+            name="name_value",
+            entry_type="entry_type_value",
+            parent_entry="parent_entry_value",
+            fully_qualified_name="fully_qualified_name_value",
         )
-        response = client.list_tasks(request)
+        response = client.delete_entry(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.ListTasksRequest()
+        request = catalog.DeleteEntryRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
-    assert isinstance(response, pagers.ListTasksPager)
-    assert response.next_page_token == "next_page_token_value"
-    assert response.unreachable_locations == ["unreachable_locations_value"]
+    assert isinstance(response, catalog.Entry)
+    assert response.name == "name_value"
+    assert response.entry_type == "entry_type_value"
+    assert response.parent_entry == "parent_entry_value"
+    assert response.fully_qualified_name == "fully_qualified_name_value"
 
 
-def test_list_tasks_empty_call():
+def test_delete_entry_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
     # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_tasks), "__call__") as call:
-        client.list_tasks()
+    with mock.patch.object(type(client.transport.delete_entry), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.delete_entry()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.ListTasksRequest()
+        assert args[0] == catalog.DeleteEntryRequest()
 
 
-@pytest.mark.asyncio
-async def test_list_tasks_async(
-    transport: str = "grpc_asyncio", request_type=service.ListTasksRequest
-):
-    client = DataplexServiceAsyncClient(
+def test_delete_entry_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
-        transport=transport,
+        transport="grpc",
     )
 
-    # Everything is optional in proto3 as far as the runtime is concerned,
-    # and we are mocking out the actual API, so just send an empty request.
-    request = request_type()
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_tasks), "__call__") as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.ListTasksResponse(
-                next_page_token="next_page_token_value",
-                unreachable_locations=["unreachable_locations_value"],
-            )
-        )
-        response = await client.list_tasks(request)
-
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls)
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.ListTasksRequest()
-
-    # Establish that the response is the type that we expect.
-    assert isinstance(response, pagers.ListTasksAsyncPager)
-    assert response.next_page_token == "next_page_token_value"
-    assert response.unreachable_locations == ["unreachable_locations_value"]
-
-
-@pytest.mark.asyncio
-async def test_list_tasks_async_from_dict():
-    await test_list_tasks_async(request_type=dict)
-
-
-def test_list_tasks_field_headers():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = catalog.DeleteEntryRequest(
+        name="name_value",
     )
 
-    # Any value that is part of the HTTP/1.1 URI should be sent as
-    # a field header. Set these to a non-empty value.
-    request = service.ListTasksRequest()
-
-    request.parent = "parent_value"
-
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_tasks), "__call__") as call:
-        call.return_value = service.ListTasksResponse()
-        client.list_tasks(request)
-
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls) == 1
+    with mock.patch.object(type(client.transport.delete_entry), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.delete_entry(request=request)
+        call.assert_called()
         _, args, _ = call.mock_calls[0]
-        assert args[0] == request
-
-    # Establish that the field header was sent.
-    _, _, kw = call.mock_calls[0]
-    assert (
-        "x-goog-request-params",
-        "parent=parent_value",
-    ) in kw["metadata"]
-
-
-@pytest.mark.asyncio
-async def test_list_tasks_field_headers_async():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Any value that is part of the HTTP/1.1 URI should be sent as
-    # a field header. Set these to a non-empty value.
-    request = service.ListTasksRequest()
-
-    request.parent = "parent_value"
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_tasks), "__call__") as call:
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.ListTasksResponse()
+        assert args[0] == catalog.DeleteEntryRequest(
+            name="name_value",
         )
-        await client.list_tasks(request)
 
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls)
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == request
 
-    # Establish that the field header was sent.
-    _, _, kw = call.mock_calls[0]
-    assert (
-        "x-goog-request-params",
-        "parent=parent_value",
-    ) in kw["metadata"]
+def test_delete_entry_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = CatalogServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
 
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
 
-def test_list_tasks_flattened():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
+        # Ensure method has been cached
+        assert client._transport.delete_entry in client._transport._wrapped_methods
 
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_tasks), "__call__") as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = service.ListTasksResponse()
-        # Call the method with a truthy value for each flattened field,
-        # using the keyword arguments to the method.
-        client.list_tasks(
-            parent="parent_value",
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
         )
+        client._transport._wrapped_methods[client._transport.delete_entry] = mock_rpc
+        request = {}
+        client.delete_entry(request)
 
-        # Establish that the underlying call was made with the expected
-        # request object values.
-        assert len(call.mock_calls) == 1
-        _, args, _ = call.mock_calls[0]
-        arg = args[0].parent
-        mock_val = "parent_value"
-        assert arg == mock_val
-
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
 
-def test_list_tasks_flattened_error():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
+        client.delete_entry(request)
 
-    # Attempting to call a method with both a request object and flattened
-    # fields is an error.
-    with pytest.raises(ValueError):
-        client.list_tasks(
-            service.ListTasksRequest(),
-            parent="parent_value",
-        )
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
 
 
 @pytest.mark.asyncio
-async def test_list_tasks_flattened_async():
-    client = DataplexServiceAsyncClient(
+async def test_delete_entry_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_tasks), "__call__") as call:
+    with mock.patch.object(type(client.transport.delete_entry), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = service.ListTasksResponse()
-
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.ListTasksResponse()
-        )
-        # Call the method with a truthy value for each flattened field,
-        # using the keyword arguments to the method.
-        response = await client.list_tasks(
-            parent="parent_value",
+            catalog.Entry(
+                name="name_value",
+                entry_type="entry_type_value",
+                parent_entry="parent_entry_value",
+                fully_qualified_name="fully_qualified_name_value",
+            )
         )
-
-        # Establish that the underlying call was made with the expected
-        # request object values.
-        assert len(call.mock_calls)
+        response = await client.delete_entry()
+        call.assert_called()
         _, args, _ = call.mock_calls[0]
-        arg = args[0].parent
-        mock_val = "parent_value"
-        assert arg == mock_val
+        assert args[0] == catalog.DeleteEntryRequest()
 
 
 @pytest.mark.asyncio
-async def test_list_tasks_flattened_error_async():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Attempting to call a method with both a request object and flattened
-    # fields is an error.
-    with pytest.raises(ValueError):
-        await client.list_tasks(
-            service.ListTasksRequest(),
-            parent="parent_value",
-        )
-
-
-def test_list_tasks_pager(transport_name: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
-        transport=transport_name,
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_tasks), "__call__") as call:
-        # Set the response to a series of pages.
-        call.side_effect = (
-            service.ListTasksResponse(
-                tasks=[
-                    tasks.Task(),
-                    tasks.Task(),
-                    tasks.Task(),
-                ],
-                next_page_token="abc",
-            ),
-            service.ListTasksResponse(
-                tasks=[],
-                next_page_token="def",
-            ),
-            service.ListTasksResponse(
-                tasks=[
-                    tasks.Task(),
-                ],
-                next_page_token="ghi",
-            ),
-            service.ListTasksResponse(
-                tasks=[
-                    tasks.Task(),
-                    tasks.Task(),
-                ],
-            ),
-            RuntimeError,
-        )
-
-        metadata = ()
-        metadata = tuple(metadata) + (
-            gapic_v1.routing_header.to_grpc_metadata((("parent", ""),)),
-        )
-        pager = client.list_tasks(request={})
-
-        assert pager._metadata == metadata
-
-        results = list(pager)
-        assert len(results) == 6
-        assert all(isinstance(i, tasks.Task) for i in results)
-
-
-def test_list_tasks_pages(transport_name: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
-        transport=transport_name,
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_tasks), "__call__") as call:
-        # Set the response to a series of pages.
-        call.side_effect = (
-            service.ListTasksResponse(
-                tasks=[
-                    tasks.Task(),
-                    tasks.Task(),
-                    tasks.Task(),
-                ],
-                next_page_token="abc",
-            ),
-            service.ListTasksResponse(
-                tasks=[],
-                next_page_token="def",
-            ),
-            service.ListTasksResponse(
-                tasks=[
-                    tasks.Task(),
-                ],
-                next_page_token="ghi",
-            ),
-            service.ListTasksResponse(
-                tasks=[
-                    tasks.Task(),
-                    tasks.Task(),
-                ],
-            ),
-            RuntimeError,
-        )
-        pages = list(client.list_tasks(request={}).pages)
-        for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
-            assert page_.raw_page.next_page_token == token
-
-
-@pytest.mark.asyncio
-async def test_list_tasks_async_pager():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_tasks), "__call__", new_callable=mock.AsyncMock
-    ) as call:
-        # Set the response to a series of pages.
-        call.side_effect = (
-            service.ListTasksResponse(
-                tasks=[
-                    tasks.Task(),
-                    tasks.Task(),
-                    tasks.Task(),
-                ],
-                next_page_token="abc",
-            ),
-            service.ListTasksResponse(
-                tasks=[],
-                next_page_token="def",
-            ),
-            service.ListTasksResponse(
-                tasks=[
-                    tasks.Task(),
-                ],
-                next_page_token="ghi",
-            ),
-            service.ListTasksResponse(
-                tasks=[
-                    tasks.Task(),
-                    tasks.Task(),
-                ],
-            ),
-            RuntimeError,
-        )
-        async_pager = await client.list_tasks(
-            request={},
+async def test_delete_entry_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = CatalogServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
         )
-        assert async_pager.next_page_token == "abc"
-        responses = []
-        async for response in async_pager:  # pragma: no branch
-            responses.append(response)
 
-        assert len(responses) == 6
-        assert all(isinstance(i, tasks.Task) for i in responses)
-
-
-@pytest.mark.asyncio
-async def test_list_tasks_async_pages():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
-    )
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
 
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_tasks), "__call__", new_callable=mock.AsyncMock
-    ) as call:
-        # Set the response to a series of pages.
-        call.side_effect = (
-            service.ListTasksResponse(
-                tasks=[
-                    tasks.Task(),
-                    tasks.Task(),
-                    tasks.Task(),
-                ],
-                next_page_token="abc",
-            ),
-            service.ListTasksResponse(
-                tasks=[],
-                next_page_token="def",
-            ),
-            service.ListTasksResponse(
-                tasks=[
-                    tasks.Task(),
-                ],
-                next_page_token="ghi",
-            ),
-            service.ListTasksResponse(
-                tasks=[
-                    tasks.Task(),
-                    tasks.Task(),
-                ],
-            ),
-            RuntimeError,
+        # Ensure method has been cached
+        assert (
+            client._client._transport.delete_entry
+            in client._client._transport._wrapped_methods
         )
-        pages = []
-        # Workaround issue in python 3.9 related to code coverage by adding `# pragma: no branch`
-        # See https://github.com/googleapis/gapic-generator-python/pull/1174#issuecomment-1025132372
-        async for page_ in (  # pragma: no branch
-            await client.list_tasks(request={})
-        ).pages:
-            pages.append(page_)
-        for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
-            assert page_.raw_page.next_page_token == token
 
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
 
-@pytest.mark.parametrize(
-    "request_type",
-    [
-        service.GetTaskRequest,
-        dict,
-    ],
-)
-def test_get_task(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-        transport=transport,
-    )
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.delete_entry
+        ] = mock_object
 
-    # Everything is optional in proto3 as far as the runtime is concerned,
-    # and we are mocking out the actual API, so just send an empty request.
-    request = request_type()
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_task), "__call__") as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = tasks.Task(
-            name="name_value",
-            uid="uid_value",
-            description="description_value",
-            display_name="display_name_value",
-            state=resources.State.ACTIVE,
-        )
-        response = client.get_task(request)
+        request = {}
+        await client.delete_entry(request)
 
         # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls) == 1
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.GetTaskRequest()
+        assert mock_object.call_count == 1
 
-    # Establish that the response is the type that we expect.
-    assert isinstance(response, tasks.Task)
-    assert response.name == "name_value"
-    assert response.uid == "uid_value"
-    assert response.description == "description_value"
-    assert response.display_name == "display_name_value"
-    assert response.state == resources.State.ACTIVE
-
-
-def test_get_task_empty_call():
-    # This test is a coverage failsafe to make sure that totally empty calls,
-    # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-        transport="grpc",
-    )
+        await client.delete_entry(request)
 
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_task), "__call__") as call:
-        client.get_task()
-        call.assert_called()
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.GetTaskRequest()
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
 
 
 @pytest.mark.asyncio
-async def test_get_task_async(
-    transport: str = "grpc_asyncio", request_type=service.GetTaskRequest
+async def test_delete_entry_async(
+    transport: str = "grpc_asyncio", request_type=catalog.DeleteEntryRequest
 ):
-    client = DataplexServiceAsyncClient(
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_task), "__call__") as call:
+    with mock.patch.object(type(client.transport.delete_entry), "__call__") as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            tasks.Task(
+            catalog.Entry(
                 name="name_value",
-                uid="uid_value",
-                description="description_value",
-                display_name="display_name_value",
-                state=resources.State.ACTIVE,
+                entry_type="entry_type_value",
+                parent_entry="parent_entry_value",
+                fully_qualified_name="fully_qualified_name_value",
             )
         )
-        response = await client.get_task(request)
+        response = await client.delete_entry(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.GetTaskRequest()
+        request = catalog.DeleteEntryRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
-    assert isinstance(response, tasks.Task)
+    assert isinstance(response, catalog.Entry)
     assert response.name == "name_value"
-    assert response.uid == "uid_value"
-    assert response.description == "description_value"
-    assert response.display_name == "display_name_value"
-    assert response.state == resources.State.ACTIVE
+    assert response.entry_type == "entry_type_value"
+    assert response.parent_entry == "parent_entry_value"
+    assert response.fully_qualified_name == "fully_qualified_name_value"
 
 
 @pytest.mark.asyncio
-async def test_get_task_async_from_dict():
-    await test_get_task_async(request_type=dict)
+async def test_delete_entry_async_from_dict():
+    await test_delete_entry_async(request_type=dict)
 
 
-def test_get_task_field_headers():
-    client = DataplexServiceClient(
+def test_delete_entry_field_headers():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.GetTaskRequest()
+    request = catalog.DeleteEntryRequest()
 
     request.name = "name_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_task), "__call__") as call:
-        call.return_value = tasks.Task()
-        client.get_task(request)
+    with mock.patch.object(type(client.transport.delete_entry), "__call__") as call:
+        call.return_value = catalog.Entry()
+        client.delete_entry(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
@@ -7443,227 +8717,368 @@
     assert (
         "x-goog-request-params",
         "name=name_value",
     ) in kw["metadata"]
 
 
 @pytest.mark.asyncio
-async def test_get_task_field_headers_async():
-    client = DataplexServiceAsyncClient(
+async def test_delete_entry_field_headers_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.GetTaskRequest()
+    request = catalog.DeleteEntryRequest()
 
     request.name = "name_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_task), "__call__") as call:
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(tasks.Task())
-        await client.get_task(request)
+    with mock.patch.object(type(client.transport.delete_entry), "__call__") as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(catalog.Entry())
+        await client.delete_entry(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
     _, _, kw = call.mock_calls[0]
     assert (
         "x-goog-request-params",
         "name=name_value",
     ) in kw["metadata"]
 
 
-def test_get_task_flattened():
-    client = DataplexServiceClient(
+def test_delete_entry_flattened():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_task), "__call__") as call:
+    with mock.patch.object(type(client.transport.delete_entry), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = tasks.Task()
+        call.return_value = catalog.Entry()
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        client.get_task(
+        client.delete_entry(
             name="name_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         arg = args[0].name
         mock_val = "name_value"
         assert arg == mock_val
 
 
-def test_get_task_flattened_error():
-    client = DataplexServiceClient(
+def test_delete_entry_flattened_error():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        client.get_task(
-            service.GetTaskRequest(),
+        client.delete_entry(
+            catalog.DeleteEntryRequest(),
             name="name_value",
         )
 
 
 @pytest.mark.asyncio
-async def test_get_task_flattened_async():
-    client = DataplexServiceAsyncClient(
+async def test_delete_entry_flattened_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_task), "__call__") as call:
+    with mock.patch.object(type(client.transport.delete_entry), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = tasks.Task()
+        call.return_value = catalog.Entry()
 
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(tasks.Task())
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(catalog.Entry())
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        response = await client.get_task(
+        response = await client.delete_entry(
             name="name_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         arg = args[0].name
         mock_val = "name_value"
         assert arg == mock_val
 
 
 @pytest.mark.asyncio
-async def test_get_task_flattened_error_async():
-    client = DataplexServiceAsyncClient(
+async def test_delete_entry_flattened_error_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        await client.get_task(
-            service.GetTaskRequest(),
+        await client.delete_entry(
+            catalog.DeleteEntryRequest(),
             name="name_value",
         )
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
-        service.ListJobsRequest,
+        catalog.ListEntriesRequest,
         dict,
     ],
 )
-def test_list_jobs(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
+def test_list_entries(request_type, transport: str = "grpc"):
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_jobs), "__call__") as call:
+    with mock.patch.object(type(client.transport.list_entries), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = service.ListJobsResponse(
+        call.return_value = catalog.ListEntriesResponse(
             next_page_token="next_page_token_value",
         )
-        response = client.list_jobs(request)
+        response = client.list_entries(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.ListJobsRequest()
+        request = catalog.ListEntriesRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
-    assert isinstance(response, pagers.ListJobsPager)
+    assert isinstance(response, pagers.ListEntriesPager)
     assert response.next_page_token == "next_page_token_value"
 
 
-def test_list_jobs_empty_call():
+def test_list_entries_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
     # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_jobs), "__call__") as call:
-        client.list_jobs()
+    with mock.patch.object(type(client.transport.list_entries), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.list_entries()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == catalog.ListEntriesRequest()
+
+
+def test_list_entries_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = CatalogServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = catalog.ListEntriesRequest(
+        parent="parent_value",
+        page_token="page_token_value",
+        filter="filter_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_entries), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.list_entries(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == catalog.ListEntriesRequest(
+            parent="parent_value",
+            page_token="page_token_value",
+            filter="filter_value",
+        )
+
+
+def test_list_entries_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = CatalogServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.list_entries in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[client._transport.list_entries] = mock_rpc
+        request = {}
+        client.list_entries(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.list_entries(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_list_entries_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = CatalogServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_entries), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            catalog.ListEntriesResponse(
+                next_page_token="next_page_token_value",
+            )
+        )
+        response = await client.list_entries()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.ListJobsRequest()
+        assert args[0] == catalog.ListEntriesRequest()
+
+
+@pytest.mark.asyncio
+async def test_list_entries_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = CatalogServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.list_entries
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.list_entries
+        ] = mock_object
+
+        request = {}
+        await client.list_entries(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.list_entries(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
 
 
 @pytest.mark.asyncio
-async def test_list_jobs_async(
-    transport: str = "grpc_asyncio", request_type=service.ListJobsRequest
+async def test_list_entries_async(
+    transport: str = "grpc_asyncio", request_type=catalog.ListEntriesRequest
 ):
-    client = DataplexServiceAsyncClient(
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_jobs), "__call__") as call:
+    with mock.patch.object(type(client.transport.list_entries), "__call__") as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.ListJobsResponse(
+            catalog.ListEntriesResponse(
                 next_page_token="next_page_token_value",
             )
         )
-        response = await client.list_jobs(request)
+        response = await client.list_entries(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.ListJobsRequest()
+        request = catalog.ListEntriesRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
-    assert isinstance(response, pagers.ListJobsAsyncPager)
+    assert isinstance(response, pagers.ListEntriesAsyncPager)
     assert response.next_page_token == "next_page_token_value"
 
 
 @pytest.mark.asyncio
-async def test_list_jobs_async_from_dict():
-    await test_list_jobs_async(request_type=dict)
+async def test_list_entries_async_from_dict():
+    await test_list_entries_async(request_type=dict)
 
 
-def test_list_jobs_field_headers():
-    client = DataplexServiceClient(
+def test_list_entries_field_headers():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.ListJobsRequest()
+    request = catalog.ListEntriesRequest()
 
     request.parent = "parent_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_jobs), "__call__") as call:
-        call.return_value = service.ListJobsResponse()
-        client.list_jobs(request)
+    with mock.patch.object(type(client.transport.list_entries), "__call__") as call:
+        call.return_value = catalog.ListEntriesResponse()
+        client.list_entries(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
@@ -7671,895 +9086,571 @@
     assert (
         "x-goog-request-params",
         "parent=parent_value",
     ) in kw["metadata"]
 
 
 @pytest.mark.asyncio
-async def test_list_jobs_field_headers_async():
-    client = DataplexServiceAsyncClient(
+async def test_list_entries_field_headers_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.ListJobsRequest()
+    request = catalog.ListEntriesRequest()
 
     request.parent = "parent_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_jobs), "__call__") as call:
+    with mock.patch.object(type(client.transport.list_entries), "__call__") as call:
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.ListJobsResponse()
+            catalog.ListEntriesResponse()
         )
-        await client.list_jobs(request)
+        await client.list_entries(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
     _, _, kw = call.mock_calls[0]
     assert (
         "x-goog-request-params",
         "parent=parent_value",
     ) in kw["metadata"]
 
 
-def test_list_jobs_flattened():
-    client = DataplexServiceClient(
+def test_list_entries_flattened():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_jobs), "__call__") as call:
+    with mock.patch.object(type(client.transport.list_entries), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = service.ListJobsResponse()
+        call.return_value = catalog.ListEntriesResponse()
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        client.list_jobs(
+        client.list_entries(
             parent="parent_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         arg = args[0].parent
         mock_val = "parent_value"
         assert arg == mock_val
 
 
-def test_list_jobs_flattened_error():
-    client = DataplexServiceClient(
+def test_list_entries_flattened_error():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        client.list_jobs(
-            service.ListJobsRequest(),
+        client.list_entries(
+            catalog.ListEntriesRequest(),
             parent="parent_value",
         )
 
 
 @pytest.mark.asyncio
-async def test_list_jobs_flattened_async():
-    client = DataplexServiceAsyncClient(
+async def test_list_entries_flattened_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_jobs), "__call__") as call:
+    with mock.patch.object(type(client.transport.list_entries), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = service.ListJobsResponse()
+        call.return_value = catalog.ListEntriesResponse()
 
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.ListJobsResponse()
+            catalog.ListEntriesResponse()
         )
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        response = await client.list_jobs(
+        response = await client.list_entries(
             parent="parent_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         arg = args[0].parent
         mock_val = "parent_value"
         assert arg == mock_val
 
 
 @pytest.mark.asyncio
-async def test_list_jobs_flattened_error_async():
-    client = DataplexServiceAsyncClient(
+async def test_list_entries_flattened_error_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        await client.list_jobs(
-            service.ListJobsRequest(),
+        await client.list_entries(
+            catalog.ListEntriesRequest(),
             parent="parent_value",
         )
 
 
-def test_list_jobs_pager(transport_name: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
+def test_list_entries_pager(transport_name: str = "grpc"):
+    client = CatalogServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
         transport=transport_name,
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_jobs), "__call__") as call:
+    with mock.patch.object(type(client.transport.list_entries), "__call__") as call:
         # Set the response to a series of pages.
         call.side_effect = (
-            service.ListJobsResponse(
-                jobs=[
-                    tasks.Job(),
-                    tasks.Job(),
-                    tasks.Job(),
+            catalog.ListEntriesResponse(
+                entries=[
+                    catalog.Entry(),
+                    catalog.Entry(),
+                    catalog.Entry(),
                 ],
                 next_page_token="abc",
             ),
-            service.ListJobsResponse(
-                jobs=[],
+            catalog.ListEntriesResponse(
+                entries=[],
                 next_page_token="def",
             ),
-            service.ListJobsResponse(
-                jobs=[
-                    tasks.Job(),
+            catalog.ListEntriesResponse(
+                entries=[
+                    catalog.Entry(),
                 ],
                 next_page_token="ghi",
             ),
-            service.ListJobsResponse(
-                jobs=[
-                    tasks.Job(),
-                    tasks.Job(),
+            catalog.ListEntriesResponse(
+                entries=[
+                    catalog.Entry(),
+                    catalog.Entry(),
                 ],
             ),
             RuntimeError,
         )
 
         metadata = ()
         metadata = tuple(metadata) + (
             gapic_v1.routing_header.to_grpc_metadata((("parent", ""),)),
         )
-        pager = client.list_jobs(request={})
+        pager = client.list_entries(request={})
 
         assert pager._metadata == metadata
 
         results = list(pager)
         assert len(results) == 6
-        assert all(isinstance(i, tasks.Job) for i in results)
+        assert all(isinstance(i, catalog.Entry) for i in results)
 
 
-def test_list_jobs_pages(transport_name: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
+def test_list_entries_pages(transport_name: str = "grpc"):
+    client = CatalogServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
         transport=transport_name,
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_jobs), "__call__") as call:
+    with mock.patch.object(type(client.transport.list_entries), "__call__") as call:
         # Set the response to a series of pages.
         call.side_effect = (
-            service.ListJobsResponse(
-                jobs=[
-                    tasks.Job(),
-                    tasks.Job(),
-                    tasks.Job(),
+            catalog.ListEntriesResponse(
+                entries=[
+                    catalog.Entry(),
+                    catalog.Entry(),
+                    catalog.Entry(),
                 ],
                 next_page_token="abc",
             ),
-            service.ListJobsResponse(
-                jobs=[],
+            catalog.ListEntriesResponse(
+                entries=[],
                 next_page_token="def",
             ),
-            service.ListJobsResponse(
-                jobs=[
-                    tasks.Job(),
+            catalog.ListEntriesResponse(
+                entries=[
+                    catalog.Entry(),
                 ],
                 next_page_token="ghi",
             ),
-            service.ListJobsResponse(
-                jobs=[
-                    tasks.Job(),
-                    tasks.Job(),
+            catalog.ListEntriesResponse(
+                entries=[
+                    catalog.Entry(),
+                    catalog.Entry(),
                 ],
             ),
             RuntimeError,
         )
-        pages = list(client.list_jobs(request={}).pages)
+        pages = list(client.list_entries(request={}).pages)
         for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
             assert page_.raw_page.next_page_token == token
 
 
 @pytest.mark.asyncio
-async def test_list_jobs_async_pager():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
+async def test_list_entries_async_pager():
+    client = CatalogServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
-        type(client.transport.list_jobs), "__call__", new_callable=mock.AsyncMock
+        type(client.transport.list_entries), "__call__", new_callable=mock.AsyncMock
     ) as call:
         # Set the response to a series of pages.
         call.side_effect = (
-            service.ListJobsResponse(
-                jobs=[
-                    tasks.Job(),
-                    tasks.Job(),
-                    tasks.Job(),
+            catalog.ListEntriesResponse(
+                entries=[
+                    catalog.Entry(),
+                    catalog.Entry(),
+                    catalog.Entry(),
                 ],
                 next_page_token="abc",
             ),
-            service.ListJobsResponse(
-                jobs=[],
+            catalog.ListEntriesResponse(
+                entries=[],
                 next_page_token="def",
             ),
-            service.ListJobsResponse(
-                jobs=[
-                    tasks.Job(),
+            catalog.ListEntriesResponse(
+                entries=[
+                    catalog.Entry(),
                 ],
                 next_page_token="ghi",
             ),
-            service.ListJobsResponse(
-                jobs=[
-                    tasks.Job(),
-                    tasks.Job(),
+            catalog.ListEntriesResponse(
+                entries=[
+                    catalog.Entry(),
+                    catalog.Entry(),
                 ],
             ),
             RuntimeError,
         )
-        async_pager = await client.list_jobs(
+        async_pager = await client.list_entries(
             request={},
         )
         assert async_pager.next_page_token == "abc"
         responses = []
         async for response in async_pager:  # pragma: no branch
             responses.append(response)
 
         assert len(responses) == 6
-        assert all(isinstance(i, tasks.Job) for i in responses)
+        assert all(isinstance(i, catalog.Entry) for i in responses)
 
 
 @pytest.mark.asyncio
-async def test_list_jobs_async_pages():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
+async def test_list_entries_async_pages():
+    client = CatalogServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
-        type(client.transport.list_jobs), "__call__", new_callable=mock.AsyncMock
+        type(client.transport.list_entries), "__call__", new_callable=mock.AsyncMock
     ) as call:
         # Set the response to a series of pages.
         call.side_effect = (
-            service.ListJobsResponse(
-                jobs=[
-                    tasks.Job(),
-                    tasks.Job(),
-                    tasks.Job(),
+            catalog.ListEntriesResponse(
+                entries=[
+                    catalog.Entry(),
+                    catalog.Entry(),
+                    catalog.Entry(),
                 ],
                 next_page_token="abc",
             ),
-            service.ListJobsResponse(
-                jobs=[],
+            catalog.ListEntriesResponse(
+                entries=[],
                 next_page_token="def",
             ),
-            service.ListJobsResponse(
-                jobs=[
-                    tasks.Job(),
+            catalog.ListEntriesResponse(
+                entries=[
+                    catalog.Entry(),
                 ],
                 next_page_token="ghi",
             ),
-            service.ListJobsResponse(
-                jobs=[
-                    tasks.Job(),
-                    tasks.Job(),
+            catalog.ListEntriesResponse(
+                entries=[
+                    catalog.Entry(),
+                    catalog.Entry(),
                 ],
             ),
             RuntimeError,
         )
         pages = []
         # Workaround issue in python 3.9 related to code coverage by adding `# pragma: no branch`
         # See https://github.com/googleapis/gapic-generator-python/pull/1174#issuecomment-1025132372
         async for page_ in (  # pragma: no branch
-            await client.list_jobs(request={})
+            await client.list_entries(request={})
         ).pages:
             pages.append(page_)
         for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
             assert page_.raw_page.next_page_token == token
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
-        service.RunTaskRequest,
+        catalog.GetEntryRequest,
         dict,
     ],
 )
-def test_run_task(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
+def test_get_entry(request_type, transport: str = "grpc"):
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.run_task), "__call__") as call:
+    with mock.patch.object(type(client.transport.get_entry), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = service.RunTaskResponse()
-        response = client.run_task(request)
+        call.return_value = catalog.Entry(
+            name="name_value",
+            entry_type="entry_type_value",
+            parent_entry="parent_entry_value",
+            fully_qualified_name="fully_qualified_name_value",
+        )
+        response = client.get_entry(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.RunTaskRequest()
+        request = catalog.GetEntryRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
-    assert isinstance(response, service.RunTaskResponse)
+    assert isinstance(response, catalog.Entry)
+    assert response.name == "name_value"
+    assert response.entry_type == "entry_type_value"
+    assert response.parent_entry == "parent_entry_value"
+    assert response.fully_qualified_name == "fully_qualified_name_value"
 
 
-def test_run_task_empty_call():
+def test_get_entry_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
     # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.run_task), "__call__") as call:
-        client.run_task()
-        call.assert_called()
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.RunTaskRequest()
-
-
-@pytest.mark.asyncio
-async def test_run_task_async(
-    transport: str = "grpc_asyncio", request_type=service.RunTaskRequest
-):
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-        transport=transport,
-    )
-
-    # Everything is optional in proto3 as far as the runtime is concerned,
-    # and we are mocking out the actual API, so just send an empty request.
-    request = request_type()
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.run_task), "__call__") as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.RunTaskResponse()
+    with mock.patch.object(type(client.transport.get_entry), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
         )
-        response = await client.run_task(request)
-
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls)
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.RunTaskRequest()
-
-    # Establish that the response is the type that we expect.
-    assert isinstance(response, service.RunTaskResponse)
-
-
-@pytest.mark.asyncio
-async def test_run_task_async_from_dict():
-    await test_run_task_async(request_type=dict)
-
-
-def test_run_task_field_headers():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Any value that is part of the HTTP/1.1 URI should be sent as
-    # a field header. Set these to a non-empty value.
-    request = service.RunTaskRequest()
-
-    request.name = "name_value"
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.run_task), "__call__") as call:
-        call.return_value = service.RunTaskResponse()
-        client.run_task(request)
-
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls) == 1
+        client.get_entry()
+        call.assert_called()
         _, args, _ = call.mock_calls[0]
-        assert args[0] == request
-
-    # Establish that the field header was sent.
-    _, _, kw = call.mock_calls[0]
-    assert (
-        "x-goog-request-params",
-        "name=name_value",
-    ) in kw["metadata"]
+        assert args[0] == catalog.GetEntryRequest()
 
 
-@pytest.mark.asyncio
-async def test_run_task_field_headers_async():
-    client = DataplexServiceAsyncClient(
+def test_get_entry_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
     )
 
-    # Any value that is part of the HTTP/1.1 URI should be sent as
-    # a field header. Set these to a non-empty value.
-    request = service.RunTaskRequest()
-
-    request.name = "name_value"
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.run_task), "__call__") as call:
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.RunTaskResponse()
-        )
-        await client.run_task(request)
-
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls)
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == request
-
-    # Establish that the field header was sent.
-    _, _, kw = call.mock_calls[0]
-    assert (
-        "x-goog-request-params",
-        "name=name_value",
-    ) in kw["metadata"]
-
-
-def test_run_task_flattened():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = catalog.GetEntryRequest(
+        name="name_value",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.run_task), "__call__") as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = service.RunTaskResponse()
-        # Call the method with a truthy value for each flattened field,
-        # using the keyword arguments to the method.
-        client.run_task(
-            name="name_value",
+    with mock.patch.object(type(client.transport.get_entry), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
         )
-
-        # Establish that the underlying call was made with the expected
-        # request object values.
-        assert len(call.mock_calls) == 1
+        client.get_entry(request=request)
+        call.assert_called()
         _, args, _ = call.mock_calls[0]
-        arg = args[0].name
-        mock_val = "name_value"
-        assert arg == mock_val
-
-
-def test_run_task_flattened_error():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Attempting to call a method with both a request object and flattened
-    # fields is an error.
-    with pytest.raises(ValueError):
-        client.run_task(
-            service.RunTaskRequest(),
+        assert args[0] == catalog.GetEntryRequest(
             name="name_value",
         )
 
 
-@pytest.mark.asyncio
-async def test_run_task_flattened_async():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.run_task), "__call__") as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = service.RunTaskResponse()
-
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.RunTaskResponse()
-        )
-        # Call the method with a truthy value for each flattened field,
-        # using the keyword arguments to the method.
-        response = await client.run_task(
-            name="name_value",
+def test_get_entry_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = CatalogServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
         )
 
-        # Establish that the underlying call was made with the expected
-        # request object values.
-        assert len(call.mock_calls)
-        _, args, _ = call.mock_calls[0]
-        arg = args[0].name
-        mock_val = "name_value"
-        assert arg == mock_val
-
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
 
-@pytest.mark.asyncio
-async def test_run_task_flattened_error_async():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
+        # Ensure method has been cached
+        assert client._transport.get_entry in client._transport._wrapped_methods
 
-    # Attempting to call a method with both a request object and flattened
-    # fields is an error.
-    with pytest.raises(ValueError):
-        await client.run_task(
-            service.RunTaskRequest(),
-            name="name_value",
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
         )
-
-
-@pytest.mark.parametrize(
-    "request_type",
-    [
-        service.GetJobRequest,
-        dict,
-    ],
-)
-def test_get_job(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-        transport=transport,
-    )
-
-    # Everything is optional in proto3 as far as the runtime is concerned,
-    # and we are mocking out the actual API, so just send an empty request.
-    request = request_type()
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_job), "__call__") as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = tasks.Job(
-            name="name_value",
-            uid="uid_value",
-            state=tasks.Job.State.RUNNING,
-            retry_count=1214,
-            service=tasks.Job.Service.DATAPROC,
-            service_job="service_job_value",
-            message="message_value",
-            trigger=tasks.Job.Trigger.TASK_CONFIG,
-        )
-        response = client.get_job(request)
+        client._transport._wrapped_methods[client._transport.get_entry] = mock_rpc
+        request = {}
+        client.get_entry(request)
 
         # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls) == 1
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.GetJobRequest()
+        assert mock_rpc.call_count == 1
 
-    # Establish that the response is the type that we expect.
-    assert isinstance(response, tasks.Job)
-    assert response.name == "name_value"
-    assert response.uid == "uid_value"
-    assert response.state == tasks.Job.State.RUNNING
-    assert response.retry_count == 1214
-    assert response.service == tasks.Job.Service.DATAPROC
-    assert response.service_job == "service_job_value"
-    assert response.message == "message_value"
-    assert response.trigger == tasks.Job.Trigger.TASK_CONFIG
+        client.get_entry(request)
 
-
-def test_get_job_empty_call():
-    # This test is a coverage failsafe to make sure that totally empty calls,
-    # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-        transport="grpc",
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_job), "__call__") as call:
-        client.get_job()
-        call.assert_called()
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.GetJobRequest()
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
 
 
 @pytest.mark.asyncio
-async def test_get_job_async(
-    transport: str = "grpc_asyncio", request_type=service.GetJobRequest
-):
-    client = DataplexServiceAsyncClient(
+async def test_get_entry_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
-        transport=transport,
+        transport="grpc_asyncio",
     )
 
-    # Everything is optional in proto3 as far as the runtime is concerned,
-    # and we are mocking out the actual API, so just send an empty request.
-    request = request_type()
-
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_job), "__call__") as call:
+    with mock.patch.object(type(client.transport.get_entry), "__call__") as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            tasks.Job(
+            catalog.Entry(
                 name="name_value",
-                uid="uid_value",
-                state=tasks.Job.State.RUNNING,
-                retry_count=1214,
-                service=tasks.Job.Service.DATAPROC,
-                service_job="service_job_value",
-                message="message_value",
-                trigger=tasks.Job.Trigger.TASK_CONFIG,
+                entry_type="entry_type_value",
+                parent_entry="parent_entry_value",
+                fully_qualified_name="fully_qualified_name_value",
             )
         )
-        response = await client.get_job(request)
-
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls)
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.GetJobRequest()
-
-    # Establish that the response is the type that we expect.
-    assert isinstance(response, tasks.Job)
-    assert response.name == "name_value"
-    assert response.uid == "uid_value"
-    assert response.state == tasks.Job.State.RUNNING
-    assert response.retry_count == 1214
-    assert response.service == tasks.Job.Service.DATAPROC
-    assert response.service_job == "service_job_value"
-    assert response.message == "message_value"
-    assert response.trigger == tasks.Job.Trigger.TASK_CONFIG
-
-
-@pytest.mark.asyncio
-async def test_get_job_async_from_dict():
-    await test_get_job_async(request_type=dict)
-
-
-def test_get_job_field_headers():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Any value that is part of the HTTP/1.1 URI should be sent as
-    # a field header. Set these to a non-empty value.
-    request = service.GetJobRequest()
-
-    request.name = "name_value"
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_job), "__call__") as call:
-        call.return_value = tasks.Job()
-        client.get_job(request)
-
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls) == 1
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == request
-
-    # Establish that the field header was sent.
-    _, _, kw = call.mock_calls[0]
-    assert (
-        "x-goog-request-params",
-        "name=name_value",
-    ) in kw["metadata"]
-
-
-@pytest.mark.asyncio
-async def test_get_job_field_headers_async():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Any value that is part of the HTTP/1.1 URI should be sent as
-    # a field header. Set these to a non-empty value.
-    request = service.GetJobRequest()
-
-    request.name = "name_value"
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_job), "__call__") as call:
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(tasks.Job())
-        await client.get_job(request)
-
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls)
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == request
-
-    # Establish that the field header was sent.
-    _, _, kw = call.mock_calls[0]
-    assert (
-        "x-goog-request-params",
-        "name=name_value",
-    ) in kw["metadata"]
-
-
-def test_get_job_flattened():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_job), "__call__") as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = tasks.Job()
-        # Call the method with a truthy value for each flattened field,
-        # using the keyword arguments to the method.
-        client.get_job(
-            name="name_value",
-        )
-
-        # Establish that the underlying call was made with the expected
-        # request object values.
-        assert len(call.mock_calls) == 1
+        response = await client.get_entry()
+        call.assert_called()
         _, args, _ = call.mock_calls[0]
-        arg = args[0].name
-        mock_val = "name_value"
-        assert arg == mock_val
-
-
-def test_get_job_flattened_error():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Attempting to call a method with both a request object and flattened
-    # fields is an error.
-    with pytest.raises(ValueError):
-        client.get_job(
-            service.GetJobRequest(),
-            name="name_value",
-        )
+        assert args[0] == catalog.GetEntryRequest()
 
 
 @pytest.mark.asyncio
-async def test_get_job_flattened_async():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_job), "__call__") as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = tasks.Job()
-
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(tasks.Job())
-        # Call the method with a truthy value for each flattened field,
-        # using the keyword arguments to the method.
-        response = await client.get_job(
-            name="name_value",
+async def test_get_entry_async_use_cached_wrapped_rpc(transport: str = "grpc_asyncio"):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = CatalogServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
         )
 
-        # Establish that the underlying call was made with the expected
-        # request object values.
-        assert len(call.mock_calls)
-        _, args, _ = call.mock_calls[0]
-        arg = args[0].name
-        mock_val = "name_value"
-        assert arg == mock_val
-
-
-@pytest.mark.asyncio
-async def test_get_job_flattened_error_async():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
 
-    # Attempting to call a method with both a request object and flattened
-    # fields is an error.
-    with pytest.raises(ValueError):
-        await client.get_job(
-            service.GetJobRequest(),
-            name="name_value",
+        # Ensure method has been cached
+        assert (
+            client._client._transport.get_entry
+            in client._client._transport._wrapped_methods
         )
 
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
 
-@pytest.mark.parametrize(
-    "request_type",
-    [
-        service.CancelJobRequest,
-        dict,
-    ],
-)
-def test_cancel_job(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-        transport=transport,
-    )
-
-    # Everything is optional in proto3 as far as the runtime is concerned,
-    # and we are mocking out the actual API, so just send an empty request.
-    request = request_type()
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.get_entry
+        ] = mock_object
 
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.cancel_job), "__call__") as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = None
-        response = client.cancel_job(request)
+        request = {}
+        await client.get_entry(request)
 
         # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls) == 1
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.CancelJobRequest()
+        assert mock_object.call_count == 1
 
-    # Establish that the response is the type that we expect.
-    assert response is None
+        await client.get_entry(request)
 
-
-def test_cancel_job_empty_call():
-    # This test is a coverage failsafe to make sure that totally empty calls,
-    # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-        transport="grpc",
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.cancel_job), "__call__") as call:
-        client.cancel_job()
-        call.assert_called()
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.CancelJobRequest()
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
 
 
 @pytest.mark.asyncio
-async def test_cancel_job_async(
-    transport: str = "grpc_asyncio", request_type=service.CancelJobRequest
+async def test_get_entry_async(
+    transport: str = "grpc_asyncio", request_type=catalog.GetEntryRequest
 ):
-    client = DataplexServiceAsyncClient(
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.cancel_job), "__call__") as call:
+    with mock.patch.object(type(client.transport.get_entry), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(None)
-        response = await client.cancel_job(request)
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            catalog.Entry(
+                name="name_value",
+                entry_type="entry_type_value",
+                parent_entry="parent_entry_value",
+                fully_qualified_name="fully_qualified_name_value",
+            )
+        )
+        response = await client.get_entry(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.CancelJobRequest()
+        request = catalog.GetEntryRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
-    assert response is None
+    assert isinstance(response, catalog.Entry)
+    assert response.name == "name_value"
+    assert response.entry_type == "entry_type_value"
+    assert response.parent_entry == "parent_entry_value"
+    assert response.fully_qualified_name == "fully_qualified_name_value"
 
 
 @pytest.mark.asyncio
-async def test_cancel_job_async_from_dict():
-    await test_cancel_job_async(request_type=dict)
+async def test_get_entry_async_from_dict():
+    await test_get_entry_async(request_type=dict)
 
 
-def test_cancel_job_field_headers():
-    client = DataplexServiceClient(
+def test_get_entry_field_headers():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.CancelJobRequest()
+    request = catalog.GetEntryRequest()
 
     request.name = "name_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.cancel_job), "__call__") as call:
-        call.return_value = None
-        client.cancel_job(request)
+    with mock.patch.object(type(client.transport.get_entry), "__call__") as call:
+        call.return_value = catalog.Entry()
+        client.get_entry(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
@@ -8567,739 +9658,381 @@
     assert (
         "x-goog-request-params",
         "name=name_value",
     ) in kw["metadata"]
 
 
 @pytest.mark.asyncio
-async def test_cancel_job_field_headers_async():
-    client = DataplexServiceAsyncClient(
+async def test_get_entry_field_headers_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.CancelJobRequest()
+    request = catalog.GetEntryRequest()
 
     request.name = "name_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.cancel_job), "__call__") as call:
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(None)
-        await client.cancel_job(request)
+    with mock.patch.object(type(client.transport.get_entry), "__call__") as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(catalog.Entry())
+        await client.get_entry(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
     _, _, kw = call.mock_calls[0]
     assert (
         "x-goog-request-params",
         "name=name_value",
     ) in kw["metadata"]
 
 
-def test_cancel_job_flattened():
-    client = DataplexServiceClient(
+def test_get_entry_flattened():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.cancel_job), "__call__") as call:
+    with mock.patch.object(type(client.transport.get_entry), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = None
+        call.return_value = catalog.Entry()
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        client.cancel_job(
+        client.get_entry(
             name="name_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         arg = args[0].name
         mock_val = "name_value"
         assert arg == mock_val
 
 
-def test_cancel_job_flattened_error():
-    client = DataplexServiceClient(
+def test_get_entry_flattened_error():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        client.cancel_job(
-            service.CancelJobRequest(),
+        client.get_entry(
+            catalog.GetEntryRequest(),
             name="name_value",
         )
 
 
 @pytest.mark.asyncio
-async def test_cancel_job_flattened_async():
-    client = DataplexServiceAsyncClient(
+async def test_get_entry_flattened_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.cancel_job), "__call__") as call:
+    with mock.patch.object(type(client.transport.get_entry), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = None
+        call.return_value = catalog.Entry()
 
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(None)
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(catalog.Entry())
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        response = await client.cancel_job(
+        response = await client.get_entry(
             name="name_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         arg = args[0].name
         mock_val = "name_value"
         assert arg == mock_val
 
 
 @pytest.mark.asyncio
-async def test_cancel_job_flattened_error_async():
-    client = DataplexServiceAsyncClient(
+async def test_get_entry_flattened_error_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        await client.cancel_job(
-            service.CancelJobRequest(),
+        await client.get_entry(
+            catalog.GetEntryRequest(),
             name="name_value",
         )
 
 
 @pytest.mark.parametrize(
     "request_type",
     [
-        service.CreateEnvironmentRequest,
+        catalog.LookupEntryRequest,
         dict,
     ],
 )
-def test_create_environment(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
+def test_lookup_entry(request_type, transport: str = "grpc"):
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.create_environment), "__call__"
-    ) as call:
+    with mock.patch.object(type(client.transport.lookup_entry), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = operations_pb2.Operation(name="operations/spam")
-        response = client.create_environment(request)
+        call.return_value = catalog.Entry(
+            name="name_value",
+            entry_type="entry_type_value",
+            parent_entry="parent_entry_value",
+            fully_qualified_name="fully_qualified_name_value",
+        )
+        response = client.lookup_entry(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.CreateEnvironmentRequest()
+        request = catalog.LookupEntryRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
-    assert isinstance(response, future.Future)
+    assert isinstance(response, catalog.Entry)
+    assert response.name == "name_value"
+    assert response.entry_type == "entry_type_value"
+    assert response.parent_entry == "parent_entry_value"
+    assert response.fully_qualified_name == "fully_qualified_name_value"
 
 
-def test_create_environment_empty_call():
+def test_lookup_entry_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
     # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.create_environment), "__call__"
-    ) as call:
-        client.create_environment()
-        call.assert_called()
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.CreateEnvironmentRequest()
-
-
-@pytest.mark.asyncio
-async def test_create_environment_async(
-    transport: str = "grpc_asyncio", request_type=service.CreateEnvironmentRequest
-):
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-        transport=transport,
-    )
-
-    # Everything is optional in proto3 as far as the runtime is concerned,
-    # and we are mocking out the actual API, so just send an empty request.
-    request = request_type()
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.create_environment), "__call__"
-    ) as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            operations_pb2.Operation(name="operations/spam")
+    with mock.patch.object(type(client.transport.lookup_entry), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
         )
-        response = await client.create_environment(request)
-
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls)
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.CreateEnvironmentRequest()
-
-    # Establish that the response is the type that we expect.
-    assert isinstance(response, future.Future)
-
-
-@pytest.mark.asyncio
-async def test_create_environment_async_from_dict():
-    await test_create_environment_async(request_type=dict)
-
-
-def test_create_environment_field_headers():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Any value that is part of the HTTP/1.1 URI should be sent as
-    # a field header. Set these to a non-empty value.
-    request = service.CreateEnvironmentRequest()
-
-    request.parent = "parent_value"
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.create_environment), "__call__"
-    ) as call:
-        call.return_value = operations_pb2.Operation(name="operations/op")
-        client.create_environment(request)
-
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls) == 1
+        client.lookup_entry()
+        call.assert_called()
         _, args, _ = call.mock_calls[0]
-        assert args[0] == request
-
-    # Establish that the field header was sent.
-    _, _, kw = call.mock_calls[0]
-    assert (
-        "x-goog-request-params",
-        "parent=parent_value",
-    ) in kw["metadata"]
+        assert args[0] == catalog.LookupEntryRequest()
 
 
-@pytest.mark.asyncio
-async def test_create_environment_field_headers_async():
-    client = DataplexServiceAsyncClient(
+def test_lookup_entry_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
     )
 
-    # Any value that is part of the HTTP/1.1 URI should be sent as
-    # a field header. Set these to a non-empty value.
-    request = service.CreateEnvironmentRequest()
-
-    request.parent = "parent_value"
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.create_environment), "__call__"
-    ) as call:
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            operations_pb2.Operation(name="operations/op")
-        )
-        await client.create_environment(request)
-
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls)
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == request
-
-    # Establish that the field header was sent.
-    _, _, kw = call.mock_calls[0]
-    assert (
-        "x-goog-request-params",
-        "parent=parent_value",
-    ) in kw["metadata"]
-
-
-def test_create_environment_flattened():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = catalog.LookupEntryRequest(
+        name="name_value",
+        entry="entry_value",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.create_environment), "__call__"
-    ) as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = operations_pb2.Operation(name="operations/op")
-        # Call the method with a truthy value for each flattened field,
-        # using the keyword arguments to the method.
-        client.create_environment(
-            parent="parent_value",
-            environment=analyze.Environment(name="name_value"),
-            environment_id="environment_id_value",
+    with mock.patch.object(type(client.transport.lookup_entry), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
         )
-
-        # Establish that the underlying call was made with the expected
-        # request object values.
-        assert len(call.mock_calls) == 1
+        client.lookup_entry(request=request)
+        call.assert_called()
         _, args, _ = call.mock_calls[0]
-        arg = args[0].parent
-        mock_val = "parent_value"
-        assert arg == mock_val
-        arg = args[0].environment
-        mock_val = analyze.Environment(name="name_value")
-        assert arg == mock_val
-        arg = args[0].environment_id
-        mock_val = "environment_id_value"
-        assert arg == mock_val
-
-
-def test_create_environment_flattened_error():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Attempting to call a method with both a request object and flattened
-    # fields is an error.
-    with pytest.raises(ValueError):
-        client.create_environment(
-            service.CreateEnvironmentRequest(),
-            parent="parent_value",
-            environment=analyze.Environment(name="name_value"),
-            environment_id="environment_id_value",
+        assert args[0] == catalog.LookupEntryRequest(
+            name="name_value",
+            entry="entry_value",
         )
 
 
-@pytest.mark.asyncio
-async def test_create_environment_flattened_async():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.create_environment), "__call__"
-    ) as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = operations_pb2.Operation(name="operations/op")
-
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            operations_pb2.Operation(name="operations/spam")
-        )
-        # Call the method with a truthy value for each flattened field,
-        # using the keyword arguments to the method.
-        response = await client.create_environment(
-            parent="parent_value",
-            environment=analyze.Environment(name="name_value"),
-            environment_id="environment_id_value",
+def test_lookup_entry_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = CatalogServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
         )
 
-        # Establish that the underlying call was made with the expected
-        # request object values.
-        assert len(call.mock_calls)
-        _, args, _ = call.mock_calls[0]
-        arg = args[0].parent
-        mock_val = "parent_value"
-        assert arg == mock_val
-        arg = args[0].environment
-        mock_val = analyze.Environment(name="name_value")
-        assert arg == mock_val
-        arg = args[0].environment_id
-        mock_val = "environment_id_value"
-        assert arg == mock_val
-
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
 
-@pytest.mark.asyncio
-async def test_create_environment_flattened_error_async():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
+        # Ensure method has been cached
+        assert client._transport.lookup_entry in client._transport._wrapped_methods
 
-    # Attempting to call a method with both a request object and flattened
-    # fields is an error.
-    with pytest.raises(ValueError):
-        await client.create_environment(
-            service.CreateEnvironmentRequest(),
-            parent="parent_value",
-            environment=analyze.Environment(name="name_value"),
-            environment_id="environment_id_value",
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
         )
-
-
-@pytest.mark.parametrize(
-    "request_type",
-    [
-        service.UpdateEnvironmentRequest,
-        dict,
-    ],
-)
-def test_update_environment(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-        transport=transport,
-    )
-
-    # Everything is optional in proto3 as far as the runtime is concerned,
-    # and we are mocking out the actual API, so just send an empty request.
-    request = request_type()
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.update_environment), "__call__"
-    ) as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = operations_pb2.Operation(name="operations/spam")
-        response = client.update_environment(request)
+        client._transport._wrapped_methods[client._transport.lookup_entry] = mock_rpc
+        request = {}
+        client.lookup_entry(request)
 
         # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls) == 1
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.UpdateEnvironmentRequest()
+        assert mock_rpc.call_count == 1
 
-    # Establish that the response is the type that we expect.
-    assert isinstance(response, future.Future)
+        client.lookup_entry(request)
 
-
-def test_update_environment_empty_call():
-    # This test is a coverage failsafe to make sure that totally empty calls,
-    # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-        transport="grpc",
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.update_environment), "__call__"
-    ) as call:
-        client.update_environment()
-        call.assert_called()
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.UpdateEnvironmentRequest()
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
 
 
 @pytest.mark.asyncio
-async def test_update_environment_async(
-    transport: str = "grpc_asyncio", request_type=service.UpdateEnvironmentRequest
-):
-    client = DataplexServiceAsyncClient(
+async def test_lookup_entry_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
-        transport=transport,
+        transport="grpc_asyncio",
     )
 
-    # Everything is optional in proto3 as far as the runtime is concerned,
-    # and we are mocking out the actual API, so just send an empty request.
-    request = request_type()
-
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.update_environment), "__call__"
-    ) as call:
+    with mock.patch.object(type(client.transport.lookup_entry), "__call__") as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            operations_pb2.Operation(name="operations/spam")
-        )
-        response = await client.update_environment(request)
-
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls)
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.UpdateEnvironmentRequest()
-
-    # Establish that the response is the type that we expect.
-    assert isinstance(response, future.Future)
-
-
-@pytest.mark.asyncio
-async def test_update_environment_async_from_dict():
-    await test_update_environment_async(request_type=dict)
-
-
-def test_update_environment_field_headers():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Any value that is part of the HTTP/1.1 URI should be sent as
-    # a field header. Set these to a non-empty value.
-    request = service.UpdateEnvironmentRequest()
-
-    request.environment.name = "name_value"
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.update_environment), "__call__"
-    ) as call:
-        call.return_value = operations_pb2.Operation(name="operations/op")
-        client.update_environment(request)
-
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls) == 1
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == request
-
-    # Establish that the field header was sent.
-    _, _, kw = call.mock_calls[0]
-    assert (
-        "x-goog-request-params",
-        "environment.name=name_value",
-    ) in kw["metadata"]
-
-
-@pytest.mark.asyncio
-async def test_update_environment_field_headers_async():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Any value that is part of the HTTP/1.1 URI should be sent as
-    # a field header. Set these to a non-empty value.
-    request = service.UpdateEnvironmentRequest()
-
-    request.environment.name = "name_value"
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.update_environment), "__call__"
-    ) as call:
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            operations_pb2.Operation(name="operations/op")
-        )
-        await client.update_environment(request)
-
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls)
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == request
-
-    # Establish that the field header was sent.
-    _, _, kw = call.mock_calls[0]
-    assert (
-        "x-goog-request-params",
-        "environment.name=name_value",
-    ) in kw["metadata"]
-
-
-def test_update_environment_flattened():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.update_environment), "__call__"
-    ) as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = operations_pb2.Operation(name="operations/op")
-        # Call the method with a truthy value for each flattened field,
-        # using the keyword arguments to the method.
-        client.update_environment(
-            environment=analyze.Environment(name="name_value"),
-            update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
+            catalog.Entry(
+                name="name_value",
+                entry_type="entry_type_value",
+                parent_entry="parent_entry_value",
+                fully_qualified_name="fully_qualified_name_value",
+            )
         )
-
-        # Establish that the underlying call was made with the expected
-        # request object values.
-        assert len(call.mock_calls) == 1
+        response = await client.lookup_entry()
+        call.assert_called()
         _, args, _ = call.mock_calls[0]
-        arg = args[0].environment
-        mock_val = analyze.Environment(name="name_value")
-        assert arg == mock_val
-        arg = args[0].update_mask
-        mock_val = field_mask_pb2.FieldMask(paths=["paths_value"])
-        assert arg == mock_val
-
-
-def test_update_environment_flattened_error():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Attempting to call a method with both a request object and flattened
-    # fields is an error.
-    with pytest.raises(ValueError):
-        client.update_environment(
-            service.UpdateEnvironmentRequest(),
-            environment=analyze.Environment(name="name_value"),
-            update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
-        )
+        assert args[0] == catalog.LookupEntryRequest()
 
 
 @pytest.mark.asyncio
-async def test_update_environment_flattened_async():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.update_environment), "__call__"
-    ) as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = operations_pb2.Operation(name="operations/op")
-
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            operations_pb2.Operation(name="operations/spam")
-        )
-        # Call the method with a truthy value for each flattened field,
-        # using the keyword arguments to the method.
-        response = await client.update_environment(
-            environment=analyze.Environment(name="name_value"),
-            update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
+async def test_lookup_entry_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = CatalogServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
         )
 
-        # Establish that the underlying call was made with the expected
-        # request object values.
-        assert len(call.mock_calls)
-        _, args, _ = call.mock_calls[0]
-        arg = args[0].environment
-        mock_val = analyze.Environment(name="name_value")
-        assert arg == mock_val
-        arg = args[0].update_mask
-        mock_val = field_mask_pb2.FieldMask(paths=["paths_value"])
-        assert arg == mock_val
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
 
-
-@pytest.mark.asyncio
-async def test_update_environment_flattened_error_async():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Attempting to call a method with both a request object and flattened
-    # fields is an error.
-    with pytest.raises(ValueError):
-        await client.update_environment(
-            service.UpdateEnvironmentRequest(),
-            environment=analyze.Environment(name="name_value"),
-            update_mask=field_mask_pb2.FieldMask(paths=["paths_value"]),
+        # Ensure method has been cached
+        assert (
+            client._client._transport.lookup_entry
+            in client._client._transport._wrapped_methods
         )
 
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
 
-@pytest.mark.parametrize(
-    "request_type",
-    [
-        service.DeleteEnvironmentRequest,
-        dict,
-    ],
-)
-def test_delete_environment(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-        transport=transport,
-    )
-
-    # Everything is optional in proto3 as far as the runtime is concerned,
-    # and we are mocking out the actual API, so just send an empty request.
-    request = request_type()
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.lookup_entry
+        ] = mock_object
 
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.delete_environment), "__call__"
-    ) as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = operations_pb2.Operation(name="operations/spam")
-        response = client.delete_environment(request)
+        request = {}
+        await client.lookup_entry(request)
 
         # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls) == 1
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.DeleteEnvironmentRequest()
-
-    # Establish that the response is the type that we expect.
-    assert isinstance(response, future.Future)
-
+        assert mock_object.call_count == 1
 
-def test_delete_environment_empty_call():
-    # This test is a coverage failsafe to make sure that totally empty calls,
-    # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-        transport="grpc",
-    )
+        await client.lookup_entry(request)
 
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.delete_environment), "__call__"
-    ) as call:
-        client.delete_environment()
-        call.assert_called()
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.DeleteEnvironmentRequest()
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
 
 
 @pytest.mark.asyncio
-async def test_delete_environment_async(
-    transport: str = "grpc_asyncio", request_type=service.DeleteEnvironmentRequest
+async def test_lookup_entry_async(
+    transport: str = "grpc_asyncio", request_type=catalog.LookupEntryRequest
 ):
-    client = DataplexServiceAsyncClient(
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.delete_environment), "__call__"
-    ) as call:
+    with mock.patch.object(type(client.transport.lookup_entry), "__call__") as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            operations_pb2.Operation(name="operations/spam")
+            catalog.Entry(
+                name="name_value",
+                entry_type="entry_type_value",
+                parent_entry="parent_entry_value",
+                fully_qualified_name="fully_qualified_name_value",
+            )
         )
-        response = await client.delete_environment(request)
+        response = await client.lookup_entry(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.DeleteEnvironmentRequest()
+        request = catalog.LookupEntryRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
-    assert isinstance(response, future.Future)
+    assert isinstance(response, catalog.Entry)
+    assert response.name == "name_value"
+    assert response.entry_type == "entry_type_value"
+    assert response.parent_entry == "parent_entry_value"
+    assert response.fully_qualified_name == "fully_qualified_name_value"
 
 
 @pytest.mark.asyncio
-async def test_delete_environment_async_from_dict():
-    await test_delete_environment_async(request_type=dict)
+async def test_lookup_entry_async_from_dict():
+    await test_lookup_entry_async(request_type=dict)
 
 
-def test_delete_environment_field_headers():
-    client = DataplexServiceClient(
+def test_lookup_entry_field_headers():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.DeleteEnvironmentRequest()
+    request = catalog.LookupEntryRequest()
 
     request.name = "name_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.delete_environment), "__call__"
-    ) as call:
-        call.return_value = operations_pb2.Operation(name="operations/op")
-        client.delete_environment(request)
+    with mock.patch.object(type(client.transport.lookup_entry), "__call__") as call:
+        call.return_value = catalog.Entry()
+        client.lookup_entry(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
@@ -9307,697 +10040,302 @@
     assert (
         "x-goog-request-params",
         "name=name_value",
     ) in kw["metadata"]
 
 
 @pytest.mark.asyncio
-async def test_delete_environment_field_headers_async():
-    client = DataplexServiceAsyncClient(
+async def test_lookup_entry_field_headers_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.DeleteEnvironmentRequest()
+    request = catalog.LookupEntryRequest()
 
     request.name = "name_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.delete_environment), "__call__"
-    ) as call:
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            operations_pb2.Operation(name="operations/op")
-        )
-        await client.delete_environment(request)
+    with mock.patch.object(type(client.transport.lookup_entry), "__call__") as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(catalog.Entry())
+        await client.lookup_entry(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
     _, _, kw = call.mock_calls[0]
     assert (
         "x-goog-request-params",
         "name=name_value",
     ) in kw["metadata"]
 
 
-def test_delete_environment_flattened():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.delete_environment), "__call__"
-    ) as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = operations_pb2.Operation(name="operations/op")
-        # Call the method with a truthy value for each flattened field,
-        # using the keyword arguments to the method.
-        client.delete_environment(
-            name="name_value",
-        )
-
-        # Establish that the underlying call was made with the expected
-        # request object values.
-        assert len(call.mock_calls) == 1
-        _, args, _ = call.mock_calls[0]
-        arg = args[0].name
-        mock_val = "name_value"
-        assert arg == mock_val
-
-
-def test_delete_environment_flattened_error():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Attempting to call a method with both a request object and flattened
-    # fields is an error.
-    with pytest.raises(ValueError):
-        client.delete_environment(
-            service.DeleteEnvironmentRequest(),
-            name="name_value",
-        )
-
-
-@pytest.mark.asyncio
-async def test_delete_environment_flattened_async():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.delete_environment), "__call__"
-    ) as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = operations_pb2.Operation(name="operations/op")
-
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            operations_pb2.Operation(name="operations/spam")
-        )
-        # Call the method with a truthy value for each flattened field,
-        # using the keyword arguments to the method.
-        response = await client.delete_environment(
-            name="name_value",
-        )
-
-        # Establish that the underlying call was made with the expected
-        # request object values.
-        assert len(call.mock_calls)
-        _, args, _ = call.mock_calls[0]
-        arg = args[0].name
-        mock_val = "name_value"
-        assert arg == mock_val
-
-
-@pytest.mark.asyncio
-async def test_delete_environment_flattened_error_async():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Attempting to call a method with both a request object and flattened
-    # fields is an error.
-    with pytest.raises(ValueError):
-        await client.delete_environment(
-            service.DeleteEnvironmentRequest(),
-            name="name_value",
-        )
-
-
 @pytest.mark.parametrize(
     "request_type",
     [
-        service.ListEnvironmentsRequest,
+        catalog.SearchEntriesRequest,
         dict,
     ],
 )
-def test_list_environments(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
+def test_search_entries(request_type, transport: str = "grpc"):
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_environments), "__call__"
-    ) as call:
+    with mock.patch.object(type(client.transport.search_entries), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = service.ListEnvironmentsResponse(
+        call.return_value = catalog.SearchEntriesResponse(
+            total_size=1086,
             next_page_token="next_page_token_value",
+            unreachable=["unreachable_value"],
         )
-        response = client.list_environments(request)
+        response = client.search_entries(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.ListEnvironmentsRequest()
+        request = catalog.SearchEntriesRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
-    assert isinstance(response, pagers.ListEnvironmentsPager)
+    assert isinstance(response, pagers.SearchEntriesPager)
+    assert response.total_size == 1086
     assert response.next_page_token == "next_page_token_value"
+    assert response.unreachable == ["unreachable_value"]
 
 
-def test_list_environments_empty_call():
+def test_search_entries_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
     # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_environments), "__call__"
-    ) as call:
-        client.list_environments()
+    with mock.patch.object(type(client.transport.search_entries), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.search_entries()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.ListEnvironmentsRequest()
+        assert args[0] == catalog.SearchEntriesRequest()
 
 
-@pytest.mark.asyncio
-async def test_list_environments_async(
-    transport: str = "grpc_asyncio", request_type=service.ListEnvironmentsRequest
-):
-    client = DataplexServiceAsyncClient(
+def test_search_entries_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
-        transport=transport,
+        transport="grpc",
     )
 
-    # Everything is optional in proto3 as far as the runtime is concerned,
-    # and we are mocking out the actual API, so just send an empty request.
-    request = request_type()
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_environments), "__call__"
-    ) as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.ListEnvironmentsResponse(
-                next_page_token="next_page_token_value",
-            )
-        )
-        response = await client.list_environments(request)
-
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls)
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.ListEnvironmentsRequest()
-
-    # Establish that the response is the type that we expect.
-    assert isinstance(response, pagers.ListEnvironmentsAsyncPager)
-    assert response.next_page_token == "next_page_token_value"
-
-
-@pytest.mark.asyncio
-async def test_list_environments_async_from_dict():
-    await test_list_environments_async(request_type=dict)
-
-
-def test_list_environments_field_headers():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = catalog.SearchEntriesRequest(
+        name="name_value",
+        query="query_value",
+        page_token="page_token_value",
+        order_by="order_by_value",
+        scope="scope_value",
     )
 
-    # Any value that is part of the HTTP/1.1 URI should be sent as
-    # a field header. Set these to a non-empty value.
-    request = service.ListEnvironmentsRequest()
-
-    request.parent = "parent_value"
-
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_environments), "__call__"
-    ) as call:
-        call.return_value = service.ListEnvironmentsResponse()
-        client.list_environments(request)
-
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls) == 1
+    with mock.patch.object(type(client.transport.search_entries), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.search_entries(request=request)
+        call.assert_called()
         _, args, _ = call.mock_calls[0]
-        assert args[0] == request
-
-    # Establish that the field header was sent.
-    _, _, kw = call.mock_calls[0]
-    assert (
-        "x-goog-request-params",
-        "parent=parent_value",
-    ) in kw["metadata"]
-
-
-@pytest.mark.asyncio
-async def test_list_environments_field_headers_async():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Any value that is part of the HTTP/1.1 URI should be sent as
-    # a field header. Set these to a non-empty value.
-    request = service.ListEnvironmentsRequest()
-
-    request.parent = "parent_value"
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_environments), "__call__"
-    ) as call:
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.ListEnvironmentsResponse()
+        assert args[0] == catalog.SearchEntriesRequest(
+            name="name_value",
+            query="query_value",
+            page_token="page_token_value",
+            order_by="order_by_value",
+            scope="scope_value",
         )
-        await client.list_environments(request)
 
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls)
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == request
 
-    # Establish that the field header was sent.
-    _, _, kw = call.mock_calls[0]
-    assert (
-        "x-goog-request-params",
-        "parent=parent_value",
-    ) in kw["metadata"]
+def test_search_entries_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = CatalogServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
 
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
 
-def test_list_environments_flattened():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
+        # Ensure method has been cached
+        assert client._transport.search_entries in client._transport._wrapped_methods
 
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_environments), "__call__"
-    ) as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = service.ListEnvironmentsResponse()
-        # Call the method with a truthy value for each flattened field,
-        # using the keyword arguments to the method.
-        client.list_environments(
-            parent="parent_value",
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
         )
+        client._transport._wrapped_methods[client._transport.search_entries] = mock_rpc
+        request = {}
+        client.search_entries(request)
 
-        # Establish that the underlying call was made with the expected
-        # request object values.
-        assert len(call.mock_calls) == 1
-        _, args, _ = call.mock_calls[0]
-        arg = args[0].parent
-        mock_val = "parent_value"
-        assert arg == mock_val
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
 
+        client.search_entries(request)
 
-def test_list_environments_flattened_error():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Attempting to call a method with both a request object and flattened
-    # fields is an error.
-    with pytest.raises(ValueError):
-        client.list_environments(
-            service.ListEnvironmentsRequest(),
-            parent="parent_value",
-        )
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
 
 
 @pytest.mark.asyncio
-async def test_list_environments_flattened_async():
-    client = DataplexServiceAsyncClient(
+async def test_search_entries_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_environments), "__call__"
-    ) as call:
+    with mock.patch.object(type(client.transport.search_entries), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = service.ListEnvironmentsResponse()
-
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.ListEnvironmentsResponse()
-        )
-        # Call the method with a truthy value for each flattened field,
-        # using the keyword arguments to the method.
-        response = await client.list_environments(
-            parent="parent_value",
+            catalog.SearchEntriesResponse(
+                total_size=1086,
+                next_page_token="next_page_token_value",
+                unreachable=["unreachable_value"],
+            )
         )
-
-        # Establish that the underlying call was made with the expected
-        # request object values.
-        assert len(call.mock_calls)
+        response = await client.search_entries()
+        call.assert_called()
         _, args, _ = call.mock_calls[0]
-        arg = args[0].parent
-        mock_val = "parent_value"
-        assert arg == mock_val
-
-
-@pytest.mark.asyncio
-async def test_list_environments_flattened_error_async():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Attempting to call a method with both a request object and flattened
-    # fields is an error.
-    with pytest.raises(ValueError):
-        await client.list_environments(
-            service.ListEnvironmentsRequest(),
-            parent="parent_value",
-        )
-
-
-def test_list_environments_pager(transport_name: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
-        transport=transport_name,
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_environments), "__call__"
-    ) as call:
-        # Set the response to a series of pages.
-        call.side_effect = (
-            service.ListEnvironmentsResponse(
-                environments=[
-                    analyze.Environment(),
-                    analyze.Environment(),
-                    analyze.Environment(),
-                ],
-                next_page_token="abc",
-            ),
-            service.ListEnvironmentsResponse(
-                environments=[],
-                next_page_token="def",
-            ),
-            service.ListEnvironmentsResponse(
-                environments=[
-                    analyze.Environment(),
-                ],
-                next_page_token="ghi",
-            ),
-            service.ListEnvironmentsResponse(
-                environments=[
-                    analyze.Environment(),
-                    analyze.Environment(),
-                ],
-            ),
-            RuntimeError,
-        )
-
-        metadata = ()
-        metadata = tuple(metadata) + (
-            gapic_v1.routing_header.to_grpc_metadata((("parent", ""),)),
-        )
-        pager = client.list_environments(request={})
-
-        assert pager._metadata == metadata
-
-        results = list(pager)
-        assert len(results) == 6
-        assert all(isinstance(i, analyze.Environment) for i in results)
-
-
-def test_list_environments_pages(transport_name: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
-        transport=transport_name,
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_environments), "__call__"
-    ) as call:
-        # Set the response to a series of pages.
-        call.side_effect = (
-            service.ListEnvironmentsResponse(
-                environments=[
-                    analyze.Environment(),
-                    analyze.Environment(),
-                    analyze.Environment(),
-                ],
-                next_page_token="abc",
-            ),
-            service.ListEnvironmentsResponse(
-                environments=[],
-                next_page_token="def",
-            ),
-            service.ListEnvironmentsResponse(
-                environments=[
-                    analyze.Environment(),
-                ],
-                next_page_token="ghi",
-            ),
-            service.ListEnvironmentsResponse(
-                environments=[
-                    analyze.Environment(),
-                    analyze.Environment(),
-                ],
-            ),
-            RuntimeError,
-        )
-        pages = list(client.list_environments(request={}).pages)
-        for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
-            assert page_.raw_page.next_page_token == token
+        assert args[0] == catalog.SearchEntriesRequest()
 
 
 @pytest.mark.asyncio
-async def test_list_environments_async_pager():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_environments),
-        "__call__",
-        new_callable=mock.AsyncMock,
-    ) as call:
-        # Set the response to a series of pages.
-        call.side_effect = (
-            service.ListEnvironmentsResponse(
-                environments=[
-                    analyze.Environment(),
-                    analyze.Environment(),
-                    analyze.Environment(),
-                ],
-                next_page_token="abc",
-            ),
-            service.ListEnvironmentsResponse(
-                environments=[],
-                next_page_token="def",
-            ),
-            service.ListEnvironmentsResponse(
-                environments=[
-                    analyze.Environment(),
-                ],
-                next_page_token="ghi",
-            ),
-            service.ListEnvironmentsResponse(
-                environments=[
-                    analyze.Environment(),
-                    analyze.Environment(),
-                ],
-            ),
-            RuntimeError,
-        )
-        async_pager = await client.list_environments(
-            request={},
+async def test_search_entries_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = CatalogServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
         )
-        assert async_pager.next_page_token == "abc"
-        responses = []
-        async for response in async_pager:  # pragma: no branch
-            responses.append(response)
-
-        assert len(responses) == 6
-        assert all(isinstance(i, analyze.Environment) for i in responses)
 
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
 
-@pytest.mark.asyncio
-async def test_list_environments_async_pages():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(
-        type(client.transport.list_environments),
-        "__call__",
-        new_callable=mock.AsyncMock,
-    ) as call:
-        # Set the response to a series of pages.
-        call.side_effect = (
-            service.ListEnvironmentsResponse(
-                environments=[
-                    analyze.Environment(),
-                    analyze.Environment(),
-                    analyze.Environment(),
-                ],
-                next_page_token="abc",
-            ),
-            service.ListEnvironmentsResponse(
-                environments=[],
-                next_page_token="def",
-            ),
-            service.ListEnvironmentsResponse(
-                environments=[
-                    analyze.Environment(),
-                ],
-                next_page_token="ghi",
-            ),
-            service.ListEnvironmentsResponse(
-                environments=[
-                    analyze.Environment(),
-                    analyze.Environment(),
-                ],
-            ),
-            RuntimeError,
+        # Ensure method has been cached
+        assert (
+            client._client._transport.search_entries
+            in client._client._transport._wrapped_methods
         )
-        pages = []
-        # Workaround issue in python 3.9 related to code coverage by adding `# pragma: no branch`
-        # See https://github.com/googleapis/gapic-generator-python/pull/1174#issuecomment-1025132372
-        async for page_ in (  # pragma: no branch
-            await client.list_environments(request={})
-        ).pages:
-            pages.append(page_)
-        for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
-            assert page_.raw_page.next_page_token == token
 
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
 
-@pytest.mark.parametrize(
-    "request_type",
-    [
-        service.GetEnvironmentRequest,
-        dict,
-    ],
-)
-def test_get_environment(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-        transport=transport,
-    )
-
-    # Everything is optional in proto3 as far as the runtime is concerned,
-    # and we are mocking out the actual API, so just send an empty request.
-    request = request_type()
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.search_entries
+        ] = mock_object
 
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_environment), "__call__") as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = analyze.Environment(
-            name="name_value",
-            display_name="display_name_value",
-            uid="uid_value",
-            description="description_value",
-            state=resources.State.ACTIVE,
-        )
-        response = client.get_environment(request)
+        request = {}
+        await client.search_entries(request)
 
         # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls) == 1
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.GetEnvironmentRequest()
-
-    # Establish that the response is the type that we expect.
-    assert isinstance(response, analyze.Environment)
-    assert response.name == "name_value"
-    assert response.display_name == "display_name_value"
-    assert response.uid == "uid_value"
-    assert response.description == "description_value"
-    assert response.state == resources.State.ACTIVE
+        assert mock_object.call_count == 1
 
+        await client.search_entries(request)
 
-def test_get_environment_empty_call():
-    # This test is a coverage failsafe to make sure that totally empty calls,
-    # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-        transport="grpc",
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_environment), "__call__") as call:
-        client.get_environment()
-        call.assert_called()
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.GetEnvironmentRequest()
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
 
 
 @pytest.mark.asyncio
-async def test_get_environment_async(
-    transport: str = "grpc_asyncio", request_type=service.GetEnvironmentRequest
+async def test_search_entries_async(
+    transport: str = "grpc_asyncio", request_type=catalog.SearchEntriesRequest
 ):
-    client = DataplexServiceAsyncClient(
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = request_type()
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_environment), "__call__") as call:
+    with mock.patch.object(type(client.transport.search_entries), "__call__") as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            analyze.Environment(
-                name="name_value",
-                display_name="display_name_value",
-                uid="uid_value",
-                description="description_value",
-                state=resources.State.ACTIVE,
+            catalog.SearchEntriesResponse(
+                total_size=1086,
+                next_page_token="next_page_token_value",
+                unreachable=["unreachable_value"],
             )
         )
-        response = await client.get_environment(request)
+        response = await client.search_entries(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == service.GetEnvironmentRequest()
+        request = catalog.SearchEntriesRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
-    assert isinstance(response, analyze.Environment)
-    assert response.name == "name_value"
-    assert response.display_name == "display_name_value"
-    assert response.uid == "uid_value"
-    assert response.description == "description_value"
-    assert response.state == resources.State.ACTIVE
+    assert isinstance(response, pagers.SearchEntriesAsyncPager)
+    assert response.total_size == 1086
+    assert response.next_page_token == "next_page_token_value"
+    assert response.unreachable == ["unreachable_value"]
 
 
 @pytest.mark.asyncio
-async def test_get_environment_async_from_dict():
-    await test_get_environment_async(request_type=dict)
+async def test_search_entries_async_from_dict():
+    await test_search_entries_async(request_type=dict)
 
 
-def test_get_environment_field_headers():
-    client = DataplexServiceClient(
+def test_search_entries_field_headers():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.GetEnvironmentRequest()
+    request = catalog.SearchEntriesRequest()
 
     request.name = "name_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_environment), "__call__") as call:
-        call.return_value = analyze.Environment()
-        client.get_environment(request)
+    with mock.patch.object(type(client.transport.search_entries), "__call__") as call:
+        call.return_value = catalog.SearchEntriesResponse()
+        client.search_entries(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
@@ -10005,626 +10343,408 @@
     assert (
         "x-goog-request-params",
         "name=name_value",
     ) in kw["metadata"]
 
 
 @pytest.mark.asyncio
-async def test_get_environment_field_headers_async():
-    client = DataplexServiceAsyncClient(
+async def test_search_entries_field_headers_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
-    request = service.GetEnvironmentRequest()
+    request = catalog.SearchEntriesRequest()
 
     request.name = "name_value"
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_environment), "__call__") as call:
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(analyze.Environment())
-        await client.get_environment(request)
+    with mock.patch.object(type(client.transport.search_entries), "__call__") as call:
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            catalog.SearchEntriesResponse()
+        )
+        await client.search_entries(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         assert args[0] == request
 
     # Establish that the field header was sent.
     _, _, kw = call.mock_calls[0]
     assert (
         "x-goog-request-params",
         "name=name_value",
     ) in kw["metadata"]
 
 
-def test_get_environment_flattened():
-    client = DataplexServiceClient(
+def test_search_entries_flattened():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_environment), "__call__") as call:
+    with mock.patch.object(type(client.transport.search_entries), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = analyze.Environment()
+        call.return_value = catalog.SearchEntriesResponse()
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        client.get_environment(
+        client.search_entries(
             name="name_value",
+            query="query_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
         arg = args[0].name
         mock_val = "name_value"
         assert arg == mock_val
+        arg = args[0].query
+        mock_val = "query_value"
+        assert arg == mock_val
 
 
-def test_get_environment_flattened_error():
-    client = DataplexServiceClient(
+def test_search_entries_flattened_error():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        client.get_environment(
-            service.GetEnvironmentRequest(),
+        client.search_entries(
+            catalog.SearchEntriesRequest(),
             name="name_value",
+            query="query_value",
         )
 
 
 @pytest.mark.asyncio
-async def test_get_environment_flattened_async():
-    client = DataplexServiceAsyncClient(
+async def test_search_entries_flattened_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.get_environment), "__call__") as call:
+    with mock.patch.object(type(client.transport.search_entries), "__call__") as call:
         # Designate an appropriate return value for the call.
-        call.return_value = analyze.Environment()
+        call.return_value = catalog.SearchEntriesResponse()
 
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(analyze.Environment())
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            catalog.SearchEntriesResponse()
+        )
         # Call the method with a truthy value for each flattened field,
         # using the keyword arguments to the method.
-        response = await client.get_environment(
+        response = await client.search_entries(
             name="name_value",
+            query="query_value",
         )
 
         # Establish that the underlying call was made with the expected
         # request object values.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
         arg = args[0].name
         mock_val = "name_value"
         assert arg == mock_val
+        arg = args[0].query
+        mock_val = "query_value"
+        assert arg == mock_val
 
 
 @pytest.mark.asyncio
-async def test_get_environment_flattened_error_async():
-    client = DataplexServiceAsyncClient(
+async def test_search_entries_flattened_error_async():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Attempting to call a method with both a request object and flattened
     # fields is an error.
     with pytest.raises(ValueError):
-        await client.get_environment(
-            service.GetEnvironmentRequest(),
+        await client.search_entries(
+            catalog.SearchEntriesRequest(),
             name="name_value",
+            query="query_value",
         )
 
 
-@pytest.mark.parametrize(
-    "request_type",
-    [
-        service.ListSessionsRequest,
-        dict,
-    ],
-)
-def test_list_sessions(request_type, transport: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-        transport=transport,
-    )
-
-    # Everything is optional in proto3 as far as the runtime is concerned,
-    # and we are mocking out the actual API, so just send an empty request.
-    request = request_type()
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_sessions), "__call__") as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = service.ListSessionsResponse(
-            next_page_token="next_page_token_value",
-        )
-        response = client.list_sessions(request)
-
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls) == 1
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.ListSessionsRequest()
-
-    # Establish that the response is the type that we expect.
-    assert isinstance(response, pagers.ListSessionsPager)
-    assert response.next_page_token == "next_page_token_value"
-
-
-def test_list_sessions_empty_call():
-    # This test is a coverage failsafe to make sure that totally empty calls,
-    # i.e. request == None and no flattened fields passed, work.
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-        transport="grpc",
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_sessions), "__call__") as call:
-        client.list_sessions()
-        call.assert_called()
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.ListSessionsRequest()
-
-
-@pytest.mark.asyncio
-async def test_list_sessions_async(
-    transport: str = "grpc_asyncio", request_type=service.ListSessionsRequest
-):
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-        transport=transport,
-    )
-
-    # Everything is optional in proto3 as far as the runtime is concerned,
-    # and we are mocking out the actual API, so just send an empty request.
-    request = request_type()
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_sessions), "__call__") as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.ListSessionsResponse(
-                next_page_token="next_page_token_value",
-            )
-        )
-        response = await client.list_sessions(request)
-
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls)
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == service.ListSessionsRequest()
-
-    # Establish that the response is the type that we expect.
-    assert isinstance(response, pagers.ListSessionsAsyncPager)
-    assert response.next_page_token == "next_page_token_value"
-
-
-@pytest.mark.asyncio
-async def test_list_sessions_async_from_dict():
-    await test_list_sessions_async(request_type=dict)
-
-
-def test_list_sessions_field_headers():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Any value that is part of the HTTP/1.1 URI should be sent as
-    # a field header. Set these to a non-empty value.
-    request = service.ListSessionsRequest()
-
-    request.parent = "parent_value"
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_sessions), "__call__") as call:
-        call.return_value = service.ListSessionsResponse()
-        client.list_sessions(request)
-
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls) == 1
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == request
-
-    # Establish that the field header was sent.
-    _, _, kw = call.mock_calls[0]
-    assert (
-        "x-goog-request-params",
-        "parent=parent_value",
-    ) in kw["metadata"]
-
-
-@pytest.mark.asyncio
-async def test_list_sessions_field_headers_async():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Any value that is part of the HTTP/1.1 URI should be sent as
-    # a field header. Set these to a non-empty value.
-    request = service.ListSessionsRequest()
-
-    request.parent = "parent_value"
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_sessions), "__call__") as call:
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.ListSessionsResponse()
-        )
-        await client.list_sessions(request)
-
-        # Establish that the underlying gRPC stub method was called.
-        assert len(call.mock_calls)
-        _, args, _ = call.mock_calls[0]
-        assert args[0] == request
-
-    # Establish that the field header was sent.
-    _, _, kw = call.mock_calls[0]
-    assert (
-        "x-goog-request-params",
-        "parent=parent_value",
-    ) in kw["metadata"]
-
-
-def test_list_sessions_flattened():
-    client = DataplexServiceClient(
+def test_search_entries_pager(transport_name: str = "grpc"):
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_sessions), "__call__") as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = service.ListSessionsResponse()
-        # Call the method with a truthy value for each flattened field,
-        # using the keyword arguments to the method.
-        client.list_sessions(
-            parent="parent_value",
-        )
-
-        # Establish that the underlying call was made with the expected
-        # request object values.
-        assert len(call.mock_calls) == 1
-        _, args, _ = call.mock_calls[0]
-        arg = args[0].parent
-        mock_val = "parent_value"
-        assert arg == mock_val
-
-
-def test_list_sessions_flattened_error():
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Attempting to call a method with both a request object and flattened
-    # fields is an error.
-    with pytest.raises(ValueError):
-        client.list_sessions(
-            service.ListSessionsRequest(),
-            parent="parent_value",
-        )
-
-
-@pytest.mark.asyncio
-async def test_list_sessions_flattened_async():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_sessions), "__call__") as call:
-        # Designate an appropriate return value for the call.
-        call.return_value = service.ListSessionsResponse()
-
-        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
-            service.ListSessionsResponse()
-        )
-        # Call the method with a truthy value for each flattened field,
-        # using the keyword arguments to the method.
-        response = await client.list_sessions(
-            parent="parent_value",
-        )
-
-        # Establish that the underlying call was made with the expected
-        # request object values.
-        assert len(call.mock_calls)
-        _, args, _ = call.mock_calls[0]
-        arg = args[0].parent
-        mock_val = "parent_value"
-        assert arg == mock_val
-
-
-@pytest.mark.asyncio
-async def test_list_sessions_flattened_error_async():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials(),
-    )
-
-    # Attempting to call a method with both a request object and flattened
-    # fields is an error.
-    with pytest.raises(ValueError):
-        await client.list_sessions(
-            service.ListSessionsRequest(),
-            parent="parent_value",
-        )
-
-
-def test_list_sessions_pager(transport_name: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
         transport=transport_name,
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_sessions), "__call__") as call:
+    with mock.patch.object(type(client.transport.search_entries), "__call__") as call:
         # Set the response to a series of pages.
         call.side_effect = (
-            service.ListSessionsResponse(
-                sessions=[
-                    analyze.Session(),
-                    analyze.Session(),
-                    analyze.Session(),
+            catalog.SearchEntriesResponse(
+                results=[
+                    catalog.SearchEntriesResult(),
+                    catalog.SearchEntriesResult(),
+                    catalog.SearchEntriesResult(),
                 ],
                 next_page_token="abc",
             ),
-            service.ListSessionsResponse(
-                sessions=[],
+            catalog.SearchEntriesResponse(
+                results=[],
                 next_page_token="def",
             ),
-            service.ListSessionsResponse(
-                sessions=[
-                    analyze.Session(),
+            catalog.SearchEntriesResponse(
+                results=[
+                    catalog.SearchEntriesResult(),
                 ],
                 next_page_token="ghi",
             ),
-            service.ListSessionsResponse(
-                sessions=[
-                    analyze.Session(),
-                    analyze.Session(),
+            catalog.SearchEntriesResponse(
+                results=[
+                    catalog.SearchEntriesResult(),
+                    catalog.SearchEntriesResult(),
                 ],
             ),
             RuntimeError,
         )
 
         metadata = ()
         metadata = tuple(metadata) + (
-            gapic_v1.routing_header.to_grpc_metadata((("parent", ""),)),
+            gapic_v1.routing_header.to_grpc_metadata((("name", ""),)),
         )
-        pager = client.list_sessions(request={})
+        pager = client.search_entries(request={})
 
         assert pager._metadata == metadata
 
         results = list(pager)
         assert len(results) == 6
-        assert all(isinstance(i, analyze.Session) for i in results)
+        assert all(isinstance(i, catalog.SearchEntriesResult) for i in results)
 
 
-def test_list_sessions_pages(transport_name: str = "grpc"):
-    client = DataplexServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
+def test_search_entries_pages(transport_name: str = "grpc"):
+    client = CatalogServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
         transport=transport_name,
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
-    with mock.patch.object(type(client.transport.list_sessions), "__call__") as call:
+    with mock.patch.object(type(client.transport.search_entries), "__call__") as call:
         # Set the response to a series of pages.
         call.side_effect = (
-            service.ListSessionsResponse(
-                sessions=[
-                    analyze.Session(),
-                    analyze.Session(),
-                    analyze.Session(),
+            catalog.SearchEntriesResponse(
+                results=[
+                    catalog.SearchEntriesResult(),
+                    catalog.SearchEntriesResult(),
+                    catalog.SearchEntriesResult(),
                 ],
                 next_page_token="abc",
             ),
-            service.ListSessionsResponse(
-                sessions=[],
+            catalog.SearchEntriesResponse(
+                results=[],
                 next_page_token="def",
             ),
-            service.ListSessionsResponse(
-                sessions=[
-                    analyze.Session(),
+            catalog.SearchEntriesResponse(
+                results=[
+                    catalog.SearchEntriesResult(),
                 ],
                 next_page_token="ghi",
             ),
-            service.ListSessionsResponse(
-                sessions=[
-                    analyze.Session(),
-                    analyze.Session(),
+            catalog.SearchEntriesResponse(
+                results=[
+                    catalog.SearchEntriesResult(),
+                    catalog.SearchEntriesResult(),
                 ],
             ),
             RuntimeError,
         )
-        pages = list(client.list_sessions(request={}).pages)
+        pages = list(client.search_entries(request={}).pages)
         for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
             assert page_.raw_page.next_page_token == token
 
 
 @pytest.mark.asyncio
-async def test_list_sessions_async_pager():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
+async def test_search_entries_async_pager():
+    client = CatalogServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
-        type(client.transport.list_sessions), "__call__", new_callable=mock.AsyncMock
+        type(client.transport.search_entries), "__call__", new_callable=mock.AsyncMock
     ) as call:
         # Set the response to a series of pages.
         call.side_effect = (
-            service.ListSessionsResponse(
-                sessions=[
-                    analyze.Session(),
-                    analyze.Session(),
-                    analyze.Session(),
+            catalog.SearchEntriesResponse(
+                results=[
+                    catalog.SearchEntriesResult(),
+                    catalog.SearchEntriesResult(),
+                    catalog.SearchEntriesResult(),
                 ],
                 next_page_token="abc",
             ),
-            service.ListSessionsResponse(
-                sessions=[],
+            catalog.SearchEntriesResponse(
+                results=[],
                 next_page_token="def",
             ),
-            service.ListSessionsResponse(
-                sessions=[
-                    analyze.Session(),
+            catalog.SearchEntriesResponse(
+                results=[
+                    catalog.SearchEntriesResult(),
                 ],
                 next_page_token="ghi",
             ),
-            service.ListSessionsResponse(
-                sessions=[
-                    analyze.Session(),
-                    analyze.Session(),
+            catalog.SearchEntriesResponse(
+                results=[
+                    catalog.SearchEntriesResult(),
+                    catalog.SearchEntriesResult(),
                 ],
             ),
             RuntimeError,
         )
-        async_pager = await client.list_sessions(
+        async_pager = await client.search_entries(
             request={},
         )
         assert async_pager.next_page_token == "abc"
         responses = []
         async for response in async_pager:  # pragma: no branch
             responses.append(response)
 
         assert len(responses) == 6
-        assert all(isinstance(i, analyze.Session) for i in responses)
+        assert all(isinstance(i, catalog.SearchEntriesResult) for i in responses)
 
 
 @pytest.mark.asyncio
-async def test_list_sessions_async_pages():
-    client = DataplexServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
+async def test_search_entries_async_pages():
+    client = CatalogServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
-        type(client.transport.list_sessions), "__call__", new_callable=mock.AsyncMock
+        type(client.transport.search_entries), "__call__", new_callable=mock.AsyncMock
     ) as call:
         # Set the response to a series of pages.
         call.side_effect = (
-            service.ListSessionsResponse(
-                sessions=[
-                    analyze.Session(),
-                    analyze.Session(),
-                    analyze.Session(),
+            catalog.SearchEntriesResponse(
+                results=[
+                    catalog.SearchEntriesResult(),
+                    catalog.SearchEntriesResult(),
+                    catalog.SearchEntriesResult(),
                 ],
                 next_page_token="abc",
             ),
-            service.ListSessionsResponse(
-                sessions=[],
+            catalog.SearchEntriesResponse(
+                results=[],
                 next_page_token="def",
             ),
-            service.ListSessionsResponse(
-                sessions=[
-                    analyze.Session(),
+            catalog.SearchEntriesResponse(
+                results=[
+                    catalog.SearchEntriesResult(),
                 ],
                 next_page_token="ghi",
             ),
-            service.ListSessionsResponse(
-                sessions=[
-                    analyze.Session(),
-                    analyze.Session(),
+            catalog.SearchEntriesResponse(
+                results=[
+                    catalog.SearchEntriesResult(),
+                    catalog.SearchEntriesResult(),
                 ],
             ),
             RuntimeError,
         )
         pages = []
         # Workaround issue in python 3.9 related to code coverage by adding `# pragma: no branch`
         # See https://github.com/googleapis/gapic-generator-python/pull/1174#issuecomment-1025132372
         async for page_ in (  # pragma: no branch
-            await client.list_sessions(request={})
+            await client.search_entries(request={})
         ).pages:
             pages.append(page_)
         for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
             assert page_.raw_page.next_page_token == token
 
 
 def test_credentials_transport_error():
     # It is an error to provide credentials and a transport instance.
-    transport = transports.DataplexServiceGrpcTransport(
+    transport = transports.CatalogServiceGrpcTransport(
         credentials=ga_credentials.AnonymousCredentials(),
     )
     with pytest.raises(ValueError):
-        client = DataplexServiceClient(
+        client = CatalogServiceClient(
             credentials=ga_credentials.AnonymousCredentials(),
             transport=transport,
         )
 
     # It is an error to provide a credentials file and a transport instance.
-    transport = transports.DataplexServiceGrpcTransport(
+    transport = transports.CatalogServiceGrpcTransport(
         credentials=ga_credentials.AnonymousCredentials(),
     )
     with pytest.raises(ValueError):
-        client = DataplexServiceClient(
+        client = CatalogServiceClient(
             client_options={"credentials_file": "credentials.json"},
             transport=transport,
         )
 
     # It is an error to provide an api_key and a transport instance.
-    transport = transports.DataplexServiceGrpcTransport(
+    transport = transports.CatalogServiceGrpcTransport(
         credentials=ga_credentials.AnonymousCredentials(),
     )
     options = client_options.ClientOptions()
     options.api_key = "api_key"
     with pytest.raises(ValueError):
-        client = DataplexServiceClient(
+        client = CatalogServiceClient(
             client_options=options,
             transport=transport,
         )
 
     # It is an error to provide an api_key and a credential.
-    options = mock.Mock()
+    options = client_options.ClientOptions()
     options.api_key = "api_key"
     with pytest.raises(ValueError):
-        client = DataplexServiceClient(
+        client = CatalogServiceClient(
             client_options=options, credentials=ga_credentials.AnonymousCredentials()
         )
 
     # It is an error to provide scopes and a transport instance.
-    transport = transports.DataplexServiceGrpcTransport(
+    transport = transports.CatalogServiceGrpcTransport(
         credentials=ga_credentials.AnonymousCredentials(),
     )
     with pytest.raises(ValueError):
-        client = DataplexServiceClient(
+        client = CatalogServiceClient(
             client_options={"scopes": ["1", "2"]},
             transport=transport,
         )
 
 
 def test_transport_instance():
     # A client may be instantiated with a custom transport instance.
-    transport = transports.DataplexServiceGrpcTransport(
+    transport = transports.CatalogServiceGrpcTransport(
         credentials=ga_credentials.AnonymousCredentials(),
     )
-    client = DataplexServiceClient(transport=transport)
+    client = CatalogServiceClient(transport=transport)
     assert client.transport is transport
 
 
 def test_transport_get_channel():
     # A client may be instantiated with a custom transport instance.
-    transport = transports.DataplexServiceGrpcTransport(
+    transport = transports.CatalogServiceGrpcTransport(
         credentials=ga_credentials.AnonymousCredentials(),
     )
     channel = transport.grpc_channel
     assert channel
 
-    transport = transports.DataplexServiceGrpcAsyncIOTransport(
+    transport = transports.CatalogServiceGrpcAsyncIOTransport(
         credentials=ga_credentials.AnonymousCredentials(),
     )
     channel = transport.grpc_channel
     assert channel
 
 
 @pytest.mark.parametrize(
     "transport_class",
     [
-        transports.DataplexServiceGrpcTransport,
-        transports.DataplexServiceGrpcAsyncIOTransport,
+        transports.CatalogServiceGrpcTransport,
+        transports.CatalogServiceGrpcAsyncIOTransport,
     ],
 )
 def test_transport_adc(transport_class):
     # Test default credentials are used if not provided.
     with mock.patch.object(google.auth, "default") as adc:
         adc.return_value = (ga_credentials.AnonymousCredentials(), None)
         transport_class()
@@ -10634,86 +10754,75 @@
 @pytest.mark.parametrize(
     "transport_name",
     [
         "grpc",
     ],
 )
 def test_transport_kind(transport_name):
-    transport = DataplexServiceClient.get_transport_class(transport_name)(
+    transport = CatalogServiceClient.get_transport_class(transport_name)(
         credentials=ga_credentials.AnonymousCredentials(),
     )
     assert transport.kind == transport_name
 
 
 def test_transport_grpc_default():
     # A client should use the gRPC transport by default.
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
     assert isinstance(
         client.transport,
-        transports.DataplexServiceGrpcTransport,
+        transports.CatalogServiceGrpcTransport,
     )
 
 
-def test_dataplex_service_base_transport_error():
+def test_catalog_service_base_transport_error():
     # Passing both a credentials object and credentials_file should raise an error
     with pytest.raises(core_exceptions.DuplicateCredentialArgs):
-        transport = transports.DataplexServiceTransport(
+        transport = transports.CatalogServiceTransport(
             credentials=ga_credentials.AnonymousCredentials(),
             credentials_file="credentials.json",
         )
 
 
-def test_dataplex_service_base_transport():
+def test_catalog_service_base_transport():
     # Instantiate the base transport.
     with mock.patch(
-        "google.cloud.dataplex_v1.services.dataplex_service.transports.DataplexServiceTransport.__init__"
+        "google.cloud.dataplex_v1.services.catalog_service.transports.CatalogServiceTransport.__init__"
     ) as Transport:
         Transport.return_value = None
-        transport = transports.DataplexServiceTransport(
+        transport = transports.CatalogServiceTransport(
             credentials=ga_credentials.AnonymousCredentials(),
         )
 
     # Every method on the transport should just blindly
     # raise NotImplementedError.
     methods = (
-        "create_lake",
-        "update_lake",
-        "delete_lake",
-        "list_lakes",
-        "get_lake",
-        "list_lake_actions",
-        "create_zone",
-        "update_zone",
-        "delete_zone",
-        "list_zones",
-        "get_zone",
-        "list_zone_actions",
-        "create_asset",
-        "update_asset",
-        "delete_asset",
-        "list_assets",
-        "get_asset",
-        "list_asset_actions",
-        "create_task",
-        "update_task",
-        "delete_task",
-        "list_tasks",
-        "get_task",
-        "list_jobs",
-        "run_task",
-        "get_job",
-        "cancel_job",
-        "create_environment",
-        "update_environment",
-        "delete_environment",
-        "list_environments",
-        "get_environment",
-        "list_sessions",
+        "create_entry_type",
+        "update_entry_type",
+        "delete_entry_type",
+        "list_entry_types",
+        "get_entry_type",
+        "create_aspect_type",
+        "update_aspect_type",
+        "delete_aspect_type",
+        "list_aspect_types",
+        "get_aspect_type",
+        "create_entry_group",
+        "update_entry_group",
+        "delete_entry_group",
+        "list_entry_groups",
+        "get_entry_group",
+        "create_entry",
+        "update_entry",
+        "delete_entry",
+        "list_entries",
+        "get_entry",
+        "lookup_entry",
+        "search_entries",
         "get_location",
         "list_locations",
         "get_operation",
         "cancel_operation",
         "delete_operation",
         "list_operations",
     )
@@ -10734,66 +10843,66 @@
         "kind",
     ]
     for r in remainder:
         with pytest.raises(NotImplementedError):
             getattr(transport, r)()
 
 
-def test_dataplex_service_base_transport_with_credentials_file():
+def test_catalog_service_base_transport_with_credentials_file():
     # Instantiate the base transport with a credentials file
     with mock.patch.object(
         google.auth, "load_credentials_from_file", autospec=True
     ) as load_creds, mock.patch(
-        "google.cloud.dataplex_v1.services.dataplex_service.transports.DataplexServiceTransport._prep_wrapped_messages"
+        "google.cloud.dataplex_v1.services.catalog_service.transports.CatalogServiceTransport._prep_wrapped_messages"
     ) as Transport:
         Transport.return_value = None
         load_creds.return_value = (ga_credentials.AnonymousCredentials(), None)
-        transport = transports.DataplexServiceTransport(
+        transport = transports.CatalogServiceTransport(
             credentials_file="credentials.json",
             quota_project_id="octopus",
         )
         load_creds.assert_called_once_with(
             "credentials.json",
             scopes=None,
             default_scopes=("https://www.googleapis.com/auth/cloud-platform",),
             quota_project_id="octopus",
         )
 
 
-def test_dataplex_service_base_transport_with_adc():
+def test_catalog_service_base_transport_with_adc():
     # Test the default credentials are used if credentials and credentials_file are None.
     with mock.patch.object(google.auth, "default", autospec=True) as adc, mock.patch(
-        "google.cloud.dataplex_v1.services.dataplex_service.transports.DataplexServiceTransport._prep_wrapped_messages"
+        "google.cloud.dataplex_v1.services.catalog_service.transports.CatalogServiceTransport._prep_wrapped_messages"
     ) as Transport:
         Transport.return_value = None
         adc.return_value = (ga_credentials.AnonymousCredentials(), None)
-        transport = transports.DataplexServiceTransport()
+        transport = transports.CatalogServiceTransport()
         adc.assert_called_once()
 
 
-def test_dataplex_service_auth_adc():
+def test_catalog_service_auth_adc():
     # If no credentials are provided, we should use ADC credentials.
     with mock.patch.object(google.auth, "default", autospec=True) as adc:
         adc.return_value = (ga_credentials.AnonymousCredentials(), None)
-        DataplexServiceClient()
+        CatalogServiceClient()
         adc.assert_called_once_with(
             scopes=None,
             default_scopes=("https://www.googleapis.com/auth/cloud-platform",),
             quota_project_id=None,
         )
 
 
 @pytest.mark.parametrize(
     "transport_class",
     [
-        transports.DataplexServiceGrpcTransport,
-        transports.DataplexServiceGrpcAsyncIOTransport,
+        transports.CatalogServiceGrpcTransport,
+        transports.CatalogServiceGrpcAsyncIOTransport,
     ],
 )
-def test_dataplex_service_transport_auth_adc(transport_class):
+def test_catalog_service_transport_auth_adc(transport_class):
     # If credentials and host are not provided, the transport class should use
     # ADC credentials.
     with mock.patch.object(google.auth, "default", autospec=True) as adc:
         adc.return_value = (ga_credentials.AnonymousCredentials(), None)
         transport_class(quota_project_id="octopus", scopes=["1", "2"])
         adc.assert_called_once_with(
             scopes=["1", "2"],
@@ -10801,19 +10910,19 @@
             quota_project_id="octopus",
         )
 
 
 @pytest.mark.parametrize(
     "transport_class",
     [
-        transports.DataplexServiceGrpcTransport,
-        transports.DataplexServiceGrpcAsyncIOTransport,
+        transports.CatalogServiceGrpcTransport,
+        transports.CatalogServiceGrpcAsyncIOTransport,
     ],
 )
-def test_dataplex_service_transport_auth_gdch_credentials(transport_class):
+def test_catalog_service_transport_auth_gdch_credentials(transport_class):
     host = "https://language.com"
     api_audience_tests = [None, "https://language2.com"]
     api_audience_expect = [host, "https://language2.com"]
     for t, e in zip(api_audience_tests, api_audience_expect):
         with mock.patch.object(google.auth, "default", autospec=True) as adc:
             gdch_mock = mock.MagicMock()
             type(gdch_mock).with_gdch_audience = mock.PropertyMock(
@@ -10823,19 +10932,19 @@
             transport_class(host=host, api_audience=t)
             gdch_mock.with_gdch_audience.assert_called_once_with(e)
 
 
 @pytest.mark.parametrize(
     "transport_class,grpc_helpers",
     [
-        (transports.DataplexServiceGrpcTransport, grpc_helpers),
-        (transports.DataplexServiceGrpcAsyncIOTransport, grpc_helpers_async),
+        (transports.CatalogServiceGrpcTransport, grpc_helpers),
+        (transports.CatalogServiceGrpcAsyncIOTransport, grpc_helpers_async),
     ],
 )
-def test_dataplex_service_transport_create_channel(transport_class, grpc_helpers):
+def test_catalog_service_transport_create_channel(transport_class, grpc_helpers):
     # If credentials and host are not provided, the transport class should use
     # ADC credentials.
     with mock.patch.object(
         google.auth, "default", autospec=True
     ) as adc, mock.patch.object(
         grpc_helpers, "create_channel", autospec=True
     ) as create_channel:
@@ -10858,19 +10967,19 @@
             ],
         )
 
 
 @pytest.mark.parametrize(
     "transport_class",
     [
-        transports.DataplexServiceGrpcTransport,
-        transports.DataplexServiceGrpcAsyncIOTransport,
+        transports.CatalogServiceGrpcTransport,
+        transports.CatalogServiceGrpcAsyncIOTransport,
     ],
 )
-def test_dataplex_service_grpc_transport_client_cert_source_for_mtls(transport_class):
+def test_catalog_service_grpc_transport_client_cert_source_for_mtls(transport_class):
     cred = ga_credentials.AnonymousCredentials()
 
     # Check ssl_channel_credentials is used if provided.
     with mock.patch.object(transport_class, "create_channel") as mock_create_channel:
         mock_ssl_channel_creds = mock.Mock()
         transport_class(
             host="squid.clam.whelk",
@@ -10907,16 +11016,16 @@
 @pytest.mark.parametrize(
     "transport_name",
     [
         "grpc",
         "grpc_asyncio",
     ],
 )
-def test_dataplex_service_host_no_port(transport_name):
-    client = DataplexServiceClient(
+def test_catalog_service_host_no_port(transport_name):
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         client_options=client_options.ClientOptions(
             api_endpoint="dataplex.googleapis.com"
         ),
         transport=transport_name,
     )
     assert client.transport._host == ("dataplex.googleapis.com:443")
@@ -10925,61 +11034,61 @@
 @pytest.mark.parametrize(
     "transport_name",
     [
         "grpc",
         "grpc_asyncio",
     ],
 )
-def test_dataplex_service_host_with_port(transport_name):
-    client = DataplexServiceClient(
+def test_catalog_service_host_with_port(transport_name):
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         client_options=client_options.ClientOptions(
             api_endpoint="dataplex.googleapis.com:8000"
         ),
         transport=transport_name,
     )
     assert client.transport._host == ("dataplex.googleapis.com:8000")
 
 
-def test_dataplex_service_grpc_transport_channel():
+def test_catalog_service_grpc_transport_channel():
     channel = grpc.secure_channel("http://localhost/", grpc.local_channel_credentials())
 
     # Check that channel is used if provided.
-    transport = transports.DataplexServiceGrpcTransport(
+    transport = transports.CatalogServiceGrpcTransport(
         host="squid.clam.whelk",
         channel=channel,
     )
     assert transport.grpc_channel == channel
     assert transport._host == "squid.clam.whelk:443"
     assert transport._ssl_channel_credentials == None
 
 
-def test_dataplex_service_grpc_asyncio_transport_channel():
+def test_catalog_service_grpc_asyncio_transport_channel():
     channel = aio.secure_channel("http://localhost/", grpc.local_channel_credentials())
 
     # Check that channel is used if provided.
-    transport = transports.DataplexServiceGrpcAsyncIOTransport(
+    transport = transports.CatalogServiceGrpcAsyncIOTransport(
         host="squid.clam.whelk",
         channel=channel,
     )
     assert transport.grpc_channel == channel
     assert transport._host == "squid.clam.whelk:443"
     assert transport._ssl_channel_credentials == None
 
 
 # Remove this test when deprecated arguments (api_mtls_endpoint, client_cert_source) are
 # removed from grpc/grpc_asyncio transport constructor.
 @pytest.mark.parametrize(
     "transport_class",
     [
-        transports.DataplexServiceGrpcTransport,
-        transports.DataplexServiceGrpcAsyncIOTransport,
+        transports.CatalogServiceGrpcTransport,
+        transports.CatalogServiceGrpcAsyncIOTransport,
     ],
 )
-def test_dataplex_service_transport_channel_mtls_with_client_cert_source(
+def test_catalog_service_transport_channel_mtls_with_client_cert_source(
     transport_class,
 ):
     with mock.patch(
         "grpc.ssl_channel_credentials", autospec=True
     ) as grpc_ssl_channel_cred:
         with mock.patch.object(
             transport_class, "create_channel"
@@ -11021,19 +11130,19 @@
 
 
 # Remove this test when deprecated arguments (api_mtls_endpoint, client_cert_source) are
 # removed from grpc/grpc_asyncio transport constructor.
 @pytest.mark.parametrize(
     "transport_class",
     [
-        transports.DataplexServiceGrpcTransport,
-        transports.DataplexServiceGrpcAsyncIOTransport,
+        transports.CatalogServiceGrpcTransport,
+        transports.CatalogServiceGrpcAsyncIOTransport,
     ],
 )
-def test_dataplex_service_transport_channel_mtls_with_adc(transport_class):
+def test_catalog_service_transport_channel_mtls_with_adc(transport_class):
     mock_ssl_cred = mock.Mock()
     with mock.patch.multiple(
         "google.auth.transport.grpc.SslCredentials",
         __init__=mock.Mock(return_value=None),
         ssl_credentials=mock.PropertyMock(return_value=mock_ssl_cred),
     ):
         with mock.patch.object(
@@ -11062,16 +11171,16 @@
                     ("grpc.max_send_message_length", -1),
                     ("grpc.max_receive_message_length", -1),
                 ],
             )
             assert transport.grpc_channel == mock_grpc_channel
 
 
-def test_dataplex_service_grpc_lro_client():
-    client = DataplexServiceClient(
+def test_catalog_service_grpc_lro_client():
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
     transport = client.transport
 
     # Ensure that we have a api-core operations client.
     assert isinstance(
@@ -11079,16 +11188,16 @@
         operations_v1.OperationsClient,
     )
 
     # Ensure that subsequent calls to the property send the exact same object.
     assert transport.operations_client is transport.operations_client
 
 
-def test_dataplex_service_grpc_lro_async_client():
-    client = DataplexServiceAsyncClient(
+def test_catalog_service_grpc_lro_async_client():
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc_asyncio",
     )
     transport = client.transport
 
     # Ensure that we have a api-core operations client.
     assert isinstance(
@@ -11096,404 +11205,267 @@
         operations_v1.OperationsAsyncClient,
     )
 
     # Ensure that subsequent calls to the property send the exact same object.
     assert transport.operations_client is transport.operations_client
 
 
-def test_action_path():
+def test_aspect_type_path():
     project = "squid"
     location = "clam"
-    lake = "whelk"
-    action = "octopus"
+    aspect_type = "whelk"
     expected = (
-        "projects/{project}/locations/{location}/lakes/{lake}/actions/{action}".format(
+        "projects/{project}/locations/{location}/aspectTypes/{aspect_type}".format(
             project=project,
             location=location,
-            lake=lake,
-            action=action,
+            aspect_type=aspect_type,
         )
     )
-    actual = DataplexServiceClient.action_path(project, location, lake, action)
+    actual = CatalogServiceClient.aspect_type_path(project, location, aspect_type)
     assert expected == actual
 
 
-def test_parse_action_path():
+def test_parse_aspect_type_path():
     expected = {
-        "project": "oyster",
-        "location": "nudibranch",
-        "lake": "cuttlefish",
-        "action": "mussel",
-    }
-    path = DataplexServiceClient.action_path(**expected)
-
-    # Check that the path construction is reversible.
-    actual = DataplexServiceClient.parse_action_path(path)
-    assert expected == actual
-
-
-def test_asset_path():
-    project = "winkle"
-    location = "nautilus"
-    lake = "scallop"
-    zone = "abalone"
-    asset = "squid"
-    expected = "projects/{project}/locations/{location}/lakes/{lake}/zones/{zone}/assets/{asset}".format(
-        project=project,
-        location=location,
-        lake=lake,
-        zone=zone,
-        asset=asset,
-    )
-    actual = DataplexServiceClient.asset_path(project, location, lake, zone, asset)
-    assert expected == actual
-
-
-def test_parse_asset_path():
-    expected = {
-        "project": "clam",
-        "location": "whelk",
-        "lake": "octopus",
-        "zone": "oyster",
-        "asset": "nudibranch",
+        "project": "octopus",
+        "location": "oyster",
+        "aspect_type": "nudibranch",
     }
-    path = DataplexServiceClient.asset_path(**expected)
+    path = CatalogServiceClient.aspect_type_path(**expected)
 
     # Check that the path construction is reversible.
-    actual = DataplexServiceClient.parse_asset_path(path)
+    actual = CatalogServiceClient.parse_aspect_type_path(path)
     assert expected == actual
 
 
-def test_environment_path():
+def test_entry_path():
     project = "cuttlefish"
     location = "mussel"
-    lake = "winkle"
-    environment = "nautilus"
-    expected = "projects/{project}/locations/{location}/lakes/{lake}/environments/{environment}".format(
+    entry_group = "winkle"
+    entry = "nautilus"
+    expected = "projects/{project}/locations/{location}/entryGroups/{entry_group}/entries/{entry}".format(
         project=project,
         location=location,
-        lake=lake,
-        environment=environment,
-    )
-    actual = DataplexServiceClient.environment_path(
-        project, location, lake, environment
+        entry_group=entry_group,
+        entry=entry,
     )
+    actual = CatalogServiceClient.entry_path(project, location, entry_group, entry)
     assert expected == actual
 
 
-def test_parse_environment_path():
+def test_parse_entry_path():
     expected = {
         "project": "scallop",
         "location": "abalone",
-        "lake": "squid",
-        "environment": "clam",
+        "entry_group": "squid",
+        "entry": "clam",
     }
-    path = DataplexServiceClient.environment_path(**expected)
+    path = CatalogServiceClient.entry_path(**expected)
 
     # Check that the path construction is reversible.
-    actual = DataplexServiceClient.parse_environment_path(path)
+    actual = CatalogServiceClient.parse_entry_path(path)
     assert expected == actual
 
 
-def test_job_path():
+def test_entry_group_path():
     project = "whelk"
     location = "octopus"
-    lake = "oyster"
-    task = "nudibranch"
-    job = "cuttlefish"
-    expected = "projects/{project}/locations/{location}/lakes/{lake}/tasks/{task}/jobs/{job}".format(
-        project=project,
-        location=location,
-        lake=lake,
-        task=task,
-        job=job,
-    )
-    actual = DataplexServiceClient.job_path(project, location, lake, task, job)
-    assert expected == actual
-
-
-def test_parse_job_path():
-    expected = {
-        "project": "mussel",
-        "location": "winkle",
-        "lake": "nautilus",
-        "task": "scallop",
-        "job": "abalone",
-    }
-    path = DataplexServiceClient.job_path(**expected)
-
-    # Check that the path construction is reversible.
-    actual = DataplexServiceClient.parse_job_path(path)
-    assert expected == actual
-
-
-def test_lake_path():
-    project = "squid"
-    location = "clam"
-    lake = "whelk"
-    expected = "projects/{project}/locations/{location}/lakes/{lake}".format(
-        project=project,
-        location=location,
-        lake=lake,
-    )
-    actual = DataplexServiceClient.lake_path(project, location, lake)
-    assert expected == actual
-
-
-def test_parse_lake_path():
-    expected = {
-        "project": "octopus",
-        "location": "oyster",
-        "lake": "nudibranch",
-    }
-    path = DataplexServiceClient.lake_path(**expected)
-
-    # Check that the path construction is reversible.
-    actual = DataplexServiceClient.parse_lake_path(path)
-    assert expected == actual
-
-
-def test_session_path():
-    project = "cuttlefish"
-    location = "mussel"
-    lake = "winkle"
-    environment = "nautilus"
-    session = "scallop"
-    expected = "projects/{project}/locations/{location}/lakes/{lake}/environments/{environment}/sessions/{session}".format(
-        project=project,
-        location=location,
-        lake=lake,
-        environment=environment,
-        session=session,
-    )
-    actual = DataplexServiceClient.session_path(
-        project, location, lake, environment, session
-    )
-    assert expected == actual
-
-
-def test_parse_session_path():
-    expected = {
-        "project": "abalone",
-        "location": "squid",
-        "lake": "clam",
-        "environment": "whelk",
-        "session": "octopus",
-    }
-    path = DataplexServiceClient.session_path(**expected)
-
-    # Check that the path construction is reversible.
-    actual = DataplexServiceClient.parse_session_path(path)
-    assert expected == actual
-
-
-def test_task_path():
-    project = "oyster"
-    location = "nudibranch"
-    lake = "cuttlefish"
-    task = "mussel"
+    entry_group = "oyster"
     expected = (
-        "projects/{project}/locations/{location}/lakes/{lake}/tasks/{task}".format(
+        "projects/{project}/locations/{location}/entryGroups/{entry_group}".format(
             project=project,
             location=location,
-            lake=lake,
-            task=task,
+            entry_group=entry_group,
         )
     )
-    actual = DataplexServiceClient.task_path(project, location, lake, task)
+    actual = CatalogServiceClient.entry_group_path(project, location, entry_group)
     assert expected == actual
 
 
-def test_parse_task_path():
+def test_parse_entry_group_path():
     expected = {
-        "project": "winkle",
-        "location": "nautilus",
-        "lake": "scallop",
-        "task": "abalone",
+        "project": "nudibranch",
+        "location": "cuttlefish",
+        "entry_group": "mussel",
     }
-    path = DataplexServiceClient.task_path(**expected)
+    path = CatalogServiceClient.entry_group_path(**expected)
 
     # Check that the path construction is reversible.
-    actual = DataplexServiceClient.parse_task_path(path)
+    actual = CatalogServiceClient.parse_entry_group_path(path)
     assert expected == actual
 
 
-def test_zone_path():
-    project = "squid"
-    location = "clam"
-    lake = "whelk"
-    zone = "octopus"
-    expected = (
-        "projects/{project}/locations/{location}/lakes/{lake}/zones/{zone}".format(
-            project=project,
-            location=location,
-            lake=lake,
-            zone=zone,
-        )
+def test_entry_type_path():
+    project = "winkle"
+    location = "nautilus"
+    entry_type = "scallop"
+    expected = "projects/{project}/locations/{location}/entryTypes/{entry_type}".format(
+        project=project,
+        location=location,
+        entry_type=entry_type,
     )
-    actual = DataplexServiceClient.zone_path(project, location, lake, zone)
+    actual = CatalogServiceClient.entry_type_path(project, location, entry_type)
     assert expected == actual
 
 
-def test_parse_zone_path():
+def test_parse_entry_type_path():
     expected = {
-        "project": "oyster",
-        "location": "nudibranch",
-        "lake": "cuttlefish",
-        "zone": "mussel",
+        "project": "abalone",
+        "location": "squid",
+        "entry_type": "clam",
     }
-    path = DataplexServiceClient.zone_path(**expected)
+    path = CatalogServiceClient.entry_type_path(**expected)
 
     # Check that the path construction is reversible.
-    actual = DataplexServiceClient.parse_zone_path(path)
+    actual = CatalogServiceClient.parse_entry_type_path(path)
     assert expected == actual
 
 
 def test_common_billing_account_path():
-    billing_account = "winkle"
+    billing_account = "whelk"
     expected = "billingAccounts/{billing_account}".format(
         billing_account=billing_account,
     )
-    actual = DataplexServiceClient.common_billing_account_path(billing_account)
+    actual = CatalogServiceClient.common_billing_account_path(billing_account)
     assert expected == actual
 
 
 def test_parse_common_billing_account_path():
     expected = {
-        "billing_account": "nautilus",
+        "billing_account": "octopus",
     }
-    path = DataplexServiceClient.common_billing_account_path(**expected)
+    path = CatalogServiceClient.common_billing_account_path(**expected)
 
     # Check that the path construction is reversible.
-    actual = DataplexServiceClient.parse_common_billing_account_path(path)
+    actual = CatalogServiceClient.parse_common_billing_account_path(path)
     assert expected == actual
 
 
 def test_common_folder_path():
-    folder = "scallop"
+    folder = "oyster"
     expected = "folders/{folder}".format(
         folder=folder,
     )
-    actual = DataplexServiceClient.common_folder_path(folder)
+    actual = CatalogServiceClient.common_folder_path(folder)
     assert expected == actual
 
 
 def test_parse_common_folder_path():
     expected = {
-        "folder": "abalone",
+        "folder": "nudibranch",
     }
-    path = DataplexServiceClient.common_folder_path(**expected)
+    path = CatalogServiceClient.common_folder_path(**expected)
 
     # Check that the path construction is reversible.
-    actual = DataplexServiceClient.parse_common_folder_path(path)
+    actual = CatalogServiceClient.parse_common_folder_path(path)
     assert expected == actual
 
 
 def test_common_organization_path():
-    organization = "squid"
+    organization = "cuttlefish"
     expected = "organizations/{organization}".format(
         organization=organization,
     )
-    actual = DataplexServiceClient.common_organization_path(organization)
+    actual = CatalogServiceClient.common_organization_path(organization)
     assert expected == actual
 
 
 def test_parse_common_organization_path():
     expected = {
-        "organization": "clam",
+        "organization": "mussel",
     }
-    path = DataplexServiceClient.common_organization_path(**expected)
+    path = CatalogServiceClient.common_organization_path(**expected)
 
     # Check that the path construction is reversible.
-    actual = DataplexServiceClient.parse_common_organization_path(path)
+    actual = CatalogServiceClient.parse_common_organization_path(path)
     assert expected == actual
 
 
 def test_common_project_path():
-    project = "whelk"
+    project = "winkle"
     expected = "projects/{project}".format(
         project=project,
     )
-    actual = DataplexServiceClient.common_project_path(project)
+    actual = CatalogServiceClient.common_project_path(project)
     assert expected == actual
 
 
 def test_parse_common_project_path():
     expected = {
-        "project": "octopus",
+        "project": "nautilus",
     }
-    path = DataplexServiceClient.common_project_path(**expected)
+    path = CatalogServiceClient.common_project_path(**expected)
 
     # Check that the path construction is reversible.
-    actual = DataplexServiceClient.parse_common_project_path(path)
+    actual = CatalogServiceClient.parse_common_project_path(path)
     assert expected == actual
 
 
 def test_common_location_path():
-    project = "oyster"
-    location = "nudibranch"
+    project = "scallop"
+    location = "abalone"
     expected = "projects/{project}/locations/{location}".format(
         project=project,
         location=location,
     )
-    actual = DataplexServiceClient.common_location_path(project, location)
+    actual = CatalogServiceClient.common_location_path(project, location)
     assert expected == actual
 
 
 def test_parse_common_location_path():
     expected = {
-        "project": "cuttlefish",
-        "location": "mussel",
+        "project": "squid",
+        "location": "clam",
     }
-    path = DataplexServiceClient.common_location_path(**expected)
+    path = CatalogServiceClient.common_location_path(**expected)
 
     # Check that the path construction is reversible.
-    actual = DataplexServiceClient.parse_common_location_path(path)
+    actual = CatalogServiceClient.parse_common_location_path(path)
     assert expected == actual
 
 
 def test_client_with_default_client_info():
     client_info = gapic_v1.client_info.ClientInfo()
 
     with mock.patch.object(
-        transports.DataplexServiceTransport, "_prep_wrapped_messages"
+        transports.CatalogServiceTransport, "_prep_wrapped_messages"
     ) as prep:
-        client = DataplexServiceClient(
+        client = CatalogServiceClient(
             credentials=ga_credentials.AnonymousCredentials(),
             client_info=client_info,
         )
         prep.assert_called_once_with(client_info)
 
     with mock.patch.object(
-        transports.DataplexServiceTransport, "_prep_wrapped_messages"
+        transports.CatalogServiceTransport, "_prep_wrapped_messages"
     ) as prep:
-        transport_class = DataplexServiceClient.get_transport_class()
+        transport_class = CatalogServiceClient.get_transport_class()
         transport = transport_class(
             credentials=ga_credentials.AnonymousCredentials(),
             client_info=client_info,
         )
         prep.assert_called_once_with(client_info)
 
 
 @pytest.mark.asyncio
 async def test_transport_close_async():
-    client = DataplexServiceAsyncClient(
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc_asyncio",
     )
     with mock.patch.object(
         type(getattr(client.transport, "grpc_channel")), "close"
     ) as close:
         async with client:
             close.assert_not_called()
         close.assert_called_once()
 
 
 def test_delete_operation(transport: str = "grpc"):
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = operations_pb2.DeleteOperationRequest()
@@ -11509,16 +11481,16 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert response is None
 
 
 @pytest.mark.asyncio
-async def test_delete_operation_async(transport: str = "grpc"):
-    client = DataplexServiceAsyncClient(
+async def test_delete_operation_async(transport: str = "grpc_asyncio"):
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = operations_pb2.DeleteOperationRequest()
@@ -11534,15 +11506,15 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert response is None
 
 
 def test_delete_operation_field_headers():
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
     request = operations_pb2.DeleteOperationRequest()
     request.name = "locations"
@@ -11563,15 +11535,15 @@
         "x-goog-request-params",
         "name=locations",
     ) in kw["metadata"]
 
 
 @pytest.mark.asyncio
 async def test_delete_operation_field_headers_async():
-    client = DataplexServiceAsyncClient(
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
     request = operations_pb2.DeleteOperationRequest()
     request.name = "locations"
@@ -11590,15 +11562,15 @@
     assert (
         "x-goog-request-params",
         "name=locations",
     ) in kw["metadata"]
 
 
 def test_delete_operation_from_dict():
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.delete_operation), "__call__") as call:
         # Designate an appropriate return value for the call.
         call.return_value = None
 
@@ -11608,15 +11580,15 @@
             }
         )
         call.assert_called()
 
 
 @pytest.mark.asyncio
 async def test_delete_operation_from_dict_async():
-    client = DataplexServiceAsyncClient(
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.delete_operation), "__call__") as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(None)
         response = await client.delete_operation(
@@ -11624,15 +11596,15 @@
                 "name": "locations",
             }
         )
         call.assert_called()
 
 
 def test_cancel_operation(transport: str = "grpc"):
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = operations_pb2.CancelOperationRequest()
@@ -11648,16 +11620,16 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert response is None
 
 
 @pytest.mark.asyncio
-async def test_cancel_operation_async(transport: str = "grpc"):
-    client = DataplexServiceAsyncClient(
+async def test_cancel_operation_async(transport: str = "grpc_asyncio"):
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = operations_pb2.CancelOperationRequest()
@@ -11673,15 +11645,15 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert response is None
 
 
 def test_cancel_operation_field_headers():
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
     request = operations_pb2.CancelOperationRequest()
     request.name = "locations"
@@ -11702,15 +11674,15 @@
         "x-goog-request-params",
         "name=locations",
     ) in kw["metadata"]
 
 
 @pytest.mark.asyncio
 async def test_cancel_operation_field_headers_async():
-    client = DataplexServiceAsyncClient(
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
     request = operations_pb2.CancelOperationRequest()
     request.name = "locations"
@@ -11729,15 +11701,15 @@
     assert (
         "x-goog-request-params",
         "name=locations",
     ) in kw["metadata"]
 
 
 def test_cancel_operation_from_dict():
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.cancel_operation), "__call__") as call:
         # Designate an appropriate return value for the call.
         call.return_value = None
 
@@ -11747,15 +11719,15 @@
             }
         )
         call.assert_called()
 
 
 @pytest.mark.asyncio
 async def test_cancel_operation_from_dict_async():
-    client = DataplexServiceAsyncClient(
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.cancel_operation), "__call__") as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(None)
         response = await client.cancel_operation(
@@ -11763,15 +11735,15 @@
                 "name": "locations",
             }
         )
         call.assert_called()
 
 
 def test_get_operation(transport: str = "grpc"):
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = operations_pb2.GetOperationRequest()
@@ -11787,16 +11759,16 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, operations_pb2.Operation)
 
 
 @pytest.mark.asyncio
-async def test_get_operation_async(transport: str = "grpc"):
-    client = DataplexServiceAsyncClient(
+async def test_get_operation_async(transport: str = "grpc_asyncio"):
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = operations_pb2.GetOperationRequest()
@@ -11814,15 +11786,15 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, operations_pb2.Operation)
 
 
 def test_get_operation_field_headers():
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
     request = operations_pb2.GetOperationRequest()
     request.name = "locations"
@@ -11843,15 +11815,15 @@
         "x-goog-request-params",
         "name=locations",
     ) in kw["metadata"]
 
 
 @pytest.mark.asyncio
 async def test_get_operation_field_headers_async():
-    client = DataplexServiceAsyncClient(
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
     request = operations_pb2.GetOperationRequest()
     request.name = "locations"
@@ -11872,15 +11844,15 @@
     assert (
         "x-goog-request-params",
         "name=locations",
     ) in kw["metadata"]
 
 
 def test_get_operation_from_dict():
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.get_operation), "__call__") as call:
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.Operation()
 
@@ -11890,15 +11862,15 @@
             }
         )
         call.assert_called()
 
 
 @pytest.mark.asyncio
 async def test_get_operation_from_dict_async():
-    client = DataplexServiceAsyncClient(
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.get_operation), "__call__") as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             operations_pb2.Operation()
@@ -11908,15 +11880,15 @@
                 "name": "locations",
             }
         )
         call.assert_called()
 
 
 def test_list_operations(transport: str = "grpc"):
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = operations_pb2.ListOperationsRequest()
@@ -11932,16 +11904,16 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, operations_pb2.ListOperationsResponse)
 
 
 @pytest.mark.asyncio
-async def test_list_operations_async(transport: str = "grpc"):
-    client = DataplexServiceAsyncClient(
+async def test_list_operations_async(transport: str = "grpc_asyncio"):
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = operations_pb2.ListOperationsRequest()
@@ -11959,15 +11931,15 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, operations_pb2.ListOperationsResponse)
 
 
 def test_list_operations_field_headers():
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
     request = operations_pb2.ListOperationsRequest()
     request.name = "locations"
@@ -11988,15 +11960,15 @@
         "x-goog-request-params",
         "name=locations",
     ) in kw["metadata"]
 
 
 @pytest.mark.asyncio
 async def test_list_operations_field_headers_async():
-    client = DataplexServiceAsyncClient(
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
     request = operations_pb2.ListOperationsRequest()
     request.name = "locations"
@@ -12017,15 +11989,15 @@
     assert (
         "x-goog-request-params",
         "name=locations",
     ) in kw["metadata"]
 
 
 def test_list_operations_from_dict():
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.list_operations), "__call__") as call:
         # Designate an appropriate return value for the call.
         call.return_value = operations_pb2.ListOperationsResponse()
 
@@ -12035,15 +12007,15 @@
             }
         )
         call.assert_called()
 
 
 @pytest.mark.asyncio
 async def test_list_operations_from_dict_async():
-    client = DataplexServiceAsyncClient(
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.list_operations), "__call__") as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             operations_pb2.ListOperationsResponse()
@@ -12053,15 +12025,15 @@
                 "name": "locations",
             }
         )
         call.assert_called()
 
 
 def test_list_locations(transport: str = "grpc"):
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = locations_pb2.ListLocationsRequest()
@@ -12077,16 +12049,16 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, locations_pb2.ListLocationsResponse)
 
 
 @pytest.mark.asyncio
-async def test_list_locations_async(transport: str = "grpc"):
-    client = DataplexServiceAsyncClient(
+async def test_list_locations_async(transport: str = "grpc_asyncio"):
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = locations_pb2.ListLocationsRequest()
@@ -12104,15 +12076,15 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, locations_pb2.ListLocationsResponse)
 
 
 def test_list_locations_field_headers():
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
     request = locations_pb2.ListLocationsRequest()
     request.name = "locations"
@@ -12133,15 +12105,15 @@
         "x-goog-request-params",
         "name=locations",
     ) in kw["metadata"]
 
 
 @pytest.mark.asyncio
 async def test_list_locations_field_headers_async():
-    client = DataplexServiceAsyncClient(
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
     request = locations_pb2.ListLocationsRequest()
     request.name = "locations"
@@ -12162,15 +12134,15 @@
     assert (
         "x-goog-request-params",
         "name=locations",
     ) in kw["metadata"]
 
 
 def test_list_locations_from_dict():
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.list_locations), "__call__") as call:
         # Designate an appropriate return value for the call.
         call.return_value = locations_pb2.ListLocationsResponse()
 
@@ -12180,15 +12152,15 @@
             }
         )
         call.assert_called()
 
 
 @pytest.mark.asyncio
 async def test_list_locations_from_dict_async():
-    client = DataplexServiceAsyncClient(
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.list_locations), "__call__") as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             locations_pb2.ListLocationsResponse()
@@ -12198,15 +12170,15 @@
                 "name": "locations",
             }
         )
         call.assert_called()
 
 
 def test_get_location(transport: str = "grpc"):
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = locations_pb2.GetLocationRequest()
@@ -12223,15 +12195,15 @@
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, locations_pb2.Location)
 
 
 @pytest.mark.asyncio
 async def test_get_location_async(transport: str = "grpc_asyncio"):
-    client = DataplexServiceAsyncClient(
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
     request = locations_pb2.GetLocationRequest()
@@ -12249,15 +12221,15 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, locations_pb2.Location)
 
 
 def test_get_location_field_headers():
-    client = DataplexServiceClient(credentials=ga_credentials.AnonymousCredentials())
+    client = CatalogServiceClient(credentials=ga_credentials.AnonymousCredentials())
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
     request = locations_pb2.GetLocationRequest()
     request.name = "locations/abc"
 
     # Mock the actual call within the gRPC stub, and fake the request.
@@ -12276,15 +12248,15 @@
         "x-goog-request-params",
         "name=locations/abc",
     ) in kw["metadata"]
 
 
 @pytest.mark.asyncio
 async def test_get_location_field_headers_async():
-    client = DataplexServiceAsyncClient(
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials()
     )
 
     # Any value that is part of the HTTP/1.1 URI should be sent as
     # a field header. Set these to a non-empty value.
     request = locations_pb2.GetLocationRequest()
     request.name = "locations/abc"
@@ -12305,15 +12277,15 @@
     assert (
         "x-goog-request-params",
         "name=locations/abc",
     ) in kw["metadata"]
 
 
 def test_get_location_from_dict():
-    client = DataplexServiceClient(
+    client = CatalogServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.list_locations), "__call__") as call:
         # Designate an appropriate return value for the call.
         call.return_value = locations_pb2.Location()
 
@@ -12323,15 +12295,15 @@
             }
         )
         call.assert_called()
 
 
 @pytest.mark.asyncio
 async def test_get_location_from_dict_async():
-    client = DataplexServiceAsyncClient(
+    client = CatalogServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
     )
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.list_locations), "__call__") as call:
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
             locations_pb2.Location()
@@ -12346,15 +12318,15 @@
 
 def test_transport_close():
     transports = {
         "grpc": "_grpc_channel",
     }
 
     for transport, close_name in transports.items():
-        client = DataplexServiceClient(
+        client = CatalogServiceClient(
             credentials=ga_credentials.AnonymousCredentials(), transport=transport
         )
         with mock.patch.object(
             type(getattr(client.transport, close_name)), "close"
         ) as close:
             with client:
                 close.assert_not_called()
@@ -12362,30 +12334,30 @@
 
 
 def test_client_ctx():
     transports = [
         "grpc",
     ]
     for transport in transports:
-        client = DataplexServiceClient(
+        client = CatalogServiceClient(
             credentials=ga_credentials.AnonymousCredentials(), transport=transport
         )
         # Test client calls underlying transport.
         with mock.patch.object(type(client.transport), "close") as close:
             close.assert_not_called()
             with client:
                 pass
             close.assert_called()
 
 
 @pytest.mark.parametrize(
     "client_class,transport_class",
     [
-        (DataplexServiceClient, transports.DataplexServiceGrpcTransport),
-        (DataplexServiceAsyncClient, transports.DataplexServiceGrpcAsyncIOTransport),
+        (CatalogServiceClient, transports.CatalogServiceGrpcTransport),
+        (CatalogServiceAsyncClient, transports.CatalogServiceGrpcAsyncIOTransport),
     ],
 )
 def test_api_key_credentials(client_class, transport_class):
     with mock.patch.object(
         google.auth._default, "get_api_key_credentials", create=True
     ) as get_api_key_credentials:
         mock_cred = mock.Mock()
@@ -12394,15 +12366,17 @@
         options.api_key = "api_key"
         with mock.patch.object(transport_class, "__init__") as patched:
             patched.return_value = None
             client = client_class(client_options=options)
             patched.assert_called_once_with(
                 credentials=mock_cred,
                 credentials_file=None,
-                host=client.DEFAULT_ENDPOINT,
+                host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                    UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+                ),
                 scopes=None,
                 client_cert_source_for_mtls=None,
                 quota_project_id=None,
                 client_info=transports.base.DEFAULT_CLIENT_INFO,
                 always_use_jwt_access=True,
                 api_audience=None,
             )
```

### Comparing `google-cloud-dataplex-1.9.0/tests/unit/gapic/dataplex_v1/test_metadata_service.py` & `google-cloud-dataplex-2.0.0/tests/unit/gapic/dataplex_v1/test_metadata_service.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 # -*- coding: utf-8 -*-
-# Copyright 2023 Google LLC
+# Copyright 2024 Google LLC
 #
 # Licensed under the Apache License, Version 2.0 (the "License");
 # you may not use this file except in compliance with the License.
 # You may obtain a copy of the License at
 #
 #     http://www.apache.org/licenses/LICENSE-2.0
 #
@@ -21,15 +21,15 @@
     from unittest.mock import AsyncMock  # pragma: NO COVER
 except ImportError:  # pragma: NO COVER
     import mock
 
 import math
 
 from google.api_core import gapic_v1, grpc_helpers, grpc_helpers_async, path_template
-from google.api_core import client_options
+from google.api_core import api_core_version, client_options
 from google.api_core import exceptions as core_exceptions
 import google.auth
 from google.auth import credentials as ga_credentials
 from google.auth.exceptions import MutualTLSChannelError
 from google.cloud.location import locations_pb2
 from google.iam.v1 import iam_policy_pb2  # type: ignore
 from google.iam.v1 import options_pb2  # type: ignore
@@ -63,14 +63,25 @@
     return (
         "foo.googleapis.com"
         if ("localhost" in client.DEFAULT_ENDPOINT)
         else client.DEFAULT_ENDPOINT
     )
 
 
+# If default endpoint template is localhost, then default mtls endpoint will be the same.
+# This method modifies the default endpoint template so the client can produce a different
+# mtls endpoint for endpoint testing purposes.
+def modify_default_endpoint_template(client):
+    return (
+        "test.{UNIVERSE_DOMAIN}"
+        if ("localhost" in client._DEFAULT_ENDPOINT_TEMPLATE)
+        else client._DEFAULT_ENDPOINT_TEMPLATE
+    )
+
+
 def test__get_default_mtls_endpoint():
     api_endpoint = "example.googleapis.com"
     api_mtls_endpoint = "example.mtls.googleapis.com"
     sandbox_endpoint = "example.sandbox.googleapis.com"
     sandbox_mtls_endpoint = "example.mtls.sandbox.googleapis.com"
     non_googleapi = "api.example.com"
 
@@ -92,14 +103,281 @@
         == sandbox_mtls_endpoint
     )
     assert (
         MetadataServiceClient._get_default_mtls_endpoint(non_googleapi) == non_googleapi
     )
 
 
+def test__read_environment_variables():
+    assert MetadataServiceClient._read_environment_variables() == (False, "auto", None)
+
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "true"}):
+        assert MetadataServiceClient._read_environment_variables() == (
+            True,
+            "auto",
+            None,
+        )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "false"}):
+        assert MetadataServiceClient._read_environment_variables() == (
+            False,
+            "auto",
+            None,
+        )
+
+    with mock.patch.dict(
+        os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "Unsupported"}
+    ):
+        with pytest.raises(ValueError) as excinfo:
+            MetadataServiceClient._read_environment_variables()
+    assert (
+        str(excinfo.value)
+        == "Environment variable `GOOGLE_API_USE_CLIENT_CERTIFICATE` must be either `true` or `false`"
+    )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "never"}):
+        assert MetadataServiceClient._read_environment_variables() == (
+            False,
+            "never",
+            None,
+        )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "always"}):
+        assert MetadataServiceClient._read_environment_variables() == (
+            False,
+            "always",
+            None,
+        )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "auto"}):
+        assert MetadataServiceClient._read_environment_variables() == (
+            False,
+            "auto",
+            None,
+        )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "Unsupported"}):
+        with pytest.raises(MutualTLSChannelError) as excinfo:
+            MetadataServiceClient._read_environment_variables()
+    assert (
+        str(excinfo.value)
+        == "Environment variable `GOOGLE_API_USE_MTLS_ENDPOINT` must be `never`, `auto` or `always`"
+    )
+
+    with mock.patch.dict(os.environ, {"GOOGLE_CLOUD_UNIVERSE_DOMAIN": "foo.com"}):
+        assert MetadataServiceClient._read_environment_variables() == (
+            False,
+            "auto",
+            "foo.com",
+        )
+
+
+def test__get_client_cert_source():
+    mock_provided_cert_source = mock.Mock()
+    mock_default_cert_source = mock.Mock()
+
+    assert MetadataServiceClient._get_client_cert_source(None, False) is None
+    assert (
+        MetadataServiceClient._get_client_cert_source(mock_provided_cert_source, False)
+        is None
+    )
+    assert (
+        MetadataServiceClient._get_client_cert_source(mock_provided_cert_source, True)
+        == mock_provided_cert_source
+    )
+
+    with mock.patch(
+        "google.auth.transport.mtls.has_default_client_cert_source", return_value=True
+    ):
+        with mock.patch(
+            "google.auth.transport.mtls.default_client_cert_source",
+            return_value=mock_default_cert_source,
+        ):
+            assert (
+                MetadataServiceClient._get_client_cert_source(None, True)
+                is mock_default_cert_source
+            )
+            assert (
+                MetadataServiceClient._get_client_cert_source(
+                    mock_provided_cert_source, "true"
+                )
+                is mock_provided_cert_source
+            )
+
+
+@mock.patch.object(
+    MetadataServiceClient,
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(MetadataServiceClient),
+)
+@mock.patch.object(
+    MetadataServiceAsyncClient,
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(MetadataServiceAsyncClient),
+)
+def test__get_api_endpoint():
+    api_override = "foo.com"
+    mock_client_cert_source = mock.Mock()
+    default_universe = MetadataServiceClient._DEFAULT_UNIVERSE
+    default_endpoint = MetadataServiceClient._DEFAULT_ENDPOINT_TEMPLATE.format(
+        UNIVERSE_DOMAIN=default_universe
+    )
+    mock_universe = "bar.com"
+    mock_endpoint = MetadataServiceClient._DEFAULT_ENDPOINT_TEMPLATE.format(
+        UNIVERSE_DOMAIN=mock_universe
+    )
+
+    assert (
+        MetadataServiceClient._get_api_endpoint(
+            api_override, mock_client_cert_source, default_universe, "always"
+        )
+        == api_override
+    )
+    assert (
+        MetadataServiceClient._get_api_endpoint(
+            None, mock_client_cert_source, default_universe, "auto"
+        )
+        == MetadataServiceClient.DEFAULT_MTLS_ENDPOINT
+    )
+    assert (
+        MetadataServiceClient._get_api_endpoint(None, None, default_universe, "auto")
+        == default_endpoint
+    )
+    assert (
+        MetadataServiceClient._get_api_endpoint(None, None, default_universe, "always")
+        == MetadataServiceClient.DEFAULT_MTLS_ENDPOINT
+    )
+    assert (
+        MetadataServiceClient._get_api_endpoint(
+            None, mock_client_cert_source, default_universe, "always"
+        )
+        == MetadataServiceClient.DEFAULT_MTLS_ENDPOINT
+    )
+    assert (
+        MetadataServiceClient._get_api_endpoint(None, None, mock_universe, "never")
+        == mock_endpoint
+    )
+    assert (
+        MetadataServiceClient._get_api_endpoint(None, None, default_universe, "never")
+        == default_endpoint
+    )
+
+    with pytest.raises(MutualTLSChannelError) as excinfo:
+        MetadataServiceClient._get_api_endpoint(
+            None, mock_client_cert_source, mock_universe, "auto"
+        )
+    assert (
+        str(excinfo.value)
+        == "mTLS is not supported in any universe other than googleapis.com."
+    )
+
+
+def test__get_universe_domain():
+    client_universe_domain = "foo.com"
+    universe_domain_env = "bar.com"
+
+    assert (
+        MetadataServiceClient._get_universe_domain(
+            client_universe_domain, universe_domain_env
+        )
+        == client_universe_domain
+    )
+    assert (
+        MetadataServiceClient._get_universe_domain(None, universe_domain_env)
+        == universe_domain_env
+    )
+    assert (
+        MetadataServiceClient._get_universe_domain(None, None)
+        == MetadataServiceClient._DEFAULT_UNIVERSE
+    )
+
+    with pytest.raises(ValueError) as excinfo:
+        MetadataServiceClient._get_universe_domain("", None)
+    assert str(excinfo.value) == "Universe Domain cannot be an empty string."
+
+
+@pytest.mark.parametrize(
+    "client_class,transport_class,transport_name",
+    [
+        (MetadataServiceClient, transports.MetadataServiceGrpcTransport, "grpc"),
+    ],
+)
+def test__validate_universe_domain(client_class, transport_class, transport_name):
+    client = client_class(
+        transport=transport_class(credentials=ga_credentials.AnonymousCredentials())
+    )
+    assert client._validate_universe_domain() == True
+
+    # Test the case when universe is already validated.
+    assert client._validate_universe_domain() == True
+
+    if transport_name == "grpc":
+        # Test the case where credentials are provided by the
+        # `local_channel_credentials`. The default universes in both match.
+        channel = grpc.secure_channel(
+            "http://localhost/", grpc.local_channel_credentials()
+        )
+        client = client_class(transport=transport_class(channel=channel))
+        assert client._validate_universe_domain() == True
+
+        # Test the case where credentials do not exist: e.g. a transport is provided
+        # with no credentials. Validation should still succeed because there is no
+        # mismatch with non-existent credentials.
+        channel = grpc.secure_channel(
+            "http://localhost/", grpc.local_channel_credentials()
+        )
+        transport = transport_class(channel=channel)
+        transport._credentials = None
+        client = client_class(transport=transport)
+        assert client._validate_universe_domain() == True
+
+    # TODO: This is needed to cater for older versions of google-auth
+    # Make this test unconditional once the minimum supported version of
+    # google-auth becomes 2.23.0 or higher.
+    google_auth_major, google_auth_minor = [
+        int(part) for part in google.auth.__version__.split(".")[0:2]
+    ]
+    if google_auth_major > 2 or (google_auth_major == 2 and google_auth_minor >= 23):
+        credentials = ga_credentials.AnonymousCredentials()
+        credentials._universe_domain = "foo.com"
+        # Test the case when there is a universe mismatch from the credentials.
+        client = client_class(transport=transport_class(credentials=credentials))
+        with pytest.raises(ValueError) as excinfo:
+            client._validate_universe_domain()
+        assert (
+            str(excinfo.value)
+            == "The configured universe domain (googleapis.com) does not match the universe domain found in the credentials (foo.com). If you haven't configured the universe domain explicitly, `googleapis.com` is the default."
+        )
+
+        # Test the case when there is a universe mismatch from the client.
+        #
+        # TODO: Make this test unconditional once the minimum supported version of
+        # google-api-core becomes 2.15.0 or higher.
+        api_core_major, api_core_minor = [
+            int(part) for part in api_core_version.__version__.split(".")[0:2]
+        ]
+        if api_core_major > 2 or (api_core_major == 2 and api_core_minor >= 15):
+            client = client_class(
+                client_options={"universe_domain": "bar.com"},
+                transport=transport_class(
+                    credentials=ga_credentials.AnonymousCredentials(),
+                ),
+            )
+            with pytest.raises(ValueError) as excinfo:
+                client._validate_universe_domain()
+            assert (
+                str(excinfo.value)
+                == "The configured universe domain (bar.com) does not match the universe domain found in the credentials (googleapis.com). If you haven't configured the universe domain explicitly, `googleapis.com` is the default."
+            )
+
+    # Test that ValueError is raised if universe_domain is provided via client options and credentials is None
+    with pytest.raises(ValueError):
+        client._compare_universes("foo.bar", None)
+
+
 @pytest.mark.parametrize(
     "client_class,transport_name",
     [
         (MetadataServiceClient, "grpc"),
         (MetadataServiceAsyncClient, "grpc_asyncio"),
     ],
 )
@@ -194,21 +472,21 @@
             transports.MetadataServiceGrpcAsyncIOTransport,
             "grpc_asyncio",
         ),
     ],
 )
 @mock.patch.object(
     MetadataServiceClient,
-    "DEFAULT_ENDPOINT",
-    modify_default_endpoint(MetadataServiceClient),
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(MetadataServiceClient),
 )
 @mock.patch.object(
     MetadataServiceAsyncClient,
-    "DEFAULT_ENDPOINT",
-    modify_default_endpoint(MetadataServiceAsyncClient),
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(MetadataServiceAsyncClient),
 )
 def test_metadata_service_client_client_options(
     client_class, transport_class, transport_name
 ):
     # Check that if channel is provided we won't create a new one.
     with mock.patch.object(MetadataServiceClient, "get_transport_class") as gtc:
         transport = transport_class(credentials=ga_credentials.AnonymousCredentials())
@@ -242,15 +520,17 @@
     with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "never"}):
         with mock.patch.object(transport_class, "__init__") as patched:
             patched.return_value = None
             client = client_class(transport=transport_name)
             patched.assert_called_once_with(
                 credentials=None,
                 credentials_file=None,
-                host=client.DEFAULT_ENDPOINT,
+                host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                    UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+                ),
                 scopes=None,
                 client_cert_source_for_mtls=None,
                 quota_project_id=None,
                 client_info=transports.base.DEFAULT_CLIENT_INFO,
                 always_use_jwt_access=True,
                 api_audience=None,
             )
@@ -272,33 +552,43 @@
                 always_use_jwt_access=True,
                 api_audience=None,
             )
 
     # Check the case api_endpoint is not provided and GOOGLE_API_USE_MTLS_ENDPOINT has
     # unsupported value.
     with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "Unsupported"}):
-        with pytest.raises(MutualTLSChannelError):
+        with pytest.raises(MutualTLSChannelError) as excinfo:
             client = client_class(transport=transport_name)
+    assert (
+        str(excinfo.value)
+        == "Environment variable `GOOGLE_API_USE_MTLS_ENDPOINT` must be `never`, `auto` or `always`"
+    )
 
     # Check the case GOOGLE_API_USE_CLIENT_CERTIFICATE has unsupported value.
     with mock.patch.dict(
         os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "Unsupported"}
     ):
-        with pytest.raises(ValueError):
+        with pytest.raises(ValueError) as excinfo:
             client = client_class(transport=transport_name)
+    assert (
+        str(excinfo.value)
+        == "Environment variable `GOOGLE_API_USE_CLIENT_CERTIFICATE` must be either `true` or `false`"
+    )
 
     # Check the case quota_project_id is provided
     options = client_options.ClientOptions(quota_project_id="octopus")
     with mock.patch.object(transport_class, "__init__") as patched:
         patched.return_value = None
         client = client_class(client_options=options, transport=transport_name)
         patched.assert_called_once_with(
             credentials=None,
             credentials_file=None,
-            host=client.DEFAULT_ENDPOINT,
+            host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+            ),
             scopes=None,
             client_cert_source_for_mtls=None,
             quota_project_id="octopus",
             client_info=transports.base.DEFAULT_CLIENT_INFO,
             always_use_jwt_access=True,
             api_audience=None,
         )
@@ -308,15 +598,17 @@
     )
     with mock.patch.object(transport_class, "__init__") as patched:
         patched.return_value = None
         client = client_class(client_options=options, transport=transport_name)
         patched.assert_called_once_with(
             credentials=None,
             credentials_file=None,
-            host=client.DEFAULT_ENDPOINT,
+            host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+            ),
             scopes=None,
             client_cert_source_for_mtls=None,
             quota_project_id=None,
             client_info=transports.base.DEFAULT_CLIENT_INFO,
             always_use_jwt_access=True,
             api_audience="https://language.googleapis.com",
         )
@@ -349,21 +641,21 @@
             "grpc_asyncio",
             "false",
         ),
     ],
 )
 @mock.patch.object(
     MetadataServiceClient,
-    "DEFAULT_ENDPOINT",
-    modify_default_endpoint(MetadataServiceClient),
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(MetadataServiceClient),
 )
 @mock.patch.object(
     MetadataServiceAsyncClient,
-    "DEFAULT_ENDPOINT",
-    modify_default_endpoint(MetadataServiceAsyncClient),
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(MetadataServiceAsyncClient),
 )
 @mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "auto"})
 def test_metadata_service_client_mtls_env_auto(
     client_class, transport_class, transport_name, use_client_cert_env
 ):
     # This tests the endpoint autoswitch behavior. Endpoint is autoswitched to the default
     # mtls endpoint, if GOOGLE_API_USE_CLIENT_CERTIFICATE is "true" and client cert exists.
@@ -378,15 +670,17 @@
         )
         with mock.patch.object(transport_class, "__init__") as patched:
             patched.return_value = None
             client = client_class(client_options=options, transport=transport_name)
 
             if use_client_cert_env == "false":
                 expected_client_cert_source = None
-                expected_host = client.DEFAULT_ENDPOINT
+                expected_host = client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                    UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+                )
             else:
                 expected_client_cert_source = client_cert_source_callback
                 expected_host = client.DEFAULT_MTLS_ENDPOINT
 
             patched.assert_called_once_with(
                 credentials=None,
                 credentials_file=None,
@@ -410,15 +704,17 @@
                 return_value=True,
             ):
                 with mock.patch(
                     "google.auth.transport.mtls.default_client_cert_source",
                     return_value=client_cert_source_callback,
                 ):
                     if use_client_cert_env == "false":
-                        expected_host = client.DEFAULT_ENDPOINT
+                        expected_host = client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                            UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+                        )
                         expected_client_cert_source = None
                     else:
                         expected_host = client.DEFAULT_MTLS_ENDPOINT
                         expected_client_cert_source = client_cert_source_callback
 
                     patched.return_value = None
                     client = client_class(transport=transport_name)
@@ -444,15 +740,17 @@
                 return_value=False,
             ):
                 patched.return_value = None
                 client = client_class(transport=transport_name)
                 patched.assert_called_once_with(
                     credentials=None,
                     credentials_file=None,
-                    host=client.DEFAULT_ENDPOINT,
+                    host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                        UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+                    ),
                     scopes=None,
                     client_cert_source_for_mtls=None,
                     quota_project_id=None,
                     client_info=transports.base.DEFAULT_CLIENT_INFO,
                     always_use_jwt_access=True,
                     api_audience=None,
                 )
@@ -534,14 +832,123 @@
                 (
                     api_endpoint,
                     cert_source,
                 ) = client_class.get_mtls_endpoint_and_cert_source()
                 assert api_endpoint == client_class.DEFAULT_MTLS_ENDPOINT
                 assert cert_source == mock_client_cert_source
 
+    # Check the case api_endpoint is not provided and GOOGLE_API_USE_MTLS_ENDPOINT has
+    # unsupported value.
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "Unsupported"}):
+        with pytest.raises(MutualTLSChannelError) as excinfo:
+            client_class.get_mtls_endpoint_and_cert_source()
+
+        assert (
+            str(excinfo.value)
+            == "Environment variable `GOOGLE_API_USE_MTLS_ENDPOINT` must be `never`, `auto` or `always`"
+        )
+
+    # Check the case GOOGLE_API_USE_CLIENT_CERTIFICATE has unsupported value.
+    with mock.patch.dict(
+        os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "Unsupported"}
+    ):
+        with pytest.raises(ValueError) as excinfo:
+            client_class.get_mtls_endpoint_and_cert_source()
+
+        assert (
+            str(excinfo.value)
+            == "Environment variable `GOOGLE_API_USE_CLIENT_CERTIFICATE` must be either `true` or `false`"
+        )
+
+
+@pytest.mark.parametrize(
+    "client_class", [MetadataServiceClient, MetadataServiceAsyncClient]
+)
+@mock.patch.object(
+    MetadataServiceClient,
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(MetadataServiceClient),
+)
+@mock.patch.object(
+    MetadataServiceAsyncClient,
+    "_DEFAULT_ENDPOINT_TEMPLATE",
+    modify_default_endpoint_template(MetadataServiceAsyncClient),
+)
+def test_metadata_service_client_client_api_endpoint(client_class):
+    mock_client_cert_source = client_cert_source_callback
+    api_override = "foo.com"
+    default_universe = MetadataServiceClient._DEFAULT_UNIVERSE
+    default_endpoint = MetadataServiceClient._DEFAULT_ENDPOINT_TEMPLATE.format(
+        UNIVERSE_DOMAIN=default_universe
+    )
+    mock_universe = "bar.com"
+    mock_endpoint = MetadataServiceClient._DEFAULT_ENDPOINT_TEMPLATE.format(
+        UNIVERSE_DOMAIN=mock_universe
+    )
+
+    # If ClientOptions.api_endpoint is set and GOOGLE_API_USE_CLIENT_CERTIFICATE="true",
+    # use ClientOptions.api_endpoint as the api endpoint regardless.
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_CLIENT_CERTIFICATE": "true"}):
+        with mock.patch(
+            "google.auth.transport.requests.AuthorizedSession.configure_mtls_channel"
+        ):
+            options = client_options.ClientOptions(
+                client_cert_source=mock_client_cert_source, api_endpoint=api_override
+            )
+            client = client_class(
+                client_options=options,
+                credentials=ga_credentials.AnonymousCredentials(),
+            )
+            assert client.api_endpoint == api_override
+
+    # If ClientOptions.api_endpoint is not set and GOOGLE_API_USE_MTLS_ENDPOINT="never",
+    # use the _DEFAULT_ENDPOINT_TEMPLATE populated with GDU as the api endpoint.
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "never"}):
+        client = client_class(credentials=ga_credentials.AnonymousCredentials())
+        assert client.api_endpoint == default_endpoint
+
+    # If ClientOptions.api_endpoint is not set and GOOGLE_API_USE_MTLS_ENDPOINT="always",
+    # use the DEFAULT_MTLS_ENDPOINT as the api endpoint.
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "always"}):
+        client = client_class(credentials=ga_credentials.AnonymousCredentials())
+        assert client.api_endpoint == client_class.DEFAULT_MTLS_ENDPOINT
+
+    # If ClientOptions.api_endpoint is not set, GOOGLE_API_USE_MTLS_ENDPOINT="auto" (default),
+    # GOOGLE_API_USE_CLIENT_CERTIFICATE="false" (default), default cert source doesn't exist,
+    # and ClientOptions.universe_domain="bar.com",
+    # use the _DEFAULT_ENDPOINT_TEMPLATE populated with universe domain as the api endpoint.
+    options = client_options.ClientOptions()
+    universe_exists = hasattr(options, "universe_domain")
+    if universe_exists:
+        options = client_options.ClientOptions(universe_domain=mock_universe)
+        client = client_class(
+            client_options=options, credentials=ga_credentials.AnonymousCredentials()
+        )
+    else:
+        client = client_class(
+            client_options=options, credentials=ga_credentials.AnonymousCredentials()
+        )
+    assert client.api_endpoint == (
+        mock_endpoint if universe_exists else default_endpoint
+    )
+    assert client.universe_domain == (
+        mock_universe if universe_exists else default_universe
+    )
+
+    # If ClientOptions does not have a universe domain attribute and GOOGLE_API_USE_MTLS_ENDPOINT="never",
+    # use the _DEFAULT_ENDPOINT_TEMPLATE populated with GDU as the api endpoint.
+    options = client_options.ClientOptions()
+    if hasattr(options, "universe_domain"):
+        delattr(options, "universe_domain")
+    with mock.patch.dict(os.environ, {"GOOGLE_API_USE_MTLS_ENDPOINT": "never"}):
+        client = client_class(
+            client_options=options, credentials=ga_credentials.AnonymousCredentials()
+        )
+        assert client.api_endpoint == default_endpoint
+
 
 @pytest.mark.parametrize(
     "client_class,transport_class,transport_name",
     [
         (MetadataServiceClient, transports.MetadataServiceGrpcTransport, "grpc"),
         (
             MetadataServiceAsyncClient,
@@ -559,15 +966,17 @@
     )
     with mock.patch.object(transport_class, "__init__") as patched:
         patched.return_value = None
         client = client_class(client_options=options, transport=transport_name)
         patched.assert_called_once_with(
             credentials=None,
             credentials_file=None,
-            host=client.DEFAULT_ENDPOINT,
+            host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+            ),
             scopes=["1", "2"],
             client_cert_source_for_mtls=None,
             quota_project_id=None,
             client_info=transports.base.DEFAULT_CLIENT_INFO,
             always_use_jwt_access=True,
             api_audience=None,
         )
@@ -598,15 +1007,17 @@
 
     with mock.patch.object(transport_class, "__init__") as patched:
         patched.return_value = None
         client = client_class(client_options=options, transport=transport_name)
         patched.assert_called_once_with(
             credentials=None,
             credentials_file="credentials.json",
-            host=client.DEFAULT_ENDPOINT,
+            host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+            ),
             scopes=None,
             client_cert_source_for_mtls=None,
             quota_project_id=None,
             client_info=transports.base.DEFAULT_CLIENT_INFO,
             always_use_jwt_access=True,
             api_audience=None,
         )
@@ -658,15 +1069,17 @@
 
     with mock.patch.object(transport_class, "__init__") as patched:
         patched.return_value = None
         client = client_class(client_options=options, transport=transport_name)
         patched.assert_called_once_with(
             credentials=None,
             credentials_file="credentials.json",
-            host=client.DEFAULT_ENDPOINT,
+            host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+            ),
             scopes=None,
             client_cert_source_for_mtls=None,
             quota_project_id=None,
             client_info=transports.base.DEFAULT_CLIENT_INFO,
             always_use_jwt_access=True,
             api_audience=None,
         )
@@ -735,15 +1148,16 @@
             uid="uid_value",
         )
         response = client.create_entity(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == metadata_.CreateEntityRequest()
+        request = metadata_.CreateEntityRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, metadata_.Entity)
     assert response.name == "name_value"
     assert response.display_name == "display_name_value"
     assert response.description == "description_value"
     assert response.id == "id_value"
@@ -763,20 +1177,166 @@
     client = MetadataServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.create_entity), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.create_entity()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == metadata_.CreateEntityRequest()
 
 
+def test_create_entity_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = MetadataServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = metadata_.CreateEntityRequest(
+        parent="parent_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.create_entity), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.create_entity(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == metadata_.CreateEntityRequest(
+            parent="parent_value",
+        )
+
+
+def test_create_entity_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = MetadataServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.create_entity in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[client._transport.create_entity] = mock_rpc
+        request = {}
+        client.create_entity(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.create_entity(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_create_entity_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = MetadataServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.create_entity), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            metadata_.Entity(
+                name="name_value",
+                display_name="display_name_value",
+                description="description_value",
+                id="id_value",
+                etag="etag_value",
+                type_=metadata_.Entity.Type.TABLE,
+                asset="asset_value",
+                data_path="data_path_value",
+                data_path_pattern="data_path_pattern_value",
+                catalog_entry="catalog_entry_value",
+                system=metadata_.StorageSystem.CLOUD_STORAGE,
+                uid="uid_value",
+            )
+        )
+        response = await client.create_entity()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == metadata_.CreateEntityRequest()
+
+
+@pytest.mark.asyncio
+async def test_create_entity_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = MetadataServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.create_entity
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.create_entity
+        ] = mock_object
+
+        request = {}
+        await client.create_entity(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.create_entity(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_create_entity_async(
     transport: str = "grpc_asyncio", request_type=metadata_.CreateEntityRequest
 ):
     client = MetadataServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
@@ -806,15 +1366,16 @@
             )
         )
         response = await client.create_entity(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == metadata_.CreateEntityRequest()
+        request = metadata_.CreateEntityRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, metadata_.Entity)
     assert response.name == "name_value"
     assert response.display_name == "display_name_value"
     assert response.description == "description_value"
     assert response.id == "id_value"
@@ -1017,15 +1578,16 @@
             uid="uid_value",
         )
         response = client.update_entity(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == metadata_.UpdateEntityRequest()
+        request = metadata_.UpdateEntityRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, metadata_.Entity)
     assert response.name == "name_value"
     assert response.display_name == "display_name_value"
     assert response.description == "description_value"
     assert response.id == "id_value"
@@ -1045,20 +1607,162 @@
     client = MetadataServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.update_entity), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.update_entity()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == metadata_.UpdateEntityRequest()
 
 
+def test_update_entity_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = MetadataServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = metadata_.UpdateEntityRequest()
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.update_entity), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.update_entity(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == metadata_.UpdateEntityRequest()
+
+
+def test_update_entity_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = MetadataServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.update_entity in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[client._transport.update_entity] = mock_rpc
+        request = {}
+        client.update_entity(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.update_entity(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_update_entity_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = MetadataServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.update_entity), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            metadata_.Entity(
+                name="name_value",
+                display_name="display_name_value",
+                description="description_value",
+                id="id_value",
+                etag="etag_value",
+                type_=metadata_.Entity.Type.TABLE,
+                asset="asset_value",
+                data_path="data_path_value",
+                data_path_pattern="data_path_pattern_value",
+                catalog_entry="catalog_entry_value",
+                system=metadata_.StorageSystem.CLOUD_STORAGE,
+                uid="uid_value",
+            )
+        )
+        response = await client.update_entity()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == metadata_.UpdateEntityRequest()
+
+
+@pytest.mark.asyncio
+async def test_update_entity_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = MetadataServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.update_entity
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.update_entity
+        ] = mock_object
+
+        request = {}
+        await client.update_entity(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.update_entity(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_update_entity_async(
     transport: str = "grpc_asyncio", request_type=metadata_.UpdateEntityRequest
 ):
     client = MetadataServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
@@ -1088,15 +1792,16 @@
             )
         )
         response = await client.update_entity(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == metadata_.UpdateEntityRequest()
+        request = metadata_.UpdateEntityRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, metadata_.Entity)
     assert response.name == "name_value"
     assert response.display_name == "display_name_value"
     assert response.description == "description_value"
     assert response.id == "id_value"
@@ -1196,15 +1901,16 @@
         # Designate an appropriate return value for the call.
         call.return_value = None
         response = client.delete_entity(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == metadata_.DeleteEntityRequest()
+        request = metadata_.DeleteEntityRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert response is None
 
 
 def test_delete_entity_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
@@ -1212,20 +1918,153 @@
     client = MetadataServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.delete_entity), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.delete_entity()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == metadata_.DeleteEntityRequest()
 
 
+def test_delete_entity_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = MetadataServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = metadata_.DeleteEntityRequest(
+        name="name_value",
+        etag="etag_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.delete_entity), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.delete_entity(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == metadata_.DeleteEntityRequest(
+            name="name_value",
+            etag="etag_value",
+        )
+
+
+def test_delete_entity_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = MetadataServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.delete_entity in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[client._transport.delete_entity] = mock_rpc
+        request = {}
+        client.delete_entity(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.delete_entity(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_delete_entity_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = MetadataServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.delete_entity), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(None)
+        response = await client.delete_entity()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == metadata_.DeleteEntityRequest()
+
+
+@pytest.mark.asyncio
+async def test_delete_entity_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = MetadataServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.delete_entity
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.delete_entity
+        ] = mock_object
+
+        request = {}
+        await client.delete_entity(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.delete_entity(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_delete_entity_async(
     transport: str = "grpc_asyncio", request_type=metadata_.DeleteEntityRequest
 ):
     client = MetadataServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
@@ -1240,15 +2079,16 @@
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(None)
         response = await client.delete_entity(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == metadata_.DeleteEntityRequest()
+        request = metadata_.DeleteEntityRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert response is None
 
 
 @pytest.mark.asyncio
 async def test_delete_entity_async_from_dict():
@@ -1429,15 +2269,16 @@
             uid="uid_value",
         )
         response = client.get_entity(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == metadata_.GetEntityRequest()
+        request = metadata_.GetEntityRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, metadata_.Entity)
     assert response.name == "name_value"
     assert response.display_name == "display_name_value"
     assert response.description == "description_value"
     assert response.id == "id_value"
@@ -1457,20 +2298,164 @@
     client = MetadataServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.get_entity), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.get_entity()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == metadata_.GetEntityRequest()
 
 
+def test_get_entity_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = MetadataServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = metadata_.GetEntityRequest(
+        name="name_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_entity), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.get_entity(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == metadata_.GetEntityRequest(
+            name="name_value",
+        )
+
+
+def test_get_entity_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = MetadataServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.get_entity in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[client._transport.get_entity] = mock_rpc
+        request = {}
+        client.get_entity(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.get_entity(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_get_entity_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = MetadataServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_entity), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            metadata_.Entity(
+                name="name_value",
+                display_name="display_name_value",
+                description="description_value",
+                id="id_value",
+                etag="etag_value",
+                type_=metadata_.Entity.Type.TABLE,
+                asset="asset_value",
+                data_path="data_path_value",
+                data_path_pattern="data_path_pattern_value",
+                catalog_entry="catalog_entry_value",
+                system=metadata_.StorageSystem.CLOUD_STORAGE,
+                uid="uid_value",
+            )
+        )
+        response = await client.get_entity()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == metadata_.GetEntityRequest()
+
+
+@pytest.mark.asyncio
+async def test_get_entity_async_use_cached_wrapped_rpc(transport: str = "grpc_asyncio"):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = MetadataServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.get_entity
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.get_entity
+        ] = mock_object
+
+        request = {}
+        await client.get_entity(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.get_entity(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_get_entity_async(
     transport: str = "grpc_asyncio", request_type=metadata_.GetEntityRequest
 ):
     client = MetadataServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
@@ -1500,15 +2485,16 @@
             )
         )
         response = await client.get_entity(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == metadata_.GetEntityRequest()
+        request = metadata_.GetEntityRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, metadata_.Entity)
     assert response.name == "name_value"
     assert response.display_name == "display_name_value"
     assert response.description == "description_value"
     assert response.id == "id_value"
@@ -1690,15 +2676,16 @@
             next_page_token="next_page_token_value",
         )
         response = client.list_entities(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == metadata_.ListEntitiesRequest()
+        request = metadata_.ListEntitiesRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, pagers.ListEntitiesPager)
     assert response.next_page_token == "next_page_token_value"
 
 
 def test_list_entities_empty_call():
@@ -1707,20 +2694,159 @@
     client = MetadataServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.list_entities), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.list_entities()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == metadata_.ListEntitiesRequest()
 
 
+def test_list_entities_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = MetadataServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = metadata_.ListEntitiesRequest(
+        parent="parent_value",
+        page_token="page_token_value",
+        filter="filter_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_entities), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.list_entities(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == metadata_.ListEntitiesRequest(
+            parent="parent_value",
+            page_token="page_token_value",
+            filter="filter_value",
+        )
+
+
+def test_list_entities_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = MetadataServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.list_entities in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[client._transport.list_entities] = mock_rpc
+        request = {}
+        client.list_entities(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.list_entities(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_list_entities_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = MetadataServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_entities), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            metadata_.ListEntitiesResponse(
+                next_page_token="next_page_token_value",
+            )
+        )
+        response = await client.list_entities()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == metadata_.ListEntitiesRequest()
+
+
+@pytest.mark.asyncio
+async def test_list_entities_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = MetadataServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.list_entities
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.list_entities
+        ] = mock_object
+
+        request = {}
+        await client.list_entities(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.list_entities(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_list_entities_async(
     transport: str = "grpc_asyncio", request_type=metadata_.ListEntitiesRequest
 ):
     client = MetadataServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
@@ -1739,15 +2865,16 @@
             )
         )
         response = await client.list_entities(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == metadata_.ListEntitiesRequest()
+        request = metadata_.ListEntitiesRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, pagers.ListEntitiesAsyncPager)
     assert response.next_page_token == "next_page_token_value"
 
 
 @pytest.mark.asyncio
@@ -1896,15 +3023,15 @@
             metadata_.ListEntitiesRequest(),
             parent="parent_value",
         )
 
 
 def test_list_entities_pager(transport_name: str = "grpc"):
     client = MetadataServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
         transport=transport_name,
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.list_entities), "__call__") as call:
         # Set the response to a series of pages.
         call.side_effect = (
@@ -1946,15 +3073,15 @@
         results = list(pager)
         assert len(results) == 6
         assert all(isinstance(i, metadata_.Entity) for i in results)
 
 
 def test_list_entities_pages(transport_name: str = "grpc"):
     client = MetadataServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
         transport=transport_name,
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.list_entities), "__call__") as call:
         # Set the response to a series of pages.
         call.side_effect = (
@@ -1988,15 +3115,15 @@
         for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
             assert page_.raw_page.next_page_token == token
 
 
 @pytest.mark.asyncio
 async def test_list_entities_async_pager():
     client = MetadataServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.list_entities), "__call__", new_callable=mock.AsyncMock
     ) as call:
         # Set the response to a series of pages.
@@ -2038,15 +3165,15 @@
         assert len(responses) == 6
         assert all(isinstance(i, metadata_.Entity) for i in responses)
 
 
 @pytest.mark.asyncio
 async def test_list_entities_async_pages():
     client = MetadataServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.list_entities), "__call__", new_callable=mock.AsyncMock
     ) as call:
         # Set the response to a series of pages.
@@ -2115,15 +3242,16 @@
             etag="etag_value",
         )
         response = client.create_partition(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == metadata_.CreatePartitionRequest()
+        request = metadata_.CreatePartitionRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, metadata_.Partition)
     assert response.name == "name_value"
     assert response.values == ["values_value"]
     assert response.location == "location_value"
     assert response.etag == "etag_value"
@@ -2135,20 +3263,160 @@
     client = MetadataServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.create_partition), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.create_partition()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == metadata_.CreatePartitionRequest()
 
 
+def test_create_partition_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = MetadataServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = metadata_.CreatePartitionRequest(
+        parent="parent_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.create_partition), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.create_partition(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == metadata_.CreatePartitionRequest(
+            parent="parent_value",
+        )
+
+
+def test_create_partition_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = MetadataServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.create_partition in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.create_partition
+        ] = mock_rpc
+        request = {}
+        client.create_partition(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.create_partition(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_create_partition_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = MetadataServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.create_partition), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            metadata_.Partition(
+                name="name_value",
+                values=["values_value"],
+                location="location_value",
+                etag="etag_value",
+            )
+        )
+        response = await client.create_partition()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == metadata_.CreatePartitionRequest()
+
+
+@pytest.mark.asyncio
+async def test_create_partition_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = MetadataServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.create_partition
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.create_partition
+        ] = mock_object
+
+        request = {}
+        await client.create_partition(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.create_partition(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_create_partition_async(
     transport: str = "grpc_asyncio", request_type=metadata_.CreatePartitionRequest
 ):
     client = MetadataServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
@@ -2170,15 +3438,16 @@
             )
         )
         response = await client.create_partition(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == metadata_.CreatePartitionRequest()
+        request = metadata_.CreatePartitionRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, metadata_.Partition)
     assert response.name == "name_value"
     assert response.values == ["values_value"]
     assert response.location == "location_value"
     assert response.etag == "etag_value"
@@ -2360,15 +3629,16 @@
         # Designate an appropriate return value for the call.
         call.return_value = None
         response = client.delete_partition(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == metadata_.DeletePartitionRequest()
+        request = metadata_.DeletePartitionRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert response is None
 
 
 def test_delete_partition_empty_call():
     # This test is a coverage failsafe to make sure that totally empty calls,
@@ -2376,20 +3646,155 @@
     client = MetadataServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.delete_partition), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.delete_partition()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == metadata_.DeletePartitionRequest()
 
 
+def test_delete_partition_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = MetadataServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = metadata_.DeletePartitionRequest(
+        name="name_value",
+        etag="etag_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.delete_partition), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.delete_partition(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == metadata_.DeletePartitionRequest(
+            name="name_value",
+            etag="etag_value",
+        )
+
+
+def test_delete_partition_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = MetadataServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.delete_partition in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[
+            client._transport.delete_partition
+        ] = mock_rpc
+        request = {}
+        client.delete_partition(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.delete_partition(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_delete_partition_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = MetadataServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.delete_partition), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(None)
+        response = await client.delete_partition()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == metadata_.DeletePartitionRequest()
+
+
+@pytest.mark.asyncio
+async def test_delete_partition_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = MetadataServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.delete_partition
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.delete_partition
+        ] = mock_object
+
+        request = {}
+        await client.delete_partition(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.delete_partition(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_delete_partition_async(
     transport: str = "grpc_asyncio", request_type=metadata_.DeletePartitionRequest
 ):
     client = MetadataServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
@@ -2404,15 +3809,16 @@
         # Designate an appropriate return value for the call.
         call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(None)
         response = await client.delete_partition(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == metadata_.DeletePartitionRequest()
+        request = metadata_.DeletePartitionRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert response is None
 
 
 @pytest.mark.asyncio
 async def test_delete_partition_async_from_dict():
@@ -2585,15 +3991,16 @@
             etag="etag_value",
         )
         response = client.get_partition(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == metadata_.GetPartitionRequest()
+        request = metadata_.GetPartitionRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, metadata_.Partition)
     assert response.name == "name_value"
     assert response.values == ["values_value"]
     assert response.location == "location_value"
     assert response.etag == "etag_value"
@@ -2605,20 +4012,158 @@
     client = MetadataServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.get_partition), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.get_partition()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == metadata_.GetPartitionRequest()
 
 
+def test_get_partition_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = MetadataServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = metadata_.GetPartitionRequest(
+        name="name_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_partition), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.get_partition(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == metadata_.GetPartitionRequest(
+            name="name_value",
+        )
+
+
+def test_get_partition_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = MetadataServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.get_partition in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[client._transport.get_partition] = mock_rpc
+        request = {}
+        client.get_partition(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.get_partition(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_get_partition_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = MetadataServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.get_partition), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            metadata_.Partition(
+                name="name_value",
+                values=["values_value"],
+                location="location_value",
+                etag="etag_value",
+            )
+        )
+        response = await client.get_partition()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == metadata_.GetPartitionRequest()
+
+
+@pytest.mark.asyncio
+async def test_get_partition_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = MetadataServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.get_partition
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.get_partition
+        ] = mock_object
+
+        request = {}
+        await client.get_partition(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.get_partition(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_get_partition_async(
     transport: str = "grpc_asyncio", request_type=metadata_.GetPartitionRequest
 ):
     client = MetadataServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
@@ -2640,15 +4185,16 @@
             )
         )
         response = await client.get_partition(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == metadata_.GetPartitionRequest()
+        request = metadata_.GetPartitionRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, metadata_.Partition)
     assert response.name == "name_value"
     assert response.values == ["values_value"]
     assert response.location == "location_value"
     assert response.etag == "etag_value"
@@ -2822,15 +4368,16 @@
             next_page_token="next_page_token_value",
         )
         response = client.list_partitions(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls) == 1
         _, args, _ = call.mock_calls[0]
-        assert args[0] == metadata_.ListPartitionsRequest()
+        request = metadata_.ListPartitionsRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, pagers.ListPartitionsPager)
     assert response.next_page_token == "next_page_token_value"
 
 
 def test_list_partitions_empty_call():
@@ -2839,20 +4386,159 @@
     client = MetadataServiceClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport="grpc",
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.list_partitions), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
         client.list_partitions()
         call.assert_called()
         _, args, _ = call.mock_calls[0]
         assert args[0] == metadata_.ListPartitionsRequest()
 
 
+def test_list_partitions_non_empty_request_with_auto_populated_field():
+    # This test is a coverage failsafe to make sure that UUID4 fields are
+    # automatically populated, according to AIP-4235, with non-empty requests.
+    client = MetadataServiceClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc",
+    )
+
+    # Populate all string fields in the request which are not UUID4
+    # since we want to check that UUID4 are populated automatically
+    # if they meet the requirements of AIP 4235.
+    request = metadata_.ListPartitionsRequest(
+        parent="parent_value",
+        page_token="page_token_value",
+        filter="filter_value",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_partitions), "__call__") as call:
+        call.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client.list_partitions(request=request)
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == metadata_.ListPartitionsRequest(
+            parent="parent_value",
+            page_token="page_token_value",
+            filter="filter_value",
+        )
+
+
+def test_list_partitions_use_cached_wrapped_rpc():
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method.wrap_method") as wrapper_fn:
+        client = MetadataServiceClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport="grpc",
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert client._transport.list_partitions in client._transport._wrapped_methods
+
+        # Replace cached wrapped function with mock
+        mock_rpc = mock.Mock()
+        mock_rpc.return_value.name = (
+            "foo"  # operation_request.operation in compute client(s) expect a string.
+        )
+        client._transport._wrapped_methods[client._transport.list_partitions] = mock_rpc
+        request = {}
+        client.list_partitions(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_rpc.call_count == 1
+
+        client.list_partitions(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_rpc.call_count == 2
+
+
+@pytest.mark.asyncio
+async def test_list_partitions_empty_call_async():
+    # This test is a coverage failsafe to make sure that totally empty calls,
+    # i.e. request == None and no flattened fields passed, work.
+    client = MetadataServiceAsyncClient(
+        credentials=ga_credentials.AnonymousCredentials(),
+        transport="grpc_asyncio",
+    )
+
+    # Mock the actual call within the gRPC stub, and fake the request.
+    with mock.patch.object(type(client.transport.list_partitions), "__call__") as call:
+        # Designate an appropriate return value for the call.
+        call.return_value = grpc_helpers_async.FakeUnaryUnaryCall(
+            metadata_.ListPartitionsResponse(
+                next_page_token="next_page_token_value",
+            )
+        )
+        response = await client.list_partitions()
+        call.assert_called()
+        _, args, _ = call.mock_calls[0]
+        assert args[0] == metadata_.ListPartitionsRequest()
+
+
+@pytest.mark.asyncio
+async def test_list_partitions_async_use_cached_wrapped_rpc(
+    transport: str = "grpc_asyncio",
+):
+    # Clients should use _prep_wrapped_messages to create cached wrapped rpcs,
+    # instead of constructing them on each call
+    with mock.patch("google.api_core.gapic_v1.method_async.wrap_method") as wrapper_fn:
+        client = MetadataServiceAsyncClient(
+            credentials=ga_credentials.AnonymousCredentials(),
+            transport=transport,
+        )
+
+        # Should wrap all calls on client creation
+        assert wrapper_fn.call_count > 0
+        wrapper_fn.reset_mock()
+
+        # Ensure method has been cached
+        assert (
+            client._client._transport.list_partitions
+            in client._client._transport._wrapped_methods
+        )
+
+        # Replace cached wrapped function with mock
+        class AwaitableMock(mock.AsyncMock):
+            def __await__(self):
+                self.await_count += 1
+                return iter([])
+
+        mock_object = AwaitableMock()
+        client._client._transport._wrapped_methods[
+            client._client._transport.list_partitions
+        ] = mock_object
+
+        request = {}
+        await client.list_partitions(request)
+
+        # Establish that the underlying gRPC stub method was called.
+        assert mock_object.call_count == 1
+
+        await client.list_partitions(request)
+
+        # Establish that a new wrapper was not created for this call
+        assert wrapper_fn.call_count == 0
+        assert mock_object.call_count == 2
+
+
 @pytest.mark.asyncio
 async def test_list_partitions_async(
     transport: str = "grpc_asyncio", request_type=metadata_.ListPartitionsRequest
 ):
     client = MetadataServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
@@ -2871,15 +4557,16 @@
             )
         )
         response = await client.list_partitions(request)
 
         # Establish that the underlying gRPC stub method was called.
         assert len(call.mock_calls)
         _, args, _ = call.mock_calls[0]
-        assert args[0] == metadata_.ListPartitionsRequest()
+        request = metadata_.ListPartitionsRequest()
+        assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, pagers.ListPartitionsAsyncPager)
     assert response.next_page_token == "next_page_token_value"
 
 
 @pytest.mark.asyncio
@@ -3028,15 +4715,15 @@
             metadata_.ListPartitionsRequest(),
             parent="parent_value",
         )
 
 
 def test_list_partitions_pager(transport_name: str = "grpc"):
     client = MetadataServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
         transport=transport_name,
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.list_partitions), "__call__") as call:
         # Set the response to a series of pages.
         call.side_effect = (
@@ -3078,15 +4765,15 @@
         results = list(pager)
         assert len(results) == 6
         assert all(isinstance(i, metadata_.Partition) for i in results)
 
 
 def test_list_partitions_pages(transport_name: str = "grpc"):
     client = MetadataServiceClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
         transport=transport_name,
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(type(client.transport.list_partitions), "__call__") as call:
         # Set the response to a series of pages.
         call.side_effect = (
@@ -3120,15 +4807,15 @@
         for page_, token in zip(pages, ["abc", "def", "ghi", ""]):
             assert page_.raw_page.next_page_token == token
 
 
 @pytest.mark.asyncio
 async def test_list_partitions_async_pager():
     client = MetadataServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.list_partitions), "__call__", new_callable=mock.AsyncMock
     ) as call:
         # Set the response to a series of pages.
@@ -3170,15 +4857,15 @@
         assert len(responses) == 6
         assert all(isinstance(i, metadata_.Partition) for i in responses)
 
 
 @pytest.mark.asyncio
 async def test_list_partitions_async_pages():
     client = MetadataServiceAsyncClient(
-        credentials=ga_credentials.AnonymousCredentials,
+        credentials=ga_credentials.AnonymousCredentials(),
     )
 
     # Mock the actual call within the gRPC stub, and fake the request.
     with mock.patch.object(
         type(client.transport.list_partitions), "__call__", new_callable=mock.AsyncMock
     ) as call:
         # Set the response to a series of pages.
@@ -3250,15 +4937,15 @@
     with pytest.raises(ValueError):
         client = MetadataServiceClient(
             client_options=options,
             transport=transport,
         )
 
     # It is an error to provide an api_key and a credential.
-    options = mock.Mock()
+    options = client_options.ClientOptions()
     options.api_key = "api_key"
     with pytest.raises(ValueError):
         client = MetadataServiceClient(
             client_options=options, credentials=ga_credentials.AnonymousCredentials()
         )
 
     # It is an error to provide scopes and a transport instance.
@@ -3978,15 +5665,15 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert response is None
 
 
 @pytest.mark.asyncio
-async def test_delete_operation_async(transport: str = "grpc"):
+async def test_delete_operation_async(transport: str = "grpc_asyncio"):
     client = MetadataServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
@@ -4117,15 +5804,15 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert response is None
 
 
 @pytest.mark.asyncio
-async def test_cancel_operation_async(transport: str = "grpc"):
+async def test_cancel_operation_async(transport: str = "grpc_asyncio"):
     client = MetadataServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
@@ -4256,15 +5943,15 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, operations_pb2.Operation)
 
 
 @pytest.mark.asyncio
-async def test_get_operation_async(transport: str = "grpc"):
+async def test_get_operation_async(transport: str = "grpc_asyncio"):
     client = MetadataServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
@@ -4401,15 +6088,15 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, operations_pb2.ListOperationsResponse)
 
 
 @pytest.mark.asyncio
-async def test_list_operations_async(transport: str = "grpc"):
+async def test_list_operations_async(transport: str = "grpc_asyncio"):
     client = MetadataServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
@@ -4546,15 +6233,15 @@
         assert args[0] == request
 
     # Establish that the response is the type that we expect.
     assert isinstance(response, locations_pb2.ListLocationsResponse)
 
 
 @pytest.mark.asyncio
-async def test_list_locations_async(transport: str = "grpc"):
+async def test_list_locations_async(transport: str = "grpc_asyncio"):
     client = MetadataServiceAsyncClient(
         credentials=ga_credentials.AnonymousCredentials(),
         transport=transport,
     )
 
     # Everything is optional in proto3 as far as the runtime is concerned,
     # and we are mocking out the actual API, so just send an empty request.
@@ -4863,15 +6550,17 @@
         options.api_key = "api_key"
         with mock.patch.object(transport_class, "__init__") as patched:
             patched.return_value = None
             client = client_class(client_options=options)
             patched.assert_called_once_with(
                 credentials=mock_cred,
                 credentials_file=None,
-                host=client.DEFAULT_ENDPOINT,
+                host=client._DEFAULT_ENDPOINT_TEMPLATE.format(
+                    UNIVERSE_DOMAIN=client._DEFAULT_UNIVERSE
+                ),
                 scopes=None,
                 client_cert_source_for_mtls=None,
                 quota_project_id=None,
                 client_info=transports.base.DEFAULT_CLIENT_INFO,
                 always_use_jwt_access=True,
                 api_audience=None,
             )
```

