# Comparing `tmp/azureml_metrics-0.0.9-py3-none-any.whl.zip` & `tmp/azureml_metrics-47.0.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,48 +1,108 @@
-Zip file size: 152892 bytes, number of entries: 46
--rw-rw-rw-  2.0 fat      267 b- defN 23-May-17 17:31 azureml/__init__.py
--rw-rw-rw-  2.0 fat   260065 b- defN 23-May-17 17:31 azureml/metrics/NOTICE
--rw-rw-rw-  2.0 fat      805 b- defN 23-May-17 17:31 azureml/metrics/__init__.py
--rw-rw-rw-  2.0 fat    49711 b- defN 23-May-17 17:31 azureml/metrics/_classification.py
--rw-rw-rw-  2.0 fat     7829 b- defN 23-May-17 17:31 azureml/metrics/_dataset_binning.py
--rw-rw-rw-  2.0 fat    32140 b- defN 23-May-17 17:31 azureml/metrics/_forecasting.py
--rw-rw-rw-  2.0 fat     5034 b- defN 23-May-17 17:31 azureml/metrics/_metric_base.py
--rw-rw-rw-  2.0 fat    25843 b- defN 23-May-17 17:31 azureml/metrics/_regression.py
--rw-rw-rw-  2.0 fat    33472 b- defN 23-May-17 17:31 azureml/metrics/_score.py
--rw-rw-rw-  2.0 fat    32841 b- defN 23-May-17 17:31 azureml/metrics/_scoring.py
--rw-rw-rw-  2.0 fat    23940 b- defN 23-May-17 17:31 azureml/metrics/_scoring_confidence.py
--rw-rw-rw-  2.0 fat    34530 b- defN 23-May-17 17:31 azureml/metrics/_scoring_utilities.py
--rw-rw-rw-  2.0 fat     2213 b- defN 23-May-17 17:31 azureml/metrics/_seq2seq_fill_mask.py
--rw-rw-rw-  2.0 fat     5135 b- defN 23-May-17 17:31 azureml/metrics/_seq2seq_qa.py
--rw-rw-rw-  2.0 fat     2137 b- defN 23-May-17 17:31 azureml/metrics/_seq2seq_summarization.py
--rw-rw-rw-  2.0 fat     1968 b- defN 23-May-17 17:31 azureml/metrics/_seq2seq_translation.py
--rw-rw-rw-  2.0 fat     5023 b- defN 23-May-17 17:31 azureml/metrics/_token_classification.py
--rw-rw-rw-  2.0 fat    44604 b- defN 23-May-17 17:31 azureml/metrics/_validation.py
--rw-rw-rw-  2.0 fat       34 b- defN 23-May-17 17:36 azureml/metrics/_version.py
--rw-rw-rw-  2.0 fat    14894 b- defN 23-May-17 17:31 azureml/metrics/azureml_classification_metrics.py
--rw-rw-rw-  2.0 fat     3975 b- defN 23-May-17 17:31 azureml/metrics/azureml_fill_mask_metrics.py
--rw-rw-rw-  2.0 fat    16778 b- defN 23-May-17 17:31 azureml/metrics/azureml_forecasting_metrics.py
--rw-rw-rw-  2.0 fat     6621 b- defN 23-May-17 17:31 azureml/metrics/azureml_metrics.py
--rw-rw-rw-  2.0 fat    13109 b- defN 23-May-17 17:31 azureml/metrics/azureml_od_is_metrics.py
--rw-rw-rw-  2.0 fat     4523 b- defN 23-May-17 17:31 azureml/metrics/azureml_qa_metrics.py
--rw-rw-rw-  2.0 fat     9157 b- defN 23-May-17 17:31 azureml/metrics/azureml_regression_metrics.py
--rw-rw-rw-  2.0 fat     3858 b- defN 23-May-17 17:31 azureml/metrics/azureml_summarization_metrics.py
--rw-rw-rw-  2.0 fat     7329 b- defN 23-May-17 17:31 azureml/metrics/azureml_text_classification_metrics.py
--rw-rw-rw-  2.0 fat     3985 b- defN 23-May-17 17:31 azureml/metrics/azureml_text_generation_metrics.py
--rw-rw-rw-  2.0 fat     4200 b- defN 23-May-17 17:31 azureml/metrics/azureml_text_ner_metrics.py
--rw-rw-rw-  2.0 fat     3646 b- defN 23-May-17 17:31 azureml/metrics/azureml_translation_metrics.py
--rw-rw-rw-  2.0 fat     4601 b- defN 23-May-17 17:31 azureml/metrics/bleu.py
--rw-rw-rw-  2.0 fat    36132 b- defN 23-May-17 17:31 azureml/metrics/constants.py
--rw-rw-rw-  2.0 fat     4820 b- defN 23-May-17 17:31 azureml/metrics/contract.py
--rw-rw-rw-  2.0 fat     6624 b- defN 23-May-17 17:31 azureml/metrics/exceptions.py
--rw-rw-rw-  2.0 fat    47695 b- defN 23-May-17 17:31 azureml/metrics/reference_codes.py
--rw-rw-rw-  2.0 fat     6424 b- defN 23-May-17 17:31 azureml/metrics/scoring.py
--rw-rw-rw-  2.0 fat    13249 b- defN 23-May-17 17:31 azureml/metrics/utilities.py
--rw-rw-rw-  2.0 fat      239 b- defN 23-May-17 17:31 azureml/metrics/od_is_eval/__init__.py
--rw-rw-rw-  2.0 fat    21196 b- defN 23-May-17 17:31 azureml/metrics/od_is_eval/incremental_voc_evaluator.py
--rw-rw-rw-  2.0 fat    17250 b- defN 23-May-17 17:31 azureml/metrics/od_is_eval/metric_computation_utils.py
--rw-rw-rw-  2.0 fat      859 b- defN 23-May-17 17:36 azureml_metrics-0.0.9.dist-info/LICENSE.txt
--rw-rw-rw-  2.0 fat     1800 b- defN 23-May-17 17:36 azureml_metrics-0.0.9.dist-info/METADATA
--rw-rw-rw-  2.0 fat       97 b- defN 23-May-17 17:36 azureml_metrics-0.0.9.dist-info/WHEEL
--rw-rw-rw-  2.0 fat        8 b- defN 23-May-17 17:36 azureml_metrics-0.0.9.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat     4256 b- defN 23-May-17 17:36 azureml_metrics-0.0.9.dist-info/RECORD
-46 files, 824916 bytes uncompressed, 146012 bytes compressed:  82.3%
+Zip file size: 262570 bytes, number of entries: 106
+-rw-rw-rw-  2.0 fat      267 b- defN 24-Mar-22 10:04 azureml/__init__.py
+-rw-rw-rw-  2.0 fat   386823 b- defN 24-Mar-22 10:04 azureml/metrics/NOTICE
+-rw-rw-rw-  2.0 fat      997 b- defN 24-Mar-22 10:04 azureml/metrics/__init__.py
+-rw-rw-rw-  2.0 fat    39718 b- defN 24-Mar-22 10:04 azureml/metrics/_score.py
+-rw-rw-rw-  2.0 fat    39942 b- defN 24-Mar-22 10:04 azureml/metrics/_scoring_utilities.py
+-rw-rw-rw-  2.0 fat       36 b- defN 24-Mar-22 10:09 azureml/metrics/_version.py
+-rw-rw-rw-  2.0 fat    43005 b- defN 24-Mar-22 10:04 azureml/metrics/constants.py
+-rw-rw-rw-  2.0 fat      250 b- defN 24-Mar-22 10:04 azureml/metrics/common/__init__.py
+-rw-rw-rw-  2.0 fat    13219 b- defN 24-Mar-22 10:04 azureml/metrics/common/_logging_utils.py
+-rw-rw-rw-  2.0 fat     5298 b- defN 24-Mar-22 10:04 azureml/metrics/common/_metric_base.py
+-rw-rw-rw-  2.0 fat     2782 b- defN 24-Mar-22 10:04 azureml/metrics/common/_run_utils.py
+-rw-rw-rw-  2.0 fat    36753 b- defN 24-Mar-22 10:04 azureml/metrics/common/_score_utils.py
+-rw-rw-rw-  2.0 fat    42103 b- defN 24-Mar-22 10:04 azureml/metrics/common/_scoring.py
+-rw-rw-rw-  2.0 fat    24708 b- defN 24-Mar-22 10:04 azureml/metrics/common/_scoring_confidence.py
+-rw-rw-rw-  2.0 fat    50701 b- defN 24-Mar-22 10:04 azureml/metrics/common/_validation.py
+-rw-rw-rw-  2.0 fat    14737 b- defN 24-Mar-22 10:04 azureml/metrics/common/azureml_custom_prompt_metric.py
+-rw-rw-rw-  2.0 fat     3683 b- defN 24-Mar-22 10:04 azureml/metrics/common/azureml_metrics.py
+-rw-rw-rw-  2.0 fat     4841 b- defN 24-Mar-22 10:04 azureml/metrics/common/contract.py
+-rw-rw-rw-  2.0 fat    11800 b- defN 24-Mar-22 10:04 azureml/metrics/common/exceptions.py
+-rw-rw-rw-  2.0 fat     6889 b- defN 24-Mar-22 10:04 azureml/metrics/common/import_utilities.py
+-rw-rw-rw-  2.0 fat     2679 b- defN 24-Mar-22 10:04 azureml/metrics/common/reference_codes.py
+-rw-rw-rw-  2.0 fat     6424 b- defN 24-Mar-22 10:04 azureml/metrics/common/scoring.py
+-rw-rw-rw-  2.0 fat    21561 b- defN 24-Mar-22 10:04 azureml/metrics/common/utilities.py
+-rw-rw-rw-  2.0 fat      183 b- defN 24-Mar-22 10:04 azureml/metrics/common/llm_connector/__init__.py
+-rw-rw-rw-  2.0 fat    15185 b- defN 24-Mar-22 10:04 azureml/metrics/common/llm_connector/_llm.py
+-rw-rw-rw-  2.0 fat     7112 b- defN 24-Mar-22 10:04 azureml/metrics/common/llm_connector/_llm_url_connector.py
+-rw-rw-rw-  2.0 fat    16969 b- defN 24-Mar-22 10:04 azureml/metrics/common/llm_connector/_openai_connector.py
+-rw-rw-rw-  2.0 fat     2588 b- defN 24-Mar-22 10:04 azureml/metrics/common/llm_connector/async_utils.py
+-rw-rw-rw-  2.0 fat     7708 b- defN 24-Mar-22 10:04 azureml/metrics/common/llm_connector/auth_manager.py
+-rw-rw-rw-  2.0 fat     1847 b- defN 24-Mar-22 10:04 azureml/metrics/common/llm_connector/http_connection_utils.py
+-rw-rw-rw-  2.0 fat    13104 b- defN 24-Mar-22 10:04 azureml/metrics/common/llm_connector/llm_utils.py
+-rw-rw-rw-  2.0 fat      183 b- defN 24-Mar-22 10:04 azureml/metrics/common/templates/__init__.py
+-rw-rw-rw-  2.0 fat     3430 b- defN 24-Mar-22 10:04 azureml/metrics/common/templates/prompt_crafter.py
+-rw-rw-rw-  2.0 fat     8786 b- defN 24-Mar-22 10:04 azureml/metrics/common/templates/prompt_template.py
+-rw-rw-rw-  2.0 fat      183 b- defN 24-Mar-22 10:04 azureml/metrics/rai/__init__.py
+-rw-rw-rw-  2.0 fat     1876 b- defN 24-Mar-22 10:04 azureml/metrics/rai/_utils.py
+-rw-rw-rw-  2.0 fat      183 b- defN 24-Mar-22 10:04 azureml/metrics/rai/groundedness/__init__.py
+-rw-rw-rw-  2.0 fat    13066 b- defN 24-Mar-22 10:04 azureml/metrics/rai/groundedness/_groundedness_base.py
+-rw-rw-rw-  2.0 fat     5747 b- defN 24-Mar-22 10:04 azureml/metrics/rai/groundedness/_groundedness_conversation.py
+-rw-rw-rw-  2.0 fat     2433 b- defN 24-Mar-22 10:04 azureml/metrics/rai/groundedness/_groundedness_qa.py
+-rw-rw-rw-  2.0 fat     1939 b- defN 24-Mar-22 10:04 azureml/metrics/rai/groundedness/_llm_groundedness_qa.py
+-rw-rw-rw-  2.0 fat      243 b- defN 24-Mar-22 10:04 azureml/metrics/tabular/__init__.py
+-rw-rw-rw-  2.0 fat      223 b- defN 24-Mar-22 10:04 azureml/metrics/tabular/forecasting/__init__.py
+-rw-rw-rw-  2.0 fat    32579 b- defN 24-Mar-22 10:04 azureml/metrics/tabular/forecasting/_forecasting.py
+-rw-rw-rw-  2.0 fat    16855 b- defN 24-Mar-22 10:04 azureml/metrics/tabular/forecasting/azureml_forecasting_metrics.py
+-rw-rw-rw-  2.0 fat      222 b- defN 24-Mar-22 10:04 azureml/metrics/tabular/regression/__init__.py
+-rw-rw-rw-  2.0 fat     7831 b- defN 24-Mar-22 10:04 azureml/metrics/tabular/regression/_dataset_binning.py
+-rw-rw-rw-  2.0 fat    26691 b- defN 24-Mar-22 10:04 azureml/metrics/tabular/regression/_regression.py
+-rw-rw-rw-  2.0 fat     9218 b- defN 24-Mar-22 10:04 azureml/metrics/tabular/regression/azureml_regression_metrics.py
+-rw-rw-rw-  2.0 fat      240 b- defN 24-Mar-22 10:04 azureml/metrics/text/__init__.py
+-rw-rw-rw-  2.0 fat      235 b- defN 24-Mar-22 10:04 azureml/metrics/text/chat_completion/__init__.py
+-rw-rw-rw-  2.0 fat     6708 b- defN 24-Mar-22 10:04 azureml/metrics/text/chat_completion/azureml_chat_completion_metrics.py
+-rw-rw-rw-  2.0 fat      245 b- defN 24-Mar-22 10:04 azureml/metrics/text/classification/__init__.py
+-rw-rw-rw-  2.0 fat    50609 b- defN 24-Mar-22 10:04 azureml/metrics/text/classification/_classification.py
+-rw-rw-rw-  2.0 fat    15825 b- defN 24-Mar-22 10:04 azureml/metrics/text/classification/azureml_classification_metrics.py
+-rw-rw-rw-  2.0 fat      235 b- defN 24-Mar-22 10:04 azureml/metrics/text/code_generation/__init__.py
+-rw-rw-rw-  2.0 fat     3926 b- defN 24-Mar-22 10:04 azureml/metrics/text/code_generation/_code_generation.py
+-rw-rw-rw-  2.0 fat    11176 b- defN 24-Mar-22 10:04 azureml/metrics/text/code_generation/azureml_code_generation.py
+-rw-rw-rw-  2.0 fat      221 b- defN 24-Mar-22 10:04 azureml/metrics/text/fill_mask/__init__.py
+-rw-rw-rw-  2.0 fat     3263 b- defN 24-Mar-22 10:04 azureml/metrics/text/fill_mask/_seq2seq_fill_mask.py
+-rw-rw-rw-  2.0 fat     8354 b- defN 24-Mar-22 10:04 azureml/metrics/text/fill_mask/azureml_fill_mask_metrics.py
+-rw-rw-rw-  2.0 fat      236 b- defN 24-Mar-22 10:04 azureml/metrics/text/ner/__init__.py
+-rw-rw-rw-  2.0 fat     6293 b- defN 24-Mar-22 10:04 azureml/metrics/text/ner/_token_classification.py
+-rw-rw-rw-  2.0 fat     7723 b- defN 24-Mar-22 10:04 azureml/metrics/text/ner/azureml_text_ner_metrics.py
+-rw-rw-rw-  2.0 fat      230 b- defN 24-Mar-22 10:04 azureml/metrics/text/qa/__init__.py
+-rw-rw-rw-  2.0 fat    27254 b- defN 24-Mar-22 10:04 azureml/metrics/text/qa/_seq2seq_qa.py
+-rw-rw-rw-  2.0 fat     2836 b- defN 24-Mar-22 10:04 azureml/metrics/text/qa/_seq2seq_qa_multiple_ground_truth.py
+-rw-rw-rw-  2.0 fat     5855 b- defN 24-Mar-22 10:04 azureml/metrics/text/qa/_similarity_utils.py
+-rw-rw-rw-  2.0 fat    20658 b- defN 24-Mar-22 10:04 azureml/metrics/text/qa/azureml_qa_metrics.py
+-rw-rw-rw-  2.0 fat      247 b- defN 24-Mar-22 10:04 azureml/metrics/text/qa/prompt_templates/__init__.py
+-rw-rw-rw-  2.0 fat     1871 b- defN 24-Mar-22 10:04 azureml/metrics/text/qa/prompt_templates/coherence_score_qa.jinja2
+-rw-rw-rw-  2.0 fat     1730 b- defN 24-Mar-22 10:04 azureml/metrics/text/qa/prompt_templates/fluency_score_qa.jinja2
+-rw-rw-rw-  2.0 fat     2928 b- defN 24-Mar-22 10:04 azureml/metrics/text/qa/prompt_templates/groundedness_score_qa.jinja2
+-rw-rw-rw-  2.0 fat     2860 b- defN 24-Mar-22 10:04 azureml/metrics/text/qa/prompt_templates/relevance_score_qa.jinja2
+-rw-rw-rw-  2.0 fat     3891 b- defN 24-Mar-22 10:04 azureml/metrics/text/qa/prompt_templates/similarity_score_qa.jinja2
+-rw-rw-rw-  2.0 fat      240 b- defN 24-Mar-22 10:04 azureml/metrics/text/qa/prompt_templates/system_prompt_qa.jinja2
+-rw-rw-rw-  2.0 fat      233 b- defN 24-Mar-22 10:04 azureml/metrics/text/rag_evaluation/__init__.py
+-rw-rw-rw-  2.0 fat    40670 b- defN 24-Mar-22 10:04 azureml/metrics/text/rag_evaluation/_rag_evaluation.py
+-rw-rw-rw-  2.0 fat     3016 b- defN 24-Mar-22 10:04 azureml/metrics/text/rag_evaluation/_rag_utils.py
+-rw-rw-rw-  2.0 fat     6396 b- defN 24-Mar-22 10:04 azureml/metrics/text/rag_evaluation/azureml_rag_evaluation_metrics.py
+-rw-rw-rw-  2.0 fat      183 b- defN 24-Mar-22 10:04 azureml/metrics/text/rag_evaluation/prompt_templates/__init__.py
+-rw-rw-rw-  2.0 fat     2882 b- defN 24-Mar-22 10:04 azureml/metrics/text/rag_evaluation/prompt_templates/generation_prompt_sbs.toml
+-rw-rw-rw-  2.0 fat     2533 b- defN 24-Mar-22 10:04 azureml/metrics/text/rag_evaluation/prompt_templates/generation_prompt_with_gt.toml
+-rw-rw-rw-  2.0 fat     2607 b- defN 24-Mar-22 10:04 azureml/metrics/text/rag_evaluation/prompt_templates/generation_prompt_without_gt.toml
+-rw-rw-rw-  2.0 fat     2539 b- defN 24-Mar-22 10:04 azureml/metrics/text/rag_evaluation/prompt_templates/grounding_prompt.toml
+-rw-rw-rw-  2.0 fat     1305 b- defN 24-Mar-22 10:04 azureml/metrics/text/rag_evaluation/prompt_templates/retrieval_prompt.toml
+-rw-rw-rw-  2.0 fat      225 b- defN 24-Mar-22 10:04 azureml/metrics/text/summarization/__init__.py
+-rw-rw-rw-  2.0 fat     3058 b- defN 24-Mar-22 10:04 azureml/metrics/text/summarization/_seq2seq_summarization.py
+-rw-rw-rw-  2.0 fat     7726 b- defN 24-Mar-22 10:04 azureml/metrics/text/summarization/azureml_summarization_metrics.py
+-rw-rw-rw-  2.0 fat      227 b- defN 24-Mar-22 10:04 azureml/metrics/text/text_generation/__init__.py
+-rw-rw-rw-  2.0 fat     9756 b- defN 24-Mar-22 10:04 azureml/metrics/text/text_generation/azureml_text_generation_metrics.py
+-rw-rw-rw-  2.0 fat      223 b- defN 24-Mar-22 10:04 azureml/metrics/text/translation/__init__.py
+-rw-rw-rw-  2.0 fat     2422 b- defN 24-Mar-22 10:04 azureml/metrics/text/translation/_seq2seq_translation.py
+-rw-rw-rw-  2.0 fat     7091 b- defN 24-Mar-22 10:04 azureml/metrics/text/translation/azureml_translation_metrics.py
+-rw-rw-rw-  2.0 fat      225 b- defN 24-Mar-22 10:04 azureml/metrics/vision/__init__.py
+-rw-rw-rw-  2.0 fat      239 b- defN 24-Mar-22 10:04 azureml/metrics/vision/od_is_eval/__init__.py
+-rw-rw-rw-  2.0 fat    13530 b- defN 24-Mar-22 10:04 azureml/metrics/vision/od_is_eval/azureml_od_is_metrics.py
+-rw-rw-rw-  2.0 fat    21734 b- defN 24-Mar-22 10:04 azureml/metrics/vision/od_is_eval/incremental_voc_evaluator.py
+-rw-rw-rw-  2.0 fat    17574 b- defN 24-Mar-22 10:04 azureml/metrics/vision/od_is_eval/metric_computation_utils.py
+-rw-rw-rw-  2.0 fat      244 b- defN 24-Mar-22 10:04 azureml/metrics/vision/track_eval/__init__.py
+-rw-rw-rw-  2.0 fat    14913 b- defN 24-Mar-22 10:04 azureml/metrics/vision/track_eval/azureml_mot_metrics.py
+-rw-rw-rw-  2.0 fat      859 b- defN 24-Mar-22 10:09 azureml_metrics-47.0.0.dist-info/LICENSE.txt
+-rw-rw-rw-  2.0 fat    15648 b- defN 24-Mar-22 10:09 azureml_metrics-47.0.0.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       92 b- defN 24-Mar-22 10:09 azureml_metrics-47.0.0.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat        8 b- defN 24-Mar-22 10:09 azureml_metrics-47.0.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 fat    11243 b- defN 24-Mar-22 10:09 azureml_metrics-47.0.0.dist-info/RECORD
+106 files, 1330890 bytes uncompressed, 243974 bytes compressed:  81.7%
```

## zipnote {}

```diff
@@ -3,137 +3,317 @@
 
 Filename: azureml/metrics/NOTICE
 Comment: 
 
 Filename: azureml/metrics/__init__.py
 Comment: 
 
-Filename: azureml/metrics/_classification.py
+Filename: azureml/metrics/_score.py
 Comment: 
 
-Filename: azureml/metrics/_dataset_binning.py
+Filename: azureml/metrics/_scoring_utilities.py
 Comment: 
 
-Filename: azureml/metrics/_forecasting.py
+Filename: azureml/metrics/_version.py
 Comment: 
 
-Filename: azureml/metrics/_metric_base.py
+Filename: azureml/metrics/constants.py
 Comment: 
 
-Filename: azureml/metrics/_regression.py
+Filename: azureml/metrics/common/__init__.py
 Comment: 
 
-Filename: azureml/metrics/_score.py
+Filename: azureml/metrics/common/_logging_utils.py
 Comment: 
 
-Filename: azureml/metrics/_scoring.py
+Filename: azureml/metrics/common/_metric_base.py
 Comment: 
 
-Filename: azureml/metrics/_scoring_confidence.py
+Filename: azureml/metrics/common/_run_utils.py
 Comment: 
 
-Filename: azureml/metrics/_scoring_utilities.py
+Filename: azureml/metrics/common/_score_utils.py
 Comment: 
 
-Filename: azureml/metrics/_seq2seq_fill_mask.py
+Filename: azureml/metrics/common/_scoring.py
 Comment: 
 
-Filename: azureml/metrics/_seq2seq_qa.py
+Filename: azureml/metrics/common/_scoring_confidence.py
 Comment: 
 
-Filename: azureml/metrics/_seq2seq_summarization.py
+Filename: azureml/metrics/common/_validation.py
 Comment: 
 
-Filename: azureml/metrics/_seq2seq_translation.py
+Filename: azureml/metrics/common/azureml_custom_prompt_metric.py
 Comment: 
 
-Filename: azureml/metrics/_token_classification.py
+Filename: azureml/metrics/common/azureml_metrics.py
 Comment: 
 
-Filename: azureml/metrics/_validation.py
+Filename: azureml/metrics/common/contract.py
 Comment: 
 
-Filename: azureml/metrics/_version.py
+Filename: azureml/metrics/common/exceptions.py
 Comment: 
 
-Filename: azureml/metrics/azureml_classification_metrics.py
+Filename: azureml/metrics/common/import_utilities.py
 Comment: 
 
-Filename: azureml/metrics/azureml_fill_mask_metrics.py
+Filename: azureml/metrics/common/reference_codes.py
 Comment: 
 
-Filename: azureml/metrics/azureml_forecasting_metrics.py
+Filename: azureml/metrics/common/scoring.py
 Comment: 
 
-Filename: azureml/metrics/azureml_metrics.py
+Filename: azureml/metrics/common/utilities.py
 Comment: 
 
-Filename: azureml/metrics/azureml_od_is_metrics.py
+Filename: azureml/metrics/common/llm_connector/__init__.py
 Comment: 
 
-Filename: azureml/metrics/azureml_qa_metrics.py
+Filename: azureml/metrics/common/llm_connector/_llm.py
 Comment: 
 
-Filename: azureml/metrics/azureml_regression_metrics.py
+Filename: azureml/metrics/common/llm_connector/_llm_url_connector.py
 Comment: 
 
-Filename: azureml/metrics/azureml_summarization_metrics.py
+Filename: azureml/metrics/common/llm_connector/_openai_connector.py
 Comment: 
 
-Filename: azureml/metrics/azureml_text_classification_metrics.py
+Filename: azureml/metrics/common/llm_connector/async_utils.py
 Comment: 
 
-Filename: azureml/metrics/azureml_text_generation_metrics.py
+Filename: azureml/metrics/common/llm_connector/auth_manager.py
 Comment: 
 
-Filename: azureml/metrics/azureml_text_ner_metrics.py
+Filename: azureml/metrics/common/llm_connector/http_connection_utils.py
 Comment: 
 
-Filename: azureml/metrics/azureml_translation_metrics.py
+Filename: azureml/metrics/common/llm_connector/llm_utils.py
 Comment: 
 
-Filename: azureml/metrics/bleu.py
+Filename: azureml/metrics/common/templates/__init__.py
 Comment: 
 
-Filename: azureml/metrics/constants.py
+Filename: azureml/metrics/common/templates/prompt_crafter.py
+Comment: 
+
+Filename: azureml/metrics/common/templates/prompt_template.py
+Comment: 
+
+Filename: azureml/metrics/rai/__init__.py
+Comment: 
+
+Filename: azureml/metrics/rai/_utils.py
+Comment: 
+
+Filename: azureml/metrics/rai/groundedness/__init__.py
+Comment: 
+
+Filename: azureml/metrics/rai/groundedness/_groundedness_base.py
+Comment: 
+
+Filename: azureml/metrics/rai/groundedness/_groundedness_conversation.py
+Comment: 
+
+Filename: azureml/metrics/rai/groundedness/_groundedness_qa.py
+Comment: 
+
+Filename: azureml/metrics/rai/groundedness/_llm_groundedness_qa.py
+Comment: 
+
+Filename: azureml/metrics/tabular/__init__.py
+Comment: 
+
+Filename: azureml/metrics/tabular/forecasting/__init__.py
+Comment: 
+
+Filename: azureml/metrics/tabular/forecasting/_forecasting.py
+Comment: 
+
+Filename: azureml/metrics/tabular/forecasting/azureml_forecasting_metrics.py
+Comment: 
+
+Filename: azureml/metrics/tabular/regression/__init__.py
+Comment: 
+
+Filename: azureml/metrics/tabular/regression/_dataset_binning.py
+Comment: 
+
+Filename: azureml/metrics/tabular/regression/_regression.py
+Comment: 
+
+Filename: azureml/metrics/tabular/regression/azureml_regression_metrics.py
+Comment: 
+
+Filename: azureml/metrics/text/__init__.py
+Comment: 
+
+Filename: azureml/metrics/text/chat_completion/__init__.py
+Comment: 
+
+Filename: azureml/metrics/text/chat_completion/azureml_chat_completion_metrics.py
+Comment: 
+
+Filename: azureml/metrics/text/classification/__init__.py
+Comment: 
+
+Filename: azureml/metrics/text/classification/_classification.py
+Comment: 
+
+Filename: azureml/metrics/text/classification/azureml_classification_metrics.py
+Comment: 
+
+Filename: azureml/metrics/text/code_generation/__init__.py
+Comment: 
+
+Filename: azureml/metrics/text/code_generation/_code_generation.py
+Comment: 
+
+Filename: azureml/metrics/text/code_generation/azureml_code_generation.py
+Comment: 
+
+Filename: azureml/metrics/text/fill_mask/__init__.py
+Comment: 
+
+Filename: azureml/metrics/text/fill_mask/_seq2seq_fill_mask.py
+Comment: 
+
+Filename: azureml/metrics/text/fill_mask/azureml_fill_mask_metrics.py
+Comment: 
+
+Filename: azureml/metrics/text/ner/__init__.py
+Comment: 
+
+Filename: azureml/metrics/text/ner/_token_classification.py
+Comment: 
+
+Filename: azureml/metrics/text/ner/azureml_text_ner_metrics.py
+Comment: 
+
+Filename: azureml/metrics/text/qa/__init__.py
+Comment: 
+
+Filename: azureml/metrics/text/qa/_seq2seq_qa.py
+Comment: 
+
+Filename: azureml/metrics/text/qa/_seq2seq_qa_multiple_ground_truth.py
+Comment: 
+
+Filename: azureml/metrics/text/qa/_similarity_utils.py
+Comment: 
+
+Filename: azureml/metrics/text/qa/azureml_qa_metrics.py
+Comment: 
+
+Filename: azureml/metrics/text/qa/prompt_templates/__init__.py
+Comment: 
+
+Filename: azureml/metrics/text/qa/prompt_templates/coherence_score_qa.jinja2
+Comment: 
+
+Filename: azureml/metrics/text/qa/prompt_templates/fluency_score_qa.jinja2
+Comment: 
+
+Filename: azureml/metrics/text/qa/prompt_templates/groundedness_score_qa.jinja2
+Comment: 
+
+Filename: azureml/metrics/text/qa/prompt_templates/relevance_score_qa.jinja2
+Comment: 
+
+Filename: azureml/metrics/text/qa/prompt_templates/similarity_score_qa.jinja2
+Comment: 
+
+Filename: azureml/metrics/text/qa/prompt_templates/system_prompt_qa.jinja2
+Comment: 
+
+Filename: azureml/metrics/text/rag_evaluation/__init__.py
+Comment: 
+
+Filename: azureml/metrics/text/rag_evaluation/_rag_evaluation.py
+Comment: 
+
+Filename: azureml/metrics/text/rag_evaluation/_rag_utils.py
+Comment: 
+
+Filename: azureml/metrics/text/rag_evaluation/azureml_rag_evaluation_metrics.py
+Comment: 
+
+Filename: azureml/metrics/text/rag_evaluation/prompt_templates/__init__.py
+Comment: 
+
+Filename: azureml/metrics/text/rag_evaluation/prompt_templates/generation_prompt_sbs.toml
+Comment: 
+
+Filename: azureml/metrics/text/rag_evaluation/prompt_templates/generation_prompt_with_gt.toml
+Comment: 
+
+Filename: azureml/metrics/text/rag_evaluation/prompt_templates/generation_prompt_without_gt.toml
+Comment: 
+
+Filename: azureml/metrics/text/rag_evaluation/prompt_templates/grounding_prompt.toml
+Comment: 
+
+Filename: azureml/metrics/text/rag_evaluation/prompt_templates/retrieval_prompt.toml
+Comment: 
+
+Filename: azureml/metrics/text/summarization/__init__.py
+Comment: 
+
+Filename: azureml/metrics/text/summarization/_seq2seq_summarization.py
+Comment: 
+
+Filename: azureml/metrics/text/summarization/azureml_summarization_metrics.py
+Comment: 
+
+Filename: azureml/metrics/text/text_generation/__init__.py
+Comment: 
+
+Filename: azureml/metrics/text/text_generation/azureml_text_generation_metrics.py
+Comment: 
+
+Filename: azureml/metrics/text/translation/__init__.py
+Comment: 
+
+Filename: azureml/metrics/text/translation/_seq2seq_translation.py
 Comment: 
 
-Filename: azureml/metrics/contract.py
+Filename: azureml/metrics/text/translation/azureml_translation_metrics.py
 Comment: 
 
-Filename: azureml/metrics/exceptions.py
+Filename: azureml/metrics/vision/__init__.py
 Comment: 
 
-Filename: azureml/metrics/reference_codes.py
+Filename: azureml/metrics/vision/od_is_eval/__init__.py
 Comment: 
 
-Filename: azureml/metrics/scoring.py
+Filename: azureml/metrics/vision/od_is_eval/azureml_od_is_metrics.py
 Comment: 
 
-Filename: azureml/metrics/utilities.py
+Filename: azureml/metrics/vision/od_is_eval/incremental_voc_evaluator.py
 Comment: 
 
-Filename: azureml/metrics/od_is_eval/__init__.py
+Filename: azureml/metrics/vision/od_is_eval/metric_computation_utils.py
 Comment: 
 
-Filename: azureml/metrics/od_is_eval/incremental_voc_evaluator.py
+Filename: azureml/metrics/vision/track_eval/__init__.py
 Comment: 
 
-Filename: azureml/metrics/od_is_eval/metric_computation_utils.py
+Filename: azureml/metrics/vision/track_eval/azureml_mot_metrics.py
 Comment: 
 
-Filename: azureml_metrics-0.0.9.dist-info/LICENSE.txt
+Filename: azureml_metrics-47.0.0.dist-info/LICENSE.txt
 Comment: 
 
-Filename: azureml_metrics-0.0.9.dist-info/METADATA
+Filename: azureml_metrics-47.0.0.dist-info/METADATA
 Comment: 
 
-Filename: azureml_metrics-0.0.9.dist-info/WHEEL
+Filename: azureml_metrics-47.0.0.dist-info/WHEEL
 Comment: 
 
-Filename: azureml_metrics-0.0.9.dist-info/top_level.txt
+Filename: azureml_metrics-47.0.0.dist-info/top_level.txt
 Comment: 
 
-Filename: azureml_metrics-0.0.9.dist-info/RECORD
+Filename: azureml_metrics-47.0.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## azureml/metrics/NOTICE

```diff
@@ -13,65 +13,65 @@
 USA
 
 Notwithstanding any other terms, you may reverse engineer this software to the extent
 required to debug changes to any libraries licensed under the GNU Lesser General Public License.
 
 ---------------------------------------------------------
 
-aiohttp 3.8.4 - Apache-2.0
+aiosignal 1.3.1 - Apache-2.0
 
 
-Copyright Fedor Indutny, 2018
-copyright f project contributors
+copyright 2013-2019, aiosignal contributors
+Copyright 2013-2019 Nikolay Kim and Andrew Svetlov
 
 Apache License
 
 Version 2.0, January 2004
 
 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 
    1. Definitions.
 
-      
+
 
       "License" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document.
 
-      
+
 
       "Licensor" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License.
 
-      
+
 
       "Legal Entity" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, "control" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity.
 
-      
+
 
       "You" (or "Your") shall mean an individual or Legal Entity exercising permissions granted by this License.
 
-      
+
 
       "Source" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files.
 
-      
+
 
       "Object" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types.
 
-      
+
 
       "Work" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below).
 
-      
+
 
       "Derivative Works" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof.
 
-      
+
 
       "Contribution" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, "submitted" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as "Not a Contribution."
 
-      
+
 
       "Contributor" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work.
 
    2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form.
 
    3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed.
 
@@ -121,65 +121,64 @@
 
 limitations under the License.
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-aiosignal 1.3.1 - Apache-2.0
+asynctest 0.13.0 - Apache-2.0
 
 
-copyright 2013-2019, aiosignal contributors
-Copyright 2013-2019 Nikolay Kim and Andrew Svetlov
+Copyright 2015 Martin Richard
 
 Apache License
 
 Version 2.0, January 2004
 
 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 
    1. Definitions.
 
-      
+
 
       "License" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document.
 
-      
+
 
       "Licensor" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License.
 
-      
+
 
       "Legal Entity" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, "control" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity.
 
-      
+
 
       "You" (or "Your") shall mean an individual or Legal Entity exercising permissions granted by this License.
 
-      
+
 
       "Source" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files.
 
-      
+
 
       "Object" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types.
 
-      
+
 
       "Work" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below).
 
-      
+
 
       "Derivative Works" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof.
 
-      
+
 
       "Contribution" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, "submitted" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as "Not a Contribution."
 
-      
+
 
       "Contributor" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work.
 
    2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form.
 
    3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed.
 
@@ -229,64 +228,68 @@
 
 limitations under the License.
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-asynctest 0.13.0 - Apache-2.0
+evaluate 0.4.0 - Apache-2.0
 
 
-Copyright 2015 Martin Richard
+Copyright 2020 Optuna, Hugging Face
+Copyright 2020 The HuggingFace Datasets
+Copyright 2020 The HuggingFace Evaluate
+Copyright 2022 The HuggingFace Datasets
+Copyright 2022 The HuggingFace Evaluate
 
 Apache License
 
 Version 2.0, January 2004
 
 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 
    1. Definitions.
 
-      
+
 
       "License" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document.
 
-      
+
 
       "Licensor" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License.
 
-      
+
 
       "Legal Entity" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, "control" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity.
 
-      
+
 
       "You" (or "Your") shall mean an individual or Legal Entity exercising permissions granted by this License.
 
-      
+
 
       "Source" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files.
 
-      
+
 
       "Object" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types.
 
-      
+
 
       "Work" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below).
 
-      
+
 
       "Derivative Works" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof.
 
-      
+
 
       "Contribution" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, "submitted" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as "Not a Contribution."
 
-      
+
 
       "Contributor" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work.
 
    2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form.
 
    3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed.
 
@@ -336,64 +339,65 @@
 
 limitations under the License.
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-async-timeout 4.0.2 - Apache-2.0
+frozenlist 1.4.0 - Apache-2.0
 
 
-Copyright 2016-2020 aio-libs collaboration
+copyright 2013-2019, frozenlist contributors
+Copyright 2013-2019 Nikolay Kim and Andrew Svetlov
 
 Apache License
 
 Version 2.0, January 2004
 
 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 
    1. Definitions.
 
-      
+
 
       "License" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document.
 
-      
+
 
       "Licensor" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License.
 
-      
+
 
       "Legal Entity" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, "control" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity.
 
-      
+
 
       "You" (or "Your") shall mean an individual or Legal Entity exercising permissions granted by this License.
 
-      
+
 
       "Source" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files.
 
-      
+
 
       "Object" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types.
 
-      
+
 
       "Work" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below).
 
-      
+
 
       "Derivative Works" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof.
 
-      
+
 
       "Contribution" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, "submitted" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as "Not a Contribution."
 
-      
+
 
       "Contributor" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work.
 
    2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form.
 
    3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed.
 
@@ -443,22 +447,17 @@
 
 limitations under the License.
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-evaluate 0.4.0 - Apache-2.0
+importlib-metadata 6.8.0 - Apache-2.0
 
 
-Copyright 2020 Optuna, Hugging Face
-Copyright 2020 The HuggingFace Datasets
-Copyright 2020 The HuggingFace Evaluate
-Copyright 2022 The HuggingFace Datasets
-Copyright 2022 The HuggingFace Evaluate
 
 Apache License
 
 Version 2.0, January 2004
 
 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 
@@ -554,19 +553,39 @@
 
 limitations under the License.
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-frozenlist 1.3.3 - Apache-2.0
+mmcv-full 1.7.1 - Apache-2.0
 
 
-copyright 2013-2019, frozenlist contributors
-Copyright 2013-2019 Nikolay Kim and Andrew Svetlov
+Copyright 2019 Yan Yan
+Copyright (c) OpenMMLab
+Copyright (c) Open-MMLab
+Copyright (c) 2018 Microsoft
+Copyright (c) 2020 SenseTime
+Copyright (c) 2021 Cambricon
+Copyright (c) 2022 Cambricon
+Copyright (c) 2019, SenseTime
+Copyright (c) 2022 Apple Inc.
+Copyright 2018-2020 Open-MMLab
+Copyright (c) 2022 by Cambricon
+Copyright (c) Microsoft Corporation
+Copyright (c) 2018 Vladislav Sovrasov
+Copyright Louis Delacroix 2010 - 2014
+Copyright (c) 2019, NVIDIA Corporation
+Copyright (c) 2021, NVIDIA Corporation
+Copyright Huawei Technologies Co., Ltd.
+Copyright (c) 2019-2022 by Cambricon, Inc.
+Copyright (c) 2022 Huawei Technologies Co., Ltd
+Copyright (c) Facebook, Inc. and its affiliates
+Copyright (c) 2014-2017, the respective contributors
+Copyright (c) 2014-2017 The Regents of the University of California (Regents)
 
 Apache License
 
 Version 2.0, January 2004
 
 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 
@@ -662,17 +681,20 @@
 
 limitations under the License.
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-importlib-resources 5.12.0 - Apache-2.0
+mmdet 2.28.2 - Apache-2.0
 
 
+Copyright (c) OpenMMLab
+Copyright (c) 2018, Alexander Kirillov
+Copyright (c) 2019 Western Digital Corporation
 
 Apache License
 
 Version 2.0, January 2004
 
 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 
@@ -1002,125 +1024,14 @@
 
 limitations under the License.
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-pyarrow 11.0.0 - Apache-2.0
-
-
-Copyright 2011 Kitware, Inc.
-Copyright 2012 Cloudera Inc.
-Copyright 2001-2009 Kitware, Inc.
-Copyright 2012 Continuum Analytics, Inc.
-Copyright 2012-2014 Continuum Analytics, Inc.
-
-Apache License
-
-Version 2.0, January 2004
-
-http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
-
-   1. Definitions.
-
-
-
-      "License" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document.
-
-
-
-      "Licensor" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License.
-
-
-
-      "Legal Entity" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, "control" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity.
-
-
-
-      "You" (or "Your") shall mean an individual or Legal Entity exercising permissions granted by this License.
-
-
-
-      "Source" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files.
-
-
-
-      "Object" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types.
-
-
-
-      "Work" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below).
-
-
-
-      "Derivative Works" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof.
-
-
-
-      "Contribution" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, "submitted" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as "Not a Contribution."
-
-
-
-      "Contributor" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work.
-
-   2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form.
-
-   3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed.
-
-   4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions:
-
-      (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and
-
-      (b) You must cause any modified files to carry prominent notices stating that You changed the files; and
-
-      (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and
-
-      (d) If the Work includes a "NOTICE" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License.
-
-      You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License.
-
-   5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions.
-
-   6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file.
-
-   7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License.
-
-   8. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages.
-
-   9. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS
-
-APPENDIX: How to apply the Apache License to your work.
-
-To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets "[]" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same "printed page" as the copyright notice for easier identification within third-party archives.
-
-Copyright [yyyy] [name of copyright owner]
-
-Licensed under the Apache License, Version 2.0 (the "License");
-
-you may not use this file except in compliance with the License.
-
-You may obtain a copy of the License at
-
-http://www.apache.org/licenses/LICENSE-2.0
-
-Unless required by applicable law or agreed to in writing, software
-
-distributed under the License is distributed on an "AS IS" BASIS,
-
-WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
-
-See the License for the specific language governing permissions and
-
-limitations under the License.
-
----------------------------------------------------------
-
----------------------------------------------------------
-
 python-dateutil 2.8.2 - Apache-2.0
 
 
 copyright 2019, dateutil
 Copyright 2017- dateutil contributors
 Copyright (c) 2015- - dateutil contributors
 Copyright 2017- Paul Ganssle <paul@ganssle.io>
@@ -1227,15 +1138,15 @@
 
 limitations under the License.
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-requests 2.28.2 - Apache-2.0
+requests 2.31.0 - Apache-2.0
 
 
 Copyright Kenneth Reitz
 Copyright 2019 Kenneth Reitz
 copyright (c) 2012 by Kenneth Reitz
 copyright (c) 2017 by Kenneth Reitz
 
@@ -1552,17 +1463,25 @@
 
 limitations under the License.
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-tokenizers 0.13.2 - Apache-2.0
+tenacity 8.2.2 - Apache-2.0
 
 
+Copyright 2013 Ray
+Copyright 2013-2014 Ray
+Copyright 2017 Elisey Zanko
+Copyright 2016 Joshua Harlow
+Copyright 2016 Julien Danjou
+Copyright 2016 Etienne Bersac
+Copyright 2016-2018 Julien Danjou
+Copyright 2016-2021 Julien Danjou
 
 Apache License
 
 Version 2.0, January 2004
 
 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 
@@ -1658,231 +1577,17 @@
 
 limitations under the License.
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-transformers 4.25.1 - Apache-2.0
+tokenizers 0.13.3 - Apache-2.0
 
 
-Copyright 2022
-Copyright 2018 T5
-Copyright 2020 T5
-Copyright 2021 T5
-Copyright 2022 LongT5
-Copyright 2022 Salesforce
-Copyright 2020 Hugging Face
-Copyright 2020, Hugging Face
-Copyright (c) 2020 tanreinama
-Copyright 2022 Meta Platforms
-Copyright 2018 Mesh TensorFlow
-Copyright 2018 The OpenAI Team
-Copyright 2020 Mesh TensorFlow
-Copyright 2021 Mesh TensorFlow
-Copyright 2021 The Marian Team
-Copyright 2021 The OpenAI Team
-Copyright 2022 The OpenAI Team
-Copyright 2022 the Big Science
-Copyright The HuggingFace team
-Copyright 2018 The Open AI Team
-Copyright 2019 The Open AI Team
-Copyright 2021 The OFA-Sys Team
-Copyright 2021 The Open AI Team
-Copyright 2022 The OFA-Sys Team
-Copyright 2022 The Open AI Team
-Copyright 2022 SwitchTransformers
-Copyright 2022 Google LLC., LongT5
-Copyright (c) HuggingFace Inc. team
-Copyright 2018 The Google Flax Team
-Copyright 2020 Optuna, Hugging Face
-Copyright 2020 The HuggingFace Team
-Copyright 2021 The Google Flax Team
-Copyright 2021 The HuggingFace Team
-Copyright 2022 The HuggingFace Team
-Copyright The HuggingFace Inc. team
-Copyright (c) 2001-2020 NLTK Project
-Copyright 2021 AlQuraishi Laboratory
-Copyright 2022 HuggingFace Inc. team
-Copyright 2018, Hao Tan, Mohit Bansal
-Copyright 2018- The Hugging Face team
-Copyright (c) 2018, Alexander Kirillov
-Copyright (c) 2018, NVIDIA CORPORATION.
-Copyright (c) 2020, NVIDIA CORPORATION.
-Copyright (c) 20121, NVIDIA CORPORATION.
-Copyright (c) 2021-, NVIDIA CORPORATION.
-Copyright 2018 The HuggingFace Inc. team
-Copyright 2020 The HuggingFace Inc. team
-Copyright 2021 The HuggingFace Inc. team
-Copyright 2022 The HuggingFace Inc. team
-Copyright 2020, The HuggingFace Inc. team
-Copyright 2018 The Google AI Language Team
-Copyright 2019 The Google AI Language Team
-Copyright 2020 The Google AI Language Team
-Copyright 2022 The Google AI Language Team
-Copyright 2022 The Trajectory Transformers
-Copyright 2022, Google and HuggingFace Inc.
-Copyright (c) 2018-2021, NVIDIA CORPORATION.
-Copyright 2020 The Facebook AI Research Team
-Copyright 2021 DeepMind Technologies Limited
-Copyright 2021 The Facebook AI Research Team
-Copyright 2022 The Facebook AI Research Team
-Copyright 2022 NVIDIA and The HuggingFace Team
-Copyright (c) Facebook, Inc. and its affiliates
-Copyright 2021 NVIDIA The HuggingFace Inc. team
-Copyright 2022 NVIDIA The HuggingFace Inc. team
-Copyright 2020-present the HuggingFace Inc. team
-Copyright 2022 Facebook and The HuggingFace Team
-Copyright Deepmind and The HuggingFace Inc. team
-Copyright 2018 Amazon.com, Inc. or its affiliates
-Copyright 2018 DPR Authors, The Hugging Face Team
-Copyright 2022 Google AI and The HuggingFace Team
-Copyright 2022 Meta and The HuggingFace Inc. team
-Copyright 2022 WeChatAI The HuggingFace Inc. team
-Copyright Google AI and The HuggingFace Inc. team
-Copyright 2010, DPR authors, The Hugging Face Team
-Copyright 2021 Google AI The HuggingFace Inc. team
-Copyright 2022 KAIST and The HuggingFace Inc. team
-Copyright 2018 Salesforce and HuggingFace Inc. team
-Copyright 2020 Google and The HuggingFace Inc. team
-Copyright 2020, The T5 Authors and HuggingFace Inc.
-Copyright 2021 NVIDIA and The HuggingFace Inc. team
-Copyright 2021 The EleutherAI and HuggingFace Teams
-Copyright 2022 EleutherAI The HuggingFace Inc. team
-Copyright 2022 HuggingFace Inc. team and BigScience
-Copyright 2022 The EleutherAI and HuggingFace Teams
-Copyright 2022 UW-Madison The HuggingFace Inc. team
-Copyright 2021, Google and The HuggingFace Inc. team
-Copyright 2022, Google and The HuggingFace Inc. team
-Copyright Studio Ousia and The HuggingFace Inc. team
-Copyright Studio-Ouisa and The HuggingFace Inc. team
-Copyright 2021 Deepmind and The HuggingFace Inc. team
-Copyright 2022 SHI Labs and The HuggingFace Inc. team
-Copyright 2022 WeChatAI and The HuggingFace Inc. team
-Copyright 2020 Microsoft and the HuggingFace Inc. team
-Copyright 2021 Google AI and The HuggingFace Inc. team
-Copyright 2021 Microsoft and The HuggingFace Inc. team
-Copyright 2022 Google AI and The HuggingFace Inc. team
-Copyright 2022 SenseTime and The HuggingFace Inc. team
-Copyright Meta Platforms and The HuggingFace Inc. team
-Copyright 2018 Salesforce and The HuggingFace Inc. team
-Copyright 2018 The T5 authors and HuggingFace Inc. team
-Copyright 2020 Microsoft and the Hugging Face Inc. team
-Copyright 2020, Microsoft and the HuggingFace Inc. team
-Copyright 2021 ASAPP Inc. and The HuggingFace Inc. team
-Copyright 2021 ASAPP Inc. and the HuggingFace Inc. team
-Copyright 2021 The Eleuther AI and The Google Flax Team
-Copyright 2022 Apple Inc. and The HuggingFace Inc. team
-Copyright 2022 EleutherAI and The HuggingFace Inc. team
-Copyright 2022 Sea AI Lab and The HuggingFace Inc. team
-Copyright 2022 The Impira Team and the HuggingFace Team
-Copyright 2022 The OpenAI team and The HuggingFace Team
-Copyright 2022 The Salesforce authors, The Open AI Team
-Copyright 2022 UW-Madison and The HuggingFace Inc. team
-Copyright 2022, The LongT5 Authors and HuggingFace Inc.
-Copyright 2022, UCLA NLP, The Facebook AI Research Team
-Copyright Google Research and The HuggingFace Inc. team
-Copyright 2018 The Microsoft Research Asia LayoutLM Team
-Copyright 2021 Google Research The HuggingFace Inc. team
-Copyright 2021 The Eleuther AI and HuggingFace Inc. team
-Copyright 2022 ABEJA, Inc. and The HuggingFace Inc. team
-Copyright 2022 Facebook AI and The HuggingFace Inc. team
-Copyright 2022 Sea AI Labs and The HuggingFace Inc. team
-Copyright 2010, The Microsoft Research Asia LayoutLM Team
-Copyright 2021 Studio Ousia and the HuggingFace Inc. team
-Copyright 2021, Google Inc. and The HuggingFace Inc. team
-Copyright 2021, The Microsoft Research Asia MarkupLM Team
-Copyright 2021 NVIDIA Corporation and The HuggingFace Team
-Copyright 2022 Microsoft Research and The HuggingFace Team
-Copyright 2022 NAVER AI Labs and The HuggingFace Inc. team
-Copyright Microsoft Research and The HuggingFace Inc. team
-Copyright 2021 Microsoft Research The HuggingFace Inc. team
-Copyright 2021 The EleutherAI and The HuggingFace Inc. team
-Copyright 2021 The Fairseq Authors and The Google Flax Team
-Copyright 2021 VinAI Research and the HuggingFace Inc. team
-Copyright 2022 Meta Platforms and The HuggingFace Inc. team
-Copyright 2022 The Fairseq Authors and The Google Flax Team
-Copyright 2019 The TensorFlow Authors, The Hugging Face Team
-Copyright 2020 Google Research and The HuggingFace Inc. team
-Copyright 2020 The HuggingFace Team and the AllenNLP authors
-Copyright 2021 Google Research and The HuggingFace Inc. team
-Copyright 2021 The Fairseq Authors The HuggingFace Inc. team
-Copyright 2021 The OpenAI Team Authors, The Google Flax Team
-Copyright The HuggingFace Team and The HuggingFace Inc. team
-Copyright 2020 The Trax Authors and The HuggingFace Inc. team
-Copyright 2020, The RAG Authors and The HuggingFace Inc. team
-Copyright 2021 Facebook AI Research The HuggingFace Inc. team
-Copyright 2021 The HuggingFace Team The HuggingFace Inc. team
-Copyright 2022 The HuggingFace Team The HuggingFace Inc. team
-Copyright 2018 Hao Tan, Mohit Bansal, and the HuggingFace team
-Copyright 2021 The Facebook Inc. and The HuggingFace Inc. team
-Copyright 2021 The Facebook, Inc and The HuggingFace Inc. team
-Copyright 2022 The REALM authors and The HuggingFace Inc. team
-Copyright 2018 The HuggingFace Inc. team, Microsoft Corporation
-Copyright 2018 The HuggingFace Inc. team, The Hugging Face Team
-Copyright 2021 Microsoft Research and The HuggingFace Inc. team
-Copyright 2021 Microsoft Research and the HuggingFace Inc. team
-Copyright 2021 The Facebook, Inc. and The HuggingFace Inc. team
-Copyright 2022 Microsoft Research and The HuggingFace Inc. team
-Copyright 2022 The OpenAI Authors and The HuggingFace Inc. team
-Copyright (c) 2020, VinAI Research and the HuggingFace Inc. team
-Copyright 2020 Ecole Polytechnique and the HuggingFace Inc. team
-Copyright 2021 The Fairseq Authors and The HuggingFace Inc. team
-Copyright 2021 The Fairseq Authors and the HuggingFace Inc. team
-Copyright 2021, The Facebook, Inc. and The HuggingFace Inc. team
-Copyright 2021- NVIDIA Corporation and The HuggingFace Inc. team
-Copyright 2022 Meta Platforms Inc. and The HuggingFace Inc. team
-Copyright 2022 Meta Platforms, Inc.and The HuggingFace Inc. team
-Copyright 2022 The Fairseq Authors and The HuggingFace Inc. team
-Copyright 2022 The Fairseq Authors and the HuggingFace Inc. team
-Copyright 2022 The Metaseq Authors and The HuggingFace Inc. team
-Copyright 2019 Facebook AI Research and the HuggingFace Inc. team
-Copyright 2021 Facebook AI Research and The HuggingFace Inc. team
-Copyright 2021 The HuggingFace Team and The HuggingFace Inc. team
-Copyright 2021 The UCLA NLP Authors and The HuggingFace Inc. team
-Copyright 2022 Facebook AI Research and the HuggingFace Inc. team
-Copyright 2022 Meta Platforms, Inc. and The HuggingFace Inc. team
-Copyright 2022 The HuggingFace Team and The HuggingFace Inc. team
-Copyright 2020 The Microsoft Authors and The HuggingFace Inc. team
-Copyright 2020-present Google Brain and Carnegie Mellon University
-Copyright 2021 Google AI, Ross Wightman, The HuggingFace Inc. team
-Copyright 2022 Intel Labs, OpenMMLab and The HuggingFace Inc. team
-Copyright 2019-present, Facebook, Inc and the HuggingFace Inc. team
-Copyright 2018 Google AI, Google Brain and the HuggingFace Inc. team
-Copyright 2020 The SqueezeBert authors and The HuggingFace Inc. team
-Copyright 2021 Google AI, Google Brain and the HuggingFace Inc. team
-Copyright 2022 Microsoft Research Asia and The HuggingFace Inc. team
-Copyright 2022 Microsoft Research Asia and the HuggingFace Inc. team
-Copyright 2018 Google AI, Google Brain and Carnegie Mellon University
-Copyright 2022 Microsoft Research, Inc. and The HuggingFace Inc. team
-Copyright 2018 The Google AI Language Team Authors, Facebook AI Research
-Copyright 2019 Inria, Facebook AI Research and the HuggingFace Inc. team
-Copyright 2019-present CNRS, Facebook Inc. and the HuggingFace Inc. team
-Copyright 2020 The Google AI Language Team Authors, Facebook AI Research
-Copyright 2021 Facebook AI Research (FAIR) and The HuggingFace Inc. team
-Copyright 2022 Facebook AI Research (FAIR) and The HuggingFace Inc. team
-Copyright 2021 Tel AViv University, AllenAI and The HuggingFace Inc. team
-Copyright 2021, The Facebook AI Research Team and The HuggingFace Inc. team
-Copyright 2020 The Allen Institute for AI team and The HuggingFace Inc. team
-Copyright 2022 University of Wisconsin-Madison and The HuggingFace Inc. team
-Copyright 2021 The Google AI Flax Team Authors, and The HuggingFace Inc. team
-Copyright (c) 2020 The Google AI Language Team Authors, The HuggingFace Inc. team
-Copyright 2020 The Google AI Team, Stanford University and The HuggingFace Inc. team
-Copyright 2021 Facebook AI Research (FAIR), Ross Wightman, The HuggingFace Inc. team
-Copyright 2021 Google Research, Google AI, Google Brain and the HuggingFace Inc. team
-Copyright 2021 The Fairseq Authors, Microsoft Research, and The HuggingFace Inc. team
-Copyright 2022, UCLA NLP, The Facebook AI Research Team and The HuggingFace Inc. team
-Copyright 2021 Iz Beltagy, Matthew E. Peters, Arman Cohan and The HuggingFace Inc. team
-Copyright 2022 Multimedia Computing Group, Nanjing University and The HuggingFace Inc. team
-Copyright 2019-present, the HuggingFace Inc. team, The Google AI Language Team and Facebook, Inc.
-Copyright 2018 The Google AI Language Team Authors, The HuggingFace Inc. team, and the Lxmert Authors
-Copyright 2021 The I-BERT Authors Sehoon Kim, Amir Gholami, Zhewei Yao, Michael Mahoney, Kurt Keutzer
-Copyright 2022 BNRist (Tsinghua University), TKLNDST (Nankai University) and The HuggingFace Inc. team
-Copyright 2022 School of EIC, Huazhong University of Science & Technology and The HuggingFace Inc. team
-Copyright 2020 The Google AI Language Team Authors, Allegro.pl, Facebook Inc. and the HuggingFace Inc. team
 
 Apache License
 
 Version 2.0, January 2004
 
 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 
@@ -1978,18 +1683,17 @@
 
 limitations under the License.
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-yarl 1.8.2 - Apache-2.0
+yarl 1.9.2 - Apache-2.0
 
 
-Copyright 2016-2021, Andrew Svetlov and aio-libs team
 copyright 2016-2018, Andrew Svetlov and aio-libs team
 
 Apache License
 
 Version 2.0, January 2004
 
 http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
@@ -2086,32 +1790,18 @@
 
 limitations under the License.
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-packaging 23.0 - Apache-2.0 OR (Apache-2.0 AND BSD-2-Clause AND BSD-3-Clause)
-
+isodate 0.6.1 - BSD-2-Clause
 
-copyright 2014-2019 s
-Copyright (c) Donald Stufft and individual contributors
-
-Apache-2.0 OR (Apache-2.0 AND BSD-2-Clause AND BSD-3-Clause)
-
----------------------------------------------------------
-
----------------------------------------------------------
 
-jinja2 3.1.2 - BSD-2-Clause
-
-
-Copyright 2007 Pallets
-copyright 2007 Pallets
-(c) Copyright 2008 by http://domain.invalid/'>
+Copyright 2009, Gerhard Weis
 
 Copyright (c) <year> <owner> . All rights reserved.
 
 Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
 
    1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
 
@@ -2119,33 +1809,19 @@
 
 THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-kiwisolver 1.4.4 - BSD-2-Clause
+mock 5.1.0 - BSD-2-Clause
 
 
-copyright 2018-2021, Nucleic team
-Copyright (c) 2001. Addison-Wesley
-Copyright (c) 2019-2021 Martin Ankerl
-Copyright (c) 2001 by Andrei Alexandrescu
-Copyright (c) 2013, Nucleic Development Team
-Copyright (c) 2019, Nucleic Development Team
-Copyright (c) 2020, Nucleic Development Team
-Copyright (c) 2021, Nucleic Development Team
-Copyright (c) 2013-2017, Nucleic Development Team
-Copyright (c) 2013-2019, Nucleic Development Team
-Copyright (c) 2013-2021, Nucleic Development Team
-Copyright (c) 2013-2022, Nucleic Development Team
-Copyright (c) 2014-2021, Nucleic Development Team
-Copyright (c) 2014-2022, Nucleic Development Team
-Copyright 2000, 2004, 2005Adobe Systems Incorporated
-Copyright (c) 2019-2021 Martin Ankerl <martin.ankerl@gmail.com>
+Copyright (c) 2007-2012 Michael Foord
+Copyright (c) 2003-2013, Michael Foord & the mock team
 
 Copyright (c) <year> <owner> . All rights reserved.
 
 Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
 
    1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
 
@@ -2153,15 +1829,15 @@
 
 THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-numpy 1.21.6 - BSD-2-Clause
+numpy 1.22.3 - BSD-2-Clause
 
 
 
 Copyright (c) <year> <owner> . All rights reserved.
 
 Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
 
@@ -2171,57 +1847,18 @@
 
 THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-scipy 1.5.3 - BSD-2-Clause
+scandir 1.10.0 - BSD-2-Clause
 
 
-
-Copyright (c) <year> <owner> . All rights reserved.
-
-Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
-
-   1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
-
-   2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.
-
-THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
----------------------------------------------------------
-
----------------------------------------------------------
-
-sympy 1.11.1 - BSD-2-Clause
-
-
-
-Copyright (c) <year> <owner> . All rights reserved.
-
-Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
-
-   1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
-
-   2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.
-
-THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
-
----------------------------------------------------------
-
----------------------------------------------------------
-
-xxhash 3.2.0 - BSD-2-Clause
-
-
-Copyright (c) 2014-2020 Yue
-Copyright (c) 2014-2020, Yue Du
-Copyright (c) 2012-2020 Yann Collet
-Copyright (c) 2019-2020 Yann Collet
+Copyright (c) 2012, Ben Hoyt
 
 Copyright (c) <year> <owner> . All rights reserved.
 
 Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
 
    1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
 
@@ -2242,236 +1879,2420 @@
 
 BSD-2-Clause AND BSD-3-Clause
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-contourpy 1.0.7 - BSD-2-Clause AND BSD-3-Clause
+fsspec 2023.6.0 - BSD-2-Clause AND BSD-3-Clause
 
 
-copyright 2021-2023, ContourPy
-Copyright (c) 2021-2023, ContourPy Developers
+Copyright (c) 2018, Martin Durant
 
 BSD-2-Clause AND BSD-3-Clause
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-cycler 0.11.0 - BSD-2-Clause AND BSD-3-Clause
+pycparser 2.21 - BSD-2-Clause AND BSD-3-Clause
 
 
-copyright 2015, Matplotlib Developers
-Copyright (c) 2015, matplotlib project
+Copyright (c) 2008-2020, Eli Bendersky
+Copyright (c) 2001-2017 David M. Beazley (Dabeaz LLC)
+David Beazley (http://www.dabeaz.com) Copyright (c) 2017
 
 BSD-2-Clause AND BSD-3-Clause
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-dill 0.3.6 - BSD-2-Clause AND BSD-3-Clause
+scipy 1.10.0 - BSD-2-Clause AND BSD-3-Clause
 
 
-Copyright (c) 2011 by science+computing
-copyright d, The Uncertainty Quantification Foundation
-Copyright (c) 2008-2010 Marius Gedminas <marius@pov.lt>
-Copyright (c) 2009 PiCloud, Inc. <http://www.picloud.com>
-Copyright (c) 2010 Stefano Rivera <stefano@rivera.za.net>
-Copyright (c) 2004-2016 California Institute of Technology
-Copyright (c) 2008-2015 California Institute of Technology
-Copyright (c) 2008-2016 California Institute of Technology
-Copyright (c) 2012, Regents of the University of California
-Copyright (c) 2022 The Uncertainty Quantification Foundation
-Copyright (c) 2016-2022 The Uncertainty Quantification Foundation
-Copyright (c) 2018-2022 The Uncertainty Quantification Foundation
-Copyright (c) 2019-2022 The Uncertainty Quantification Foundation
-Copyright (c) 2021-2022 The Uncertainty Quantification Foundation
+(c), (c)
+(c) . B' Both
+(c) B Whether
+Copyright 2001
+Copyright 2003
+Copyright 2008
+(c) 2003, C. Bond
+(c) Case 2 Caller
+(c) Copyright John
+Copyright 2014 LRI
+Copyright 2015 LRI
+(c) Date July, 1988
+Copyright 2018 Nico
+Gamma (c) Gamma (c)
+(c) Compute Hessian H
+Copyright 2014 LASMEA
+Copyright Jens Maurer
+copyright Cephes Math
+(c) David Abrahams 2002
+Copyright (c) 2010 Ilya
+Copyright Albert Steppi
+Copyright Gautam Sewani
+Copyright Nat Goodspeed
+(c) 2008 Gordon Woodhull
+(c) 2011 import warnings
+Copyright (c) 2018 Yi Ji
+Copyright 2012 IBM Corp.
+Copyright 2013 Kyle Lutz
+Copyright 2018 Ulf Adams
+Copyright Catch2 Authors
+Copyright Lingxi Li 2015
+copyright Boost Software
+copyright Xiaogang Zhang
+copyrighted by Alan Genz
+(c) Peter Kankowski, 2008
+Copyright (c) 2019 Damian
+Copyright 2003 Bruce Barr
+Copyright 2006 Johan Rade
+Copyright 2011 Simon West
+Copyright 2012 K R Walker
+Copyright Jaap Suter 2003
+Copyright Jan Langer 2002
+Copyright Paul A. Bristow
+Csp self.spmatrix (c) Dsp
+copyright Jason Rice 2016
+copyright Jason Rice 2017
+copyright by Renee Touzin
+Copyright 2000 Jens Maurer
+Copyright 2003 Jeremy Siek
+Copyright 2005 Dan Marsden
+Copyright 2005 Peter Dimov
+Copyright 2007 Peter Dimov
+Copyright 2008 Beman Dawes
+Copyright 2008 Peter Dimov
+Copyright 2009 Neil Groves
+Copyright 2010 Beman Dawes
+Copyright 2013 Ankur Sinha
+Copyright 2013 Peter Dimov
+Copyright 2014 Neil Groves
+Copyright 2014 Peter Dimov
+Copyright 2015 Peter Dimov
+Copyright 2016 Jorge Lodos
+Copyright 2017 Peter Dimov
+Copyright 2018 Peter Dimov
+Copyright 2019 Peter Dimov
+Copyright 2020 Peter Dimov
+Copyright Beman Dawes 2001
+Copyright Beman Dawes 2002
+Copyright Beman Dawes 2003
+Copyright Beman Dawes 2005
+Copyright Beman Dawes 2006
+Copyright Beman Dawes 2007
+Copyright Beman Dawes 2008
+Copyright Beman Dawes 2009
+Copyright Beman Dawes 2010
+Copyright Beman Dawes 2011
+Copyright Beman Dawes 2013
+Copyright Beman Dawes 2014
+Copyright Beman Dawes 2015
+Copyright Bruno Dutra 2015
+Copyright Evan Miller 2020
+Copyright Franz Detro 2014
+Copyright Jens Maurer 2000
+Copyright Jens Maurer 2002
+Copyright Jens Maurer 2006
+Copyright Joel Falcou 2015
+Copyright Neil Groves 2007
+Copyright Neil Groves 2009
+Copyright Neil Groves 2010
+Copyright Neil Groves 2014
+Copyright Peter Dimov 2001
+Copyright Peter Dimov 2019
+Copyright Rene Rivera 2013
+Copyright Rene Rivera 2014
+Copyright Rene Rivera 2015
+Copyright Rene Rivera 2017
+Copyright Thomas Mang 2012
+Copyright ohn Maddock 2012
+(c) 2011 import numpy as np
+(c) 2012 import numpy as np
+(c) 2014 import numpy as np
+(c) Copyright 2014 Jim Bell
+Copyright (c) 2011 Jamboree
+Copyright (c) 2013 Jamboree
+Copyright (c) 2014 Jamboree
+Copyright 2000 by Alan Genz
+Copyright 2001 John Maddock
+Copyright 2004 Eric Niebler
+Copyright 2005 Eric Niebler
+Copyright 2006 Eric Niebler
+Copyright 2006 John Maddock
+Copyright 2007 Eric Niebler
+Copyright 2008 Eric Niebler
+Copyright 2008 John Maddock
+Copyright 2009 Eric Niebler
+Copyright 2010 Eric Niebler
+Copyright 2010 John Maddock
+Copyright 2011 Eric Niebler
+Copyright 2011 John Maddock
+Copyright 2011, Andrew Ross
+Copyright 2012 Eric Niebler
+Copyright 2012 John Maddock
+Copyright 2013 John Maddock
+Copyright 2013 Paul Bristow
+Copyright 2014 John Maddock
+Copyright 2014 NumScale SAS
+Copyright 2014 Paul Bristow
+Copyright 2015 John Maddock
+Copyright 2015 NumScale SAS
+Copyright 2016 John Maddock
+Copyright 2017 Daniel James
+Copyright 2017 John Maddock
+Copyright 2017 Vinnie Falco
+Copyright 2018 John Maddock
+Copyright 2019 John Maddock
+Copyright 2020 John Maddock
+Copyright Beman Dawes, 2009
+Copyright Eric Niebler 2005
+Copyright Eric Niebler 2008
+Copyright Eric Niebler 2009
+Copyright Eric Niebler 2014
+Copyright John Maddock 2005
+Copyright John Maddock 2006
+Copyright John Maddock 2007
+Copyright John Maddock 2008
+Copyright John Maddock 2009
+Copyright John Maddock 2010
+Copyright John Maddock 2011
+Copyright John Maddock 2012
+Copyright John Maddock 2013
+Copyright John Maddock 2014
+Copyright John Maddock 2015
+Copyright John Maddock 2016
+Copyright John Maddock 2017
+Copyright John Maddock 2018
+Copyright Louis Dionne 2013
+Copyright Orson Peters 2017
+Copyright Paul Bristow 2007
+Copyright Paul Bristow 2014
+Copyright Robert Ramey 2007
+Copyright Robin Eckert 2015
+Copyright Timmo Stange 2007
+copyright Louis Dionne 2016
+(c) Copyright Francois Faure
+(c) Copyright Howard Hinnant
+Copyright (c) 2017 Dynatrace
+Copyright (c) 2018 ERGO-Code
+Copyright (c) 2021 ERGO-Code
+Copyright (c) 2022 ERGO-Code
+Copyright (c) Piers Lawrence
+Copyright 2002 Daryle Walker
+Copyright 2003 - 2011 LASMEA
+Copyright 2005 Ben Hutchings
+Copyright 2005 Daniel Egloff
+Copyright 2005 Daniel Wallin
+Copyright 2006 Andy Tompkins
+Copyright 2006 Ion Gaztanaga
+Copyright 2007 Aaron Windsor
+Copyright 2007 Andy Tompkins
+Copyright 2007 Baruch Zilber
+Copyright 2007 Boris Gubenko
+Copyright 2007 David Jenkins
+Copyright 2008 CodeRage, LLC
+Copyright 2008 David Jenkins
+Copyright 2008 Gautam Sewani
+Copyright 2009 Andy Tompkins
+Copyright 2010 Andy Tompkins
+Copyright 2012 Chung-Lin Wen
+Copyright 2012 Denis Demidov
+Copyright 2013 Andrea Gavana
+Copyright 2014 MetaScale SAS
+Copyright 2015 John Fletcher
+Copyright 2020 Ion Gaztanaga
+Copyright Andy Tompkins 2006
+Copyright Bryce Lelbach 2010
+Copyright Daniel Walker 2006
+Copyright Daniel Walker 2007
+Copyright Daniel Wallin 2005
+Copyright Daniel Wallin 2006
+Copyright Daniel Wallin 2007
+Copyright Dietmar Kuehl 2001
+Copyright Eric Friedman 2002
+Copyright Eric Friedman 2003
+Copyright Gautam Sewani 2008
+Copyright John Maddock, 2020
+Copyright Nat Goodspeed 2014
+Copyright Nick Thompson 2017
+Copyright Nick Thompson 2019
+Copyright Samuel Krempp 2003
+Copyright Vladimir Prus 2002
+Copyright Vladimir Prus 2004
+Copyright Yosef Meller, 2009
+(c) Copyright Bill Kempf 2001
+(c) Copyright Bill Kempf 2002
+(c) Copyright Brian Kuhl 2016
+(c) Copyright Jens Mauer 2001
+(c) Copyright Johan Rade 2006
+(c) Copyright Paul Moore 1999
+(c) Copyright Synge Todo 2003
+Copyright (c) 2002 Bill Kempf
+Copyright (c) 2004 Peder Holt
+Copyright (c) 2005 Peder Holt
+Copyright (c) 2006 Johan Rade
+Copyright (c) 2007 Peder Holt
+Copyright (c) 2010 Peder Holt
+Copyright (c) 2014 Eric Moore
+Copyright (c) 2014 Ian Forbed
+Copyright (c) 2015 Mario Lang
+Copyright (c) 2018 Fady Essam
+Copyright (c) 2018 agate-pris
+Copyright (c) 2019 Peter Bell
+Copyright (c) 2019 agate-pris
+Copyright (c) 2020 Jeff Trull
+Copyright 2002 Gary Strangman
+Copyright 2002 Pearu Peterson
+Copyright 2005 Douglas Gregor
+Copyright 2005 Jeremy G. Siek
+Copyright 2005 Joel de Guzman
+Copyright 2006 Douglas Gregor
+Copyright 2006 Roland Schwarz
+Copyright 2008 Hartmut Kaiser
+Copyright 2008 Howard Hinnant
+Copyright 2009, Andrew Sutton
+Copyright 2010 Mario Mulansky
+Copyright 2011 Karsten Ahnert
+Copyright 2011 Mario Mulansky
+Copyright 2012 Christoph Koke
+Copyright 2012 Karsten Ahnert
+Copyright 2012 Mario Mulansky
+Copyright 2013 Karsten Ahnert
+Copyright 2013 Mario Mulansky
+Copyright 2013 Nikhar Agrawal
+Copyright 2014 Anton Bikineev
+Copyright 2014 Bill Gallafent
+Copyright 2014, Eric W. Moore
+Copyright 2015 Mario Mulansky
+Copyright 2018 Hans Dembinski
+Copyright 2018 Stefan Seefeld
+Copyright 2019 Hans Dembinski
+Copyright 2019 Mateusz Loskot
+Copyright 2020 Hans Dembinski
+Copyright 2020 Madhur Chauhan
+Copyright Alain Miniussi 2014
+Copyright Andreas Schwab 2019
+Copyright Beman Dawes 1994-99
+Copyright Christian Lorentzen
+Copyright David Abrahams 2001
+Copyright David Abrahams 2002
+Copyright David Abrahams 2003
+Copyright David Abrahams 2004
+Copyright David Abrahams 2005
+Copyright David Abrahams 2006
+Copyright David Abrahams 2009
+Copyright Douglas Gregor 2003
+Copyright Douglas Gregor 2004
+Copyright Hans Dembinski 2020
+Copyright Jim Bosch 2010-2012
+Copyright John Maddock 2006-7
+Copyright John Maddock 2007-8
+Copyright Marco Guazzone 2014
+Copyright Nick Thompson, 2017
+Copyright Nick Thompson, 2018
+Copyright Nick Thompson, 2019
+Copyright Nick Thompson, 2020
+Copyright Oliver Kowalke 2009
+Copyright Oliver Kowalke 2013
+Copyright Oliver Kowalke 2014
+Copyright Oliver Kowalke 2015
+Copyright Oliver Kowalke 2016
+Copyright Oliver Kowalke 2017
+Copyright Oliver Kowalke 2018
+Copyright Ruslan Baratov 2017
+Copyright Shreyans Doshi 2017
+Copyright Stefan Seefeld 2005
+Copyright Stefan Seefeld 2016
+Copyright Steven J. Ross 2014
+Copyright Vladimir Prus, 2002
+Copyright Xiaogang Zhang 2006
+(c) Copyright Beman Dawes 1999
+(c) Copyright Beman Dawes 2000
+(c) Copyright Beman Dawes 2001
+(c) Copyright Beman Dawes 2002
+(c) Copyright Beman Dawes 2003
+(c) Copyright Boris Rasin 2014
+(c) Copyright Darin Adler 2000
+(c) Copyright Darin Adler 2001
+(c) Copyright Jens Maurer 2001
+(c) Copyright Jens Maurer 2003
+(c) Copyright Jeremy Siek 1999
+(c) Copyright Jeremy Siek 2000
+(c) Copyright Jeremy Siek 2001
+(c) Copyright Jeremy Siek 2002
+(c) Copyright Jeremy Siek 2004
+(c) Copyright Jeremy Siek 2006
+(c) Copyright Jim Douglas 2005
+(c) Copyright Jorge Lodos 2008
+(c) Copyright Peter Dimov 2001
+(c) Copyright Peter Dimov 2002
+(c) Copyright Peter Dimov 2008
+(c) Copyright Peter Dimov 2017
+(c) Copyright Peter Dimov 2019
+(c) Copyright Rene Rivera 2005
+(c) Copyright Thomas Witt 2002
+(c) Copyright Tobias Schwinger
+(c) Copyright Toon Knapen 2001
+(c) Copyright Toon Knapen 2003
+Copyright (c) 2001 Darin Adler
+Copyright (c) 2001 Doug Gregor
+Copyright (c) 2001 Peter Dimov
+Copyright (c) 2002 Beman Dawes
+Copyright (c) 2002 Jens Maurer
+Copyright (c) 2002 Peter Dimov
+Copyright (c) 2003 Daniel Frey
+Copyright (c) 2003 Peter Dimov
+Copyright (c) 2003 Thomas Witt
+Copyright (c) 2005 Dan Marsden
+Copyright (c) 2005 Peter Dimov
+Copyright (c) 2006 Dan Marsden
+Copyright (c) 2006 Peter Dimov
+Copyright (c) 2007 Dan Marsden
+Copyright (c) 2007 Peter Dimov
+Copyright (c) 2008 Beman Dawes
+Copyright (c) 2008 Damian Eads
+Copyright (c) 2008 Peter Dimov
+Copyright (c) 2009 Carl Barron
+Copyright (c) 2009 Peter Dimov
+Copyright (c) 2010 Neil Groves
+Copyright (c) 2012 David Stone
+Copyright (c) 2012 Google Inc.
+Copyright (c) 2013 Carl Barron
+Copyright (c) 2013 Peter Dimov
+Copyright (c) 2014 Lee Clagett
+Copyright (c) 2014 Peter Dimov
+Copyright (c) 2014 Tomoki Imai
+Copyright (c) 2015 Seth Heeren
+Copyright (c) 2016 Lee Clagett
+Copyright (c) 2016 Peter Dimov
+Copyright (c) 2018 Peter Dimov
+Copyright (c) 2019 Peter Dimov
+Copyright (c) 2020 Peter Dimov
+Copyright (c) Beman Dawes 2011
+Copyright (c) Beman Dawes 2015
+Copyright (c) Dan Watkins 2003
+Copyright (c) Jeremy Siek 2001
+Copyright (c) Thomas Witt 2002
+Copyright 1999 Travis Oliphant
+Copyright 2000 Maarten Keijzer
+Copyright 2005 Matthias Troyer
+Copyright 2005 Travis Oliphant
+Copyright 2008 Joaquin M Lopez
+Copyright 2009 Steven Watanabe
+Copyright 2010 Kenneth Riddile
+Copyright 2010 Paul A. Bristow
+Copyright 2011 Paul A. Bristow
+Copyright 2011 Steven Watanabe
+Copyright 2012 Andreas Pokorny
+Copyright 2012 Paul A. Bristow
+Copyright 2012 Steven Watanabe
+Copyright 2012-20 John Maddock
+Copyright 2013 Andrey Semashev
+Copyright 2013 Pascal Germroth
+Copyright 2014 Andrey Semashev
+Copyright 2014 Antony Polukhin
+Copyright 2015 Andrey Semashev
+Copyright 2015 Antony Polukhin
+Copyright 2015 Steven Watanabe
+Copyright 2016 Andrey Semashev
+Copyright 2016 Joaquin M Lopez
+Copyright 2017 Andrey Semashev
+Copyright 2017 Joaquin M Lopez
+Copyright 2018 Joaquin M Lopez
+Copyright 2018 Steven Watanabe
+Copyright 2019 Emil Dotchevski
+Copyright 2019 Henry Schreiner
+Copyright 2020 Andrey Semashev
+Copyright 2020 Samuel Debionne
+Copyright Adam D. Walling 2012
+Copyright Alexander Grund 2018
+Copyright Andrey Semashev 2013
+Copyright Andrey Semashev 2015
+Copyright Andrey Semashev 2016
+Copyright Andrey Semashev 2018
+Copyright Andrey Semashev 2019
+Copyright Andrey Semashev 2020
+Copyright Bertolt Mildner 2004
+Copyright Daniel Trebbien 2010
+Copyright Emil Dotchevski 2007
+Copyright Frank Mori Hess 2007
+Copyright Frank Mori Hess 2008
+Copyright Frank Mori Hess 2009
+Copyright John Maddock 2008-11
+Copyright John R. Bandela 2001
+Copyright Paul A. Bristow 2006
+Copyright Paul A. Bristow 2007
+Copyright Paul A. Bristow 2010
+Copyright Paul A. Bristow 2012
+Copyright Paul A. Bristow 2013
+Copyright Paul A. Bristow 2014
+Copyright Paul A. Bristow 2017
+Copyright Paul Mensonides 2003
+Copyright Sergey Krivonos 2017
+Copyright Steven Watanabe 2009
+Copyright Steven Watanabe 2010
+Copyright Steven Watanabe 2011
+Copyright Steven Watanabe 2014
+copyrighted by Enthought, Inc.
+(c) Copyright 2005 John Maddock
+(c) Copyright 2008 Robert Ramey
+(c) Copyright 2010 Daniel James
+(c) Copyright 2010 Robert Ramey
+(c) Copyright 2020 Robert Ramey
+(c) Copyright Daniel K. O. 2005
+(c) Copyright Hubert Holin 2001
+(c) Copyright Hubert Holin 2003
+(c) Copyright Jeremy Siek, 2001
+(c) Copyright John Maddock 2000
+(c) Copyright John Maddock 2001
+(c) Copyright John Maddock 2002
+(c) Copyright John Maddock 2003
+(c) Copyright John Maddock 2005
+(c) Copyright John Maddock 2006
+(c) Copyright John Maddock 2007
+(c) Copyright John Maddock 2008
+(c) Copyright John Maddock 2010
+(c) Copyright John Maddock 2011
+(c) Copyright John Maddock 2015
+(c) Copyright John Maddock 2017
+(c) Copyright John Maddock 2018
+(c) Copyright Lie-Quan Lee 2001
+(c) Copyright Martin Wille 2003
+(c) Copyright Orson Peters 2017
+(c) Copyright Rani Sharoni 2003
+(c) Copyright Robert Ramey 2004
+Copyright (c) 2002 John Maddock
+Copyright (c) 2003 John Maddock
+Copyright (c) 2003 Martin Wille
+Copyright (c) 2004 John Maddock
+Copyright (c) 2005 Eric Niebler
+Copyright (c) 2006 Eric Niebler
+Copyright (c) 2006 John Maddock
+Copyright (c) 2006 Stephen Nutt
+Copyright (c) 2007 John Maddock
+Copyright (c) 2007, Damian Eads
+Copyright (c) 2008 Eric Niebler
+Copyright (c) 2008 Roelof Naude
+Copyright (c) 2009 John Maddock
+Copyright (c) 2010 Eric Niebler
+Copyright (c) 2011 Aaron Graham
+Copyright (c) 2011 Brandon Kohn
+Copyright (c) 2011 Eric Niebler
+Copyright (c) 2011 John Maddock
+Copyright (c) 2012 Nathan Ridge
+Copyright (c) 2012 Oswin Krause
+Copyright (c) 2012 Robert Ramey
+Copyright (c) 2013 Eurodecision
+Copyright (c) 2014 Eric Niebler
+Copyright (c) 2014 Mageswaran.D
+Copyright (c) 2015 John Maddock
+Copyright (c) 2015 Orson Peters
+Copyright (c) 2015 Robert Ramey
+Copyright (c) 2016 Adrian Veres
+Copyright (c) 2017 John Maddock
+Copyright (c) 2017 Michel Morin
+Copyright (c) 2017 Robert Ramey
+Copyright (c) 2017 Vinnie Falco
+Copyright (c) 2020 John Maddock
+Copyright (c) 2021 Orson Peters
+Copyright (c) Tyler Reddy, 2016
+Copyright 2002-2018 Peter Dimov
+Copyright 2003-2005 Peter Dimov
+Copyright 2004-2005 Peter Dimov
+Copyright 2004-2006 Peter Dimov
+Copyright 2004-2008 Peter Dimov
+Copyright 2005-2013 Peter Dimov
+Copyright 2006 Thorsten Ottosen
+Copyright 2007 Tobias Schwinger
+Copyright 2008 Christophe Henry
+Copyright 2008,2012 Peter Dimov
+Copyright 2009-2014 Neil Groves
+Copyright 2011 Christophe Henry
+Copyright 2012 (c) Google, Inc.
+Copyright 2012 Lucanus Simonson
+Copyright 2012, Philipp Moeller
+Copyright 2013 Maciej Piechotka
+Copyright 2015-2017 Peter Dimov
+Copyright 2015-2019 Peter Dimov
+Copyright 2015-2020 Peter Dimov
+Copyright 2017-2019 Peter Dimov
+Copyright Aleksey Gurtovoy 2004
+Copyright Aleksey Gurtovoy 2006
+Copyright Aleksey Gurtovoy 2008
+Copyright Beman Dawes 1995-2001
+Copyright Beman Dawes 2002-2009
+Copyright Benjamin Sobotta 2012
+Copyright Benjamin Worpitz 2018
+Copyright Charly Chevalier 2015
+Copyright Jens Maurer 2000-2001
+Copyright Jessica Hamilton 2014
+Copyright Neil Groves 2003-2004
+Copyright Nikolay Mladenov 2007
+Copyright Pavol Droba 2002-2003
+Copyright Pavol Droba 2002-2004
+Copyright Pavol Droba 2002-2006
+Copyright Peter Dimov 2000-2002
+Copyright Peter Dimov 2000-2003
+Copyright Peter Dimov 2001-2002
+Copyright Peter Dimov 2001-2003
+Copyright Rene Rivera 2005-2016
+Copyright Rene Rivera 2008-2013
+Copyright Rene Rivera 2008-2015
+Copyright Rene Rivera 2008-2017
+Copyright Rene Rivera 2008-2019
+Copyright Rene Rivera 2011-2012
+Copyright Rene Rivera 2011-2015
+Copyright Rene Rivera 2012-2015
+Copyright Rene Rivera 2013-2015
+Copyright Rene Rivera 2014-2015
+Copyright Rene Rivera 2015-2016
+Copyright Rene Rivera 2015-2019
+Copyright Thorsten Ottosen 2006
+Copyright Thorsten Ottosen 2008
+(c) Copyright 2007 Andrew Sutton
+(c) Copyright 2007 David Deakins
+(c) Copyright 2008 CodeRage, LLC
+(c) Copyright 2012 Vicente Botet
+(c) Copyright 2013 Tim Blechmann
+(c) Copyright Andrew Sutton 2007
+(c) Copyright Artyom Beilis 2010
+(c) Copyright Balint Cserni 2017
+(c) Copyright Boris Gubenko 2007
+(c) Copyright Bruno Lalande 2008
+(c) Copyright Bryce Lelbach 2010
+(c) Copyright Bryce Lelbach 2011
+(c) Copyright Daniel Wallin 2004
+(c) Copyright Daryle Walker 2001
+(c) Copyright Edward Diener 2011
+(c) Copyright Edward Diener 2012
+(c) Copyright Edward Diener 2013
+(c) Copyright Edward Diener 2014
+(c) Copyright Edward Diener 2015
+(c) Copyright Edward Diener 2016
+(c) Copyright Edward Diener 2019
+(c) Copyright Edward Diener 2020
+(c) Copyright Gennaro Prota 2003
+(c) Copyright Ion Gaztanaga 2005
+(c) Copyright Ion Gaztanaga 2006
+(c) Copyright Ion Gaztanaga 2008
+(c) Copyright Ion Gaztanaga 2009
+(c) Copyright Ion Gaztanaga 2014
+(c) Copyright Milan Svoboda 2008
+(c) Copyright Nick Thompson 2017
+(c) Copyright Nick Thompson 2018
+(c) Copyright Nick Thompson 2019
+(c) Copyright Nick Thompson 2020
+(c) Copyright Noel Belcourt 2007
+(c) Copyright Pablo Halpern 2009
+(c) Copyright Ronald Garcia 2002
+Copyright (c) 2001 Bruce Florman
+Copyright (c) 2001 Daniel Nuffer
+Copyright (c) 2001 Daryle Walker
+Copyright (c) 2001 Dietmar Kuehl
+Copyright (c) 2002 Jeff Westfahl
+Copyright (c) 2003 Eric Friedman
+Copyright (c) 2003 Gennaro Prota
+Copyright (c) 2003 Giovanni Bajo
+Copyright (c) 2003 Vaclav Vesely
+Copyright (c) 2003 Vesa Karvonen
+Copyright (c) 2003 Vladimir Prus
+Copyright (c) 2004 Angus Leeming
+Copyright (c) 2004 Daniel Wallin
+Copyright (c) 2005 Aaron Windsor
+Copyright (c) 2005 Stefan Arentz
+Copyright (c) 2006 Daniel Wallin
+Copyright (c) 2006 Tomas Puverle
+Copyright (c) 2008 Ion Gaztanaga
+Copyright (c) 2009 Andrew Sutton
+Copyright (c) 2009 Helge Bahmann
+Copyright (c) 2009 Phil Endecott
+Copyright (c) 2010 Artyom Beilis
+Copyright (c) 2010 Bryce Lelbach
+Copyright (c) 2010 Helge Bahmann
+Copyright (c) 2010 Thomas Heller
+Copyright (c) 2010 Tim Blechmann
+Copyright (c) 2011 Bryce Lelbach
+Copyright (c) 2011 Helge Bahmann
+Copyright (c) 2011 Thomas Heller
+Copyright (c) 2011 Tim Blechmann
+Copyright (c) 2012 Artyom Beilis
+Copyright (c) 2012 Bruno Lalande
+Copyright (c) 2012 Paul Fultz II
+Copyright (c) 2012 Tim Blechmann
+Copyright (c) 2013 Agustin Berge
+Copyright (c) 2013 Bruno Lalande
+Copyright (c) 2013 Joaquim Duran
+Copyright (c) 2013 Kenneth L. Ho
+Copyright (c) 2013 Tim Blechmann
+Copyright (c) 2014 Agustin Berge
+Copyright (c) 2014 Ahmed Charles
+Copyright (c) 2014 Bruno Lalande
+Copyright (c) 2014 John Fletcher
+Copyright (c) 2014 Paul Fultz II
+Copyright (c) 2015 Artyom Beilis
+Copyright (c) 2015 Ion Gaztanaga
+Copyright (c) 2015 John Fletcher
+Copyright (c) 2015 Paul Fultz II
+Copyright (c) 2016 Barrett Adair
+Copyright (c) 2016 Paul Fultz II
+Copyright (c) 2018 Artyom Beilis
+Copyright (c) Aaron Windsor 2007
+Copyright (c) Chris Glover, 2016
+Copyright (c) Kevlin Henney 2001
+Copyright (c) Marshall Clow 2014
+Copyright (c) Marshall Clow 2017
+Copyright (c) Pablo Aguilar 2005
+Copyright (c) Vladimir Prus 2003
+Copyright 1991 Dieter Kraft, FHM
+Copyright 1997-2008 by Agner Fog
+Copyright 2002, 2009 Peter Dimov
+Copyright 2002, 2020 Peter Dimov
+Copyright 2002-2008 by Agner Fog
+Copyright 2002-2014 by Agner Fog
+Copyright 2004-2008 by Agner Fog
+Copyright 2004-2013 by Agner Fog
+Copyright 2005 Alexander Nasonov
+Copyright 2005, 2014 Peter Dimov
+Copyright 2005-2009 Daniel James
+Copyright 2005-2011 Daniel James
+Copyright 2005-2012 Daniel James
+Copyright 2005-2014 Daniel James
+Copyright 2006, 2020 Peter Dimov
+Copyright 2007 Christian Henning
+Copyright 2007, 2014 Peter Dimov
+Copyright 2007, 2019 Peter Dimov
+Copyright 2007, 2020 Peter Dimov
+Copyright 2008 Christian Henning
+Copyright 2008 Intel Corporation
+Copyright 2008, 2020 Peter Dimov
+Copyright 2009 Christian Henning
+Copyright 2010 Christian Henning
+Copyright 2010 Thomas Claveirole
+Copyright 2012 Christian Henning
+Copyright 2012 Olivier Tournaire
+Copyright 2012-2020 John Maddock
+Copyright 2013 Christian Henning
+Copyright 2013 Christian Shelton
+Copyright 2013 Cromwell D. Enage
+Copyright 2015, 2016 Peter Dimov
+Copyright 2015, 2019 Peter Dimov
+Copyright 2016, 2017 Peter Dimov
+Copyright 2017 James E. King III
+Copyright 2017, 2018 Peter Dimov
+Copyright 2017, 2019 Peter Dimov
+Copyright 2018, 2020 Peter Dimov
+Copyright 2019, 2020 Peter Dimov
+Copyright 2019-20 Madhur Chauhan
+Copyright Alexander Nasonov 2004
+Copyright Anne M. Archibald 2008
+Copyright Beman Dawes 2002, 2006
+Copyright Beman Dawes 2003, 2006
+Copyright Beman Dawes 2006, 2007
+Copyright Beman Dawes, 2002-2005
+Copyright Christopher Brown 2013
+Copyright Cromwell D. Enage 2013
+Copyright Cromwell D. Enage 2017
+Copyright Cromwell D. Enage 2018
+Copyright Cromwell D. Enage 2019
+Copyright Jason Rhinelander 2016
+Copyright John Maddock 2005-2006
+Copyright John Maddock 2005-2008
+Copyright Louis Dionne 2013-2017
+Copyright Nicholas Thompson 2018
+Copyright Nikhar Agrawal 2013-14
+Copyright Paul A. Bristow 2006-7
+Copyright Peter Dimov 2017, 2018
+Copyright Thorsten Ottosen, 2009
+copyright Louis Dionne 2013-2016
+copyright Louis Dionne 2013-2017
+(c) Copyright 2006 Douglas Gregor
+(c) Copyright 2009 Eric Bose-Wolf
+(c) Copyright 2013 Ruslan Baratov
+(c) Copyright Anton Bikineev 2014
+(c) Copyright David Abrahams 2000
+(c) Copyright David Abrahams 2001
+(c) Copyright David Abrahams 2002
+(c) Copyright David Abrahams 2003
+(c) Copyright David Abrahams 2004
+(c) Copyright Douglas Gregor 2001
+(c) Copyright Douglas Gregor 2002
+(c) Copyright Douglas Gregor 2010
+(c) Copyright Howard Hinnant 2004
+(c) Copyright Joel de Guzman 2003
+(c) Copyright John Maddock 2001-8
+(c) Copyright John Maddock 2006-7
+(c) Copyright John Maddock 2006-8
+(c) Copyright Juergen Hunold 2008
+(c) Copyright Roland Richter 2003
+(c) Copyright Stefan Slapeta 2004
+(c) Copyright Stephen Cleary 2000
+Copyright (c) 2000 David Abrahams
+Copyright (c) 2000 Stephen Cleary
+Copyright (c) 2001 David Abrahams
+Copyright (c) 2002 David Abrahams
+Copyright (c) 2002 Joel de Guzman
+Copyright (c) 2003 David Abrahams
+Copyright (c) 2003 Hartmut Kaiser
+Copyright (c) 2003 Howard Hinnant
+Copyright (c) 2003 Joel de Guzman
+Copyright (c) 2004 Hartmut Kaiser
+Copyright (c) 2004 Joel de Guzman
+Copyright (c) 2004 Ralf Mattethat
+Copyright (c) 2005 Douglas Gregor
+Copyright (c) 2005 Igor Chesnokov
+Copyright (c) 2006 Douglas Gregor
+Copyright (c) 2006 Piotr Wyderski
+Copyright (c) 2006 Xiaogang Zhang
+Copyright (c) 2006-7 John Maddock
+Copyright (c) 2007 Douglas Gregor
+Copyright (c) 2007 Hartmut Kaiser
+Copyright (c) 2007 Joel de Guzman
+Copyright (c) 2008 Michael Marcin
+Copyright (c) 2009 Chris Hoeppler
+Copyright (c) 2009 Francois Barel
+Copyright (c) 2009 Gunter Winkler
+Copyright (c) 2009 Hartmut Kaiser
+Copyright (c) 2009 Pauli Virtanen
+Copyright (c) 2009 Sebastian Redl
+Copyright (c) 2009, Motorola, Inc
+Copyright (c) 2010 Alfredo Correa
+Copyright (c) 2011 ! Brandon Kohn
+Copyright (c) 2011 Hartmut Kaiser
+Copyright (c) 2011 Thomas Bernard
+Copyright (c) 2012 Hartmut Kaiser
+Copyright (c) 2012 Martin Raspaud
+Copyright (c) 2012, Michele Caini
+Copyright (c) 2013 Anton Bikineev
+Copyright (c) 2013 Mateusz Loskot
+Copyright (c) 2013 Pauli Virtanen
+Copyright (c) 2013 Sebastian Redl
+Copyright (c) 2014 Erik Erlandson
+Copyright (c) 2014 Glen Fernandes
+Copyright (c) 2014 Joel de Guzman
+Copyright (c) 2014 Oliver Kowalke
+Copyright (c) 2014 Thomas Bernard
+Copyright (c) 2015 Sebastian Redl
+Copyright (c) 2016 Norbert Wenzel
+Copyright (c) 2016-2018 ERGO-Code
+Copyright (c) 2016-2019 ERGO-Code
+Copyright (c) 2017 Daniela Engert
+Copyright (c) 2018 Alain Miniussi
+Copyright (c) 2018 Evgeny Shulgin
+Copyright (c) 2018 Sergei Fedorov
+Copyright (c) 2018 Stefan Seefeld
+Copyright (c) 2018-2019 ERGO-Code
+Copyright (c) 2018-2021 ERGO-Code
+Copyright (c) 2019 Joel de Guzman
+Copyright (c) 2020 Nikita Kniazev
+Copyright (c) David Abrahams 2001
+Copyright (c) Douglas Gregor 2004
+Copyright (c) Douglas Gregor 2008
+Copyright 2001 Indiana University
+Copyright 2002 Indiana University
+Copyright 2006-2007 Boris Gubenko
+Copyright 2007 Alexandre Courpron
+Copyright 2007-2008 CodeRage, LLC
+Copyright 2007-2012 Ion Gaztanaga
+Copyright 2011 -2013 John Maddock
+Copyright 2011 Paul A. Bristow To
+Copyright 2017 James E. King, III
+Copyright Barrett Adair 2015-2017
+Copyright Barrett Adair 2015-2018
+Copyright Barrett Adair 2016-2017
+Copyright Dave Abrahams 2001-2002
+Copyright Eric Friedman 2002-2003
+Copyright James E. King III, 2017
+Copyright John Maddock 2006, 2007
+Copyright John Maddock 2006, 2010
+Copyright John Maddock 2006, 2011
+Copyright John Maddock 2006, 2012
+Copyright John Maddock 2007, 2014
+Copyright John Maddock 2008, 2012
+Copyright John Maddock 2010, 2012
+Copyright Paul Bristow 2006, 2007
+Copyright Paul Bristow 2007, 2011
+Copyright Thijs van den Berg 2014
+Copyright Vladimir Prus 2002-2004
+(c) Copyright 2004 Pavel Vozenilek
+(c) Copyright 2005 Matthias Troyer
+(c) Copyright 2007 Matthias Troyer
+(c) Copyright 2008 Matthias Troyer
+(c) Copyright 2013 Andrey Semashev
+(c) Copyright 2016 Raffi Enficiaud
+(c) Copyright 2017 Andrey Semashev
+(c) Copyright Andrey Semashev 2017
+(c) Copyright Antony Polukhin 2013
+(c) Copyright Antony Polukhin 2014
+(c) Copyright Craig Henderson 2002
+(c) Copyright Dustin Spicuzza 2009
+(c) Copyright Ignacy Gawedzki 2010
+(c) Copyright Jonathan Graehl 2004
+(c) Copyright Paul A. Bristow 2006
+(c) Copyright Paul A. Bristow 2011
+(c) Copyright Paul Mensonides 2002
+(c) Copyright Paul Mensonides 2003
+(c) Copyright Paul Mensonides 2005
+(c) Copyright Paul Mensonides 2011
+(c) Copyright Paul Mensonides 2012
+(c) Copyright Raffi Enficiaud 2017
+(c) Copyright Raffi Enficiaud 2018
+(c) Copyright Raffi Enficiaud 2019
+Copyright (c) 1995, Gerald Evenden
+Copyright (c) 2002 Travis Oliphant
+Copyright (c) 2003 Paul Mensonides
+Copyright (c) 2003-2008 Jan Gaspar
+Copyright (c) 2005-2007 Peder Holt
+Copyright (c) 2006 Steven Watanabe
+Copyright (c) 2006-2008 Johan Rade
+Copyright (c) 2007 Alexey Baskakov
+Copyright (c) 2007 Matthias Troyer
+Copyright (c) 2008 Frank Mori Hess
+Copyright (c) 2008 Steven Watanabe
+Copyright (c) 2008-2009 Ben Hanson
+Copyright (c) 2009 Boris Schaeling
+Copyright (c) 2009 Frank Mori Hess
+Copyright (c) 2009 Steven Watanabe
+Copyright (c) 2009, Gunter Winkler
+Copyright (c) 2009, Marco Guazzone
+Copyright (c) 2010 Paul A. Bristow
+Copyright (c) 2011 Emil Dotchevski
+Copyright (c) 2011 Julio Hoffimann
+Copyright (c) 2011 Paul A. Bristow
+Copyright (c) 2011 Steven Watanabe
+Copyright (c) 2012 Boris Schaeling
+Copyright (c) 2012 Kohei Takahashi
+Copyright (c) 2012 Paul A. Bristow
+Copyright (c) 2013 Antony Polukhin
+Copyright (c) 2013 Paul A. Bristow
+Copyright (c) 2014 Andrey Semashev
+Copyright (c) 2014 Christoph Weiss
+Copyright (c) 2014 Kohei Takahashi
+Copyright (c) 2015 Andrey Semashev
+Copyright (c) 2015 Kohei Takahashi
+Copyright (c) 2016 Kohei Takahashi
+Copyright (c) 2017 Andrey Semashev
+Copyright (c) 2017 Kohei Takahashi
+Copyright (c) 2017-2018 Chris Beck
+Copyright (c) 2018 Andrey Semashev
+Copyright (c) 2018 Kohei Takahashi
+Copyright (c) 2018, Quansight-Labs
+Copyright (c) 2018-2019 Cem Bassoy
+Copyright (c) 2019 Andrey Semashev
+Copyright (c) 2019-2020 Peter Bell
+Copyright (c) 2020 Alexander Grund
+Copyright (c) 2020 Andrey Semashev
+Copyright (c) Andrey Semashev 2017
+Copyright (c) Pauli Virtanen, 2010
+Copyright 2002, 2005 Daryle Walker
+Copyright 2003 Guillaume Melquiond
+Copyright 2005 Guillaume Melquiond
+Copyright 2007 Stanford University
+Copyright 2009-2011 Karsten Ahnert
+Copyright 2009-2011 Mario Mulansky
+Copyright 2009-2012 Karsten Ahnert
+Copyright 2009-2012 Mario Mulansky
+Copyright 2009-2013 Karsten Ahnert
+Copyright 2009-2013 Mario Mulansky
+Copyright 2009-2015 Mario Mulansky
+Copyright 2010-2011 Karsten Ahnert
+Copyright 2010-2011 Mario Mulansky
+Copyright 2010-2012 Karsten Ahnert
+Copyright 2010-2012 Mario Mulansky
+Copyright 2010-2013 Karsten Ahnert
+Copyright 2010-2013 Mario Mulansky
+Copyright 2010-2014 Mario Mulansky
+Copyright 2010-2015 Mario Mulansky
+Copyright 2011 - 2013 John Maddock
+Copyright 2011-2012 Karsten Ahnert
+Copyright 2011-2012 Mario Mulansky
+Copyright 2011-2013 Karsten Ahnert
+Copyright 2011-2013 Mario Mulansky
+Copyright 2011-2015 Mario Mulansky
+Copyright 2012-2013 Karsten Ahnert
+Copyright 2012-2013 Mario Mulansky
+Copyright 2012-2015 Mario Mulansky
+Copyright 2013-2014 Karsten Ahnert
+Copyright 2013-2014 Mario Mulansky
+Copyright 2015 Jon Lund Steffensen
+Copyright 2015 Klemens Morgenstern
+Copyright 2015-2016 Hans Dembinski
+Copyright 2015-2017 Hans Dembinski
+Copyright 2015-2018 Hans Dembinski
+Copyright 2015-2019 Hans Dembinski
+Copyright 2016 Klemens Morgenstern
+Copyright 2017 Two Blue Cubes Ltd.
+Copyright 2018-2019 Hans Dembinski
+Copyright 2019 Przemyslaw Bartosik
+Copyright Christoper Kohlhoff 2007
+Copyright David Abrahams 2000-2002
+Copyright David Abrahams 2001-2002
+Copyright David Abrahams 2002-2003
+Copyright David Abrahams 2003-2004
+Copyright Douglas Gregor 2001-2003
+Copyright Douglas Gregor 2001-2004
+Copyright Douglas Gregor 2001-2006
+Copyright Douglas Gregor 2002-2003
+Copyright Douglas Gregor 2002-2004
+Copyright Gottfried Ganssauge 2003
+Copyright Howard Hinnant 2007-2010
+Copyright Kevlin Henney, 2000-2005
+Copyright Michael Drexl 2005, 2006
+Copyright Sebastian Ramacher, 2007
+Copyright Thijs van den Berg, 2008
+(c) Copyright 2007 Anthony Williams
+(c) Copyright 2008 Anthony Williams
+(c) Copyright Aleksey Gurtovoy 2002
+(c) Copyright Aleksey Gurtovoy 2003
+(c) Copyright Beman Dawes 1995-2001
+(c) Copyright Beman Dawes 1999-2003
+(c) Copyright Daniel Frey 2002-2017
+(c) Copyright Herve Bronnimann 2004
+(c) Copyright Jeremy Siek 1999-2001
+(c) Copyright Jessica Hamilton 2014
+(c) Copyright Matthias Troyerk 2006
+(c) Copyright Peter Dimov 2004-2005
+(c) Copyright Reimar Doffinger 2018
+(c) Copyright Thorsten Ottosen 2005
+Copyright (c) 1988 by Theo Jurriens
+Copyright (c) 1993-2019 C.B. Barber
+Copyright (c) 2000, Frank Warmerdam
+Copyright (c) 2001 Daniel C. Nuffer
+Copyright (c) 2001-2003 Mac Murrett
+Copyright (c) 2001-2005 Peter Dimov
+Copyright (c) 2001-2008 Peter Dimov
+Copyright (c) 2002, Frank Warmerdam
+Copyright (c) 2003-2005 Peter Dimov
+Copyright (c) 2004 Arkadiy Vertleyb
+Copyright (c) 2005 Arkadiy Vertleyb
+Copyright (c) 2005-2006 Dan Marsden
+Copyright (c) 2005-2007 Dan Marsden
+Copyright (c) 2006 Arkadiy Vertleyb
+Copyright (c) 2006 Tobias Schwinger
+Copyright (c) 2007 Tobias Schwinger
+Copyright (c) 2012 Anthony Williams
+Copyright (c) 2012 Lorenzo Caminiti
+Copyright (c) 2013-2014 Damien Buhl
+Copyright (c) 2016 K. Noel Belcourt
+Copyright (c) 2019 T. Zachary Laine
+Copyright (c) Benjamin Sobotta 2012
+Copyright (c) Jeremy Siek 2001-2003
+Copyright (c) T. Zachary Laine 2018
+Copyright 2002 H Lohninger, TU Wein
+Copyright 2003-2008 Joaquin M Lopez
+Copyright 2003-2013 Joaquin M Lopez
+Copyright 2003-2014 Joaquin M Lopez
+Copyright 2003-2015 Joaquin M Lopez
+Copyright 2003-2016 Joaquin M Lopez
+Copyright 2003-2017 Joaquin M Lopez
+Copyright 2003-2018 Joaquin M Lopez
+Copyright 2003-2019 Joaquin M Lopez
+Copyright 2003-2020 Joaquin M Lopez
+Copyright 2006-2008 Joaquin M Lopez
+Copyright 2006-2009 Joaquin M Lopez
+Copyright 2006-2011 Joaquin M Lopez
+Copyright 2006-2013 Joaquin M Lopez
+Copyright 2006-2014 Joaquin M Lopez
+Copyright 2006-2015 Joaquin M Lopez
+Copyright 2006-2018 Joaquin M Lopez
+Copyright 2006-2019 Joaquin M Lopez
+Copyright 2006-2020 Joaquin M Lopez
+Copyright 2008 Andreas Huber Doenni
+Copyright 2008-2009 Frank Mori Hess
+Copyright 2008-2010 Gordon Woodhull
+Copyright 2011-2012 Steven Watanabe
+Copyright 2012-2013 Steven Watanabe
+Copyright 2012-2020 Antony Polukhin
+Copyright 2013 University of Warsaw
+Copyright 2013-2020 Antony Polukhin
+Copyright 2015-2018 Andrey Semashev
+Copyright 2015-2019 Antony Polukhin
+Copyright 2015-2020 Antony Polukhin
+Copyright 2016-2017 Joaquin M Lopez
+Copyright 2016-2018 Andrey Semashev
+Copyright 2016-2018 Joaquin M Lopez
+Copyright 2016-2019 Antony Polukhin
+Copyright 2016-2019 Joaquin M Lopez
+Copyright 2016-2020 Joaquin M Lopez
+Copyright 2017, NVIDIA CORPORATION.
+Copyright 2017-2018 Joaquin M Lopez
+Copyright 2018-2019 Antony Polukhin
+Copyright 2019-2020 Antony Polukhin
+Copyright Eric Niebler 2013-present
+Copyright Frank Mori Hess 2007,2009
+Copyright Frank Mori Hess 2007-2008
+Copyright Frank Mori Hess 2007-2009
+Copyright Frank Mori Hess 2007-2010
+Copyright John R. Bandela 2000-2002
+Copyright Kohei Takahashi 2012-2014
+Copyright Paul A. Bristow 2006-2011
+Copyright Shunsuke Sogame 2005-2006
+Copyright Steven Watanabe 2009-2011
+Copyright Steven Watanabe 2010-2011
+(c) Copyright 2002, 2003 Beman Dawes
+(c) Copyright 2002-4 Pavel Vozenilek
+(c) Copyright 2016 Ashish Sadanandan
+(c) Copyright Eric Niebler 2004-2005
+(c) Copyright Gennadiy Rozental 2001
+(c) Copyright Hubert Holin 2003-2005
+(c) Copyright Jeremiah Willcock 2004
+(c) Copyright John Maddock 2005-2006
+(c) Copyright Jonathan Turkanis 2003
+(c) Copyright Jonathan Turkanis 2004
+(c) Copyright Markus Schoepflin 2005
+(c) Copyright Markus Schoepflin 2007
+(c) Copyright Michael Glassford 2004
+(c) Copyright Peter Dimov 2001, 2002
+(c) Copyright Rani Sharoni 2003-2005
+(c) Copyright Thomas Claveirole 2010
+(c) Copyright Yuriy Krasnoschek 2009
+Copyright (c) 1998-2002 John Maddock
+Copyright (c) 1998-2004 John Maddock
+Copyright (c) 1998-2005 John Maddock
+Copyright (c) 1998-2009 John Maddock
+Copyright (c) 1999-2003 Jaakko Jarvi
+Copyright (c) 2001 Alexander Peslyak
+Copyright (c) 2001, 2002 Peter Dimov
+Copyright (c) 2001, Daniel C. Nuffer
+Copyright (c) 2001-2003 John Maddock
+Copyright (c) 2002, 2003 Peter Dimov
+Copyright (c) 2002-2003 Martin Wille
+Copyright (c) 2003 Gerald I. Evenden
+Copyright (c) 2003-2005 John Maddock
+Copyright (c) 2004 Gerald I. Evenden
+Copyright (c) 2005 Matthew Calabrese
+Copyright (c) 2005-2008 Daniel James
+Copyright (c) 2005-2009 Jongsoo Park
+Copyright (c) 2005-2011 Daniel James
+Copyright (c) 2005-2016 Daniel James
+Copyright (c) 2007 Cybozu Labs, Inc.
+Copyright (c) 2007 Marcin Kalicinski
+Copyright (c) 2007, 2008 Peter Dimov
+Copyright (c) 2007, 2013 Peter Dimov
+Copyright (c) 2007, 2014 Peter Dimov
+Copyright (c) 2007, Tobias Schwinger
+Copyright (c) 2008 Gerald I. Evenden
+Copyright (c) 2008, 2009 Peter Dimov
+Copyright (c) 2008, 2011 Peter Dimov
+Copyright (c) 2008, 2018 Peter Dimov
+Copyright (c) 2008-2011 Daniel James
+Copyright (c) 2008-2016 Daniel James
+Copyright (c) 2009, 2015 Peter Dimov
+Copyright (c) 2010-2011 David Bellot
+Copyright (c) 2011-2013 Andrew Hundt
+Copyright (c) 2013 Tim Blechmann ARM
+Copyright (c) 2015-2019 Vinnie Falco
+Copyright (c) 2016-2019 Damian Jarek
+Copyright (c) 2016-2019 Vinnie Falco
+Copyright (c) 2017 James E. King III
+Copyright (c) 2018 James E. King III
+Copyright (c) 2020 Michael Feldmeier
+Copyright (c) Christof Meerwald 2003
+Copyright (c) Damian Eads, 2007-2008
+Copyright (c) Intel Corporation 2008
+Copyright 1999-2003 Aleksey Gurtovoy
+Copyright 2011, 2012 Paul A. Bristow
+Copyright 2011-2013 Thorsten Ottosen
+Copyright 2013 Christopher Kormanyos
+Copyright 2013, 2017 Andrey Semashev
+Copyright 2013, 2017-2018 Cray, Inc.
+Copyright 2014 Christopher Kormanyos
+Copyright 2015, 2017 Andrey Semashev
+Copyright 2015, 2020 Andrey Semashev
+Copyright 2016, 2017 Andrey Semashev
+Copyright 2018, 2019 Andrey Semashev
+Copyright Aleksey Gurtovoy 2000-2002
+Copyright Aleksey Gurtovoy 2000-2003
+Copyright Aleksey Gurtovoy 2000-2004
+Copyright Aleksey Gurtovoy 2000-2006
+Copyright Aleksey Gurtovoy 2000-2008
+Copyright Aleksey Gurtovoy 2000-2009
+Copyright Aleksey Gurtovoy 2000-2010
+Copyright Aleksey Gurtovoy 2001-2004
+Copyright Aleksey Gurtovoy 2001-2006
+Copyright Aleksey Gurtovoy 2001-2007
+Copyright Aleksey Gurtovoy 2001-2008
+Copyright Aleksey Gurtovoy 2002-2004
+Copyright Aleksey Gurtovoy 2002-2006
+Copyright Aleksey Gurtovoy 2003-2004
+Copyright Aleksey Gurtovoy 2003-2007
+Copyright Andrii Sydorchuk 2010-2012
+Copyright Antony Polukhin, 2011-2020
+Copyright Antony Polukhin, 2013-2014
+Copyright Antony Polukhin, 2013-2020
+Copyright Antony Polukhin, 2016-2019
+Copyright Antony Polukhin, 2016-2020
+Copyright Christopher Kormanyos 2013
+Copyright Christopher Kormanyos 2014
+Copyright Matthew Pulver 2018 - 2019
+Copyright Paul A. Bristow 2006, 2007
+Copyright Paul A. Bristow 2007, 2009
+Copyright Paul A. Bristow 2007, 2010
+Copyright Paul A. Bristow 2007, 2012
+Copyright Paul A. Bristow 2008, 2009
+Copyright Paul A. Bristow 2008, 2010
+Copyright Paul A. Bristow 2008, 2014
+Copyright Paul A. Bristow 2009, 2011
+Copyright Paul A. Bristow 2011, 2012
+Copyright Steven J. Ross 2001 - 2009
+Copyright Steven J. Ross 2001 - 2014
+Copyright Thorsten Ottosen 2003-2004
+Copyright Thorsten Ottosen 2003-2005
+Copyright Thorsten Ottosen 2003-2006
+Copyright Thorsten Ottosen 2003-2007
+Copyright Thorsten Ottosen 2003-2008
+copyright 2004 Brian Ravnsgaard Riis
+(c) Copyright 2005-7 Anthony Williams
+(c) Copyright 2005-8 Anthony Williams
+(c) Copyright 2006-7 Anthony Williams
+(c) Copyright 2006-8 Anthony Williams
+(c) Copyright 2007-2009 Andrew Sutton
+(c) Copyright 2007-8 Anthony Williams
+(c) Copyright 2007-9 Anthony Williams
+(c) Copyright 2008-9 Anthony Williams
+(c) Copyright 2009-2011 Frederic Bron
+(c) Copyright Beman Dawes 2001 - 2003
+(c) Copyright Beman Dawes 2002 - 2003
+(c) Copyright Darin Adler 2001 - 2002
+(c) Copyright Daryle Walker 2000-2001
+(c) Copyright Daryle Walker 2001-2002
+(c) Copyright Edward Diener 2011,2012
+(c) Copyright Edward Diener 2011,2013
+(c) Copyright Edward Diener 2011,2014
+(c) Copyright Edward Diener 2011-2015
+(c) Copyright Edward Diener 2011-2020
+(c) Copyright Edward Diener 2012,2013
+(c) Copyright Edward Diener 2014,2019
+(c) Copyright Eric Friedman 2002-2003
+(c) Copyright Ion Gaztanaga 2004-2015
+(c) Copyright Ion Gaztanaga 2005-2012
+(c) Copyright Ion Gaztanaga 2005-2013
+(c) Copyright Ion Gaztanaga 2005-2014
+(c) Copyright Ion Gaztanaga 2005-2015
+(c) Copyright Ion Gaztanaga 2005-2016
+(c) Copyright Ion Gaztanaga 2006-2012
+(c) Copyright Ion Gaztanaga 2006-2013
+(c) Copyright Ion Gaztanaga 2006-2014
+(c) Copyright Ion Gaztanaga 2006-2015
+(c) Copyright Ion Gaztanaga 2007-2012
+(c) Copyright Ion Gaztanaga 2007-2013
+(c) Copyright Ion Gaztanaga 2007-2014
+(c) Copyright Ion Gaztanaga 2008-2012
+(c) Copyright Ion Gaztanaga 2008-2013
+(c) Copyright Ion Gaztanaga 2008-2015
+(c) Copyright Ion Gaztanaga 2009-2012
+(c) Copyright Ion Gaztanaga 2009-2013
+(c) Copyright Ion Gaztanaga 2010-2012
+(c) Copyright Ion Gaztanaga 2010-2013
+(c) Copyright Ion Gaztanaga 2010-2016
+(c) Copyright Ion Gaztanaga 2011-2012
+(c) Copyright Ion Gaztanaga 2011-2013
+(c) Copyright Ion Gaztanaga 2011-2014
+(c) Copyright Ion Gaztanaga 2012-2012
+(c) Copyright Ion Gaztanaga 2012-2013
+(c) Copyright Ion Gaztanaga 2012-2015
+(c) Copyright Ion Gaztanaga 2012-2016
+(c) Copyright Ion Gaztanaga 2013-2013
+(c) Copyright Ion Gaztanaga 2013-2014
+(c) Copyright Ion Gaztanaga 2014-2014
+(c) Copyright Ion Gaztanaga 2014-2015
+(c) Copyright Ion Gaztanaga 2014-2017
+(c) Copyright Ion Gaztanaga 2015-2015
+(c) Copyright Ion Gaztanaga 2015-2016
+(c) Copyright Ion Gaztanaga 2015-2017
+(c) Copyright Ion Gaztanaga 2016-2016
+(c) Copyright Ion Gaztanaga 2017-2017
+(c) Copyright Ion Gaztanaga 2017-2018
+(c) Copyright Ion Gaztanaga 2018-2018
+(c) Copyright Ion Gaztanaga 2019-2020
+(c) Copyright Jens Maurer 2001 - 2002
+(c) Copyright Jens Maurer 2001 - 2003
+(c) Copyright Jens Maurer 2002 - 2003
+(c) Copyright John Maddock 2006, 2015
+(c) Copyright Toon Knapen 2001 - 2003
+Copyright (c) 2001-2003 Daniel Nuffer
+Copyright (c) 2002 Raghavendra Satish
+Copyright (c) 2002-2003 Eric Friedman
+Copyright (c) 2003-2004 Gennaro Prota
+Copyright (c) 2004 Kristopher Beevers
+Copyright (c) 2005, 2014 Eric Niebler
+Copyright (c) 2005-2006 Joao Abecasis
+Copyright (c) 2006, Stephan Diederich
+Copyright (c) 2007 - Sebastien Fabbro
+Copyright (c) 2007, 2008, Damian Eads
+Copyright (c) 2007, 2013 John Maddock
+Copyright (c) 2007-8 Anthony Williams
+Copyright (c) 2007-9 Anthony Williams
+Copyright (c) 2008-2011 Bruno Lalande
+Copyright (c) 2008-2012 Bruno Lalande
+Copyright (c) 2008-2013 Bruno Lalande
+Copyright (c) 2008-2013 Tim Blechmann
+Copyright (c) 2008-2014 Bruno Lalande
+Copyright (c) 2008-2015 Bruno Lalande
+Copyright (c) 2008-2016 Tim Blechmann
+Copyright (c) 2008-2017 Bruno Lalande
+Copyright (c) 2009-2011 Artyom Beilis
+Copyright (c) 2009-2013 Tim Blechmann
+Copyright (c) 2010-2011 Bryce Lelbach
+Copyright (c) 2010-2011 Thomas Heller
+Copyright (c) 2010-2011 Tim Blechmann
+Copyright (c) 2011 Jan Frederick Eick
+Copyright (c) 2011 Paul A. Bristow To
+Copyright (c) 2011-2012 Bruno Lalande
+Copyright (c) 2012-2014 Bruno Lalande
+Copyright (c) 2013-2014 Agustin Berge
+Copyright (c) 2013-2014 Ion Gaztanaga
+Copyright (c) 2014 Mathjax Consortium
+Copyright (c) 2014-2015 Bruno Lalande
+Copyright (c) 2014-2015 John Fletcher
+Copyright (c) 2015-2017 Martin Hensel
+Copyright (c) 2016 2017 Felix Lenders
+Copyright (c) 2019 Max-Planck-Society
+Copyright (c) Marshall Clow 2008-2012
+Copyright (c) Marshall Clow 2010-2012
+Copyright (c) Marshall Clow 2011-2012
+Copyright (c) Marshall Clow 2012-2012
+Copyright (c) Marshall Clow 2012-2015
+Copyright 2007-2008 Christian Henning
+Copyright 2016 Klemens D. Morgenstern
+Copyright 2017 Valentin Noah Hartmann
+Copyright Andrey Semashev 2007 - 2013
+Copyright Andrey Semashev 2007 - 2014
+Copyright Andrey Semashev 2007 - 2015
+Copyright Andrey Semashev 2007 - 2016
+Copyright Andrey Semashev 2018 - 2020
+Copyright Beman Dawes 1994-2007, 2011
+Copyright Beman Dawes 2002-2005, 2009
+copyright Gonzalo Brito Gadeschi 2015
+(c) Copyright 2007-10 Anthony Williams
+(c) Copyright 2008-10 Anthony Williams
+(c) Copyright Benedek Thaler 2015-2016
+(c) Copyright Daryle Walker 2001, 2006
+(c) Copyright Guillaume Melquiond 2003
+(c) Copyright Howard Hinnant 2007-2010
+(c) Copyright John Maddock 2001 - 2002
+(c) Copyright John Maddock 2001 - 2003
+(c) Copyright John Maddock 2002 - 2003
+(c) Copyright Nicolai M. Josuttis 2001
+(c) Copyright Olaf Krzikalla 2004-2006
+(c) Copyright Vicente J. Botet Escriba
+(c) Rasmus Munk Larsen, Stanford, 2004
+Copyright (c) 1998-2003 Joel de Guzman
+Copyright (c) 1998-2008 Joel de Guzman
+Copyright (c) 2001-2002 Joel de Guzman
+Copyright (c) 2001-2003 Hartmut Kaiser
+Copyright (c) 2001-2003 Joel de Guzman
+Copyright (c) 2001-2007 Hartmut Kaiser
+Copyright (c) 2001-2007 Joel de Guzman
+Copyright (c) 2001-2008 Hartmut Kaiser
+Copyright (c) 2001-2008 Joel de Guzman
+Copyright (c) 2001-2009 Joel de Guzman
+Copyright (c) 2001-2010 Hartmut Kaiser
+Copyright (c) 2001-2010 Joel de Guzman
+Copyright (c) 2001-2011 Hartmut Kaiser
+Copyright (c) 2001-2011 Joel de Guzman
+Copyright (c) 2001-2011 Thomas Bernard
+Copyright (c) 2001-2012 Hartmut Kaiser
+Copyright (c) 2001-2012 Joel de Guzman
+Copyright (c) 2001-2013 Hartmut Kaiser
+Copyright (c) 2001-2013 Joel de Guzman
+Copyright (c) 2001-2014 Joel de Guzman
+Copyright (c) 2001-2015 Joel de Guzman
+Copyright (c) 2001-2019 Joel de Guzman
+Copyright (c) 2002-2003 David Abrahams
+Copyright (c) 2002-2003 Hartmut Kaiser
+Copyright (c) 2002-2003 Joel de Guzman
+Copyright (c) 2002-2006 Hartmut Kaiser
+Copyright (c) 2004 Jonathan Brandmeyer
+Copyright (c) 2005-2006 Alain Miniussi
+Copyright (c) 2005-2006 Douglas Gregor
+Copyright (c) 2005-2008 Hartmut Kaiser
+Copyright (c) 2005-2010 Joel de Guzman
+Copyright (c) 2005-2011 Joel de Guzman
+Copyright (c) 2005-2012 Joel de Guzman
+Copyright (c) 2005-2013 Joel de Guzman
+Copyright (c) 2007-2011 Hartmut Kaiser
+Copyright (c) 2008, 2016 Tim Blechmann
+Copyright (c) 2008-2011 Hartmut Kaiser
+Copyright (c) 2009 Christopher Schmidt
+Copyright (c) 2009, 2011 Helge Bahmann
+Copyright (c) 2009, 2016 Tim Blechmann
+Copyright (c) 2009-2010 Hartmut Kaiser
+Copyright (c) 2009-2020 Vladimir Batov
+Copyright (c) 2010 Christopher Schmidt
+Copyright (c) 2011, 2016 Tim Blechmann
+Copyright (c) 2011-2012 ! Brandon Kohn
+Copyright (c) 2011-2012 Thomas Bernard
+Copyright (c) 2012, Jaydeep P. Bardhan
+Copyright (c) 2012, Matthew G. Knepley
+Copyright (c) 2014 Riccardo Marcangelo
+Copyright (c) 2014, Janani Padmanabhan
+Copyright (c) 2015 Andrzej Krzemienski
+Copyright (c) 2016 Andrzej Krzemienski
+Copyright (c) 2016-2019 Viktor Kirilov
+Copyright (c) 2017 Andrzej Krzemienski
+Copyright (c) 2020 Krystian Stasiowski
+Copyright (c) 2022 Two Blue Cubes Ltd.
+Copyright (c) Christopher Diggins 2005
+Copyright 2002, 2009, 2014 Peter Dimov
+Copyright 2004-2005 by Enthought, Inc.
+Copyright 2007 University of Karlsruhe
+Copyright 2015, 2017, 2019 Peter Dimov
+Copyright 2016, 2018, 2019 Peter Dimov
+Copyright Alexander Nasonov, 2006-2010
+Copyright Beman Dawes 1994, 2006, 2008
+Copyright Beman Dawes 2003, 2006, 2008
+Copyright Beman Dawes 2003, 2006, 2010
+Copyright Beman Dawes 2003, 2006, 2011
+Copyright Beman Dawes 2010, 2011, 2014
+Copyright John Maddock 2005-2006, 2011
+Copyright John Maddock 2006-7, 2013-14
+Copyright Peter Dimov 2017, 2018, 2020
+copyright 2008- s, The SciPy community
+(c) Copyright 2005-2006 Matthias Troyer
+(c) Copyright 2005-2007 Matthias Troyer
+(c) Copyright Boris Gubenko 2006 - 2007
+(c) Copyright Gennaro Prota 2003 - 2004
+(c) Copyright Paul Mensonides 2002-2011
+Copyright (c) 1989-2004 Johannes Braams
+Copyright (c) 1994 by Xerox Corporation
+Copyright (c) 1996-2008 Rice University
+Copyright (c) 1998-2000 Dr John Maddock
+Copyright (c) 2000, 2001 Stephen Cleary
+Copyright (c) 2001-2009, Hartmut Kaiser
+Copyright (c) 2005, 2006 Douglas Gregor
+Copyright (c) 2007-2008 Steven Watanabe
+Copyright (c) 2007-2009 Steven Watanabe
+Copyright (c) 2007-2010 Steven Watanabe
+Copyright (c) 2008-2009 Frank Mori Hess
+Copyright (c) 2009-2010, Marco Guazzone
+Copyright (c) 2009-2012, Marco Guazzone
+Copyright (c) 2010 Thomas P. Robitaille
+Copyright (c) 2011-2015 Akira Takahashi
+Copyright (c) 2011-2020 Antony Polukhin
+Copyright (c) 2012 Pieter Bastiaan Ober
+Copyright (c) 2012-2014 Kohei Takahashi
+Copyright (c) 2012-2020 Antony Polukhin
+Copyright (c) 2013-2020 Antony Polukhin
+Copyright (c) 2014 Pieter Bastiaan Ober
+Copyright (c) 2014, Andrzej Krzemienski
+Copyright (c) 2014,2018 Kohei Takahashi
+Copyright (c) 2014-2015 Kohei Takahashi
+Copyright (c) 2014-2020 Andrey Semashev
+Copyright (c) 2014-2020 Antony Polukhin
+Copyright (c) 2015-2020 Antony Polukhin
+Copyright (c) 2016-2020 Antony Polukhin
+Copyright (c) 2018-2020 Antony Polukhin
+Copyright (c) 2019-2020 Alexander Grund
+Copyright (c) 2019-2020 Antony Polukhin
+Copyright 2000 University of Notre Dame
+Copyright 2001 University of Notre Dame
+Copyright 2002-2003 Guillaume Melquiond
+Copyright 2009 Vicente J. Botet Escriba
+Copyright 2010 Vicente J. Botet Escriba
+Copyright 2011 Vicente J. Botet Escriba
+Copyright 2012 Vicente J. Botet Escriba
+Copyright 2019-20 Christopher Kormanyos
+Copyright Christopher Kormanyos 2013-14
+Copyright Paul A. Bristow 2007, 2013-14
+Copyright Ralf W. Grosse-Kunstleve 2006
+Copyright Vicente J. Botet Escriba 2009
+Copyright Vicente J. Botet Escriba 2010
+Copyright Vicente J. Botet Escriba 2012
+(c) Copyright 2007-2010 Anthony Williams
+(c) Copyright 2009-2012 Anthony Williams
+(c) Copyright 2013, 2020 Andrey Semashev
+(c) Copyright Christopher Jefferson 2011
+(c) Copyright David Abrahams 2001 - 2002
+(c) Copyright David Abrahams 2002 - 2003
+(c) Copyright Jeremy William Murphy 2015
+(c) Copyright Jeremy William Murphy 2016
+(c) Copyright Microsoft Corporation 2014
+(c) Copyright R.W. Grosse-Kunstleve 2002
+(c) Copyright Thorsten Ottosen 2002-2003
+Copyright (arg) 2001-2014 Joel de Guzman
+Copyright (c) 2001, 2002 Enthought, Inc.
+Copyright (c) 2001-2003 William E. Kempf
+Copyright (c) 2003, 2007-14 Matteo Frigo
+Copyright (c) 2003-2005 Peter J. Verveer
+Copyright (c) 2004-2008 Rene Nyffenegger
+Copyright (c) 2006-2007 Matias Capeletto
+Copyright (c) 2006-2007 Tobias Schwinger
+Copyright (c) 2007-2008 Tobias Schwinger
+Copyright (c) 2008 Federico J. Fernandez
+Copyright (c) 2008-2012 Simonson Lucanus
+Copyright (c) 2008-2018 Lorenzo Caminiti
+Copyright (c) 2008-2019 Lorenzo Caminiti
+Copyright (c) 2009-2012 Lorenzo Caminiti
+Copyright (c) 2010 Athanasios Iliopoulos
+Copyright (c) 2011 Christopher Jefferson
+Copyright (c) 2012-2012 Andrii Sydorchuk
+Copyright (c) 2013 Christopher Kormanyos
+Copyright (c) 2014, 2019 Andrey Semashev
+Copyright (c) 2014, 2020 Andrey Semashev
+Copyright (c) 2015 Agustin K-ballo Berge
+Copyright (c) 2016-2018 T. Zachary Laine
+Copyright (c) Microsoft Corporation 2014
+Copyright 2001, 2004, 2011 Daryle Walker
+Copyright 2002-2006 Andreas Huber Doenni
+Copyright 2002-2007 Andreas Huber Doenni
+Copyright 2002-2008 Andreas Huber Doenni
+Copyright 2002-2010 Andreas Huber Doenni
+Copyright 2002-2016 The SciPy Developers
+Copyright 2005-2006 Andreas Huber Doenni
+Copyright 2005-2008 Andreas Huber Doenni
+Copyright 2010-2012, D. E. Shaw Research
+Copyright 2012-2013 Andreas Angelopoulos
+Copyright Gottfried Ganssauge 2003..2006
+(c) Copyright 2003-2007 Jonathan Turkanis
+(c) Copyright 2004-2007 Jonathan Turkanis
+(c) Copyright 2005-2007 Jonathan Turkanis
+(c) Copyright Jonathan Turkanis 2004-2005
+(c) Copyright Samuli-Petrus Korhonen 2017
+CNRS/Univ. Clermont II Copyright 2014 LRI
+Copyright (c) 1999-2003 Jeremiah Willcock
+Copyright (c) 2001 by Andrei Alexandrescu
+Copyright (c) 2001-2009, 2012 Peter Dimov
+Copyright (c) 2002 by Andrei Alexandrescu
+Copyright (c) 2002-2006 Marcin Kalicinski
+Copyright (c) 2002-2007 Marcin Kalicinski
+Copyright (c) 2004, 2005 Arkadiy Vertleyb
+Copyright (c) 2005-2022, NumPy Developers
+Copyright (c) 2007-2009 Joachim Faulhaber
+Copyright (c) 2007-2010 Joachim Faulhaber
+Copyright (c) 2007-2011 Joachim Faulhaber
+Copyright (c) 2007-2012 Joachim Faulhaber
+Copyright (c) 2008-2009 Joachim Faulhaber
+Copyright (c) 2008-2010 Joachim Faulhaber
+Copyright (c) 2008-2011 Joachim Faulhaber
+Copyright (c) 2008-2012 Joachim Faulhaber
+Copyright (c) 2009-2009 Joachim Faulhaber
+Copyright (c) 2009-2010 Joachim Faulhaber
+Copyright (c) 2009-2011 Joachim Faulhaber
+Copyright (c) 2010-2010 Joachim Faulhaber
+Copyright (c) 2010-2011 Joachim Faulhaber
+Copyright (c) 2011-2011 Joachim Faulhaber
+Copyright (c) 2012 - 2014 Andrey Semashev
+Copyright (c) 2013 - 2014 Andrey Semashev
+Copyright (c) 2013 - 2020 Andrey Semashev
+Copyright (c) 2014, Athanasios Iliopoulos
+Copyright (c) 2016 Klemens D. Morgenstern
+Copyright (c) 2017 - 2018 Andrey Semashev
+Copyright (c) 2017 Klemens D. Morgenstern
+Copyright (c) 2018 Klemens D. Morgenstern
+Copyright (c) 2019 - 2020 Alexander Grund
+Copyright (c) 2019 Klemens D. Morgenstern
+Copyright 2006 Eric Niebler, Olivier Gygi
+Copyright 2006 Michael van der Westhuizen
+Copyright 2008 Adobe Systems Incorporated
+Copyright Arno Schoedl & Neil Groves 2009
+Copyright Kevlin Henney, 2000, 2001, 2002
+copyright (c) 1995-2010 Geodan, Amsterdam
+(c) Copyright 2011Vicente J. Botet Escriba
+(c) Copyright Aleksey Gurtovoy 2002 - 2003
+(c) Copyright Beman Dawes 2006, 2009, 2014
+(c) Copyright Edward Diener 2011,2012,2013
+(c) Copyright Edward Diener 2011,2012,2019
+(c) Copyright Edward Diener 2011-2015,2019
+(c) Copyright Edward Diener 2012,2013,2019
+(c) Copyright Peter Dimov 2001, 2002, 2003
+Copyright (c) 1994 Hewlett-Packard Company
+Copyright (c) 2000 Cadenza New Zealand Ltd
+Copyright (c) 2001, 2002, 2003 Peter Dimov
+Copyright (c) 2001, 2002, 2012 Peter Dimov
+Copyright (c) 2002, 2008, 2013 Peter Dimov
+Copyright (c) 2002, 2009, 2014 Peter Dimov
+Copyright (c) 2002, 2018, 2019 Peter Dimov
+Copyright (c) 2003, 2006 Gerald I. Evenden
+Copyright (c) 2005-2015, Michele Simionato
+Copyright (c) 2006, 2009 Marcin Kalicinski
+Copyright (c) 2006-2008 Alexander Chemeris
+Copyright (c) 2007, 2008, 2012 Peter Dimov
+Copyright (c) 2010-2019 Max-Planck-Society
+Copyright (c) 2010-2020 Max-Planck-Society
+Copyright (c) 2017, 2018 James E. King III
+Copyright 1984, 1995 by Stephen L. Moshier
+Copyright 1984, 1996 by Stephen L. Moshier
+Copyright 2005 Daniel Egloff, Eric Niebler
+Copyright 2005 Daniel Egloff, Olivier Gygi
+Copyright 2005 Eric Niebler, Daniel Egloff
+Copyright 2006 Daniel Egloff, Olivier Gygi
+Copyright 2006 Olivier Gygi, Daniel Egloff
+Copyright 2006, Eric Niebler, Olivier Gygi
+Copyright 2010 Daniel Wallin, Eric Niebler
+Copyright 2015-2018 Klemens D. Morgenstern
+Copyright Nick Thompson, John Maddock 2020
+Copyright Paul A. Bristow 2006, 2007, 2012
+Copyright Paul A. Bristow 2006, 2012, 2017
+Copyright Paul A. Bristow 2016, 2017, 2018
+Portions Copyright (c) 2002 David Abrahams
+(c) Copyright 2010 Vicente J. Botet Escriba
+(c) Copyright 2011 Vicente J. Botet Escriba
+(c) Copyright 2012 Vicente J. Botet Escriba
+(c) Copyright 2013 Vicente J. Botet Escriba
+(c) Copyright 2014 Vicente J. Botet Escriba
+(c) Copyright Eric Ford & Hubert Holin 2001
+(c) Copyright Eric Ford 2001 & Hubert Holin
+(c) Copyright Markus Schoepflin 2002 - 2003
+(c) Copyright Vicente J. Botet Escriba 2010
+(c) Copyright Vicente J. Botet Escriba 2014
+(c) Rasmus Munk Larsen, Stanford University
+Copyright (c) 1993-2019 The Geometry Center
+Copyright (c) 2003-2004, 2008 Gennaro Prota
+Copyright (c) 2003-2006, 2008 Gennaro Prota
+Copyright (c) 2009-2010 Christopher Schmidt
+Copyright (c) 2009-2011 Christopher Schmidt
+Copyright (c) 2010-2011 Christopher Schmidt
+Copyright (c) 2011 Vicente J. Botet Escriba
+Copyright (c) 2011-2013, 2016 Tim Blechmann
+Copyright (c) 2012 Vicente J. Botet Escriba
+Copyright (c) 2013 Vicente J. Botet Escriba
+Copyright (c) 2014 Vicente J. Botet Escriba
+Copyright (c) 2014-2016 Andrzej Krzemienski
+Copyright (c) 2015 Vicente J. Botet Escriba
+Copyright (c) 2015-2018 Andrzej Krzemienski
+Copyright (c) 2017 Vicente J. Botet Escriba
+Copyright (c) 2019-2020 Krystian Stasiowski
+Copyright 1984 - 1994 by Stephen L. Moshier
+Copyright 1985 by Stephen L. Moshier Direct
+Copyright 2002 Brad King and Douglas Gregor
+Copyright 2012 (c) Jeffrey Lee Hellrung, Jr
+Copyright Christopher Kormanyos 2002 - 2011
+Copyright Christopher Kormanyos 2002 - 2013
+(c) Rasmus Munk Larsen, Stanford, 1999, 2004
+Copyright (c) 2001-2011 - Scilab Enterprises
+Copyright (c) 2002 Eric Friedman, Itay Maman
+Copyright (c) 2002 Juan Carlos Arevalo-Baeza
+Copyright (c) 2003 Eric Friedman, Itay Maman
+Copyright (c) 2008, 2009, 2016 Tim Blechmann
+Copyright (c) 2010 - Jordi Gutierrez Hermoso
+Copyright (c) 2012 Barend Gehrels, Amsterdam
+Copyright (c) 2013 Barend Gehrels, Amsterdam
+Copyright (c) 2014 Barend Gehrels, Amsterdam
+Copyright (c) 2014, 2015 Andrzej Krzemienski
+Copyright (c) 2014,2015,2018 Kohei Takahashi
+Copyright (c) 2015 Barend Gehrels, Amsterdam
+Copyright (c) 2017 Barend Gehrels, Amsterdam
+Copyright (c) 2019 Barend Gehrels, Amsterdam
+Copyright (c) 2020 Barend Gehrels, Amsterdam
+Copyright 1997-2001 University of Notre Dame
+Copyright 2009-2010 Vicente J. Botet Escriba
+Copyright 2009-2011 Vicente J. Botet Escriba
+Copyright 2009-2012 Vicente J. Botet Escriba
+Copyright Beman Dawes and Daryle Walker 1999
+Copyright Daniel Wallin, David Abrahams 2005
+Copyright Daniel Wallin, David Abrahams 2010
+Copyright David Abrahams, Daniel Wallin 2003
+Copyright David Abrahams, Daniel Wallin 2005
+Copyright Thorsten Ottosen, Neil Groves 2006
+Copyright Vicente J. Botet Escriba 2009-2011
+(c) Copyright Guillaume Melquiond 2002 - 2003
+(c) Copyright Joaquin M Lopez Munoz 2006-2013
+Copyright (c) 2011-2014, The OpenBLAS Project
+Copyright (c) 2013-2014, 2020 Andrey Semashev
+Copyright (c) 2014 - 2018 Andrzej Krzemienski
+Copyright (c) 2014-2018, 2020 Andrey Semashev
+Copyright (c) 2015 - 2017 Andrzej Krzemienski
+Copyright 2000 Jeremy Siek (jsiek@lsc.nd.edu)
+Copyright 2005 Eric Niebler, Michael Gauckler
+Copyright 2005 Trustees of Indiana University
+Copyright 2006 Trustees of Indiana University
+Copyright 2009 Trustees of Indiana University
+Copyright David Abrahams and Jeremy Siek 2003
+Copyright John Maddock 2006, 2007, 2012, 2014
+Copyright Peter Dimov and David Abrahams 2002
+Copyright (c) 2004 CrystalClear Software, Inc.
+Copyright (c) 2005 CrystalClear Software, Inc.
+Copyright (c) 2006 CrystalClear Software, Inc.
+Copyright (c) 2006, 2007 Julio M. Merino Vidal
+Copyright (c) 2009-2017 The MathJax Consortium
+Copyright (c) 2010-2017 The MathJax Consortium
+Copyright (c) 2011 Jeff Flinn, Boris Schaeling
+Copyright (c) 2011-2015 The MathJax Consortium
+Copyright (c) 2011-2017 The MathJax Consortium
+Copyright (c) 2012 Mateusz Loskot, London, UK.
+Copyright (c) 2013 Mateusz Loskot, London, UK.
+Copyright (c) 2013-2017 The MathJax Consortium
+Copyright (c) 2014 Mateusz Loskot, London, UK.
+Copyright (c) 2014-2017 The MathJax Consortium
+Copyright (c) 2015-2017 The MathJax Consortium
+Copyright (c) 2016 Modified Work Barrett Adair
+Copyright (c) 2016-2017 The MathJax Consortium
+Copyright 2001, 2003, 2004, 2012 Daryle Walker
+Copyright 2005-2007 Adobe Systems Incorporated
+Copyright 2011 Garmin Ltd. or its subsidiaries
+Copyright 2012 Chung-Lin Wen, Davide Anastasia
+Copyright J.S. Roy (js@jeannot.org), 2002-2005
+(c) Copyright Daniel Frey and Robert Ramey 2009
+Copyright (c) 1995 Maarten Hilferink, Amsterdam
+Copyright (c) 2002 Brad King and Douglas Gregor
+Copyright (c) 2003 Gunter Winkler, Joerg Walter
+Copyright (c) 2003-2011 Christopher M. Kohlhoff
+Copyright (c) 2003-2020 Christopher M. Kohlhoff
+Copyright (c) 2005 Arkadiy Vertleyb, Peder Holt
+Copyright (c) 2005 Voipster / Indrek dot Juhani
+Copyright (c) 2005-2020 Christopher M. Kohlhoff
+Copyright (c) 2006-2009, 2012 Alexander Nasonov
+Copyright (c) 2009, Pauli Virtanen <pav@iki.fi>
+Copyright (c) 2012 - 2014, 2017 Andrey Semashev
+Copyright (c) 2013 - 2018, 2020 Andrey Semashev
+Copyright (c) 2013 Tim Blechmann Linux-specific
+Copyright (c) 2015 Oracle and/or its affiliates
+Copyright (c) 2015, Pauli Virtanen <pav@iki.fi>
+Copyright (c) 2016 Oracle and/or its affiliates
+Copyright (c) 2017 Oracle and/or its affiliates
+Copyright (c) 2018 Oracle and/or its affiliates
+Copyright (c) 2019 Oracle and/or its affiliates
+Copyright (c) 2020 Oracle and/or its affiliates
+Copyright 2002 Rensselaer Polytechnic Institute
+Copyright 2004-9 Trustees of Indiana University
+Copyright 2010 Fabien Castan, Christian Henning
+Copyright 2010 Gaetano Mendola, 2011 Simon West
+copyright (c) 2014 Oracle and/or its affiliates
+copyright (c) 2015 Oracle and/or its affiliates
+copyright (c) 2016 Oracle and/or its affiliates
+copyright (c) 2017 Oracle and/or its affiliates
+copyright (c) 2018 Oracle and/or its affiliates
+copyright (c) 2019 Oracle and/or its affiliates
+copyright (c) 2020 Oracle and/or its affiliates
+(c) Copyright 2004 Robert Ramey and Martin Ecker
+(c) Copyright 2009-2012 Vicente J. Botet Escriba
+(c) Copyright 2010-2011 Vicente J. Botet Escriba
+(c) Copyright 2011-2012 Vicente J. Botet Escriba
+(c) Copyright 2011-2013 Vicente J. Botet Escriba
+(c) Copyright 2011-2015 Vicente J. Botet Escriba
+(c) Copyright 2013,2014 Vicente J. Botet Escriba
+(c) Copyright 2013,2015 Vicente J. Botet Escriba
+(c) Copyright David Abrahams, Vicente Botet 2009
+(c) Copyright Eric Jourdanneau, Joel Falcou 2010
+(c) Copyright John Maddock and Steve Cleary 2000
+(c) Copyright Vicente J. Botet Escriba 2013-2014
+(c) Copyright Vicente J. Botet Escriba 2013-2017
+(c) Copyright Vicente J. Botet Escriba 2014-2015
+CNRS/Univ. Clermont II Copyright 2009 - 2011 LRI
+Copyright (c) 2001, Thomas Flemming, tf@ttqv.com
+Copyright (c) 2003-2004 Jeremy B. Maitin-Shepard
+Copyright (c) 2008 Ilya Sokolov, Boris Schaeling
+Copyright (c) 2009, Spirent Communications, Inc.
+Copyright (c) 2010 Eric Jourdanneau, Joel Falcou
+Copyright (c) 2010 Felipe Tanus, Boris Schaeling
+Copyright (c) 2010 Nuovation System Designs, LLC
+Copyright (c) 2011-2012 Vicente J. Botet Escriba
+Copyright (c) 2011-2013 Vicente J. Botet Escriba
+Copyright (c) 2012-2013 Vicente J. Botet Escriba
+Copyright (c) 2013 Adam Wulkiewicz, Lodz, Poland
+Copyright (c) 2013 John Maddock, Antony Polukhin
+Copyright (c) 2013,2014 Vicente J. Botet Escriba
+Copyright (c) 2013-2014 Vicente J. Botet Escriba
+Copyright (c) 2014 Adam Wulkiewicz, Lodz, Poland
+Copyright (c) 2014, 2015, 2016, 2017 Jarryd Beck
+Copyright (c) 2014, Oracle and/or its affiliates
+Copyright (c) 2014-2015 Vicente J. Botet Escriba
+Copyright (c) 2014-2017 Vicente J. Botet Escriba
+Copyright (c) 2015, Oracle and/or its affiliates
+Copyright (c) 2016, Oracle and/or its affiliates
+Copyright (c) 2017 Adam Wulkiewicz, Lodz, Poland
+Copyright (c) 2017, Oracle and/or its affiliates
+Copyright (c) 2018 Adam Butcher, Antony Polukhin
+Copyright (c) 2018 Adam Wulkiewicz, Lodz, Poland
+Copyright (c) 2018, Oracle and/or its affiliates
+Copyright (c) 2019, Oracle and/or its affiliates
+Copyright (c) 2020, Oracle and/or its affiliates
+Copyright 1984, 1987, 1995 by Stephen L. Moshier
+Copyright 1984, 1987, 2000 by Stephen L. Moshier
+Copyright 1984, 1995, 2000 by Stephen L. Moshier
+Copyright 1985, 1987, 2000 by Stephen L. Moshier
+Copyright 2003 Guillaume Melquiond, Sylvain Pion
+Copyright Justinas Vygintas Daugmaudis 2010-2018
+Copyright Paul A. Bristow 2006, 2007, 2009, 2010
+Copyright Paul A. Bristow 2007, 2009, 2010, 2012
+Copyright Paul A. Bristow 2007, 2010, 2012, 2014
+copyright (c) 2013, Oracle and/or its affiliates
+copyright (c) 2014, Oracle and/or its affiliates
+copyright (c) 2015, Oracle and/or its affiliates
+copyright (c) 2016, Oracle and/or its affiliates
+copyright (c) 2017, Oracle and/or its affiliates
+copyright (c) 2018, Oracle and/or its affiliates
+copyright (c) 2020, Oracle and/or its affiliates
+(c) Rasmus Munk Larsen, Stanford University, 2000
+(c) Rasmus Munk Larsen, Stanford University, 2004
+Copyright (c) 2002-2003 Eric Friedman, Itay Maman
+Copyright (c) 2006 Trustees of Indiana University
+Copyright (c) 2007 Trustees of Indiana University
+Copyright (c) 2007-2011 Barend Gehrels, Amsterdam
+Copyright (c) 2007-2012 Barend Gehrels, Amsterdam
+Copyright (c) 2007-2013 Barend Gehrels, Amsterdam
+Copyright (c) 2007-2014 Barend Gehrels, Amsterdam
+Copyright (c) 2007-2015 Barend Gehrels, Amsterdam
+Copyright (c) 2007-2016 Barend Gehrels, Amsterdam
+Copyright (c) 2007-2017 Barend Gehrels, Amsterdam
+Copyright (c) 2007-2020 Barend Gehrels, Amsterdam
+Copyright (c) 2008-2012 Barend Gehrels, Amsterdam
+Copyright (c) 2008-2014 Barend Gehrels, Amsterdam
+Copyright (c) 2008-2015 Barend Gehrels, Amsterdam
+Copyright (c) 2009 Trustees of Indiana University
+Copyright (c) 2009-2012 Barend Gehrels, Amsterdam
+Copyright (c) 2009-2015 Barend Gehrels, Amsterdam
+Copyright (c) 2010-2012 Barend Gehrels, Amsterdam
+Copyright (c) 2011-2012 Barend Gehrels, Amsterdam
+Copyright (c) 2011-2015 Barend Gehrels, Amsterdam
+Copyright (c) 2012-2014 Barend Gehrels, Amsterdam
+Copyright (c) 2012-2015 Barend Gehrels, Amsterdam
+Copyright (c) 2012-2020 Barend Gehrels, Amsterdam
+Copyright (c) 2014-2015 Barend Gehrels, Amsterdam
+Copyright (c) 2015-2016 Barend Gehrels, Amsterdam
+Copyright (c) 2015-2020 Barend Gehrels, Amsterdam
+Copyright (c) 2017-2017 Barend Gehrels, Amsterdam
+Copyright (c) 2018-2019 Barend Gehrels, Amsterdam
+Copyright (c) 2019-2019 Barend Gehrels, Amsterdam
+Copyright 1984, 1987 by Stephen L. Moshier Direct
+Copyright 1984, 1991 by Stephen L. Moshier Direct
+Copyright 1985, 1987 by Stephen L. Moshier Direct
+Copyright 2002 The Trustees of Indiana University
+Copyright 2003 The Trustees of Indiana University
+Copyright 2004 The Trustees of Indiana University
+Copyright 2005 Felix Hofling, Guillaume Melquiond
+Copyright 2005 The Trustees of Indiana University
+Copyright 2006 The Trustees of Indiana University
+Copyright 2008 Christian Henning, Lubomir Bourdev
+Copyright 2009 The Trustees of Indiana University
+Copyright 2010 The Trustees of Indiana University
+Copyright 2012 Kenneth Riddile, Christian Henning
+Copyright 2012 The Trustees of Indiana University
+Copyright Abel Sinkovics (abel@sinkovics.hu) 2010
+Copyright Abel Sinkovics (abel@sinkovics.hu) 2011
+Copyright Abel Sinkovics (abel@sinkovics.hu) 2012
+Copyright Abel Sinkovics (abel@sinkovics.hu) 2013
+Copyright Abel Sinkovics (abel@sinkovics.hu) 2014
+Copyright Abel Sinkovics (abel@sinkovics.hu) 2015
+Copyright Abel Sinkovics (abel@sinkovics.hu) 2016
+Copyright Abel Sinkovics (abel@sinkovics.hu) 2017
+Copyright Abel Sinkovics (abel@sinkovics.hu) 2018
+(c) Copyright Dave Abrahams and Daryle Walker 2001
+(c) Copyright Jeremy Siek and John R. Bandela 2001
+(c) Copyright John Maddock & Thorsten Ottosen 2005
+(c) Copyright Kevlin Henney and Dave Abrahams 1999
+Copyright (c) 2000-2002 Joerg Walter, Mathias Koch
+Copyright (c) 2000-2004 Joerg Walter, Mathias Koch
+Copyright (c) 2001 Vladimir Prus <ghost@cs.msu.su>
+Copyright (c) 2003-2008 Matthias Christian Schabel
+Copyright (c) 2003-2009 Matthias Christian Schabel
+Copyright (c) 2010 David Fong and Michael Saunders
+Copyright (c) 2019 Dario Menendez, Banco Santander
+Copyright 2005 David Abrahams and Aleksey Gurtovoy
+Copyright 2012 Fernando Vilas 2010 Daniel Trebbien
+Copyright 2014 Renato Tegon Forti, Antony Polukhin
+Copyright 2018 Mateusz Loskot <mateusz@loskot.net>
+Copyright Alexander Nasonov & Paul A. Bristow 2006
+Copyright David Abrahams and Nikolay Mladenov 2003
+Copyright (c) 2000 Gary Powell (powellg@amazon.com)
+Copyright (c) 2001 Peter Dimov and Multi Media Ltd.
+Copyright (c) 2001, 2002 Python Software Foundation
+Copyright (c) 2001-2007 Hartmut Kaiser Revised 2007
+Copyright (c) 2002 Peter Dimov and Multi Media Ltd.
+Copyright (c) 2002,2003 CrystalClear Software, Inc.
+Copyright (c) 2002-2004 CrystalClear Software, Inc.
+Copyright (c) 2002-2005 CrystalClear Software, Inc.
+Copyright (c) 2002-2020 CrystalClear Software, Inc.
+Copyright (c) 2003-2004 CrystalClear Software, Inc.
+Copyright (c) 2003-2005 CrystalClear Software, Inc.
+Copyright (c) 2004-2005 CrystalClear Software, Inc.
+Copyright (c) 2006, Systems Optimization Laboratory
+Copyright (c) 2007, John Travers <jtravs@gmail.com>
+Copyright (c) 2009-2011 Mateusz Loskot, London, UK.
+Copyright (c) 2009-2012 Mateusz Loskot, London, UK.
+Copyright (c) 2009-2013 Mateusz Loskot, London, UK.
+Copyright (c) 2009-2014 Mateusz Loskot, London, UK.
+Copyright (c) 2009-2015 Mateusz Loskot, London, UK.
+Copyright (c) 2009-2017 Mateusz Loskot, London, UK.
+Copyright (c) 2011-2012 Mateusz Loskot, London, UK.
+Copyright (c) 2012-2014 Mateusz Loskot, London, UK.
+Copyright (c) 2014-2015 Mateusz Loskot, London, UK.
+Copyright (c) 2018 Adeel Ahmad, Islamabad, Pakistan
+Copyright 2004, 2005 Trustees of Indiana University
+Copyright 2004-5 The Trustees of Indiana University
+Copyright 2012 Olivier Tournaire, Christian Henning
+Copyright 2016 Klemens Morgenstern, Antony Polukhin
+Copyright 2019 Miral Shah <miralshah2211@gmail.com>
+Copyright David Abrahams 2002, Joel de Guzman, 2002
+Copyright Thorsten Ottosen, Neil Groves 2006 - 2008
+(c) Copyright 2005 Matthias Troyer and Dave Abrahams
+(c) Copyright Greg Colvin and Beman Dawes 1998, 1999
+Copyright (c) 1998-2003 by the University of Florida
+Copyright (c) 2003, Fernando Luis Cacciola Carballal
+Copyright (c) 2005, Fernando Luis Cacciola Carballal
+Copyright (c) 2006 Xiaogang Zhang, 2015 John Maddock
+Copyright (c) 2011, 2012 Jeff Flinn, Boris Schaeling
+Copyright (c) 2013 Kyle Lutz <kyle.r.lutz@gmail.com>
+Copyright (c) 2014 Samuel Debionne, Grenoble, France
+Copyright (c) 2014-2016 Oracle and/or its affiliates
+Copyright (c) 2014-2018 Oracle and/or its affiliates
+Copyright (c) 2014-2020 Oracle and/or its affiliates
+Copyright (c) 2015 Jakub Pola <jakub.pola@gmail.com>
+Copyright (c) 2015 Jakub Szuppe <j.szuppe@gmail.com>
+Copyright (c) 2015-2016 Oracle and/or its affiliates
+Copyright (c) 2015-2018 Oracle and/or its affiliates
+Copyright (c) 2015-2020 Oracle and/or its affiliates
+Copyright (c) 2016 Jakub Szuppe <j.szuppe@gmail.com>
+Copyright (c) 2016-2018 Oracle and/or its affiliates
+Copyright (c) 2016-2019 Oracle and/or its affiliates
+Copyright (c) 2016-2020 Oracle and/or its affiliates
+Copyright (c) 2017-2018 Oracle and/or its affiliates
+Copyright (c) 2017-2019 Oracle and/or its affiliates
+Copyright (c) 2017-2020 Oracle and/or its affiliates
+Copyright (c) 2018 Jakub Szuppe <j.szuppe@gmail.com>
+Copyright (c) 2018, Cem Bassoy, cem.bassoy@gmail.com
+Copyright (c) 2018-2019 Oracle and/or its affiliates
+Copyright (c) 2018-2020 Oracle and/or its affiliates
+Copyright (c) 2020 Caian Benedicto, Campinas, Brazil
+Copyright 2000 John Maddock (john@johnmaddock.co.uk)
+Copyright 2013 Christian Henning and Juan V. Puertos
+Copyright 2015 Ontario Institute for Cancer Research
+Copyright David Abrahams 2002, Nikolay Mladenov 2007
+Copyright David Abrahams and Thomas Becker 2000-2006
+Copyright Peter Dimov and Multi Media Ltd 2001, 2002
+copyright (c) 2013-2017 Oracle and/or its affiliates
+copyright (c) 2013-2018 Oracle and/or its affiliates
+copyright (c) 2013-2019 Oracle and/or its affiliates
+copyright (c) 2013-2020 Oracle and/or its affiliates
+copyright (c) 2014-2015 Oracle and/or its affiliates
+copyright (c) 2014-2017 Oracle and/or its affiliates
+copyright (c) 2014-2018 Oracle and/or its affiliates
+copyright (c) 2014-2019 Oracle and/or its affiliates
+copyright (c) 2014-2020 Oracle and/or its affiliates
+copyright (c) 2015-2016 Oracle and/or its affiliates
+copyright (c) 2015-2017 Oracle and/or its affiliates
+copyright (c) 2015-2019 Oracle and/or its affiliates
+copyright (c) 2015-2020 Oracle and/or its affiliates
+copyright (c) 2016-2018 Oracle and/or its affiliates
+copyright (c) 2016-2020 Oracle and/or its affiliates
+copyright (c) 2017-2018 Oracle and/or its affiliates
+copyright (c) 2017-2020 Oracle and/or its affiliates
+copyright (c) 2018-2020 Oracle and/or its affiliates
+copyright (c) 2019-2020 Oracle and/or its affiliates
+(c) Copyright 2002 Robert Ramey - http://www.rrsd.com
+(c) Copyright 2004 Robert Ramey - http://www.rrsd.com
+(c) Copyright 2005 Robert Ramey - http://www.rrsd.com
+(c) Copyright 2007 Robert Ramey - http://www.rrsd.com
+(c) Copyright 2008-2009,2012 Vicente J. Botet Escriba
+(c) Copyright 2009 Robert Ramey - http://www.rrsd.com
+(c) Copyright 2011,2012,2015 Vicente J. Botet Escriba
+(c) Copyright 2011-2012,2015 Vicente J. Botet Escriba
+(c) Copyright 2014 Robert Ramey - http://www.rrsd.com
+(c) Copyright Vicente J. Botet Escriba 2008-2009,2012
+Copyright (c) 2000 Gary Powell (gwpowell@hotmail.com)
+Copyright (c) 2001 Jeremy Siek <jsiek@cs.indiana.edu>
+Copyright (c) 2001-2002 Chuck Allison and Jeremy Siek
+Copyright (c) 2002 Gary Powell (gwpowell@hotmail.com)
+Copyright (c) 2002-2003 David Moore, William E. Kempf
+Copyright (c) 2004 The Trustees of Indiana University
+Copyright (c) 2006 The Trustees of Indiana University
+Copyright (c) 2007 Douglas Gregor and Matthias Troyer
+Copyright (c) 2007 The Trustees of Indiana University
+Copyright (c) 2011-2013 Adam Wulkiewicz, Lodz, Poland
+Copyright (c) 2011-2014 Adam Wulkiewicz, Lodz, Poland
+Copyright (c) 2011-2015 Adam Wulkiewicz, Lodz, Poland
+Copyright (c) 2011-2016 Adam Wulkiewicz, Lodz, Poland
+Copyright (c) 2011-2017 Adam Wulkiewicz, Lodz, Poland
+Copyright (c) 2011-2018 Adam Wulkiewicz, Lodz, Poland
+Copyright (c) 2011-2019 Adam Wulkiewicz, Lodz, Poland
+Copyright (c) 2012-2013 Adam Wulkiewicz, Lodz, Poland
+Copyright (c) 2012-2015 Adam Wulkiewicz, Lodz, Poland
+Copyright (c) 2012-2020 Adam Wulkiewicz, Lodz, Poland
+Copyright (c) 2013-2014 Adam Wulkiewicz, Lodz, Poland
+Copyright (c) 2013-2015 Adam Wulkiewicz, Lodz, Poland
+Copyright (c) 2013-2017 Adam Wulkiewicz, Lodz, Poland
+Copyright (c) 2014-2015 Adam Wulkiewicz, Lodz, Poland
+Copyright (c) 2014-2015, Oracle and/or its affiliates
+Copyright (c) 2014-2017 Adam Wulkiewicz, Lodz, Poland
+Copyright (c) 2014-2017, Oracle and/or its affiliates
+Copyright (c) 2014-2018 Adam Wulkiewicz, Lodz, Poland
+Copyright (c) 2014-2018, Oracle and/or its affiliates
+Copyright (c) 2014-2019, Oracle and/or its affiliates
+Copyright (c) 2014-2020, Oracle and/or its affiliates
+Copyright (c) 2015-2017, Oracle and/or its affiliates
+Copyright (c) 2015-2018, Oracle and/or its affiliates
+Copyright (c) 2015-2020, Oracle and/or its affiliates
+Copyright (c) 2016, 2018 Oracle and/or its affiliates
+Copyright (c) 2016-2017, Oracle and/or its affiliates
+Copyright (c) 2016-2020, Oracle and/or its affiliates
+Copyright (c) 2017, 2019 Oracle and/or its affiliates
+Copyright (c) 2017-2018, Oracle and/or its affiliates
+Copyright (c) 2017-2019, Oracle and/or its affiliates
+Copyright (c) 2017-2020, Oracle and/or its affiliates
+Copyright (c) 2018-2019, Oracle and/or its affiliates
+Copyright (c) 2018-2020, Oracle and/or its affiliates
+Copyright (c) 2019-2020, Oracle and/or its affiliates
+Copyright (c) 2020 Digvijay Janartha, Hamirpur, India
+copyright (c) 2013, 2014 Oracle and/or its affiliates
+copyright (c) 2013-2014, Oracle and/or its affiliates
+copyright (c) 2013-2015, Oracle and/or its affiliates
+copyright (c) 2013-2017, Oracle and/or its affiliates
+copyright (c) 2013-2018, Oracle and/or its affiliates
+copyright (c) 2013-2019, Oracle and/or its affiliates
+copyright (c) 2013-2020, Oracle and/or its affiliates
+copyright (c) 2014-2017, Oracle and/or its affiliates
+copyright (c) 2014-2018, Oracle and/or its affiliates
+copyright (c) 2014-2019, Oracle and/or its affiliates
+copyright (c) 2014-2020, Oracle and/or its affiliates
+copyright (c) 2015-2016, Oracle and/or its affiliates
+copyright (c) 2015-2017, Oracle and/or its affiliates
+copyright (c) 2015-2018, Oracle and/or its affiliates
+copyright (c) 2015-2019, Oracle and/or its affiliates
+copyright (c) 2015-2020, Oracle and/or its affiliates
+copyright (c) 2016-2019, Oracle and/or its affiliates
+copyright (c) 2016-2020, Oracle and/or its affiliates
+copyright (c) 2017, 2019 Oracle and/or its affiliates
+copyright (c) 2017-2018, Oracle and/or its affiliates
+copyright (c) 2017-2019, Oracle and/or its affiliates
+copyright (c) 2017-2020, Oracle and/or its affiliates
+copyright (c) 2018-2019, Oracle and/or its affiliates
+copyright (c) 2018-2020, Oracle and/or its affiliates
+(c) Copyright Beman Dawes and Ullrich Koethe 1995-2001
+(c) Copyright David Abrahams 2001, Howard Hinnant 2001
+(c) Copyright Hubert Holin and Daryle Walker 2001-2002
+(c) Rasmus Munk Larsen, Stanford University, 2000,2004
+Copyright (c) 2002-2017 Free Software Foundation, Inc.
+Copyright (c) 2014, 2018, Oracle and/or its affiliates
+Copyright (c) 2014, 2019, Oracle and/or its affiliates
+Copyright (c) 2016 Wenzel Jakob <wenzel.jakob@epfl.ch>
+Copyright (c) 2020 Richard Hodges (hodges.r@gmail.com)
+Copyright (c) Jeremy Siek 2001, Marc Wintermantel 2002
+Copyright 1984, 1987, 1988, 2000 by Stephen L. Moshier
+Copyright 1984, 1987, 1989, 1995 by Stephen L. Moshier
+Copyright 1984, 1987, 1989, 2000 by Stephen L. Moshier
+Copyright 1984, 1987, 1992, 2000 by Stephen L. Moshier
+Copyright 2004-2006 The Trustees of Indiana University
+Copyright 2005-2009 The Trustees of Indiana University
+Copyright 2007-2008 Andreas Pokorny, Christian Henning
+Copyright 2007-2008 Christian Henning, Andreas Pokorny
+Copyright 2007-2012 Christian Henning, Andreas Pokorny
+Copyright 2007-2012 Christian Henning, Lubomir Bourdev
+Copyright 2010-2012 Kenneth Riddile, Christian Henning
+copyright (c) 2014, 2018, Oracle and/or its affiliates
+copyright (c) 2014, 2019, Oracle and/or its affiliates
+copyright (c) 2015, 2018, Oracle and/or its affiliates
+copyright (c) 2017, 2019, Oracle and/or its affiliates
+copyright (c) 2018, 2019, Oracle and/or its affiliates
+(c) 2020 Niall Douglas <http://www.nedproductions.biz/>
+(c) Copyright Boris Rasin and Antony Polukhin 2014-2019
+(c) Copyright Dave Abrahams and Daniel Walker 1999-2003
+(c) Copyright Robert Ramey 2003. Jonathan Turkanis 2004
+(c) Rasmus Munk Larsen, Stanford University, 1999, 2004
+(c) Rasmus Munk Larsen, Stanford University, 2000, 2004
+Copyright (c) 1995, 2007-2015 Barend Gehrels, Amsterdam
+Copyright (c) 1995-2013 Jean-loup Gailly and Mark Adler
+Copyright (c) 2000 Gary Powell (gary.powell@sierra.com)
+Copyright (c) 2001 Gary Powell (gary.powell@sierra.com)
+Copyright (c) 2002 Lars Gullik Bjonnes <larsbj@lyx.org>
+Copyright (c) 2011 Boris Schaeling (boris@highscore.de)
+Copyright (c) 2014 Roshan <thisisroshansmail@gmail.com>
+Copyright (c) 2015 Orson Peters <orsonpeters@gmail.com>
+Copyright (c) 2021 Orson Peters <orsonpeters@gmail.com>
+Copyright (c) Donald Stufft and individual contributors
+Copyright 1984, 1987, 1988 by Stephen L. Moshier Direct
+Copyright 1984, 1987, 1989 by Stephen L. Moshier Direct
+Copyright 1984, 1987, 1993 by Stephen L. Moshier Direct
+Copyright 1985, 1987, 1989 by Stephen L. Moshier Direct
+Copyright 2004, 2005 The Trustees of Indiana University
+Copyright 2014-2015 Renato Tegon Forti, Antony Polukhin
+Copyright 2019 Pranam Lashkari <plashkari628@gmail.com>
+(c) Copyright 2006 David Abrahams - http://www.boost.org
+(c) Copyright Daryle Walker and Stephen Cleary 2001-2002
+(c) Copyright Fernando Luis Cacciola Carballal 2000-2004
+Copyright (c) 2001 Jaakko Jarvi (jaakko.jarvi@cs.utu.fi)
+Copyright (c) 2001-2004 Peter Dimov and Multi Media Ltd.
+Copyright (c) 2002 Jaakko Jarvi (jaakko.jarvi@cs.utu.fi)
+Copyright (c) 2002,2003,2005 CrystalClear Software, Inc.
+Copyright (c) 2002,2003,2020 CrystalClear Software, Inc.
+Copyright (c) 2002-2003,2005 CrystalClear Software, Inc.
+Copyright (c) 2012 Massachusetts Institute of Technology
+Copyright (c) 2019 Vinnie Falco (vinnie.falco@gmail.com)
+Copyright (c) 2020 Vinnie Falco (vinnie.falco@gmail.com)
+Copyright 2008 CodeRage, LLC 2004-2007 Jonathan Turkanis
+Copyright 2014 Marco Guazzone (marco.guazzone@gmail.com)
+Copyright Abel Sinkovics (abel@sinkovics.hu) 2009 - 2010
+Copyright Abel Sinkovics (abel@sinkovics.hu) 2009 - 2011
+Copyright Abel Sinkovics (abel@sinkovics.hu) 2009 - 2012
+Copyright Abel Sinkovics (abel@sinkovics.hu) 2010 - 2011
+Copyright Abel Sinkovics (abel@sinkovics.hu) 2011 - 2012
+Copyright Ralf W. Grosse-Kunstleve & David Abrahams 2006
+(c) ACM, 2011. http://doi.acm.org/10.1145/1916461.1916469
+(c) Copyright 2002-2008, Fernando Luis Cacciola Carballal
+Copyright (c) 1999-2006 Cortex Software GmbH, Kantstrasse
+Copyright (c) 2001, 2002 Peter Dimov and Multi Media Ltd.
+Copyright (c) 2002, 2003 Peter Dimov and Multi Media Ltd.
+Copyright (c) 2002,2003, 2007 CrystalClear Software, Inc.
+Copyright (c) 2002,2003, 2020 CrystalClear Software, Inc.
+Copyright (c) 2003, 2008 Fernando Luis Cacciola Carballal
+Copyright (c) 2006-2013 The University of Colorado Denver
+Copyright (c) 2007 Douglas Gregor <doug.gregor@gmail.com>
+Copyright (c) 2009 Ben Hanson (http://www.benhanson.net/)
+Copyright (c) 2013-2014 Kyle Lutz <kyle.r.lutz@gmail.com>
+Copyright (c) 2013-2015 Kyle Lutz <kyle.r.lutz@gmail.com>
+Copyright (c) 2014-2015 Samuel Debionne, Grenoble, France
+Copyright (c) 2015 Francisco Jose Tapia fjtapia@gmail.com
+Copyright (c) 2016 Francisco Jose Tapia fjtapia@gmail.com
+Copyright (c) 2017 Francisco Jose Tapia fjtapia@gmail.com
+Copyright (c) 2018 Alain Miniussi <alain.miniussi@oca.eu>
+Copyright (c) 2018-2019, Cem Bassoy, cem.bassoy@gmail.com
+Copyright (c) 2019 Mika Fischer (mika.fischer@zoopnet.de)
+Copyright 1997, 1998, 1999, 2000 University of Notre Dame
+Copyright 2002 Aleksey Gurtovoy (agurtovoy@meta-comm.com)
+Copyright 2014 Glen Joseph Fernandes (glenjofe@gmail.com)
+Copyright 2015 Glen Joseph Fernandes (glenjofe@gmail.com)
+Copyright 2017 Glen Joseph Fernandes (glenjofe@gmail.com)
+Copyright 2018 Glen Joseph Fernandes (glenjofe@gmail.com)
+Copyright 2019 Glen Joseph Fernandes (glenjofe@gmail.com)
+Copyright 2020 Glen Joseph Fernandes (glenjofe@gmail.com)
+(c) Copyright 2002-2009 Robert Ramey - http://www.rrsd.com
+(c) Copyright 2002-2014 Robert Ramey - http://www.rrsd.com
+(c) Copyright 2002-2020 Robert Ramey - http://www.rrsd.com
+(c) Copyright 2011-2012,2017-2018 Vicente J. Botet Escriba
+Copyright (c) 1996 Silicon Graphics Computer Systems, Inc.
+Copyright (c) 1998 Silicon Graphics Computer Systems, Inc.
+Copyright (c) 2004-2006 The Trustees of Indiana University
+Copyright (c) 2004-2008 The Trustees of Indiana University
+Copyright (c) 2004-2009 The Trustees of Indiana University
+Copyright (c) 2005-2006 The Trustees of Indiana University
+Copyright (c) 2005-2008 The Trustees of Indiana University
+Copyright (c) 2005-2010 The Trustees of Indiana University
+Copyright (c) 2006-2007, Robert Hetland <hetland@tamu.edu>
+Copyright (c) 2006-2010 The Trustees of Indiana University
+Copyright (c) 2011, 2012 Martin Lambers <marlam@marlam.de>
+Copyright (c) 2012 Flavio De Lorenzi (fdlorenzi@gmail.com)
+Copyright 1999, 2000 Jaakko Jarvi (jaakko.jarvi@cs.utu.fi)
+Copyright 2009 (c) Dean Michael Berris <me@deanberris.com>
+(c) 1995 Ernst Stadlober, Institut fuer Statistitk, TU Graz
+Copyright (c) 2001 Jeremy Siek, Douglas Gregor, Brian Osman
+Copyright (c) 2005, Rasmus Munk Larsen, Stanford University
+Copyright (c) 2006 Tiago de Paula Peixoto <tiago@forked.de>
+Copyright (c) 2006-2009 Dmitry Bufistov and Andrey Parfenov
+Copyright (c) 2014, 2019, 2020 Oracle and/or its affiliates
+Copyright (c) 2017 Denis Demidov <dennis.demidov@gmail.com>
+Copyright (c) 2017-2018 Alexandr Poltavsky, Antony Polukhin
+Copyright 2013 Juan V. Puertos G-Cluster, Christian Henning
+(c) 2015-2020 Niall Douglas <http://www.nedproductions.biz/>
+(c) 2017-2020 Niall Douglas <http://www.nedproductions.biz/>
+(c) 2018-2020 Niall Douglas <http://www.nedproductions.biz/>
+(c) 2019-2020 Niall Douglas <http://www.nedproductions.biz/>
+Copyright (c) 2001 Housemarque Oy http://www.housemarque.com
+Copyright (c) 2002-2005, Jean-Sebastien Roy (js@jeannot.org)
+Copyright (c) 2004-2005, Jean-Sebastien Roy (js@jeannot.org)
+Copyright (c) 2014, 2018, 2019, Oracle and/or its affiliates
+Copyright (c) Alexander Zaitsev <zamazan4ik@gmail.by> , 2017
+Copyright (c) Tobias Schwinger http://spirit.sourceforge.net
+Copyright 1984, 1987, 1988, 1992, 2000 by Stephen L. Moshier
+Copyright 1984, 1987, 1989, 1992, 2000 by Stephen L. Moshier
+(c) Copyright Runar Undheim, Robert Ramey & John Maddock 2008
+Copyright (c) 2000-2003 Brian McNamara and Yannis Smaragdakis
+Copyright (c) 2000-2013 The University of California Berkeley
+Copyright (c) 2002,2003,2005,2020 CrystalClear Software, Inc.
+Copyright (c) 2003 Martin Wille http://spirit.sourceforge.net
+Copyright (c) 2011 Aaron Graham http://spirit.sourceforge.net
+Copyright (c) 2014 Glen Joseph Fernandes (glenjofe@gmail.com)
+Copyright (c) 2017 Glen Joseph Fernandes (glenjofe@gmail.com)
+Copyright (c) 2020 Krystian Stasiowski (sdkrystian@gmail.com)
+Copyright (c) Alexander Zaitsev <zamazan4ik@gmail.com> , 2016
+Copyright (c) Alexander Zaitsev <zamazan4ik@gmail.com> , 2017
+Copyright (c) Charles Karney (2008-2017) <charles@karney.com>
+Copyright (c) Glen Joseph Fernandes 2019 (glenjofe@gmail.com)
+Copyright 1984, 1987, 1988, 1992 by Stephen L. Moshier Direct
+Copyright 1984, 1987, 1989, 1992 by Stephen L. Moshier Direct
+Copyright Daniel Walker, Eric Niebler, Michel Morin 2008-2012
+(c) 2018 - 2019 Niall Douglas <http://www.nedproductions.biz/>
+(c) 2018 - 2020 Niall Douglas <http://www.nedproductions.biz/>
+(c) Copyright 2002-2008 Robert Ramey and Joaquin M Lopez Munoz
+Copyright (c) 1999, 2000 Jaakko Jarvi (jaakko.jarvi@cs.utu.fi)
+Copyright (c) 1999, 2000, 2001 North Carolina State University
+Copyright (c) 2001 Bruce Florman http://spirit.sourceforge.net
+Copyright (c) 2001 Daniel Nuffer http://spirit.sourceforge.net
+Copyright (c) 2002 Jeff Westfahl http://spirit.sourceforge.net
+Copyright (c) 2003 Giovanni Bajo http://spirit.sourceforge.net
+Copyright (c) 2003 Vaclav Vesely http://spirit.sourceforge.net
+Copyright (c) 2005-2006 Douglas Gregor <doug.gregor@gmail.com>
+Copyright (c) 2006 Joao Abecasis http://spirit.sourceforge.net
+Copyright (c) 2007-2009 Ben Hanson (http://www.benhanson.net/)
+Copyright (c) 2008-2009 Ben Hanson (http://www.benhanson.net/)
+Copyright (c) 2010 2015 Francisco Jose Tapia fjtapia@gmail.com
+Copyright (c) 2010 Bryce Lelbach http://spirit.sourceforge.net
+Copyright (c) 2010 Matthias Walter (xammy@xammy.homelinux.net)
+Copyright (c) 2011 Bryce Lelbach http://spirit.sourceforge.net
+Copyright (c) 2013 Agustin Berge http://spirit.sourceforge.net
+Copyright (c) 2017 Kristian Popov <kristian.popov@outlook.com>
+Copyright (c) Tyler Reddy, Richard Gowers, and Max Linke, 2016
+Copyright 2012-2019 Glen Joseph Fernandes (glenjofe@gmail.com)
+Copyright 2014,2018 Glen Joseph Fernandes (glenjofe@gmail.com)
+Copyright 2014-2015 Glen Joseph Fernandes (glenjofe@gmail.com)
+Copyright 2014-2016 Glen Joseph Fernandes (glenjofe@gmail.com)
+Copyright 2014-2020 Glen Joseph Fernandes (glenjofe@gmail.com)
+Copyright 2016-2021 Matthew Brett, Isuru Fernando, Matti Picus
+Copyright 2017-2018 Glen Joseph Fernandes (glenjofe@gmail.com)
+Copyright 2017-2019 Glen Joseph Fernandes (glenjofe@gmail.com)
+Copyright 2019-2020 Glen Joseph Fernandes (glenjofe@gmail.com)
+(c) Copyright Andreas Huber Doenni 2002-2005, Eric Niebler 2006
+(c) Copyright Peter Dimov and Multi Media Ltd. 2001, 2002, 2003
+Copyright (c) 1996,1997 Silicon Graphics Computer Systems, Inc.
+Copyright (c) 1996-1998 Silicon Graphics Computer Systems, Inc.
+Copyright (c) 2001, 2002, 2003 Peter Dimov and Multi Media Ltd.
+Copyright (c) 2002 Hartmut Kaiser http://spirit.sourceforge.net
+Copyright (c) 2003 Gustavo Guerra http://spirit.sourceforge.net
+Copyright (c) 2003 Hartmut Kaiser http://spirit.sourceforge.net
+Copyright (c) 2003 Joel de Guzman http://spirit.sourceforge.net
+Copyright (c) 2003 Jonathan de Halleux (dehalleux@pelikhan.com)
+Copyright (c) 2004 David M. Cooke <cookedm@physics.mcmaster.ca>
+Copyright (c) 2009 Francois Barel http://spirit.sourceforge.net
+Copyright (c) 2011 Thomas Bernard http://spirit.sourceforge.net
+Copyright (c) 2016 Frank Hein, maxence business consulting gmbh
+Copyright Daryle Walker, Hubert Holin, John Maddock 2006 - 2007
+(c) Copyright Mat Marcus, Jesse Jones and Adobe Systems Inc 2001
+Copyright (c) 2000-2010 Joerg Walter, Mathias Koch, David Bellot
+Copyright (c) 2000-2011 Joerg Walter, Mathias Koch, David Bellot
+Copyright (c) 2000-2013 Joerg Walter, Mathias Koch. David Bellot
+Copyright (c) 2003, Hartmut Kaiser http://spirit.sourceforge.net
+Copyright (c) 2007 Matthias Troyer <troyer@boost-consulting.com>
+Copyright Neil Groves & Thorsten Ottosen & Pavol Droba 2003-2004
+copyrighted 2004 by David M. Cooke <cookedm@physics.mcmaster.ca>
+(c) 2000 W. Hoermann & J. Leydold, Institut f. Statistik, WU Wien
+(c) 2007 W. Hoermann & J. Leydold, Institut f. Statistik, WU Wien
+Copyright (c) 2002-2003 Toon Knapen, Kresimir Fresl, Joerg Walter
+Copyright (c) 2003, 2007-14 Massachusetts Institute of Technology
+Copyright (c) 2006 Tobias Schwinger http://spirit.sourceforge.net
+Copyright (c) 2006-2008 Emil Dotchevski and Reverge Studios, Inc.
+Copyright (c) 2006-2009 Emil Dotchevski and Reverge Studios, Inc.
+Copyright (c) 2006-2010 Emil Dotchevski and Reverge Studios, Inc.
+Copyright (c) 2006-2013 Emil Dotchevski and Reverge Studios, Inc.
+Copyright (c) 2008-2009 Emil Dotchevski and Reverge Studios, Inc.
+Copyright (c) 2008-2016 Emil Dotchevski and Reverge Studios, Inc.
+Copyright (c) 2008-2017 Emil Dotchevski and Reverge Studios, Inc.
+Copyright (c) 2018-2020 Emil Dotchevski and Reverge Studios, Inc.
+(c) Copyright David Abrahams, Jeremy Siek, Daryle Walker 1999-2001
+Copyright (c) 2000-2007 Joerg Walter, Mathias Koch, Gunter Winkler
+Copyright (c) 2000-2009 Joerg Walter, Mathias Koch, Gunter Winkler
+Copyright (c) 2001, Daniel C. Nuffer http://spirit.sourceforge.net
+Copyright (c) 2002-2003 Martin Wille http://spirit.sourceforge.net
+Copyright (c) 2018 Yaghyavardhan Singh Khangarot, Hyderabad, India
+Copyright 2002 Herve Bronnimann, Guillaume Melquiond, Sylvain Pion
+Copyright 2012 Christian Henning, Andreas Pokorny, Lubomir Bourdev
+Copyright (c) 2001-2002 Enthought, Inc. 2003-2022, SciPy Developers
+Copyright (c) 2001-2003 Daniel Nuffer http://spirit.sourceforge.net
+Copyright (c) 2001-2009 Daniel Nuffer http://spirit.sourceforge.net
+Copyright (c) 2002 Raghavendra Satish http://spirit.sourceforge.net
+Copyright (c) 2007 Free Software Foundation, Inc. <http://fsf.org/>
+Copyright (c) 2009 Free Software Foundation, Inc. <http://fsf.org/>
+Copyright (c) 2020, Debabrata Mandal <mandaldebabrata123@gmail.com>
+Copyright 2019 Olzhas Zhumabek <anonymous.from.applecity@gmail.com>
+Copyright (c) 1998-2002 Joel de Guzman http://spirit.sourceforge.net
+Copyright (c) 1998-2003 Joel de Guzman http://spirit.sourceforge.net
+Copyright (c) 2001-2003 Hartmut Kaiser http://spirit.sourceforge.net
+Copyright (c) 2001-2003 Joel de Guzman http://spirit.sourceforge.net
+Copyright (c) 2001-2007 Hartmut Kaiser http://spirit.sourceforge.net
+Copyright (c) 2001-2008 Hartmut Kaiser http://spirit.sourceforge.net
+Copyright (c) 2001-2010 Hartmut Kaiser http://spirit.sourceforge.net
+Copyright (c) 2001-2011 Hartmut Kaiser http://spirit.sourceforge.net
+Copyright (c) 2001-2011 Joel de Guzman http://spirit.sourceforge.net
+Copyright (c) 2001-2012 Hartmut Kaiser http://spirit.sourceforge.net
+Copyright (c) 2001-2012 Joel de Guzman http://spirit.sourceforge.net
+Copyright (c) 2001-2014 Joel de Guzman http://spirit.sourceforge.net
+Copyright (c) 2002-2003 Hartmut Kaiser http://spirit.sourceforge.net
+Copyright (c) 2002-2006 Hartmut Kaiser http://spirit.sourceforge.net
+(c) Copyright 2004-2009 Robert Ramey, Martin Ecker and Takatoshi Kondo
+Copyright (c) 1996, 1997, 1998, 1999, 2000 Gerard Jungman, Brian Gough
+Copyright (c) 2008 Rep Invariant Systems, Inc. (info@repinvariant.com)
+(c) Copyright 2007, 2008 Steven Watanabe, Joseph Gauterin, Niels Dekker
+Copyright (c) 2007, 2008 Steven Watanabe, Joseph Gauterin, Niels Dekker
+Copyright (c) 2015 Muhammad Junaid Muzammil <mjunaidmuzammil@gmail.com>
+Copyright 2002-2003 Herve Bronnimann, Guillaume Melquiond, Sylvain Pion
+Copyright 2007-2008 Christian Henning, Andreas Pokorny, Lubomir Bourdev
+Copyright 2007-2012 Christian Henning, Andreas Pokorny, Lubomir Bourdev
+Copyright (c) 1998-2000 Theodore C. Belding University of Michigan Center
+Copyright (c) 2000-2013 Joerg Walter, Mathias Koch, Athanasios Iliopoulos
+Copyright 2003-2013 Joaquin M Lopez Munoz. 2019 Mike Dev <mike.dev@gmx.de>
+(c) Copyright 2002 Rani Sharoni (rani_sharoni@hotmail.com) and Robert Ramey
+(c) Copyright 2003-4 Pavel Vozenilek and Robert Ramey - http://www.rrsd.com
+(c) Copyright Steve Cleary, Beman Dawes, Howard Hinnant & John Maddock 2000
+Copyright 2014 by P.-G. Martinsson, V. Rokhlin, Y. Shkolnisky, and M. Tygert
+Copyright (c) 2021-04-21 Stefan van der Walt https://github.com/stefanv/lloyd
+copyright A. Volgenant/Amsterdam School of Economics, University of Amsterdam
+Copyright (c) 2002-2003 Juan Carlos Arevalo-Baeza http://spirit.sourceforge.net
+(c) Copyright Steve Cleary, Beman Dawes, Howard Hinnant & John Maddock 2000-2005
+Copyright (c) 2000-2010 Joerg Walter, Mathias Koch, Gunter Winkler, David Bellot
+Copyright 1987-, A. Volgenant/Amsterdam School of Economics, University of Amsterdam
+(c) Copyright 2010 Just Software Solutions Ltd http://www.justsoftwaresolutions.co.uk
+copyright (c) 2005 troy d. straszheim <troy@resophonic.com> http://www.resophonic.com
+Copyright (c) 2002 Brad King (brad.king@kitware.com) Douglas Gregor (gregod@cs.rpi.edu)
+(c) Copyright 2009-2011 Frederic Bron, Robert Stewart, Steven Watanabe & Roman Perepelitsa
+(c) Copyright Dave Abrahams, Steve Cleary, Beman Dawes, Howard Hinnant & John Maddock 2000
+(c) Copyright Dave Abrahams, Steve Cleary, Beman Dawes, Howard Hinnant and John Maddock 2000
+Copyright (c) 2018 Sylvain Gubian <sylvain.gubian@pmi.com> , Yang Xiang <yang.xiang@pmi.com>
+(c) Copyright Steve Cleary, Beman Dawes, Aleksey Gurtovoy, Howard Hinnant & John Maddock 2000
+Copyright (c) 2003 Jonathan de Halleux (dehalleux@pelikhan.com) http://spirit.sourceforge.net
+(c) Copyright Dave Abrahams, Steve Cleary, Beman Dawes, Howard Hinnant & John Maddock 2000-2003
+(c) Copyright David Abrahams Steve Cleary, Beman Dawes, Howard Hinnant & John Maddock 2000-2002
+Copyright (c) 1999-2001 Jaakko Jarvi (jaakko.jarvi@cs.utu.fi) Gary Powell (gwpowell@hotmail.com)
+Copyright (c) Tyler Reddy, Ross Hemsley, Edd Edmondson, Nikolai Nowaczyk, Joe Pitt-Francis, 2015
+Copyright (c) 2013 Jakob Lykke Andersen, University of Southern Denmark (jlandersen@imada.sdu.dk)
+(c) Copyright Dave Abrahams, Steve Cleary, Beman Dawes, Howard Hinnant and John Maddock 2000, 2010
+Copyright (c) 2001 Jaakko Jarvi (jaakko.jarvi@cs.utu.fi) 2001 Gary Powell (gary.powell@sierra.com)
+Copyright (c) 2003 Jonathan de Halleux http://spirit.sourceforge.net http://www.boost.org/libs/spirit
+Copyright (c) 1992-2013 The University of Tennessee and The University of Tennessee Research Foundation
+(c) Copyright Dave Abrahams, Steve Cleary, Beman Dawes, Aleksey Gurtovoy, Howard Hinnant & John Maddock 2000
+Copyright (c) 1990-2004 by Johannes Braams texniek at braams.cistron.nl Kersengaarde 33 2723 BP Zoetermeer NL
+Copyright (c) 2003, The Regents of the University of California, through Lawrence Berkeley National Laboratory
+Copyright (c) 2008 Wolfgang Hoermann and Josef Leydold Department of Statistics and Mathematics, WU Wien, Austria
+Copyright (c) 2009 Wolfgang Hoermann and Josef Leydold Department of Statistics and Mathematics, WU Wien, Austria
+Copyright (c) 2010 Wolfgang Hoermann and Josef Leydold Department of Statistics and Mathematics, WU Wien, Austria
+Copyright (c) 2003-2009, The Regents of the University of California, through Lawrence Berkeley National Laboratory
+Copyright (c) 2000-2010 Wolfgang Hoermann and Josef Leydold Department of Statistics and Mathematics, WU Wien, Austria
+Copyright (c) 2000-2022 Wolfgang Hoermann and Josef Leydold Department of Statistics and Mathematics, WU Wien, Austria
+Copyright (c) 2008-2010 Wolfgang Hoermann and Josef Leydold Department of Statistics and Mathematics, WU Wien, Austria
+Copyright (c) 2009-2010 Wolfgang Hoermann and Josef Leydold Department of Statistics and Mathematics, WU Wien, Austria
+Copyright (c) 2009-2011 Wolfgang Hoermann and Josef Leydold Department of Statistics and Mathematics, WU Wien, Austria
+Copyright (c) 2009-2012 Wolfgang Hoermann and Josef Leydold Department of Statistics and Mathematics, WU Wien, Austria
+Copyright (c) 2011-2012 Wolfgang Hoermann and Josef Leydold Institute for Statistics and Mathematics, WU Wien, Austria
+Copyright (c) 2000-2006 Wolfgang Hoermann and Josef Leydold Dept. for Statistics, University of Economics, Vienna, Austria
+Copyright (c) 2000-2006, 2010 Wolfgang Hoermann and Josef Leydold Department of Statistics and Mathematics, WU Wien, Austria
+Copyright (c) 2001 Ronald Garcia, Indiana University (garcia@osl.iu.edu) Andrew Lumsdaine, Indiana University (lums@osl.iu.edu)
+Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021 Python Software Foundation
+(c) KOKOKOKOKKuKyKxKxKxKxKxKxKxKxKxKxKxKxKxKxKxKxKxKxKxKxKxKxKxKxKxKxKxKxKxKyK KyKxKzKzKzKzKzKzKzKzKzKzKzKzKyKxKzKzKzKzKzKzKzKzKzKzKzKzKzKzKzKzKzKzKzKzKzKzKzKzK K K KzK K
+Copyright 2002 Marc Wintermantel (wintermantel@even-ag.ch) ETH Zurich, Center of Structure Technologies (https://web.archive.org/web/20050307090307/http://www.structures.ethz.ch/)
 
 BSD-2-Clause AND BSD-3-Clause
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-fsspec 2023.3.0 - BSD-2-Clause AND BSD-3-Clause
+threadpoolctl 3.2.0 - BSD-2-Clause AND BSD-3-Clause
 
 
-Copyright (c) 2018, Martin Durant
+Copyright (c) 2017, Intel Corporation
+(Copyright (c) 2017, Intel Corporation)
+Copyright (c) 2019, threadpoolctl contributors
 
 BSD-2-Clause AND BSD-3-Clause
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-joblib 1.2.0 - BSD-2-Clause AND BSD-3-Clause
+pycocotools 2.0.6 - BSD-2-Clause-Views
 
 
-Copyright 2009 Brian Quinlan
-Copyright 2017, Thomas Moreau
-Copyright 2010, Gael Varoquaux
-Copyright 2012, Olivier Grisel
-Copyright (c) 2008 Gael Varoquaux
-Copyright (c) 2009 Gael Varoquaux
-Copyright (c) 2010 Gael Varoquaux
-Copyright (c) 2008-2021, The joblib
-Copyright (c) 2010-2011 Gael Varoquaux
-copyright 2008-2021, Joblib developers
-Copyright (c) 2012, Regents of the University of California
-Copyright 2010, Gael Varoquaux 2001-2004, Fernando Perez 2001 Nathaniel Gray
-Copyright (c) 2009 PiCloud, Inc. <https://web.archive.org/web/20140626004012/http://www.picloud.com/>
 
-BSD-2-Clause AND BSD-3-Clause
+BSD-2-Clause-Views
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-mpmath 1.3.0 - BSD-2-Clause AND BSD-3-Clause
+attrs 23.1.0 - MIT
 
 
-Copyright 2013 Timo Hartmann (thartmann15 at gmail.com)
-Copyright (c) 2005-2021 Fredrik Johansson and mpmath contributors
-
-BSD-2-Clause AND BSD-3-Clause
-
----------------------------------------------------------
+(c) N Revealed
+Hynek Schlawack copyright f'2015
+Copyright (c) 2015 Hynek Schlawack
+Copyright (c) 2015 Hynek Schlawack"
+Copyright (c) 2015 Hynek Schlawack" == mod.__copyright
+Copyright ..." is shown in the HTML footer. Default is True.
 
----------------------------------------------------------
+MIT License
 
-multiprocess 0.70.14 - BSD-2-Clause AND BSD-3-Clause
+Copyright (c) <year> <copyright holders>
 
+Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
 
-Copyright (c) 2006-2008, R Oudkerk
-Copyright (c) 2008-2016 California Institute of Technology
-Copyright (c) 2022 The Uncertainty Quantification Foundation
-Copyright (c) 2016-2022 The Uncertainty Quantification Foundation
-Copyright (c) 2018-2022 The Uncertainty Quantification Foundation
+The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
 
-BSD-2-Clause AND BSD-3-Clause
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-networkx 3.0 - BSD-2-Clause AND BSD-3-Clause
-
+azure-common 1.1.28 - MIT
 
-Copyright (c) 2015 - Thomson Licensing, SAS
-Copyright 2011 Alex Levenson <alex@isnotinvain.com>
-Copyright 2011 Reya Group <http://www.reyagroup.com>
-copyright f'2004- date.today .year, NetworkX Developers
-Copyright 2011 Diederik van Liere <diederik.vanliere@rotman.utoronto.ca>
-Copyright (c) 2004-2023 NetworkX Developers Aric Hagberg <hagberg@lanl.gov> Dan Schult <dschult@colgate.edu>
-Copyright (c) 2004-2023, NetworkX Developers Aric Hagberg <hagberg@lanl.gov> Dan Schult <dschult@colgate.edu>
 
-BSD-2-Clause AND BSD-3-Clause
 
----------------------------------------------------------
-
----------------------------------------------------------
+MIT License
 
-psutil 5.9.4 - BSD-2-Clause AND BSD-3-Clause
+Copyright (c) <year> <copyright holders>
 
+Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
 
-copyright 2009- s, s
-Copyright (c) 2009, Giampaolo
-Copyright (c) 2017, Arnon Yaari
-Copyright (c) 2015, Ryo ONODERA.
-Copyright (c) 2009 Giampaolo Rodola
-Copyright (c) 2009, Giampaolo Rodola
-Copyright 2007-2011 by the Sphinx team
-Copyright (c) 2009, Jay Loden, Giampaolo Rodola
-Copyright (c) 2009, Giampaolo Rodola', Jeff Tang
-Copyright (c) 2009, Giampaolo Rodola', karthikrev
-Copyright (c) 2009, Giampaolo Rodola', Landry Breuil
-Copyright (c) 2009, Giampaolo Rodola', Himanshu Shekhar
-Copyright (c) 2009, Giampaolo Rodola', Oleksii Shevchuk
-Copyright (c) 2009, Giampaolo Rodola', Landry Breuil (OpenBSD)
-Copyright (c) 2009, Jay Loden, Dave Daeschler, Giampaolo Rodola
+The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
 
-BSD-2-Clause AND BSD-3-Clause
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-threadpoolctl 3.1.0 - BSD-2-Clause AND BSD-3-Clause
-
-
-Copyright (c) 2017, Intel Corporation
-(Copyright (c) 2017, Intel Corporation)
-Copyright (c) 2019, threadpoolctl contributors
+azure-keyvault-certificates 4.7.0 - MIT
 
-BSD-2-Clause AND BSD-3-Clause
 
----------------------------------------------------------
+Copyright (c) Microsoft Corporation
 
----------------------------------------------------------
+MIT License
 
-pycocotools 2.0.4 - BSD-2-Clause-Views
+Copyright (c) <year> <copyright holders>
 
+Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
 
+The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
 
-BSD-2-Clause-Views
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-pandas 1.1.5 - BSD-3-Clause
+azure-keyvault-keys 4.8.0 - MIT
 
 
+Copyright (c) Microsoft Corporation
 
-Copyright (c) <year> <owner> . All rights reserved.
-
-Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
+MIT License
 
-   1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
+Copyright (c) <year> <copyright holders>
 
-   2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.
+Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
 
-   3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.
+The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
 
-THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-scikit-learn 0.24.2 - BSD-3-Clause
+azure-keyvault-secrets 4.7.0 - MIT
 
 
+Copyright (c) Microsoft Corporation
 
-Copyright (c) <year> <owner> . All rights reserved.
-
-Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
+MIT License
 
-   1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
+Copyright (c) <year> <copyright holders>
 
-   2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.
+Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
 
-   3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.
+The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
 
-THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-attrs 22.2.0 - MIT
+azure-nspkg 3.0.2 - MIT
 
 
-(c) N Revealed
-Hynek Schlawack copyright f'2015
-Copyright (c) 2015 Hynek Schlawack
-Copyright (c) 2015 Hynek Schlawack"
-Copyright ..." is shown in the HTML footer. Default is True.
 
 MIT License
 
 Copyright (c) <year> <copyright holders>
 
 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
 
@@ -2497,25 +4318,18 @@
 
 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-charset-normalizer 3.1.0 - MIT
+msal-extensions 1.0.0 - MIT
 
 
-COPYRIGHT (c) FOOBAR
-copyright 2019, Ahmed TAHRI
-Copyright (c) 2019 TAHRI Ahmed R.
-copyright (c) 2021 by Ahmed TAHRI
-Copyright (c) 2019 Ahmed TAHRI Ousret
-(c) 2012 Denny Vrandecic (http://simia.net/letters/)
-Copyright (c) Ahmed TAHRI Ousret (https://github.com/Ousret)
-(c) https://stackoverflow.com/questions/3041986/apt-command-line-interface-like-yes-no-input
+Copyright (c) Microsoft Corporation
 
 MIT License
 
 Copyright (c) <year> <copyright holders>
 
 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
 
@@ -2523,18 +4337,28 @@
 
 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-openai 0.27.2 - MIT
+pathlib2 2.3.7.post1 - MIT
 
 
-Copyright (c) OpenAI (https://openai.com)
+Copyright 2007-2021 by the Sphinx team
+(c) JS Foundation and other contributors
+Copyright JS Foundation and other contributors
+Copyright (c) 2014-2017 Matthias C. M. Troffaes
+Copyright (c) 2014-2021 Matthias C. M. Troffaes
+Copyright (c) 2012-2014 Antoine Pitrou and contributors
+Copyright (c) 2014-2021 Matthias C. M. Troffaes and contributors
+(c) 2012-2014 Antoine Pitrou and contributors 2014-2021, Matthias C. M. Troffaes and contributors
+copyright 2012-2014 Antoine Pitrou and contributors 2014-2021, Matthias C. M. Troffaes and contributors
+copyright ^2012-2014 Antoine Pitrou and contributors 2014-2021, Matthias C. M. Troffaes and contributors
+(c) 2009-2021 Jeremy Ashkenas, Julian Gonggrijp, and DocumentCloud and Investigative Reporters & Editors Underscore
 
 MIT License
 
 Copyright (c) <year> <copyright holders>
 
 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
 
@@ -2542,85 +4366,18 @@
 
 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-pyparsing 3.0.9 - MIT
+seqeval 1.2.2 - MIT
 
 
-Copyright 2004-2010
-Copyright, Tom Coonan
-Copyright (c) 2021 Dot
-Copyright 2004, Paul McGuire
-Copyright 2006, Paul McGuire
-Copyright 2008 Chris Lambrou
-Copyright 2008, Paul McGuire
-Copyright 2010, Paul McGuire
-Copyright 2011, Paul McGuire
-Copyright 2015, Paul McGuire
-Copyright 2016, Paul McGuire
-Copyright 2018, Paul McGuire
-Copyright 2019, Paul McGuire
-Copyright 2020, Paul McGuire
-Copyright 2021, Paul McGuire
-Copyright Paul McGuire, 2019
-Copyright Paul McGuire, 2021
-copyright 2006, Paul McGuire
-Copyright, 2010, Paul McGuire
-Copyright 2007 by Paul McGuire
-Copyright, 2007 - Paul McGuire
-Copyright, 2012 - Paul McGuire
-Copyright 2006, by Paul McGuire
-Copyright 2008, by Paul McGuire
-Copyright 2012, Paul T. McGuire
-Copyright 2022, by Paul McGuire
-Copyright (c) 2003, Paul McGuire
-Copyright (c) 2004, Paul McGuire
-Copyright (c) 2006, Paul McGuire
-Copyright (c) 2009 Zarko Zivanov
-Copyright (c) 2016, Paul McGuire
-Copyright 2010,2019 Paul McGuire
-Copyright, 2006, by Paul McGuire
-Copyright (c) 2008, InformAsic AB
-Copyright 2002-2021, Paul McGuire
-Copyright 2005-2006, Paul McGuire
-Copyright 2009, 2011 Paul McGuire
-Copyright (c) 2018 Paul T. McGuire
-Copyright Ellis & Grant, Inc. 2005
-Copyright 2003-2019 by Paul McGuire
-Copyright 2011,2015 Paul T. McGuire
-Copyright (c) 2003,2019 Paul McGuire
-Copyright (c) 2006,2016 Paul McGuire
-Copyright 2003, 2019 by Paul McGuire
-Copyright 2004-2016, by Paul McGuire
-Copyright 2007-2011, by Paul McGuire
-Copyright 2010, 2019 by Paul McGuire
-Copyright 2012, 2019 Paul T. McGuire
-copyright 2018-2021, Paul T. McGuire
-Copyright (c) 2003,2016, Paul McGuire
-Copyright (c) 2004, 2006 Paul McGuire
-Copyright (c) 2004-2016, Paul McGuire
-Copyright copy 2003-2022 Paul McGuire
-Copyright (c) 2006, 2016, Paul McGuire
-Copyright (c) 2006, 2019, Paul McGuire
-Copyright (c) 2003-2019 Paul T. McGuire
-Copyright (c) 2003-2022 Paul T. McGuire
-Copyright (c) 2004-2011 Paul T. McGuire
-Copyright (c) 1992-1993 Jean-loup Gailly
-Copyright (c) 2006, Estrate, the Netherlands
-Copyright 1989 by Carnegie Mellon University
-Copyright (c) 2000 Rudolf Usselmann rudi@asics.ws
-Copyright (c) 2006 Tim Cera timcera@earthlink.net
-Copyright Petri Savolainen <firstname.lastname@iki.fi>
-copyright 1999, Kluwer Academic Publishers, Norwell, MA
-Copyright 2004, by Alberto Santini http://www.albertosantini.it/chess
-copyright 1998, Sutherland HDL Inc, Portland, Oregon, USA Contact www.sutherland.com
-Copyright (c) 1999 Fulvio Corno, Matteo Sonze Reorda, Giovanni Squillero Politecnico di Torino
+Copyright (c) 2018
 
 MIT License
 
 Copyright (c) <year> <copyright holders>
 
 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
 
@@ -2628,19 +4385,19 @@
 
 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-pyyaml 6.0 - MIT
+six 1.16.0 - MIT
 
 
-Copyright (c) 2017-2021 Ingy dot Net
-Copyright (c) 2006-2016 Kirill Simonov
+copyright u'2010-2020, Benjamin Peterson
+Copyright (c) 2010-2020 Benjamin Peterson
 
 MIT License
 
 Copyright (c) <year> <copyright holders>
 
 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
 
@@ -2648,18 +4405,18 @@
 
 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-seqeval 1.2.2 - MIT
+terminaltables 3.1.10 - MIT
 
 
-Copyright (c) 2018
+Copyright (c) 2017 Robpol86
 
 MIT License
 
 Copyright (c) <year> <copyright holders>
 
 Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
 
@@ -2667,359 +4424,1206 @@
 
 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-six 1.16.0 - MIT
+portalocker 1.7.1 - Python-2.0
 
 
-copyright u'2010-2020, Benjamin Peterson
-Copyright (c) 2010-2020 Benjamin Peterson
+Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010 Python Software Foundation
 
-MIT License
+PYTHON SOFTWARE FOUNDATION LICENSE VERSION 2
 
-Copyright (c) <year> <copyright holders>
+   1. This LICENSE AGREEMENT is between the Python Software Foundation ("PSF"), and the Individual or Organization ("Licensee") accessing and otherwise using this software ("Python") in source or binary form and its associated documentation.
 
-Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
+   2. Subject to the terms and conditions of this License Agreement, PSF hereby grants Licensee a nonexclusive, royalty-free, world-wide license to reproduce, analyze, test, perform and/or display publicly, prepare derivative works, distribute, and otherwise use Python alone or in any derivative version, provided, however, that PSF's License Agreement and PSF's notice of copyright, i.e., "Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006 Python Software Foundation; All Rights Reserved" are retained in Python alone or in any derivative version prepared by Licensee.
 
-The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
+   3. In the event Licensee prepares a derivative work that is based on or incorporates Python or any part thereof, and wants to make the derivative work available to others as provided herein, then Licensee hereby agrees to include in any such work a brief summary of the changes made to Python.
 
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+   4. PSF is making Python available to Licensee on an "AS IS" basis. PSF MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR IMPLIED. BY WAY OF EXAMPLE, BUT NOT LIMITATION, PSF MAKES NO AND DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF PYTHON WILL NOT INFRINGE ANY THIRD PARTY RIGHTS.
 
----------------------------------------------------------
+   5. PSF SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF PYTHON FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS A RESULT OF MODIFYING, DISTRIBUTING, OR OTHERWISE USING PYTHON, OR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.
 
----------------------------------------------------------
+   6. This License Agreement will automatically terminate upon a material breach of its terms and conditions.
 
-tqdm 4.65.0 - MIT
+   7. Nothing in this License Agreement shall be deemed to create any relationship of agency, partnership, or joint venture between PSF and Licensee. This License Agreement does not grant permission to use PSF trademarks or trade name in a trademark sense to endorse or promote products or services of Licensee, or any third party.
 
+   8. By copying, installing or otherwise using Python, Licensee agrees to be bound by the terms and conditions of this License Agreement. BEOPEN.COM LICENSE AGREEMENT FOR PYTHON 2.0
 
-Copyright (c) 2013 noamraph
-(c) Noam Yorav-Raphael, original author
-(c) Casper da Costa-Luis casperdcl (https://github.com/casperdcl)
+BEOPEN PYTHON OPEN SOURCE LICENSE AGREEMENT VERSION 1
 
-MIT License
+   1. This LICENSE AGREEMENT is between BeOpen.com ("BeOpen"), having an office at 160 Saratoga Avenue, Santa Clara, CA 95051, and the Individual or Organization ("Licensee") accessing and otherwise using this software in source or binary form and its associated documentation ("the Software").
 
-Copyright (c) <year> <copyright holders>
+   2. Subject to the terms and conditions of this BeOpen Python License Agreement, BeOpen hereby grants Licensee a non-exclusive, royalty-free, world-wide license to reproduce, analyze, test, perform and/or display publicly, prepare derivative works, distribute, and otherwise use the Software alone or in any derivative version, provided, however, that the BeOpen Python License is retained in the Software, alone or in any derivative version prepared by Licensee.
 
-Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
+   3. BeOpen is making the Software available to Licensee on an "AS IS" basis. BEOPEN MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR IMPLIED. BY WAY OF EXAMPLE, BUT NOT LIMITATION, BEOPEN MAKES NO AND DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF THE SOFTWARE WILL NOT INFRINGE ANY THIRD PARTY RIGHTS.
 
-The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
+   4. BEOPEN SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF THE SOFTWARE FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS A RESULT OF USING, MODIFYING OR DISTRIBUTING THE SOFTWARE, OR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.
 
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+   5. This License Agreement will automatically terminate upon a material breach of its terms and conditions.
 
----------------------------------------------------------
+   6. This License Agreement shall be governed by and interpreted in all respects by the law of the State of California, excluding conflict of law provisions. Nothing in this License Agreement shall be deemed to create any relationship of agency, partnership, or joint venture between BeOpen and Licensee. This License Agreement does not grant permission to use BeOpen trademarks or trade names in a trademark sense to endorse or promote products or services of Licensee, or any third party. As an exception, the "BeOpen Python" logos available at http://www.pythonlabs.com/logos.html may be used according to the permissions granted on that web page.
 
----------------------------------------------------------
+   7. By copying, installing or otherwise using the software, Licensee agrees to be bound by the terms and conditions of this License Agreement. CNRI OPEN SOURCE LICENSE AGREEMENT (for Python 1.6b1) IMPORTANT: PLEASE READ THE FOLLOWING AGREEMENT CAREFULLY.
 
-urllib3 1.26.15 - MIT
+BY CLICKING ON "ACCEPT" WHERE INDICATED BELOW, OR BY COPYING, INSTALLING OR OTHERWISE USING PYTHON 1.6, beta 1 SOFTWARE, YOU ARE DEEMED TO HAVE AGREED TO THE TERMS AND CONDITIONS OF THIS LICENSE AGREEMENT.
 
+   1. This LICENSE AGREEMENT is between the Corporation for National Research Initiatives, having an office at 1895 Preston White Drive, Reston, VA 20191 ("CNRI"), and the Individual or Organization ("Licensee") accessing and otherwise using Python 1.6, beta 1 software in source or binary form and its associated documentation, as released at the www.python.org Internet site on August 4, 2000 ("Python 1.6b1").
 
-Copyright 2015 Google Inc.
-Copyright (c) 2010-2020 Benjamin Peterson
-Copyright (c) 2015-2016 Will Bond <will@wbond.net>
-Copyright (c) 2008-2020 Andrey Petrov and contributors
-Copyright (c) 2012 Senko Rasic <senko.rasic@dobarkod.hr>
+   2. Subject to the terms and conditions of this License Agreement, CNRI hereby grants Licensee a non-exclusive, royalty-free, world-wide license to reproduce, analyze, test, perform and/or display publicly, prepare derivative works, distribute, and otherwise use Python 1.6b1 alone or in any derivative version, provided, however, that CNRIs License Agreement is retained in Python 1.6b1, alone or in any derivative version prepared by Licensee.
 
-MIT License
+   Alternately, in lieu of CNRIs License Agreement, Licensee may substitute the following text (omitting the quotes): "Python 1.6, beta 1, is made available subject to the terms and conditions in CNRIs License Agreement. This Agreement may be located on the Internet using the following unique, persistent identifier (known as a handle): 1895.22/1011. This Agreement may also be obtained from a proxy server on the Internet using the URL:http://hdl.handle.net/1895.22/1011".
 
-Copyright (c) <year> <copyright holders>
+   3. In the event Licensee prepares a derivative work that is based on or incorporates Python 1.6b1 or any part thereof, and wants to make the derivative work available to the public as provided herein, then Licensee hereby agrees to indicate in any such work the nature of the modifications made to Python 1.6b1.
 
-Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
+   4. CNRI is making Python 1.6b1 available to Licensee on an "AS IS" basis. CNRI MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR IMPLIED. BY WAY OF EXAMPLE, BUT NOT LIMITATION, CNRI MAKES NO AND DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF PYTHON 1.6b1 WILL NOT INFRINGE ANY THIRD PARTY RIGHTS.
 
-The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
+   5. CNRI SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF THE SOFTWARE FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS A RESULT OF USING, MODIFYING OR DISTRIBUTING PYTHON 1.6b1, OR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.
 
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+   6. This License Agreement will automatically terminate upon a material breach of its terms and conditions.
+
+   7. This License Agreement shall be governed by and interpreted in all respects by the law of the State of Virginia, excluding conflict of law provisions. Nothing in this License Agreement shall be deemed to create any relationship of agency, partnership, or joint venture between CNRI and Licensee. This License Agreement does not grant permission to use CNRI trademarks or trade name in a trademark sense to endorse or promote products or services of Licensee, or any third party.
+
+   8. By clicking on the "ACCEPT" button where indicated, or by copying, installing or otherwise using Python 1.6b1, Licensee agrees to be bound by the terms and conditions of this License Agreement. ACCEPT CWI LICENSE AGREEMENT FOR PYTHON 0.9.0 THROUGH 1.2
+
+Copyright (c) 1991 - 1995, Stichting Mathematisch Centrum Amsterdam, The Netherlands. All rights reserved.
+
+Permission to use, copy, modify, and distribute this software and its documentation for any purpose and without fee is hereby granted, provided that the above copyright notice appear in all copies and that both that copyright notice and this permission notice appear in supporting documentation, and that the name of Stichting Mathematisch Centrum or CWI not be used in advertising or publicity pertaining to distribution of the software without specific, written prior permission.
+
+STICHTING MATHEMATISCH CENTRUM DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS, IN NO EVENT SHALL STICHTING MATHEMATISCH CENTRUM BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-zipp 3.15.0 - MIT
+typing 3.10.0.0 - Python-2.0
 
 
-Copyright Jason R. Coombs
+Copyright (c) 1991 - 1995, Stichting Mathematisch Centrum Amsterdam
+Copyright (c) 1995-2001 Corporation for National Research Initiatives
+Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014 Python Software Foundation
 
-MIT License
+PYTHON SOFTWARE FOUNDATION LICENSE VERSION 2
 
-Copyright (c) <year> <copyright holders>
+   1. This LICENSE AGREEMENT is between the Python Software Foundation ("PSF"), and the Individual or Organization ("Licensee") accessing and otherwise using this software ("Python") in source or binary form and its associated documentation.
 
-Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:
+   2. Subject to the terms and conditions of this License Agreement, PSF hereby grants Licensee a nonexclusive, royalty-free, world-wide license to reproduce, analyze, test, perform and/or display publicly, prepare derivative works, distribute, and otherwise use Python alone or in any derivative version, provided, however, that PSF's License Agreement and PSF's notice of copyright, i.e., "Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006 Python Software Foundation; All Rights Reserved" are retained in Python alone or in any derivative version prepared by Licensee.
 
-The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.
+   3. In the event Licensee prepares a derivative work that is based on or incorporates Python or any part thereof, and wants to make the derivative work available to others as provided herein, then Licensee hereby agrees to include in any such work a brief summary of the changes made to Python.
 
-THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.
+   4. PSF is making Python available to Licensee on an "AS IS" basis. PSF MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR IMPLIED. BY WAY OF EXAMPLE, BUT NOT LIMITATION, PSF MAKES NO AND DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF PYTHON WILL NOT INFRINGE ANY THIRD PARTY RIGHTS.
 
----------------------------------------------------------
+   5. PSF SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF PYTHON FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS A RESULT OF MODIFYING, DISTRIBUTING, OR OTHERWISE USING PYTHON, OR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.
 
----------------------------------------------------------
+   6. This License Agreement will automatically terminate upon a material breach of its terms and conditions.
 
-certifi 2022.12.7 - MPL-2.0
+   7. Nothing in this License Agreement shall be deemed to create any relationship of agency, partnership, or joint venture between PSF and Licensee. This License Agreement does not grant permission to use PSF trademarks or trade name in a trademark sense to endorse or promote products or services of Licensee, or any third party.
 
+   8. By copying, installing or otherwise using Python, Licensee agrees to be bound by the terms and conditions of this License Agreement. BEOPEN.COM LICENSE AGREEMENT FOR PYTHON 2.0
 
-(c) 2006 Entrust, Inc.
-(c) 1999 Entrust.net Limited
-(c) 2009 Entrust, Inc. - for
-(c) 2012 Entrust, Inc. - for
-(c) 2015 Entrust, Inc. - for
-(c) 2006 Entrust, Inc. Label Entrust Root Certification
-(c) 1999 Entrust.net Limited Label Entrust.net Premium 2048 Secure Server CA Serial
+BEOPEN PYTHON OPEN SOURCE LICENSE AGREEMENT VERSION 1
+
+   1. This LICENSE AGREEMENT is between BeOpen.com ("BeOpen"), having an office at 160 Saratoga Avenue, Santa Clara, CA 95051, and the Individual or Organization ("Licensee") accessing and otherwise using this software in source or binary form and its associated documentation ("the Software").
 
-Mozilla Public License Version 2.0
+   2. Subject to the terms and conditions of this BeOpen Python License Agreement, BeOpen hereby grants Licensee a non-exclusive, royalty-free, world-wide license to reproduce, analyze, test, perform and/or display publicly, prepare derivative works, distribute, and otherwise use the Software alone or in any derivative version, provided, however, that the BeOpen Python License is retained in the Software, alone or in any derivative version prepared by Licensee.
 
-   1. Definitions
+   3. BeOpen is making the Software available to Licensee on an "AS IS" basis. BEOPEN MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR IMPLIED. BY WAY OF EXAMPLE, BUT NOT LIMITATION, BEOPEN MAKES NO AND DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF THE SOFTWARE WILL NOT INFRINGE ANY THIRD PARTY RIGHTS.
 
-      1.1. "Contributor" means each individual or legal entity that creates, contributes to the creation of, or owns Covered Software.
+   4. BEOPEN SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF THE SOFTWARE FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS A RESULT OF USING, MODIFYING OR DISTRIBUTING THE SOFTWARE, OR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.
 
-      1.2. "Contributor Version" means the combination of the Contributions of others (if any) used by a Contributor and that particular Contributor's Contribution.
+   5. This License Agreement will automatically terminate upon a material breach of its terms and conditions.
+
+   6. This License Agreement shall be governed by and interpreted in all respects by the law of the State of California, excluding conflict of law provisions. Nothing in this License Agreement shall be deemed to create any relationship of agency, partnership, or joint venture between BeOpen and Licensee. This License Agreement does not grant permission to use BeOpen trademarks or trade names in a trademark sense to endorse or promote products or services of Licensee, or any third party. As an exception, the "BeOpen Python" logos available at http://www.pythonlabs.com/logos.html may be used according to the permissions granted on that web page.
+
+   7. By copying, installing or otherwise using the software, Licensee agrees to be bound by the terms and conditions of this License Agreement. CNRI OPEN SOURCE LICENSE AGREEMENT (for Python 1.6b1) IMPORTANT: PLEASE READ THE FOLLOWING AGREEMENT CAREFULLY.
 
-      1.3. "Contribution" means Covered Software of a particular Contributor.
+BY CLICKING ON "ACCEPT" WHERE INDICATED BELOW, OR BY COPYING, INSTALLING OR OTHERWISE USING PYTHON 1.6, beta 1 SOFTWARE, YOU ARE DEEMED TO HAVE AGREED TO THE TERMS AND CONDITIONS OF THIS LICENSE AGREEMENT.
 
-      1.4. "Covered Software" means Source Code Form to which the initial Contributor has attached the notice in Exhibit A, the Executable Form of such Source Code Form, and Modifications of such Source Code Form, in each case including portions thereof.
+   1. This LICENSE AGREEMENT is between the Corporation for National Research Initiatives, having an office at 1895 Preston White Drive, Reston, VA 20191 ("CNRI"), and the Individual or Organization ("Licensee") accessing and otherwise using Python 1.6, beta 1 software in source or binary form and its associated documentation, as released at the www.python.org Internet site on August 4, 2000 ("Python 1.6b1").
 
-      1.5. "Incompatible With Secondary Licenses" means
+   2. Subject to the terms and conditions of this License Agreement, CNRI hereby grants Licensee a non-exclusive, royalty-free, world-wide license to reproduce, analyze, test, perform and/or display publicly, prepare derivative works, distribute, and otherwise use Python 1.6b1 alone or in any derivative version, provided, however, that CNRIs License Agreement is retained in Python 1.6b1, alone or in any derivative version prepared by Licensee.
 
-         (a) that the initial Contributor has attached the notice described in Exhibit B to the Covered Software; or
+   Alternately, in lieu of CNRIs License Agreement, Licensee may substitute the following text (omitting the quotes): "Python 1.6, beta 1, is made available subject to the terms and conditions in CNRIs License Agreement. This Agreement may be located on the Internet using the following unique, persistent identifier (known as a handle): 1895.22/1011. This Agreement may also be obtained from a proxy server on the Internet using the URL:http://hdl.handle.net/1895.22/1011".
 
-         (b) that the Covered Software was made available under the terms of version 1.1 or earlier of the License, but not also under the terms of a Secondary License.
+   3. In the event Licensee prepares a derivative work that is based on or incorporates Python 1.6b1 or any part thereof, and wants to make the derivative work available to the public as provided herein, then Licensee hereby agrees to indicate in any such work the nature of the modifications made to Python 1.6b1.
 
-      1.6. "Executable Form" means any form of the work other than Source Code Form.
+   4. CNRI is making Python 1.6b1 available to Licensee on an "AS IS" basis. CNRI MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR IMPLIED. BY WAY OF EXAMPLE, BUT NOT LIMITATION, CNRI MAKES NO AND DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF PYTHON 1.6b1 WILL NOT INFRINGE ANY THIRD PARTY RIGHTS.
 
-      1.7. "Larger Work" means a work that combines Covered Software with other material, in a separate file or files, that is not Covered Software.
+   5. CNRI SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF THE SOFTWARE FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS A RESULT OF USING, MODIFYING OR DISTRIBUTING PYTHON 1.6b1, OR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.
 
-      1.8. "License" means this document.
+   6. This License Agreement will automatically terminate upon a material breach of its terms and conditions.
 
-      1.9. "Licensable" means having the right to grant, to the maximum extent possible, whether at the time of the initial grant or subsequently, any and all of the rights conveyed by this License.
+   7. This License Agreement shall be governed by and interpreted in all respects by the law of the State of Virginia, excluding conflict of law provisions. Nothing in this License Agreement shall be deemed to create any relationship of agency, partnership, or joint venture between CNRI and Licensee. This License Agreement does not grant permission to use CNRI trademarks or trade name in a trademark sense to endorse or promote products or services of Licensee, or any third party.
 
-      1.10. "Modifications" means any of the following:
+   8. By clicking on the "ACCEPT" button where indicated, or by copying, installing or otherwise using Python 1.6b1, Licensee agrees to be bound by the terms and conditions of this License Agreement. ACCEPT CWI LICENSE AGREEMENT FOR PYTHON 0.9.0 THROUGH 1.2
 
-         (a) any file in Source Code Form that results from an addition to, deletion from, or modification of the contents of Covered Software; or
+Copyright (c) 1991 - 1995, Stichting Mathematisch Centrum Amsterdam, The Netherlands. All rights reserved.
 
-         (b) any new file in Source Code Form that contains any Covered Software.
+Permission to use, copy, modify, and distribute this software and its documentation for any purpose and without fee is hereby granted, provided that the above copyright notice appear in all copies and that both that copyright notice and this permission notice appear in supporting documentation, and that the name of Stichting Mathematisch Centrum or CWI not be used in advertising or publicity pertaining to distribution of the software without specific, written prior permission.
 
-      1.11. "Patent Claims" of a Contributor means any patent claim(s), including without limitation, method, process, and apparatus claims, in any patent Licensable by such Contributor that would be infringed, but for the grant of the License, by the making, using, selling, offering for sale, having made, import, or transfer of either its Contributions or its Contributor Version.
+STICHTING MATHEMATISCH CENTRUM DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS, IN NO EVENT SHALL STICHTING MATHEMATISCH CENTRUM BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
 
-      1.12. "Secondary License" means either the GNU General Public License, Version 2.0, the GNU Lesser General Public License, Version 2.1, the GNU Affero General Public License, Version 3.0, or any later versions of those licenses.
+---------------------------------------------------------
 
-      1.13. "Source Code Form" means the form of the work preferred for making modifications.
 
-      1.14. "You" (or "Your") means an individual or a legal entity exercising rights under this License. For legal entities, "You" includes any entity that controls, is controlled by, or is under common control with You. For purposes of this definition, "control" means (a) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (b) ownership of more than fifty percent (50%) of the outstanding shares or beneficial ownership of such entity.
+---------------------------------------------------------
 
-   2. License Grants and Conditions
+transformers 4.21.1 - Apache-2.0
 
-      2.1. Grants
 
-      Each Contributor hereby grants You a world-wide, royalty-free, non-exclusive license:
+Copyright 2018 T5
+Copyright 2020 T5
+Copyright 2021 T5
+Copyright 2022 LongT5
+Copyright 2022 Salesforce
+Copyright 2020 Hugging Face
+Copyright 2020, Hugging Face
+Copyright 2022 Meta Platforms
+Copyright 2018 Mesh TensorFlow
+Copyright 2018 The OpenAI Team
+Copyright 2020 Mesh TensorFlow
+Copyright 2021 Mesh TensorFlow
+Copyright 2021 The Marian Team
+Copyright 2021 The OpenAI Team
+Copyright 2022 the Big Science
+Copyright The HuggingFace team
+Copyright 2018 The Open AI Team
+Copyright 2019 The Open AI Team
+Copyright 2021 The Open AI Team
+Copyright 2022 Google LLC., LongT5
+Copyright (c) HuggingFace Inc. team
+Copyright 2018 The Google Flax Team
+Copyright 2020 Optuna, Hugging Face
+Copyright 2020 The HuggingFace Team
+Copyright 2021 The Google Flax Team
+Copyright 2021 The HuggingFace Team
+Copyright 2022 The HuggingFace Team
+Copyright The HuggingFace Inc. team
+Copyright (c) 2001-2020 NLTK Project
+Copyright 2022 HuggingFace Inc. team
+Copyright 2018, Hao Tan, Mohit Bansal
+Copyright 2018- The Hugging Face team
+Copyright (c) 2018, Alexander Kirillov
+Copyright (c) 2018, NVIDIA CORPORATION.
+Copyright (c) 2020, NVIDIA CORPORATION.
+Copyright (c) 20121, NVIDIA CORPORATION.
+Copyright (c) 2021-, NVIDIA CORPORATION.
+Copyright 2018 The HuggingFace Inc. team
+Copyright 2020 The HuggingFace Inc. team
+Copyright 2021 The HuggingFace Inc. team
+Copyright 2022 The HuggingFace Inc. team
+Copyright 2020, The HuggingFace Inc. team
+Copyright 2018 The Google AI Language Team
+Copyright 2019 The Google AI Language Team
+Copyright 2020 The Google AI Language Team
+Copyright 2022 The Trajectory Transformers
+Copyright (c) 2018-2021, NVIDIA CORPORATION.
+Copyright 2020 The Facebook AI Research Team
+Copyright 2021 The Facebook AI Research Team
+Copyright 2022 The Facebook AI Research Team
+Copyright 2022 NVIDIA and The HuggingFace Team
+Copyright (c) Facebook, Inc. and its affiliates
+Copyright 2021 NVIDIA The HuggingFace Inc. team
+Copyright 2022 NVIDIA The HuggingFace Inc. team
+Copyright 2020-present the HuggingFace Inc. team
+Copyright Deepmind and The HuggingFace Inc. team
+Copyright 2018 DPR Authors, The Hugging Face Team
+Copyright 2022 Google AI and The HuggingFace Team
+Copyright Google AI and The HuggingFace Inc. team
+Copyright 2010, DPR authors, The Hugging Face Team
+Copyright 2021 Google AI The HuggingFace Inc. team
+Copyright 2022 KAIST and The HuggingFace Inc. team
+Copyright 2018 Salesforce and HuggingFace Inc. team
+Copyright 2020 Google and The HuggingFace Inc. team
+Copyright 2020, The T5 Authors and HuggingFace Inc.
+Copyright 2021 NVIDIA and The HuggingFace Inc. team
+Copyright 2021 The EleutherAI and HuggingFace Teams
+Copyright 2022 EleutherAI The HuggingFace Inc. team
+Copyright 2022 HuggingFace Inc. team and BigScience
+Copyright 2022 The EleutherAI and HuggingFace Teams
+Copyright 2022 UW-Madison The HuggingFace Inc. team
+Copyright 2021, Google and The HuggingFace Inc. team
+Copyright Studio Ousia and The HuggingFace Inc. team
+Copyright Studio-Ouisa and The HuggingFace Inc. team
+Copyright 2021 Deepmind and The HuggingFace Inc. team
+Copyright 2020 Microsoft and the HuggingFace Inc. team
+Copyright 2021 Google AI and The HuggingFace Inc. team
+Copyright 2021 Microsoft and The HuggingFace Inc. team
+Copyright Meta Platforms and The HuggingFace Inc. team
+Copyright 2018 Salesforce and The HuggingFace Inc. team
+Copyright 2018 The T5 authors and HuggingFace Inc. team
+Copyright 2020 Microsoft and the Hugging Face Inc. team
+Copyright 2020, Microsoft and the HuggingFace Inc. team
+Copyright 2021 ASAPP Inc. and The HuggingFace Inc. team
+Copyright 2021 ASAPP Inc. and the HuggingFace Inc. team
+Copyright 2021 The Eleuther AI and The Google Flax Team
+Copyright 2022 Apple Inc. and The HuggingFace Inc. team
+Copyright 2022 EleutherAI and The HuggingFace Inc. team
+Copyright 2022 Sea AI Lab and The HuggingFace Inc. team
+Copyright 2022 The Salesforce authors, The Open AI Team
+Copyright 2022 UW-Madison and The HuggingFace Inc. team
+Copyright 2022, The LongT5 Authors and HuggingFace Inc.
+Copyright 2022, UCLA NLP, The Facebook AI Research Team
+Copyright Google Research and The HuggingFace Inc. team
+Copyright 2018 The Microsoft Research Asia LayoutLM Team
+Copyright 2021 Google Research The HuggingFace Inc. team
+Copyright 2021 The Eleuther AI and HuggingFace Inc. team
+Copyright 2022 Facebook AI and The HuggingFace Inc. team
+Copyright 2022 Sea AI Labs and The HuggingFace Inc. team
+Copyright 2010, The Microsoft Research Asia LayoutLM Team
+Copyright 2021 Studio Ousia and the HuggingFace Inc. team
+Copyright 2021, Google Inc. and The HuggingFace Inc. team
+Copyright 2021 NVIDIA Corporation and The HuggingFace Team
+Copyright 2022 NAVER AI Labs and The HuggingFace Inc. team
+Copyright Microsoft Research and The HuggingFace Inc. team
+Copyright 2021 Microsoft Research The HuggingFace Inc. team
+Copyright 2021 The EleutherAI and The HuggingFace Inc. team
+Copyright 2021 The Fairseq Authors and The Google Flax Team
+Copyright 2021 VinAI Research and the HuggingFace Inc. team
+Copyright 2022 Meta Platforms and The HuggingFace Inc. team
+Copyright 2022 The Fairseq Authors and The Google Flax Team
+Copyright 2019 The TensorFlow Authors, The Hugging Face Team
+Copyright 2020 Google Research and The HuggingFace Inc. team
+Copyright 2020 The HuggingFace Team and the AllenNLP authors
+Copyright 2021 Google Research and The HuggingFace Inc. team
+Copyright 2021 The Fairseq Authors The HuggingFace Inc. team
+Copyright 2021 The OpenAI Team Authors, The Google Flax Team
+Copyright The HuggingFace Team and The HuggingFace Inc. team
+Copyright 2020 The Trax Authors and The HuggingFace Inc. team
+Copyright 2020, The RAG Authors and The HuggingFace Inc. team
+Copyright 2021 Facebook AI Research The HuggingFace Inc. team
+Copyright 2021 The HuggingFace Team The HuggingFace Inc. team
+Copyright 2022 The HuggingFace Team The HuggingFace Inc. team
+Copyright 2018 Hao Tan, Mohit Bansal, and the HuggingFace team
+Copyright 2021 The Facebook Inc. and The HuggingFace Inc. team
+Copyright 2021 The Facebook, Inc and The HuggingFace Inc. team
+Copyright 2022 The REALM authors and The HuggingFace Inc. team
+Copyright 2018 The HuggingFace Inc. team, Microsoft Corporation
+Copyright 2018 The HuggingFace Inc. team, The Hugging Face Team
+Copyright 2021 Microsoft Research and The HuggingFace Inc. team
+Copyright 2021 Microsoft Research and the HuggingFace Inc. team
+Copyright 2021 The Facebook, Inc. and The HuggingFace Inc. team
+Copyright 2022 Microsoft Research and The HuggingFace Inc. team
+Copyright (c) 2020, VinAI Research and the HuggingFace Inc. team
+Copyright 2020 Ecole Polytechnique and the HuggingFace Inc. team
+Copyright 2021 The Fairseq Authors and The HuggingFace Inc. team
+Copyright 2021 The Fairseq Authors and the HuggingFace Inc. team
+Copyright 2021, The Facebook, Inc. and The HuggingFace Inc. team
+Copyright 2021- NVIDIA Corporation and The HuggingFace Inc. team
+Copyright 2022 Meta Platforms Inc. and The HuggingFace Inc. team
+Copyright 2022 Meta Platforms, Inc.and The HuggingFace Inc. team
+Copyright 2022 The Fairseq Authors and The HuggingFace Inc. team
+Copyright 2022 The Fairseq Authors and the HuggingFace Inc. team
+Copyright 2022 The Metaseq Authors and The HuggingFace Inc. team
+Copyright 2019 Facebook AI Research and the HuggingFace Inc. team
+Copyright 2021 Facebook AI Research and The HuggingFace Inc. team
+Copyright 2021 The HuggingFace Team and The HuggingFace Inc. team
+Copyright 2021 The UCLA NLP Authors and The HuggingFace Inc. team
+Copyright 2022 Facebook AI Research and the HuggingFace Inc. team
+Copyright 2022 Meta Platforms, Inc. and The HuggingFace Inc. team
+Copyright 2022 The HuggingFace Team and The HuggingFace Inc. team
+Copyright 2020 The Microsoft Authors and The HuggingFace Inc. team
+Copyright 2020-present Google Brain and Carnegie Mellon University
+Copyright 2021 Google AI, Ross Wightman, The HuggingFace Inc. team
+Copyright 2022 Intel Labs, OpenMMLab and The HuggingFace Inc. team
+Copyright 2019-present, Facebook, Inc and the HuggingFace Inc. team
+Copyright 2018 Google AI, Google Brain and the HuggingFace Inc. team
+Copyright 2020 The SqueezeBert authors and The HuggingFace Inc. team
+Copyright 2021 Google AI, Google Brain and the HuggingFace Inc. team
+Copyright 2018 Google AI, Google Brain and Carnegie Mellon University
+Copyright 2022 Microsoft Research, Inc. and The HuggingFace Inc. team
+Copyright 2018 The Google AI Language Team Authors, Facebook AI Research
+Copyright 2019 Inria, Facebook AI Research and the HuggingFace Inc. team
+Copyright 2019-present CNRS, Facebook Inc. and the HuggingFace Inc. team
+Copyright 2020 The Google AI Language Team Authors, Facebook AI Research
+Copyright 2021 Facebook AI Research (FAIR) and The HuggingFace Inc. team
+Copyright 2022 Facebook AI Research (FAIR) and The HuggingFace Inc. team
+Copyright 2021 Tel AViv University, AllenAI and The HuggingFace Inc. team
+Copyright 2021, The Facebook AI Research Team and The HuggingFace Inc. team
+Copyright 2020 The Allen Institute for AI team and The HuggingFace Inc. team
+Copyright 2022 University of Wisconsin-Madison and The HuggingFace Inc. team
+Copyright 2021 The Google AI Flax Team Authors, and The HuggingFace Inc. team
+Copyright (c) 2020 The Google AI Language Team Authors, The HuggingFace Inc. team
+Copyright 2020 The Google AI Team, Stanford University and The HuggingFace Inc. team
+Copyright 2021 Facebook AI Research (FAIR), Ross Wightman, The HuggingFace Inc. team
+Copyright 2021 Google Research, Google AI, Google Brain and the HuggingFace Inc. team
+Copyright 2021 The Fairseq Authors, Microsoft Research, and The HuggingFace Inc. team
+Copyright 2022, UCLA NLP, The Facebook AI Research Team and The HuggingFace Inc. team
+Copyright 2021 Iz Beltagy, Matthew E. Peters, Arman Cohan and The HuggingFace Inc. team
+Copyright 2019-present, the HuggingFace Inc. team, The Google AI Language Team and Facebook, Inc.
+Copyright 2018 The Google AI Language Team Authors, The HuggingFace Inc. team, and the Lxmert Authors
+Copyright 2021 The I-BERT Authors Sehoon Kim, Amir Gholami, Zhewei Yao, Michael Mahoney, Kurt Keutzer
+Copyright 2022 BNRist (Tsinghua University), TKLNDST (Nankai University) and The HuggingFace Inc. team
+Copyright 2022 School of EIC, Huazhong University of Science & Technology and The HuggingFace Inc. team
+Copyright 2020 The Google AI Language Team Authors, Allegro.pl, Facebook Inc. and the HuggingFace Inc. team
 
-         (a) under intellectual property rights (other than patent or trademark) Licensable by such Contributor to use, reproduce, make available, modify, display, perform, distribute, and otherwise exploit its Contributions, either on an unmodified basis, with Modifications, or as part of a Larger Work; and
+Apache License
 
-         (b) under Patent Claims of such Contributor to make, use, sell, offer for sale, have made, import, and otherwise transfer either its Contributions or its Contributor Version.
+Version 2.0, January 2004
 
-      2.2. Effective Date
+http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 
-      The licenses granted in Section 2.1 with respect to any Contribution become effective for each Contribution on the date the Contributor first distributes such Contribution.
+   1. Definitions.
 
-      2.3. Limitations on Grant Scope
 
-      The licenses granted in this Section 2 are the only rights granted under this License. No additional rights or licenses will be implied from the distribution or licensing of Covered Software under this License. Notwithstanding Section 2.1(b) above, no patent license is granted by a Contributor:
 
-         (a) for any code that a Contributor has removed from Covered Software; or
+      "License" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document.
 
-         (b) for infringements caused by: (i) Your and any other third party's modifications of Covered Software, or (ii) the combination of its Contributions with other software (except as part of its Contributor Version); or
 
-         (c) under Patent Claims infringed by Covered Software in the absence of its Contributions.
 
-      This License does not grant any rights in the trademarks, service marks, or logos of any Contributor (except as may be necessary to comply with the notice requirements in Section 3.4).
+      "Licensor" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License.
 
-      2.4. Subsequent Licenses
 
-      No Contributor makes additional grants as a result of Your choice to distribute the Covered Software under a subsequent version of this License (see Section 10.2) or under the terms of a Secondary License (if permitted under the terms of Section 3.3).
 
-      2.5. Representation
+      "Legal Entity" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, "control" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity.
 
-      Each Contributor represents that the Contributor believes its Contributions are its original creation(s) or it has sufficient rights to grant the rights to its Contributions conveyed by this License.
 
-      2.6. Fair Use
 
-      This License is not intended to limit any rights You have under applicable copyright doctrines of fair use, fair dealing, or other equivalents.
+      "You" (or "Your") shall mean an individual or Legal Entity exercising permissions granted by this License.
 
-      2.7. Conditions
 
-      Sections 3.1, 3.2, 3.3, and 3.4 are conditions of the licenses granted in Section 2.1.
 
-   3. Responsibilities
+      "Source" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files.
 
-      3.1. Distribution of Source Form
 
-      All distribution of Covered Software in Source Code Form, including any Modifications that You create or to which You contribute, must be under the terms of this License. You must inform recipients that the Source Code Form of the Covered Software is governed by the terms of this License, and how they can obtain a copy of this License. You may not attempt to alter or restrict the recipients' rights in the Source Code Form.
 
-      3.2. Distribution of Executable Form
+      "Object" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types.
 
-      If You distribute Covered Software in Executable Form then:
 
-         (a) such Covered Software must also be made available in Source Code Form, as described in Section 3.1, and You must inform recipients of the Executable Form how they can obtain a copy of such Source Code Form by reasonable means in a timely manner, at a charge no more than the cost of distribution to the recipient; and
 
-         (b) You may distribute such Executable Form under the terms of this License, or sublicense it under different terms, provided that the license for the Executable Form does not attempt to limit or alter the recipients' rights in the Source Code Form under this License.
+      "Work" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below).
 
-      3.3. Distribution of a Larger Work
 
-      You may create and distribute a Larger Work under terms of Your choice, provided that You also comply with the requirements of this License for the Covered Software. If the Larger Work is a combination of Covered Software with a work governed by one or more Secondary Licenses, and the Covered Software is not Incompatible With Secondary Licenses, this License permits You to additionally distribute such Covered Software under the terms of such Secondary License(s), so that the recipient of the Larger Work may, at their option, further distribute the Covered Software under the terms of either this License or such Secondary License(s).
 
-      3.4. Notices
+      "Derivative Works" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof.
 
-      You may not remove or alter the substance of any license notices (including copyright notices, patent notices, disclaimers of warranty, or limitations of liability) contained within the Source Code Form of the Covered Software, except that You may alter any license notices to the extent required to remedy known factual inaccuracies.
 
-      3.5. Application of Additional Terms
 
-      You may choose to offer, and to charge a fee for, warranty, support, indemnity or liability obligations to one or more recipients of Covered Software. However, You may do so only on Your own behalf, and not on behalf of any Contributor. You must make it absolutely clear that any such warranty, support, indemnity, or liability obligation is offered by You alone, and You hereby agree to indemnify every Contributor for any liability incurred by such Contributor as a result of warranty, support, indemnity or liability terms You offer. You may include additional disclaimers of warranty and limitations of liability specific to any jurisdiction.
+      "Contribution" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, "submitted" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as "Not a Contribution."
 
-   4. Inability to Comply Due to Statute or Regulation
 
-   If it is impossible for You to comply with any of the terms of this License with respect to some or all of the Covered Software due to statute, judicial order, or regulation then You must: (a) comply with the terms of this License to the maximum extent possible; and (b) describe the limitations and the code they affect. Such description must be placed in a text file included with all distributions of the Covered Software under this License. Except to the extent prohibited by statute or regulation, such description must be sufficiently detailed for a recipient of ordinary skill to be able to understand it.
 
-   5. Termination
+      "Contributor" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work.
 
-      5.1. The rights granted under this License will terminate automatically if You fail to comply with any of its terms. However, if You become compliant, then the rights granted under this License from a particular Contributor are reinstated (a) provisionally, unless and until such Contributor explicitly and finally terminates Your grants, and (b) on an ongoing basis, if such Contributor fails to notify You of the non-compliance by some reasonable means prior to 60 days after You have come back into compliance. Moreover, Your grants from a particular Contributor are reinstated on an ongoing basis if such Contributor notifies You of the non-compliance by some reasonable means, this is the first time You have received notice of non-compliance with this License from such Contributor, and You become compliant prior to 30 days after Your receipt of the notice.
+   2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form.
 
-      5.2. If You initiate litigation against any entity by asserting a patent infringement claim (excluding declaratory judgment actions, counter-claims, and cross-claims) alleging that a Contributor Version directly or indirectly infringes any patent, then the rights granted to You by any and all Contributors for the Covered Software under Section 2.1 of this License shall terminate.
+   3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed.
 
-      5.3. In the event of termination under Sections 5.1 or 5.2 above, all end user license agreements (excluding distributors and resellers) which have been validly granted by You or Your distributors under this License prior to termination shall survive termination.
+   4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions:
 
-   6. Disclaimer of Warranty
+      (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and
 
-   Covered Software is provided under this License on an "as is" basis, without warranty of any kind, either expressed, implied, or statutory, including, without limitation, warranties that the Covered Software is free of defects, merchantable, fit for a particular purpose or non-infringing. The entire risk as to the quality and performance of the Covered Software is with You. Should any Covered Software prove defective in any respect, You (not any Contributor) assume the cost of any necessary servicing, repair, or correction. This disclaimer of warranty constitutes an essential part of this License. No use of any Covered Software is authorized under this License except under this disclaimer.
+      (b) You must cause any modified files to carry prominent notices stating that You changed the files; and
 
-   7. Limitation of Liability
+      (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and
 
-   Under no circumstances and under no legal theory, whether tort (including negligence), contract, or otherwise, shall any Contributor, or anyone who distributes Covered Software as permitted above, be liable to You for any direct, indirect, special, incidental, or consequential damages of any character including, without limitation, damages for lost profits, loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses, even if such party shall have been informed of the possibility of such damages. This limitation of liability shall not apply to liability for death or personal injury resulting from such party's negligence to the extent applicable law prohibits such limitation. Some jurisdictions do not allow the exclusion or limitation of incidental or consequential damages, so this exclusion and limitation may not apply to You.
+      (d) If the Work includes a "NOTICE" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License.
 
-   8. Litigation
+      You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License.
 
-   Any litigation relating to this License may be brought only in the courts of a jurisdiction where the defendant maintains its principal place of business and such litigation shall be governed by laws of that jurisdiction, without reference to its conflict-of-law provisions. Nothing in this Section shall prevent a party's ability to bring cross-claims or counter-claims.
+   5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions.
 
-   9. Miscellaneous
+   6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file.
 
-   This License represents the complete agreement concerning the subject matter hereof. If any provision of this License is held to be unenforceable, such provision shall be reformed only to the extent necessary to make it enforceable. Any law or regulation which provides that the language of a contract shall be construed against the drafter shall not be used to construe this License against a Contributor.
+   7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License.
 
-   10. Versions of the License
+   8. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages.
 
-      10.1. New Versions
+   9. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS
 
-      Mozilla Foundation is the license steward. Except as provided in Section 10.3, no one other than the license steward has the right to modify or publish new versions of this License. Each version will be given a distinguishing version number.
+APPENDIX: How to apply the Apache License to your work.
 
-      10.2. Effect of New Versions
+To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets "[]" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same "printed page" as the copyright notice for easier identification within third-party archives.
 
-      You may distribute the Covered Software under the terms of the version of the License under which You originally received the Covered Software, or under the terms of any subsequent version published by the license steward.
+Copyright [yyyy] [name of copyright owner]
 
-      10.3. Modified Versions
+Licensed under the Apache License, Version 2.0 (the "License");
 
-      If you create software not governed by this License, and you want to create a new license for such software, you may create and use a modified version of this License if you rename the license and remove any references to the name of the license steward (except to note that such modified license differs from this License).
+you may not use this file except in compliance with the License.
 
-      10.4. Distributing Source Code Form that is Incompatible With Secondary Licenses
+You may obtain a copy of the License at
 
-      If You choose to distribute Source Code Form that is Incompatible With Secondary Licenses under the terms of this version of the License, the notice described in Exhibit B of this License must be attached. Exhibit A - Source Code Form License Notice
+http://www.apache.org/licenses/LICENSE-2.0
 
-This Source Code Form is subject to the terms of the Mozilla Public License, v. 2.0. If a copy of the MPL was not distributed with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
+Unless required by applicable law or agreed to in writing, software
 
-If it is not possible or desirable to put the notice in a particular file, then You may include the notice in a location (such as a LICENSE file in a relevant directory) where a recipient would be likely to look for such a notice.
+distributed under the License is distributed on an "AS IS" BASIS,
 
-You may add additional accurate notices of copyright ownership.
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 
-Exhibit B - "Incompatible With Secondary Licenses" Notice
+See the License for the specific language governing permissions and
 
-This Source Code Form is "Incompatible With Secondary Licenses", as defined by the Mozilla Public License, v. 2.0.
+limitations under the License.
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-typing-extensions 4.5.0 - Python-2.0
+transformers 4.26.1 - Apache-2.0
 
 
-Copyright (c) 1995-2001 Corporation for National Research Initiatives
-Copyright (c) 1991 - 1995, Stichting Mathematisch Centrum Amsterdam, The Netherlands
-Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022 Python Software Foundation
+Copyright 2022
+Copyright 2018 T5
+Copyright 2020 T5
+Copyright 2021 T5
+Copyright 2022 LongT5
+Copyright 2022 Microsoft
+Copyright 2022 Salesforce
+Copyright 2020 Hugging Face
+Copyright (c) 2018 Microsoft
+Copyright (c) 2020 SenseTime
+Copyright 2020, Hugging Face
+Copyright (c) 2020 tanreinama
+Copyright 2022 Meta Platforms
+Copyright 2022 The BAAI Teams
+Copyright 2018 Mesh TensorFlow
+Copyright 2018 The OpenAI Team
+Copyright 2020 Mesh TensorFlow
+Copyright 2021 Mesh TensorFlow
+Copyright 2021 The Marian Team
+Copyright 2021 The OpenAI Team
+Copyright 2022 The OpenAI Team
+Copyright 2022 the Big Science
+Copyright The HuggingFace team
+Copyright 2018 The Open AI Team
+Copyright 2019 The Open AI Team
+Copyright 2021 The OFA-Sys Team
+Copyright 2021 The Open AI Team
+Copyright 2022 The OFA-Sys Team
+Copyright 2022 The Open AI Team
+Copyright 2022 SwitchTransformers
+Copyright 2022 Google LLC., LongT5
+Copyright 2022 The Salesforce Team
+Copyright (c) HuggingFace Inc. team
+Copyright 2018 The Google Flax Team
+Copyright 2020 Optuna, Hugging Face
+Copyright 2020 The HuggingFace Team
+Copyright 2021 The Google Flax Team
+Copyright 2021 The HuggingFace Team
+Copyright 2022 The Google Flax Team
+Copyright 2022 The HuggingFace Team
+Copyright 2023 The HuggingFace Team
+Copyright The HuggingFace Inc. team
+Copyright (c) 2001-2020 NLTK Project
+Copyright 2021 AlQuraishi Laboratory
+Copyright 2022 HuggingFace Inc. team
+Copyright 2018, Hao Tan, Mohit Bansal
+Copyright 2018- The Hugging Face team
+Copyright (c) 2018, Alexander Kirillov
+Copyright (c) 2018, NVIDIA CORPORATION.
+Copyright (c) 2020, NVIDIA CORPORATION.
+Copyright (c) 20121, NVIDIA CORPORATION.
+Copyright (c) 2021-, NVIDIA CORPORATION.
+Copyright 2018 The HuggingFace Inc. team
+Copyright 2020 The HuggingFace Inc. team
+Copyright 2021 The HuggingFace Inc. team
+Copyright 2022 The HuggingFace Inc. team
+Copyright 2020, The HuggingFace Inc. team
+Copyright 2018 The Google AI Language Team
+Copyright 2019 The Google AI Language Team
+Copyright 2020 The Google AI Language Team
+Copyright 2022 The Google AI Language Team
+Copyright 2022 The Trajectory Transformers
+Copyright 2022, Google and HuggingFace Inc.
+Copyright (c) 2018-2021, NVIDIA CORPORATION.
+Copyright 2020 The Facebook AI Research Team
+Copyright 2021 DeepMind Technologies Limited
+Copyright 2021 The Facebook AI Research Team
+Copyright 2022 The Facebook AI Research Team
+Copyright 2022 NVIDIA and The HuggingFace Team
+Copyright (c) Facebook, Inc. and its affiliates
+Copyright 2021 NVIDIA The HuggingFace Inc. team
+Copyright 2022 NVIDIA The HuggingFace Inc. team
+Copyright 2020-present the HuggingFace Inc. team
+Copyright 2022 Facebook and The HuggingFace Team
+Copyright Deepmind and The HuggingFace Inc. team
+Copyright 2018 Amazon.com, Inc. or its affiliates
+Copyright 2018 DPR Authors, The Hugging Face Team
+Copyright 2022 Google AI and The HuggingFace Team
+Copyright 2022 Meta and The HuggingFace Inc. team
+Copyright 2022 WeChatAI The HuggingFace Inc. team
+Copyright Google AI and The HuggingFace Inc. team
+Copyright 2010, DPR authors, The Hugging Face Team
+Copyright 2021 Google AI The HuggingFace Inc. team
+Copyright 2022 KAIST and The HuggingFace Inc. team
+Copyright (c) Microsoft Corporation and HuggingFace
+Copyright 2018 Salesforce and HuggingFace Inc. team
+Copyright 2020 Google and The HuggingFace Inc. team
+Copyright 2020, The T5 Authors and HuggingFace Inc.
+Copyright 2021 NVIDIA and The HuggingFace Inc. team
+Copyright 2021 The EleutherAI and HuggingFace Teams
+Copyright 2022 EleutherAI The HuggingFace Inc. team
+Copyright 2022 Google LLC and HuggingFace Inc. team
+Copyright 2022 HuggingFace Inc. team and BigScience
+Copyright 2022 The EleutherAI and HuggingFace Teams
+Copyright 2022 UW-Madison The HuggingFace Inc. team
+Copyright 2021, Google and The HuggingFace Inc. team
+Copyright 2022, Google and The HuggingFace Inc. team
+Copyright Studio Ousia and The HuggingFace Inc. team
+Copyright Studio-Ouisa and The HuggingFace Inc. team
+Copyright 2021 Deepmind and The HuggingFace Inc. team
+Copyright 2022 SHI Labs and The HuggingFace Inc. team
+Copyright 2022 WeChatAI and The HuggingFace Inc. team
+Copyright 2020 Microsoft and the HuggingFace Inc. team
+Copyright 2021 Google AI and The HuggingFace Inc. team
+Copyright 2021 Microsoft and The HuggingFace Inc. team
+Copyright 2022 Google AI and The HuggingFace Inc. team
+Copyright 2022 SenseTime and The HuggingFace Inc. team
+Copyright Meta Platforms and The HuggingFace Inc. team
+Copyright 2018 Salesforce and The HuggingFace Inc. team
+Copyright 2018 The T5 authors and HuggingFace Inc. team
+Copyright 2020 Microsoft and the Hugging Face Inc. team
+Copyright 2020, Microsoft and the HuggingFace Inc. team
+Copyright 2021 ASAPP Inc. and The HuggingFace Inc. team
+Copyright 2021 ASAPP Inc. and the HuggingFace Inc. team
+Copyright 2021 The Eleuther AI and The Google Flax Team
+Copyright 2022 Apple Inc. and The HuggingFace Inc. team
+Copyright 2022 EleutherAI and The HuggingFace Inc. team
+Copyright 2022 Sea AI Lab and The HuggingFace Inc. team
+Copyright 2022 The Impira Team and the HuggingFace Team
+Copyright 2022 The OpenAI team and The HuggingFace Team
+Copyright 2022 The Salesforce authors, The Open AI Team
+Copyright 2022 UW-Madison and The HuggingFace Inc. team
+Copyright 2022, The LongT5 Authors and HuggingFace Inc.
+Copyright 2022, UCLA NLP, The Facebook AI Research Team
+Copyright Google Research and The HuggingFace Inc. team
+Copyright 2018 The Microsoft Research Asia LayoutLM Team
+Copyright 2021 Google Research The HuggingFace Inc. team
+Copyright 2021 The Eleuther AI and HuggingFace Inc. team
+Copyright 2022 ABEJA, Inc. and The HuggingFace Inc. team
+Copyright 2022 Facebook AI and The HuggingFace Inc. team
+Copyright 2022 Sea AI Labs and The HuggingFace Inc. team
+Copyright 2010, The Microsoft Research Asia LayoutLM Team
+Copyright 2021 Studio Ousia and the HuggingFace Inc. team
+Copyright 2021, Google Inc. and The HuggingFace Inc. team
+Copyright 2021, The Microsoft Research Asia MarkupLM Team
+Copyright 2021 NVIDIA Corporation and The HuggingFace Team
+Copyright 2022 Microsoft Research and The HuggingFace Team
+Copyright 2022 NAVER AI Labs and The HuggingFace Inc. team
+Copyright Microsoft Research and The HuggingFace Inc. team
+Copyright 2021 Microsoft Research The HuggingFace Inc. team
+Copyright 2021 The EleutherAI and The HuggingFace Inc. team
+Copyright 2021 The Fairseq Authors and The Google Flax Team
+Copyright 2021 VinAI Research and the HuggingFace Inc. team
+Copyright 2022 Meta Platforms and The HuggingFace Inc. team
+Copyright 2022 The Fairseq Authors and The Google Flax Team
+Copyright 2019 The TensorFlow Authors, The Hugging Face Team
+Copyright 2020 Google Research and The HuggingFace Inc. team
+Copyright 2020 The HuggingFace Team and the AllenNLP authors
+Copyright 2021 Google Research and The HuggingFace Inc. team
+Copyright 2021 The Fairseq Authors The HuggingFace Inc. team
+Copyright 2021 The OpenAI Team Authors, The Google Flax Team
+Copyright 2022 The HuggingFace Inc. team and the OpenAI team
+Copyright The HuggingFace Team and The HuggingFace Inc. team
+Copyright 2020 The Trax Authors and The HuggingFace Inc. team
+Copyright 2020, The RAG Authors and The HuggingFace Inc. team
+Copyright 2021 Facebook AI Research The HuggingFace Inc. team
+Copyright 2021 The HuggingFace Team The HuggingFace Inc. team
+Copyright 2022 The HuggingFace Team The HuggingFace Inc. team
+Copyright 2018 Hao Tan, Mohit Bansal, and the HuggingFace team
+Copyright 2021 The Facebook Inc. and The HuggingFace Inc. team
+Copyright 2021 The Facebook, Inc and The HuggingFace Inc. team
+Copyright 2022 Snapchat Research and The HuggingFace Inc. team
+Copyright 2022 The REALM authors and The HuggingFace Inc. team
+Copyright 2018 The HuggingFace Inc. team, Microsoft Corporation
+Copyright 2018 The HuggingFace Inc. team, The Hugging Face Team
+Copyright 2021 Microsoft Research and The HuggingFace Inc. team
+Copyright 2021 Microsoft Research and the HuggingFace Inc. team
+Copyright 2021 The Facebook, Inc. and The HuggingFace Inc. team
+Copyright 2022 Microsoft Research and The HuggingFace Inc. team
+Copyright 2022 Microsoft, clefourrier The HuggingFace Inc. team
+Copyright 2022 The HuggingFace Inc. team and the AI-Sweden team
+Copyright 2022 The OpenAI Authors and The HuggingFace Inc. team
+Copyright (c) 2020, VinAI Research and the HuggingFace Inc. team
+Copyright 2020 Ecole Polytechnique and the HuggingFace Inc. team
+Copyright 2021 The Fairseq Authors and The HuggingFace Inc. team
+Copyright 2021 The Fairseq Authors and the HuggingFace Inc. team
+Copyright 2021, The Facebook, Inc. and The HuggingFace Inc. team
+Copyright 2021- NVIDIA Corporation and The HuggingFace Inc. team
+Copyright 2022 Meta Platforms Inc. and The HuggingFace Inc. team
+Copyright 2022 Meta Platforms, Inc.and The HuggingFace Inc. team
+Copyright 2022 The Fairseq Authors and The HuggingFace Inc. team
+Copyright 2022 The Fairseq Authors and the HuggingFace Inc. team
+Copyright 2022 The Metaseq Authors and The HuggingFace Inc. team
+Copyright 2019 Facebook AI Research and the HuggingFace Inc. team
+Copyright 2021 Facebook AI Research and The HuggingFace Inc. team
+Copyright 2021 The HuggingFace Team and The HuggingFace Inc. team
+Copyright 2021 The UCLA NLP Authors and The HuggingFace Inc. team
+Copyright 2022 Facebook AI Research and the HuggingFace Inc. team
+Copyright 2022 Meta Platforms, Inc. and The HuggingFace Inc. team
+Copyright 2022 The HuggingFace Team and The HuggingFace Inc. team
+Copyright 2020 The Microsoft Authors and The HuggingFace Inc. team
+Copyright 2020-present Google Brain and Carnegie Mellon University
+Copyright 2021 Google AI, Ross Wightman, The HuggingFace Inc. team
+Copyright 2022 Google AI, Ross Wightman, The HuggingFace Inc. team
+Copyright 2022 Intel Labs, OpenMMLab and The HuggingFace Inc. team
+Copyright 2019-present, Facebook, Inc and the HuggingFace Inc. team
+Copyright 2018 Google AI, Google Brain and the HuggingFace Inc. team
+Copyright 2020 The SqueezeBert authors and The HuggingFace Inc. team
+Copyright 2021 Google AI, Google Brain and the HuggingFace Inc. team
+Copyright 2022 Microsoft Research Asia and The HuggingFace Inc. team
+Copyright 2022 Microsoft Research Asia and the HuggingFace Inc. team
+Copyright 2018 Google AI, Google Brain and Carnegie Mellon University
+Copyright 2022 Microsoft Research, Inc. and The HuggingFace Inc. team
+Copyright 2022 The HuggingFace Team and Microsoft Research AI4Science
+Copyright 2018 The Google AI Language Team Authors, Facebook AI Research
+Copyright 2019 Inria, Facebook AI Research and the HuggingFace Inc. team
+Copyright 2019-present CNRS, Facebook Inc. and the HuggingFace Inc. team
+Copyright 2020 The Google AI Language Team Authors, Facebook AI Research
+Copyright 2021 Facebook AI Research (FAIR) and The HuggingFace Inc. team
+Copyright 2022 Facebook AI Research (FAIR) and The HuggingFace Inc. team
+Copyright 2021 Tel AViv University, AllenAI and The HuggingFace Inc. team
+Copyright 2021, The Facebook AI Research Team and The HuggingFace Inc. team
+Copyright 2020 The Allen Institute for AI team and The HuggingFace Inc. team
+Copyright 2022 University of Wisconsin-Madison and The HuggingFace Inc. team
+Copyright 2021 The Google AI Flax Team Authors, and The HuggingFace Inc. team
+Copyright (c) 2020 The Google AI Language Team Authors, The HuggingFace Inc. team
+Copyright 2020 The Google AI Team, Stanford University and The HuggingFace Inc. team
+Copyright 2021 Facebook AI Research (FAIR), Ross Wightman, The HuggingFace Inc. team
+Copyright 2021 Google Research, Google AI, Google Brain and the HuggingFace Inc. team
+Copyright 2021 The Fairseq Authors, Microsoft Research, and The HuggingFace Inc. team
+Copyright 2022, UCLA NLP, The Facebook AI Research Team and The HuggingFace Inc. team
+Copyright 2021 Iz Beltagy, Matthew E. Peters, Arman Cohan and The HuggingFace Inc. team
+Copyright 2022 Multimedia Computing Group, Nanjing University and The HuggingFace Inc. team
+Copyright 2022 WenXiang ZhongzhiCheng LedellWu LiuGuang BoWenZhang The HuggingFace Inc. team
+Copyright 2022 WenXiang ZhongzhiCheng LedellWu LiuGuang BoWenZhang and The HuggingFace Inc. team
+Copyright 2019-present, the HuggingFace Inc. team, The Google AI Language Team and Facebook, Inc.
+Copyright 2018 The Google AI Language Team Authors, The HuggingFace Inc. team, and the Lxmert Authors
+Copyright 2021 The I-BERT Authors Sehoon Kim, Amir Gholami, Zhewei Yao, Michael Mahoney, Kurt Keutzer
+Copyright 2022 BNRist (Tsinghua University), TKLNDST (Nankai University) and The HuggingFace Inc. team
+Copyright 2022 School of EIC, Huazhong University of Science & Technology and The HuggingFace Inc. team
+Copyright 2020 The Google AI Language Team Authors, Allegro.pl, Facebook Inc. and the HuggingFace Inc. team
 
-PYTHON SOFTWARE FOUNDATION LICENSE VERSION 2
+Apache License
 
-   1. This LICENSE AGREEMENT is between the Python Software Foundation ("PSF"), and the Individual or Organization ("Licensee") accessing and otherwise using this software ("Python") in source or binary form and its associated documentation.
+Version 2.0, January 2004
 
-   2. Subject to the terms and conditions of this License Agreement, PSF hereby grants Licensee a nonexclusive, royalty-free, world-wide license to reproduce, analyze, test, perform and/or display publicly, prepare derivative works, distribute, and otherwise use Python alone or in any derivative version, provided, however, that PSF's License Agreement and PSF's notice of copyright, i.e., "Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006 Python Software Foundation; All Rights Reserved" are retained in Python alone or in any derivative version prepared by Licensee.
+http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
 
-   3. In the event Licensee prepares a derivative work that is based on or incorporates Python or any part thereof, and wants to make the derivative work available to others as provided herein, then Licensee hereby agrees to include in any such work a brief summary of the changes made to Python.
+   1. Definitions.
 
-   4. PSF is making Python available to Licensee on an "AS IS" basis. PSF MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR IMPLIED. BY WAY OF EXAMPLE, BUT NOT LIMITATION, PSF MAKES NO AND DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF PYTHON WILL NOT INFRINGE ANY THIRD PARTY RIGHTS.
 
-   5. PSF SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF PYTHON FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS A RESULT OF MODIFYING, DISTRIBUTING, OR OTHERWISE USING PYTHON, OR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.
 
-   6. This License Agreement will automatically terminate upon a material breach of its terms and conditions.
+      "License" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document.
 
-   7. Nothing in this License Agreement shall be deemed to create any relationship of agency, partnership, or joint venture between PSF and Licensee. This License Agreement does not grant permission to use PSF trademarks or trade name in a trademark sense to endorse or promote products or services of Licensee, or any third party.
 
-   8. By copying, installing or otherwise using Python, Licensee agrees to be bound by the terms and conditions of this License Agreement. BEOPEN.COM LICENSE AGREEMENT FOR PYTHON 2.0
 
-BEOPEN PYTHON OPEN SOURCE LICENSE AGREEMENT VERSION 1
+      "Licensor" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License.
 
-   1. This LICENSE AGREEMENT is between BeOpen.com ("BeOpen"), having an office at 160 Saratoga Avenue, Santa Clara, CA 95051, and the Individual or Organization ("Licensee") accessing and otherwise using this software in source or binary form and its associated documentation ("the Software").
 
-   2. Subject to the terms and conditions of this BeOpen Python License Agreement, BeOpen hereby grants Licensee a non-exclusive, royalty-free, world-wide license to reproduce, analyze, test, perform and/or display publicly, prepare derivative works, distribute, and otherwise use the Software alone or in any derivative version, provided, however, that the BeOpen Python License is retained in the Software, alone or in any derivative version prepared by Licensee.
 
-   3. BeOpen is making the Software available to Licensee on an "AS IS" basis. BEOPEN MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR IMPLIED. BY WAY OF EXAMPLE, BUT NOT LIMITATION, BEOPEN MAKES NO AND DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF THE SOFTWARE WILL NOT INFRINGE ANY THIRD PARTY RIGHTS.
+      "Legal Entity" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, "control" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity.
 
-   4. BEOPEN SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF THE SOFTWARE FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS A RESULT OF USING, MODIFYING OR DISTRIBUTING THE SOFTWARE, OR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.
 
-   5. This License Agreement will automatically terminate upon a material breach of its terms and conditions.
 
-   6. This License Agreement shall be governed by and interpreted in all respects by the law of the State of California, excluding conflict of law provisions. Nothing in this License Agreement shall be deemed to create any relationship of agency, partnership, or joint venture between BeOpen and Licensee. This License Agreement does not grant permission to use BeOpen trademarks or trade names in a trademark sense to endorse or promote products or services of Licensee, or any third party. As an exception, the "BeOpen Python" logos available at http://www.pythonlabs.com/logos.html may be used according to the permissions granted on that web page.
+      "You" (or "Your") shall mean an individual or Legal Entity exercising permissions granted by this License.
 
-   7. By copying, installing or otherwise using the software, Licensee agrees to be bound by the terms and conditions of this License Agreement. CNRI OPEN SOURCE LICENSE AGREEMENT (for Python 1.6b1) IMPORTANT: PLEASE READ THE FOLLOWING AGREEMENT CAREFULLY.
 
-BY CLICKING ON "ACCEPT" WHERE INDICATED BELOW, OR BY COPYING, INSTALLING OR OTHERWISE USING PYTHON 1.6, beta 1 SOFTWARE, YOU ARE DEEMED TO HAVE AGREED TO THE TERMS AND CONDITIONS OF THIS LICENSE AGREEMENT.
 
-   1. This LICENSE AGREEMENT is between the Corporation for National Research Initiatives, having an office at 1895 Preston White Drive, Reston, VA 20191 ("CNRI"), and the Individual or Organization ("Licensee") accessing and otherwise using Python 1.6, beta 1 software in source or binary form and its associated documentation, as released at the www.python.org Internet site on August 4, 2000 ("Python 1.6b1").
+      "Source" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files.
 
-   2. Subject to the terms and conditions of this License Agreement, CNRI hereby grants Licensee a non-exclusive, royalty-free, world-wide license to reproduce, analyze, test, perform and/or display publicly, prepare derivative works, distribute, and otherwise use Python 1.6b1 alone or in any derivative version, provided, however, that CNRIs License Agreement is retained in Python 1.6b1, alone or in any derivative version prepared by Licensee.
 
-   Alternately, in lieu of CNRIs License Agreement, Licensee may substitute the following text (omitting the quotes): "Python 1.6, beta 1, is made available subject to the terms and conditions in CNRIs License Agreement. This Agreement may be located on the Internet using the following unique, persistent identifier (known as a handle): 1895.22/1011. This Agreement may also be obtained from a proxy server on the Internet using the URL:http://hdl.handle.net/1895.22/1011".
 
-   3. In the event Licensee prepares a derivative work that is based on or incorporates Python 1.6b1 or any part thereof, and wants to make the derivative work available to the public as provided herein, then Licensee hereby agrees to indicate in any such work the nature of the modifications made to Python 1.6b1.
+      "Object" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types.
 
-   4. CNRI is making Python 1.6b1 available to Licensee on an "AS IS" basis. CNRI MAKES NO REPRESENTATIONS OR WARRANTIES, EXPRESS OR IMPLIED. BY WAY OF EXAMPLE, BUT NOT LIMITATION, CNRI MAKES NO AND DISCLAIMS ANY REPRESENTATION OR WARRANTY OF MERCHANTABILITY OR FITNESS FOR ANY PARTICULAR PURPOSE OR THAT THE USE OF PYTHON 1.6b1 WILL NOT INFRINGE ANY THIRD PARTY RIGHTS.
 
-   5. CNRI SHALL NOT BE LIABLE TO LICENSEE OR ANY OTHER USERS OF THE SOFTWARE FOR ANY INCIDENTAL, SPECIAL, OR CONSEQUENTIAL DAMAGES OR LOSS AS A RESULT OF USING, MODIFYING OR DISTRIBUTING PYTHON 1.6b1, OR ANY DERIVATIVE THEREOF, EVEN IF ADVISED OF THE POSSIBILITY THEREOF.
 
-   6. This License Agreement will automatically terminate upon a material breach of its terms and conditions.
+      "Work" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below).
 
-   7. This License Agreement shall be governed by and interpreted in all respects by the law of the State of Virginia, excluding conflict of law provisions. Nothing in this License Agreement shall be deemed to create any relationship of agency, partnership, or joint venture between CNRI and Licensee. This License Agreement does not grant permission to use CNRI trademarks or trade name in a trademark sense to endorse or promote products or services of Licensee, or any third party.
 
-   8. By clicking on the "ACCEPT" button where indicated, or by copying, installing or otherwise using Python 1.6b1, Licensee agrees to be bound by the terms and conditions of this License Agreement. ACCEPT CWI LICENSE AGREEMENT FOR PYTHON 0.9.0 THROUGH 1.2
 
-Copyright (c) 1991 - 1995, Stichting Mathematisch Centrum Amsterdam, The Netherlands. All rights reserved.
+      "Derivative Works" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof.
 
-Permission to use, copy, modify, and distribute this software and its documentation for any purpose and without fee is hereby granted, provided that the above copyright notice appear in all copies and that both that copyright notice and this permission notice appear in supporting documentation, and that the name of Stichting Mathematisch Centrum or CWI not be used in advertising or publicity pertaining to distribution of the software without specific, written prior permission.
 
-STICHTING MATHEMATISCH CENTRUM DISCLAIMS ALL WARRANTIES WITH REGARD TO THIS SOFTWARE, INCLUDING ALL IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS, IN NO EVENT SHALL STICHTING MATHEMATISCH CENTRUM BE LIABLE FOR ANY SPECIAL, INDIRECT OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.
+
+      "Contribution" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, "submitted" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as "Not a Contribution."
+
+
+
+      "Contributor" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work.
+
+   2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form.
+
+   3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed.
+
+   4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions:
+
+      (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and
+
+      (b) You must cause any modified files to carry prominent notices stating that You changed the files; and
+
+      (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and
+
+      (d) If the Work includes a "NOTICE" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License.
+
+      You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License.
+
+   5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions.
+
+   6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file.
+
+   7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License.
+
+   8. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages.
+
+   9. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS
+
+APPENDIX: How to apply the Apache License to your work.
+
+To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets "[]" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same "printed page" as the copyright notice for easier identification within third-party archives.
+
+Copyright [yyyy] [name of copyright owner]
+
+Licensed under the Apache License, Version 2.0 (the "License");
+
+you may not use this file except in compliance with the License.
+
+You may obtain a copy of the License at
+
+http://www.apache.org/licenses/LICENSE-2.0
+
+Unless required by applicable law or agreed to in writing, software
+
+distributed under the License is distributed on an "AS IS" BASIS,
+
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+
+See the License for the specific language governing permissions and
+
+limitations under the License.
 
 ---------------------------------------------------------
 
 ---------------------------------------------------------
 
-sklearn-pandas 1.7.0 - Zlib
+transformers 4.28.1 - Apache-2.0
+
+
+Copyright 2022
+Copyright 2018 T5
+Copyright 2020 T5
+Copyright 2021 T5
+Copyright 2022 LongT5
+Copyright 2023 NllbMoe
+copyright Meta Research
+Copyright 2022 Microsoft
+Copyright 2023 Toshiyuki
+Copyright 2022 Salesforce
+Copyright 2020 Hugging Face
+Copyright (c) 2018 Microsoft
+Copyright (c) 2020 SenseTime
+Copyright 2020, Hugging Face
+Copyright (c) 2020 tanreinama
+Copyright 2022 Meta Platforms
+Copyright 2022 The BAAI Teams
+Copyright 2018 Mesh TensorFlow
+Copyright 2018 The OpenAI Team
+Copyright 2020 Mesh TensorFlow
+Copyright 2021 Mesh TensorFlow
+Copyright 2021 The Marian Team
+Copyright 2021 The OpenAI Team
+Copyright 2022 The OpenAI Team
+Copyright 2022 the Big Science
+Copyright The HuggingFace team
+Copyright 2018 The Open AI Team
+Copyright 2019 HuggingFace Inc.
+Copyright 2019 The Open AI Team
+Copyright 2021 HuggingFace Inc.
+Copyright 2021 The OFA-Sys Team
+Copyright 2021 The Open AI Team
+Copyright 2022 HuggingFace Inc.
+Copyright 2022 The OFA-Sys Team
+Copyright 2022 The Open AI Team
+Copyright 2023 HuggingFace Inc.
+Copyright 2023 The Meta AI Team
+Copyright 2023, HuggingFace Inc.
+Copyright 2022 SwitchTransformers
+Copyright 2022 Google LLC., LongT5
+Copyright 2022 The Salesforce Team
+Copyright 2023 The Salesforce Team
+Copyright (c) HuggingFace Inc. team
+Copyright 2018 The Google Flax Team
+Copyright 2020 Optuna, Hugging Face
+Copyright 2020 The HuggingFace Team
+Copyright 2021 The Google Flax Team
+Copyright 2021 The HuggingFace Team
+Copyright 2022 The Google Flax Team
+Copyright 2022 The HuggingFace Team
+Copyright 2023 The Google Flax Team
+Copyright 2023 The HuggingFace Team
+Copyright The HuggingFace Inc. team
+Copyright (c) 2001-2020 NLTK Project
+Copyright 2021 AlQuraishi Laboratory
+Copyright 2022 HuggingFace Inc. team
+Copyright 2023 HuggingFace Inc. team
+Copyright 2018, Hao Tan, Mohit Bansal
+Copyright 2018- The Hugging Face team
+Copyright (c) 2018, Alexander Kirillov
+Copyright (c) 2018, NVIDIA CORPORATION.
+Copyright (c) 2020, NVIDIA CORPORATION.
+Copyright 2023 The Google Research Team
+Copyright (c) 20121, NVIDIA CORPORATION.
+Copyright (c) 2021-, NVIDIA CORPORATION.
+Copyright 2018 The HuggingFace Inc. team
+Copyright 2020 The HuggingFace Inc. team
+Copyright 2021 The HuggingFace Inc. team
+Copyright 2022 The HuggingFace Inc. team
+Copyright 2023 The HuggingFace Inc. team
+Copyright 2020, The HuggingFace Inc. team
+Copyright 2018 The Google AI Language Team
+Copyright 2019 The Google AI Language Team
+Copyright 2020 The Google AI Language Team
+Copyright 2022 The Google AI Language Team
+Copyright 2022 The Trajectory Transformers
+Copyright 2022, Google and HuggingFace Inc.
+Copyright (c) 2018-2021, NVIDIA CORPORATION.
+Copyright 2020 The Facebook AI Research Team
+Copyright 2021 DeepMind Technologies Limited
+Copyright 2021 The Facebook AI Research Team
+Copyright 2022 The Facebook AI Research Team
+Copyright 2023 The HuggingFace and Baidu Team
+Copyright 2022 NVIDIA and The HuggingFace Team
+Copyright (c) Facebook, Inc. and its affiliates
+Copyright 2021 NVIDIA The HuggingFace Inc. team
+Copyright 2022 NVIDIA The HuggingFace Inc. team
+Copyright 2020-present the HuggingFace Inc. team
+Copyright 2022 Facebook and The HuggingFace Team
+Copyright Deepmind and The HuggingFace Inc. team
+Copyright 2018 Amazon.com, Inc. or its affiliates
+Copyright 2018 DPR Authors, The Hugging Face Team
+Copyright 2022 Google AI and The HuggingFace Team
+Copyright 2022 Meta and The HuggingFace Inc. team
+Copyright 2022 WeChatAI The HuggingFace Inc. team
+Copyright 2023 The HuggingFace Inc. & Google team
+Copyright Google AI and The HuggingFace Inc. team
+Copyright 2010, DPR authors, The Hugging Face Team
+Copyright 2021 Google AI The HuggingFace Inc. team
+Copyright 2022 KAIST and The HuggingFace Inc. team
+Copyright (c) Microsoft Corporation and HuggingFace
+Copyright 2018 Salesforce and HuggingFace Inc. team
+Copyright 2020 Google and The HuggingFace Inc. team
+Copyright 2020, The T5 Authors and HuggingFace Inc.
+Copyright 2021 NVIDIA and The HuggingFace Inc. team
+Copyright 2021 The EleutherAI and HuggingFace Teams
+Copyright 2022 EleutherAI The HuggingFace Inc. team
+Copyright 2022 Google LLC and HuggingFace Inc. team
+Copyright 2022 HuggingFace Inc. team and BigScience
+Copyright 2022 The EleutherAI and HuggingFace Teams
+Copyright 2022 UW-Madison The HuggingFace Inc. team
+Copyright 2023 Amazon and The HuggingFace Inc. team
+Copyright 2021, Google and The HuggingFace Inc. team
+Copyright 2022, Google and The HuggingFace Inc. team
+Copyright Studio Ousia and The HuggingFace Inc. team
+Copyright Studio-Ouisa and The HuggingFace Inc. team
+Copyright 2021 Deepmind and The HuggingFace Inc. team
+Copyright 2022 SHI Labs and The HuggingFace Inc. team
+Copyright 2022 WeChatAI and The HuggingFace Inc. team
+Copyright 2020 Microsoft and the HuggingFace Inc. team
+Copyright 2021 Google AI and The HuggingFace Inc. team
+Copyright 2021 Microsoft and The HuggingFace Inc. team
+Copyright 2022 Google AI and The HuggingFace Inc. team
+Copyright 2022 SenseTime and The HuggingFace Inc. team
+Copyright 2023 MURGe-Lab and The HuggingFace Inc. team
+Copyright Meta Platforms and The HuggingFace Inc. team
+Copyright 2018 Salesforce and The HuggingFace Inc. team
+Copyright 2018 The T5 authors and HuggingFace Inc. team
+Copyright 2020 Microsoft and the Hugging Face Inc. team
+Copyright 2020, Microsoft and the HuggingFace Inc. team
+Copyright 2021 ASAPP Inc. and The HuggingFace Inc. team
+Copyright 2021 ASAPP Inc. and the HuggingFace Inc. team
+Copyright 2021 The Eleuther AI and The Google Flax Team
+Copyright 2022 Apple Inc. and The HuggingFace Inc. team
+Copyright 2022 EleutherAI and The HuggingFace Inc. team
+Copyright 2022 EleutherAI and the HuggingFace Inc. team
+Copyright 2022 Sea AI Lab and The HuggingFace Inc. team
+Copyright 2022 The Impira Team and the HuggingFace Team
+Copyright 2022 The OpenAI team and The HuggingFace Team
+Copyright 2022 The Salesforce authors, The Open AI Team
+Copyright 2022 UW-Madison and The HuggingFace Inc. team
+Copyright 2022, The LongT5 Authors and HuggingFace Inc.
+Copyright 2022, UCLA NLP, The Facebook AI Research Team
+Copyright Google Research and The HuggingFace Inc. team
+Copyright 2018 The Microsoft Research Asia LayoutLM Team
+Copyright 2021 Google Research The HuggingFace Inc. team
+Copyright 2021 The Eleuther AI and HuggingFace Inc. team
+Copyright 2022 ABEJA, Inc. and The HuggingFace Inc. team
+Copyright 2022 Facebook AI and The HuggingFace Inc. team
+Copyright 2022 Sea AI Labs and The HuggingFace Inc. team
+Copyright 2022 The HuggingFace Team and The OpenBMB Team
+Copyright 2010, The Microsoft Research Asia LayoutLM Team
+Copyright 2021 Studio Ousia and the HuggingFace Inc. team
+Copyright 2021, Google Inc. and The HuggingFace Inc. team
+Copyright 2021, The Microsoft Research Asia MarkupLM Team
+Copyright 2023 Meta AI Team and the HuggingFace Inc. team
+Copyright 2023 The BigCode team and HuggingFace Inc. team
+Copyright 2023 The Bigcode team and HuggingFace Inc. team
+Copyright 2023 The LAION-AI Team and The HuggingFace Team
+Copyright 2021 NVIDIA Corporation and The HuggingFace Team
+Copyright 2022 Microsoft Research and The HuggingFace Team
+Copyright 2022 NAVER AI Labs and The HuggingFace Inc. team
+Copyright Microsoft Research and The HuggingFace Inc. team
+Copyright 2021 Microsoft Research The HuggingFace Inc. team
+Copyright 2021 The EleutherAI and The HuggingFace Inc. team
+Copyright 2021 The Fairseq Authors and The Google Flax Team
+Copyright 2021 VinAI Research and the HuggingFace Inc. team
+Copyright 2022 Meta Platforms and The HuggingFace Inc. team
+Copyright 2022 The Fairseq Authors and The Google Flax Team
+Copyright 2019 The TensorFlow Authors, The Hugging Face Team
+Copyright 2020 Google Research and The HuggingFace Inc. team
+Copyright 2020 The HuggingFace Team and the AllenNLP authors
+Copyright 2021 Google Research and The HuggingFace Inc. team
+Copyright 2021 The Fairseq Authors The HuggingFace Inc. team
+Copyright 2021 The OpenAI Team Authors, The Google Flax Team
+Copyright 2022 The HuggingFace Inc. team and the OpenAI team
+Copyright The HuggingFace Team and The HuggingFace Inc. team
+Copyright 2020 The Trax Authors and The HuggingFace Inc. team
+Copyright 2020, The RAG Authors and The HuggingFace Inc. team
+Copyright 2021 Facebook AI Research The HuggingFace Inc. team
+Copyright 2021 The HuggingFace Team The HuggingFace Inc. team
+Copyright 2022 The HuggingFace Team The HuggingFace Inc. team
+Copyright 2022 The OpenBMB Team and The HuggingFace Inc. team
+Copyright 2023 Alibaba Research and The HuggingFace Inc. team
+Copyright 2023 The Mega Authors and The HuggingFace Inc. team
+Copyright 2018 Hao Tan, Mohit Bansal, and the HuggingFace team
+Copyright 2021 The Facebook Inc. and The HuggingFace Inc. team
+Copyright 2021 The Facebook, Inc and The HuggingFace Inc. team
+Copyright 2022 Snapchat Research and The HuggingFace Inc. team
+Copyright 2022 The REALM authors and The HuggingFace Inc. team
+Copyright 2023 The Facebook Inc. and The HuggingFace Inc. team
+Copyright 2023 The Salesforce Authors and The HuggingFace Team
+Copyright 2018 The HuggingFace Inc. team, Microsoft Corporation
+Copyright 2018 The HuggingFace Inc. team, The Hugging Face Team
+Copyright 2021 Microsoft Research and The HuggingFace Inc. team
+Copyright 2021 Microsoft Research and the HuggingFace Inc. team
+Copyright 2021 The Facebook, Inc. and The HuggingFace Inc. team
+Copyright 2022 Microsoft Research and The HuggingFace Inc. team
+Copyright 2022 Microsoft, clefourrier The HuggingFace Inc. team
+Copyright 2022 The HuggingFace Inc. team and the AI-Sweden team
+Copyright 2022 The OpenAI Authors and The HuggingFace Inc. team
+Copyright (c) 2020, VinAI Research and the HuggingFace Inc. team
+Copyright 2020 Ecole Polytechnique and the HuggingFace Inc. team
+Copyright 2021 The Fairseq Authors and The HuggingFace Inc. team
+Copyright 2021 The Fairseq Authors and the HuggingFace Inc. team
+Copyright 2021, The Facebook, Inc. and The HuggingFace Inc. team
+Copyright 2021- NVIDIA Corporation and The HuggingFace Inc. team
+Copyright 2022 Meta Platforms Inc. and The HuggingFace Inc. team
+Copyright 2022 Meta Platforms, Inc.and The HuggingFace Inc. team
+Copyright 2022 The Fairseq Authors and The HuggingFace Inc. team
+Copyright 2022 The Fairseq Authors and the HuggingFace Inc. team
+Copyright 2022 The Metaseq Authors and The HuggingFace Inc. team
+Copyright 2019 Facebook AI Research and the HuggingFace Inc. team
+Copyright 2021 Facebook AI Research and The HuggingFace Inc. team
+Copyright 2021 The HuggingFace Team and The HuggingFace Inc. team
+Copyright 2021 The UCLA NLP Authors and The HuggingFace Inc. team
+Copyright 2022 Facebook AI Research and the HuggingFace Inc. team
+Copyright 2022 Meta Platforms, Inc. and The HuggingFace Inc. team
+Copyright 2022 The HuggingFace Team and The HuggingFace Inc. team
+Copyright 2023 Meta Platforms, Inc. and The HuggingFace Inc. team
+Copyright 2020 The Microsoft Authors and The HuggingFace Inc. team
+Copyright 2020-present Google Brain and Carnegie Mellon University
+Copyright 2021 Google AI, Ross Wightman, The HuggingFace Inc. team
+Copyright 2022 Google AI, Ross Wightman, The HuggingFace Inc. team
+Copyright 2022 Intel Labs, OpenMMLab and The HuggingFace Inc. team
+Copyright 2023 Google Research, Inc. and The HuggingFace Inc. team
+Copyright 2019-present, Facebook, Inc and the HuggingFace Inc. team
+Copyright 2018 Google AI, Google Brain and the HuggingFace Inc. team
+Copyright 2020 The SqueezeBert authors and The HuggingFace Inc. team
+Copyright 2021 Google AI, Google Brain and the HuggingFace Inc. team
+Copyright 2022 Microsoft Research Asia and The HuggingFace Inc. team
+Copyright 2022 Microsoft Research Asia and the HuggingFace Inc. team
+Copyright 2018 Google AI, Google Brain and Carnegie Mellon University
+Copyright 2022 Microsoft Research, Inc. and The HuggingFace Inc. team
+Copyright 2022 The HuggingFace Team and Microsoft Research AI4Science
+Copyright 2023 The Intel Labs Team Authors, The Microsoft Research Team
+Copyright 2018 The Google AI Language Team Authors, Facebook AI Research
+Copyright 2019 Inria, Facebook AI Research and the HuggingFace Inc. team
+Copyright 2019-present CNRS, Facebook Inc. and the HuggingFace Inc. team
+Copyright 2020 The Google AI Language Team Authors, Facebook AI Research
+Copyright 2021 Facebook AI Research (FAIR) and The HuggingFace Inc. team
+Copyright 2022 Facebook AI Research (FAIR) and The HuggingFace Inc. team
+Copyright 2021 Tel AViv University, AllenAI and The HuggingFace Inc. team
+Copyright 2021, The Facebook AI Research Team and The HuggingFace Inc. team
+Copyright 2020 The Allen Institute for AI team and The HuggingFace Inc. team
+Copyright 2022 University of Wisconsin-Madison and The HuggingFace Inc. team
+Copyright 2021 The Google AI Flax Team Authors, and The HuggingFace Inc. team
+Copyright (c) 2020 The Google AI Language Team Authors, The HuggingFace Inc. team
+Copyright 2020 The Google AI Team, Stanford University and The HuggingFace Inc. team
+Copyright 2021 Facebook AI Research (FAIR), Ross Wightman, The HuggingFace Inc. team
+Copyright 2021 Google Research, Google AI, Google Brain and the HuggingFace Inc. team
+Copyright 2021 The Fairseq Authors, Microsoft Research, and The HuggingFace Inc. team
+Copyright 2022, UCLA NLP, The Facebook AI Research Team and The HuggingFace Inc. team
+Copyright 2023 The Fairseq Authors, Microsoft Research, and the HuggingFace Inc. team
+Copyright 2021 Iz Beltagy, Matthew E. Peters, Arman Cohan and The HuggingFace Inc. team
+Copyright 2022 Multimedia Computing Group, Nanjing University and The HuggingFace Inc. team
+Copyright 2022 WenXiang ZhongzhiCheng LedellWu LiuGuang BoWenZhang The HuggingFace Inc. team
+Copyright 2022 WenXiang ZhongzhiCheng LedellWu LiuGuang BoWenZhang and The HuggingFace Inc. team
+Copyright 2019-present, the HuggingFace Inc. team, The Google AI Language Team and Facebook, Inc.
+Copyright 2018 The Google AI Language Team Authors, The HuggingFace Inc. team, and the Lxmert Authors
+Copyright 2021 The I-BERT Authors Sehoon Kim, Amir Gholami, Zhewei Yao, Michael Mahoney, Kurt Keutzer
+Copyright 2022 BNRist (Tsinghua University), TKLNDST (Nankai University) and The HuggingFace Inc. team
+Copyright 2022 School of EIC, Huazhong University of Science & Technology and The HuggingFace Inc. team
+Copyright 2020 The Google AI Language Team Authors, Allegro.pl, Facebook Inc. and the HuggingFace Inc. team
+Copyright 2023 Xuan Ouyang, Shuohuan Wang, Chao Pang, Yu Sun, Hao Tian, Hua Wu, Haifeng Wang The HuggingFace Inc. team
+Copyright 2023 Xuan Ouyang, Shuohuan Wang, Chao Pang, Yu Sun, Hao Tian, Hua Wu, Haifeng Wang and The HuggingFace Inc. team
+
+Apache License
+
+Version 2.0, January 2004
+
+http://www.apache.org/licenses/ TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION
+
+   1. Definitions.
+
+
+
+      "License" shall mean the terms and conditions for use, reproduction, and distribution as defined by Sections 1 through 9 of this document.
+
+
+
+      "Licensor" shall mean the copyright owner or entity authorized by the copyright owner that is granting the License.
 
 
-Copyright (c) 2013, Ben Hamner
 
-zlib License Copyright (c) <year> <copyright holders>
+      "Legal Entity" shall mean the union of the acting entity and all other entities that control, are controlled by, or are under common control with that entity. For the purposes of this definition, "control" means (i) the power, direct or indirect, to cause the direction or management of such entity, whether by contract or otherwise, or (ii) ownership of fifty percent (50%) or more of the outstanding shares, or (iii) beneficial ownership of such entity.
+
+
+
+      "You" (or "Your") shall mean an individual or Legal Entity exercising permissions granted by this License.
+
+
+
+      "Source" form shall mean the preferred form for making modifications, including but not limited to software source code, documentation source, and configuration files.
+
+
+
+      "Object" form shall mean any form resulting from mechanical transformation or translation of a Source form, including but not limited to compiled object code, generated documentation, and conversions to other media types.
+
+
+
+      "Work" shall mean the work of authorship, whether in Source or Object form, made available under the License, as indicated by a copyright notice that is included in or attached to the work (an example is provided in the Appendix below).
+
+
+
+      "Derivative Works" shall mean any work, whether in Source or Object form, that is based on (or derived from) the Work and for which the editorial revisions, annotations, elaborations, or other modifications represent, as a whole, an original work of authorship. For the purposes of this License, Derivative Works shall not include works that remain separable from, or merely link (or bind by name) to the interfaces of, the Work and Derivative Works thereof.
+
+
+
+      "Contribution" shall mean any work of authorship, including the original version of the Work and any modifications or additions to that Work or Derivative Works thereof, that is intentionally submitted to Licensor for inclusion in the Work by the copyright owner or by an individual or Legal Entity authorized to submit on behalf of the copyright owner. For the purposes of this definition, "submitted" means any form of electronic, verbal, or written communication sent to the Licensor or its representatives, including but not limited to communication on electronic mailing lists, source code control systems, and issue tracking systems that are managed by, or on behalf of, the Licensor for the purpose of discussing and improving the Work, but excluding communication that is conspicuously marked or otherwise designated in writing by the copyright owner as "Not a Contribution."
+
+
+
+      "Contributor" shall mean Licensor and any individual or Legal Entity on behalf of whom a Contribution has been received by Licensor and subsequently incorporated within the Work.
+
+   2. Grant of Copyright License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable copyright license to reproduce, prepare Derivative Works of, publicly display, publicly perform, sublicense, and distribute the Work and such Derivative Works in Source or Object form.
+
+   3. Grant of Patent License. Subject to the terms and conditions of this License, each Contributor hereby grants to You a perpetual, worldwide, non-exclusive, no-charge, royalty-free, irrevocable (except as stated in this section) patent license to make, have made, use, offer to sell, sell, import, and otherwise transfer the Work, where such license applies only to those patent claims licensable by such Contributor that are necessarily infringed by their Contribution(s) alone or by combination of their Contribution(s) with the Work to which such Contribution(s) was submitted. If You institute patent litigation against any entity (including a cross-claim or counterclaim in a lawsuit) alleging that the Work or a Contribution incorporated within the Work constitutes direct or contributory patent infringement, then any patent licenses granted to You under this License for that Work shall terminate as of the date such litigation is filed.
+
+   4. Redistribution. You may reproduce and distribute copies of the Work or Derivative Works thereof in any medium, with or without modifications, and in Source or Object form, provided that You meet the following conditions:
+
+      (a) You must give any other recipients of the Work or Derivative Works a copy of this License; and
+
+      (b) You must cause any modified files to carry prominent notices stating that You changed the files; and
+
+      (c) You must retain, in the Source form of any Derivative Works that You distribute, all copyright, patent, trademark, and attribution notices from the Source form of the Work, excluding those notices that do not pertain to any part of the Derivative Works; and
+
+      (d) If the Work includes a "NOTICE" text file as part of its distribution, then any Derivative Works that You distribute must include a readable copy of the attribution notices contained within such NOTICE file, excluding those notices that do not pertain to any part of the Derivative Works, in at least one of the following places: within a NOTICE text file distributed as part of the Derivative Works; within the Source form or documentation, if provided along with the Derivative Works; or, within a display generated by the Derivative Works, if and wherever such third-party notices normally appear. The contents of the NOTICE file are for informational purposes only and do not modify the License. You may add Your own attribution notices within Derivative Works that You distribute, alongside or as an addendum to the NOTICE text from the Work, provided that such additional attribution notices cannot be construed as modifying the License.
+
+      You may add Your own copyright statement to Your modifications and may provide additional or different license terms and conditions for use, reproduction, or distribution of Your modifications, or for any such Derivative Works as a whole, provided Your use, reproduction, and distribution of the Work otherwise complies with the conditions stated in this License.
+
+   5. Submission of Contributions. Unless You explicitly state otherwise, any Contribution intentionally submitted for inclusion in the Work by You to the Licensor shall be under the terms and conditions of this License, without any additional terms or conditions. Notwithstanding the above, nothing herein shall supersede or modify the terms of any separate license agreement you may have executed with Licensor regarding such Contributions.
+
+   6. Trademarks. This License does not grant permission to use the trade names, trademarks, service marks, or product names of the Licensor, except as required for reasonable and customary use in describing the origin of the Work and reproducing the content of the NOTICE file.
+
+   7. Disclaimer of Warranty. Unless required by applicable law or agreed to in writing, Licensor provides the Work (and each Contributor provides its Contributions) on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied, including, without limitation, any warranties or conditions of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A PARTICULAR PURPOSE. You are solely responsible for determining the appropriateness of using or redistributing the Work and assume any risks associated with Your exercise of permissions under this License.
+
+   8. Limitation of Liability. In no event and under no legal theory, whether in tort (including negligence), contract, or otherwise, unless required by applicable law (such as deliberate and grossly negligent acts) or agreed to in writing, shall any Contributor be liable to You for damages, including any direct, indirect, special, incidental, or consequential damages of any character arising as a result of this License or out of the use or inability to use the Work (including but not limited to damages for loss of goodwill, work stoppage, computer failure or malfunction, or any and all other commercial damages or losses), even if such Contributor has been advised of the possibility of such damages.
+
+   9. Accepting Warranty or Additional Liability. While redistributing the Work or Derivative Works thereof, You may choose to offer, and charge a fee for, acceptance of support, warranty, indemnity, or other liability obligations and/or rights consistent with this License. However, in accepting such obligations, You may act only on Your own behalf and on Your sole responsibility, not on behalf of any other Contributor, and only if You agree to indemnify, defend, and hold each Contributor harmless for any liability incurred by, or claims asserted against, such Contributor by reason of your accepting any such warranty or additional liability. END OF TERMS AND CONDITIONS
+
+APPENDIX: How to apply the Apache License to your work.
+
+To apply the Apache License to your work, attach the following boilerplate notice, with the fields enclosed by brackets "[]" replaced with your own identifying information. (Don't include the brackets!) The text should be enclosed in the appropriate comment syntax for the file format. We also recommend that a file or class name and description of purpose be included on the same "printed page" as the copyright notice for easier identification within third-party archives.
+
+Copyright [yyyy] [name of copyright owner]
+
+Licensed under the Apache License, Version 2.0 (the "License");
+
+you may not use this file except in compliance with the License.
+
+You may obtain a copy of the License at
+
+http://www.apache.org/licenses/LICENSE-2.0
 
-This software is provided 'as-is', without any express or implied warranty. In no event will the authors be held liable for any damages arising from the use of this software.
+Unless required by applicable law or agreed to in writing, software
+
+distributed under the License is distributed on an "AS IS" BASIS,
 
-Permission is granted to anyone to use this software for any purpose, including commercial applications, and to alter it and redistribute it freely, subject to the following restrictions:
+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 
-   1. The origin of this software must not be misrepresented; you must not claim that you wrote the original software. If you use this software in a product, an acknowledgment in the product documentation would be appreciated but is not required.
+See the License for the specific language governing permissions and
 
-   2. Altered source versions must be plainly marked as such, and must not be misrepresented as being the original software.
+limitations under the License.
 
-   3. This notice may not be removed or altered from any source distribution.
+---------------------------------------------------------
 
 ---------------------------------------------------------
 
+pandas 2.0.1 - BSD-2-Clause AND BSD-3-Clause
+
+
+Copyright (c) 2009', join
+Copyright 2014-2019, xarray
+Copyright (c) 2012 Google Inc.
+Copyright (c) 2015 Jared Hobbs
+Copyright (c) 1994 David Burren
+Copyright (c) 2011 Szabolcs Nagy
+Copyright (c) 2011 Valentin Ochs
+Copyright (c) 2017 Anthony Sottile
+Copyright (c) 2005-2014 Rich Felker
+Copyright (c) 2010, Albert Sweigart
+Copyright (c) 2002 Michael Ringgaard
+Copyright (c) 2003-2011 David Schultz
+Copyright (c) 2008 Stephen L. Moshier
+Copyright (c) 2011 by Enthought, Inc.
+Copyright 2017- dateutil contributors
+Copyright (c) 2003-2009 Bruce D. Evans
+Copyright (c) 2001-2008 Ville Laurikari
+Copyright (c) 2003-2009 Steven G. Kargl
+Copyright (c) 1993,2004 Sun Microsystems
+Copyright (c) 2001, 2002 Enthought, Inc.
+Copyright (c) 2003-2012 SciPy Developers
+Copyright (c) 2012, Lambda Foundry, Inc.
+Copyright (c) 1994 Sun Microsystems, Inc.
+Copyright (c) 2005-2011, NumPy Developers
+Copyright (c) 2017 - dateutil contributors
+Copyright (c) 2012, PyData Development Team
+Copyright (c) 2015- - dateutil contributors
+Copyright (c) 2016, PyData Development Team
+Copyright (c) 2020, PyData Development Team
+Copyright (c) 2011-2012, Lambda Foundry, Inc.
+Copyright 2017- Paul Ganssle <paul@ganssle.io>
+Copyright (c) 2011-2012, PyData Development Team
+Copyright (c) 2011-2023, Open source contributors
+Copyright (c) 2008 The Android Open Source Project
+Copyright (c) 2008-2011 AQR Capital Management, LLC
+Copyright (c) 2015- - Paul Ganssle <paul@ganssle.io>
+Copyright (c) 2010-2012 Archipel Asset Management AB.
+Copyright (c) 2007 Nick Galbreath nickg at modp dot com
+Copyright (c) Donald Stufft and individual contributors
+Copyright (c) 2014-2016 - Yaron de Leeuw <me@jarondl.net>
+Copyright (c) 2019 Hadley Wickham RStudio and Evan Miller
+Copyright (c) 2008- Attractive Chaos <attractor@live.co.uk>
+Copyright (c) 2003-2011 - Gustavo Niemeyer <gustavo@niemeyer.net>
+Copyright (c) 1988-1993 The Regents of the University of California
+Copyright (c) 2011-2013, ESN Social Software AB and Jonas Tarnstrom
+Copyright (c) 2012-2014 - Tomi Pievilainen <tomi.pievilainen@iki.fi>
+Copyright (c) 1995-2001 Corporation for National Research Initiatives
+Copyright (c) 2008, 2009, 2011 by Attractive Chaos <attractor@live.co.uk>
+Copyright (c) 1991 - 1995, Stichting Mathematisch Centrum Amsterdam, The Netherlands
+Copyright (c) 2001, 2002, 2003, 2004, 2005, 2006, 2007, 2008, 2009, 2010 Python Software Foundation
+Copyright (c) 2008-2011, AQR Capital Management, LLC, Lambda Foundry, Inc. and PyData Development Team
+
+BSD-2-Clause AND BSD-3-Clause
+
+---------------------------------------------------------
```

## azureml/metrics/__init__.py

```diff
@@ -1,20 +1,24 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 """Contains metrics computation classes for Azure Machine Learning."""
 import sys
 
 from ._score import compute_metrics, score
-from ._score import list_metrics
+from ._score import list_metrics, list_tasks, list_prompts
+from azureml.metrics.common.azureml_custom_prompt_metric import AzureMLCustomPromptMetric
 
 __all__ = [
     "compute_metrics",
     "score",
-    "list_metrics"
+    "list_metrics",
+    "list_tasks",
+    "list_prompts",
+    "AzureMLCustomPromptMetric",
 ]
 
 # TODO copy this file as part of setup in runtime package
 __path__ = __import__('pkgutil').extend_path(__path__, __name__)  # type: ignore
 
 try:
     from ._version import ver as VERSION, selfver as SELFVERSION
```

## azureml/metrics/_score.py

```diff
@@ -1,53 +1,65 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 """Computation of AzureML model evaluation metrics."""
 import logging
 from typing import Any, Dict, Optional, Union, List
 
+import inspect
 import numpy as np
 import pandas as pd
 import ast
 
-from azureml.metrics import constants, utilities
-from azureml.metrics.azureml_classification_metrics import AzureMLClassificationMetrics
-from azureml.metrics.azureml_forecasting_metrics import AzureMLForecastingMetrics
-from azureml.metrics.azureml_regression_metrics import AzureMLRegressionMetrics
-from azureml.metrics.azureml_translation_metrics import AzureMLTranslationMetrics
-from azureml.metrics.azureml_summarization_metrics import AzureMLSummarizationMetrics
-from azureml.metrics.azureml_qa_metrics import AzureMLQAMetrics
-from azureml.metrics.azureml_text_ner_metrics import AzureMLTextNERMetrics
-from azureml.metrics.azureml_fill_mask_metrics import AzureMLFillMaskMetrics
-from azureml.metrics.azureml_text_generation_metrics import AzureMLTextGenerationMetrics
-from azureml.metrics.azureml_od_is_metrics import AzureMLODISMetrics, AzureMLODMetrics, AzureMLISMetrics
+from azureml.metrics import constants
+from azureml.metrics.common import utilities
+from azureml.metrics.common._logging_utils import (
+    default_log_activity, get_logger, log_activity,
+    sanitize_custom_dims, flush_logger,
+    formatter, telemetry_filter
+)
+from azureml.metrics.common._score_utils import compute_metrics_classification, compute_metrics_regression, \
+    compute_metrics_translation, compute_metrics_ner, compute_metrics_summarization, compute_metrics_qa, \
+    compute_metrics_fill_mask, compute_metrics_text_generation, \
+    compute_metrics_forecasting, \
+    compute_metrics_image_od_is, compute_metrics_chat_completion, compute_metrics_rag_evaluation, \
+    compute_metrics_video_mot, compute_metrics_code_generation, \
+    get_supported_metrics, compute_metrics_custom_prompt, get_supported_prompts
+from azureml.metrics.text.classification.azureml_classification_metrics import AzureMLClassificationMetrics
+from azureml.metrics.common.exceptions import InvalidUserInputException, InvalidOperationException, \
+    DataErrorException, MetricsSystemException, MetricsException
+
 
 logger = logging.getLogger(__name__)
+appinsights_logger = get_logger(name=__name__)
 
 
 def compute_metrics(*,
-                    task_type: constants.TASKS,
+                    task_type: Optional[constants.Tasks] = None,
                     y_test: Optional[Union[np.ndarray, pd.DataFrame, List]] = None,
                     # Either y_pred or y_pred_proba should be passed for classification
                     y_pred: Optional[Union[np.ndarray, pd.DataFrame, List]] = None,
                     y_pred_proba: Optional[Union[np.ndarray, pd.DataFrame, List]] = None,
                     **kwargs) -> Dict[str, Dict[str, Any]]:
     """Given task type, y_test, y_pred or y_pred_proba compute metrics for the respective task.
 
         :param task_type: Accepts an argument of type constants.Tasks for which metrics have to be computed.
             Can accept from any of the values constants.Tasks.CLASSIFICATION, constants.Tasks.REGRESSION,
             constants.Tasks.TEXT_CLASSIFICATION, constants.Tasks.TEXT_CLASSIFICATION_MULTILABEL,
             constants.Tasks.TEXT_NER, constants.Tasks.SUMMARIZATION, constants.Tasks.TRANSLATION,
             constants.Tasks.QUESTION_ANSWERING, constants.Tasks.IMAGE_OBJECT_DETECTION,
             constants.Tasks.IMAGE_INSTANCE_SEGMENTATION, constants.Tasks.FORECASTING.
         :param y_test: Ground truths or reference values.
-            optional for computing few of language_modeling metrics.
+            optional for computing few of language_modeling metrics and gpt related metrics.
         :param y_pred: Prediction values.
         :param y_pred_proba: Predicted probability values.
 
+        :param user_type: Optional. Custom user type which gives more context about the job. Is logged.
+        :param disable_logging: Optional. Boolean to disbale telemetry logging. Default: True
+
         Example for multiclass classification:
         --------------------------------------
         from azureml.metrics import compute_metrics, constants
         y_pred = [0, 2, 1, 3]
         y_true = [0, 1, 2, 3]
         compute_metrics(task_type=constants.Tasks.CLASSIFICATION, y_test=y_true,
                            y_pred=y_pred)
@@ -98,28 +110,67 @@
         Example for question-answering:
         -------------------------------
         from azureml.metrics import compute_metrics, constants
         y_pred = ["hello there general kenobi the 123","foo bar foobar", "ram 234", "sid"]
         y_test = ["hello there general kenobi san", "foo bar foobar", "ram 23", "sid$"]
         result = compute_metrics(task_type=constants.Tasks.QUESTION_ANSWERING, y_test=y_test, y_pred=y_pred)
 
+        from azureml.metrics import compute_metrics, constants
+        y_test = ["hello", "red and blue", "movie is good"]
+        y_pred = ["hi", "green and blue", "he dances"]
+        result=compute_metrics(task_type=constants.Tasks.QUESTION_ANSWERING, y_test=y_test, y_pred=y_pred,
+                               model_type="microsoft/deberta-large", idf=True, rescale_with_baseline=True)
+
+        # computing gpt-star and llm-star metrics
+        from azureml.metrics import compute_metrics, constants
+        openai_params = {'api_version': "<placeholder>",
+                         'api_base': "<placeholder>",
+                         'api_type': "<placeholder>",
+                         'api_key': "<placeholder>"}
+        llm_params = {
+            "llm_url": '<placeholder>',
+            "llm_api_key": '<placeholder>'
+        }
+        contexts = ["Virgin Mary allegedly appear in 1858 in Lourdes France to Saint
+                     Bernadette Soubirous"] * 3
+        questions = ["To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?"] * 3
+        y_test = ["Saint Bernadette Soubirous"] * 3
+        y_pred = ["Virgin Mary allegedly appear to Saint Bernadette Soubirous"] * 3
+        metrics_config = {
+            "questions": questions,
+            "contexts": contexts,
+            "openai_params" : openai_params,
+            "llm_params" : llm_params
+        }
+        result = compute_metrics(task_type=constants.Tasks.QUESTION_ANSWERING,
+                                 y_test=y_test,
+                                 y_pred=y_pred,
+                                 **metrics_config)
+
         Example for fill-mask:
         ---------------------
         from azureml.metrics import compute_metrics, constants
         y_pred = ["hi", "green and blue", "he dances"]
-        compute_metrics(task_type=constants.Tasks.FILL_MASK, y_pred=y_pred,
+        result = compute_metrics(task_type=constants.Tasks.FILL_MASK, y_pred=y_pred,
                         model_id="gpt2")
 
         Example for text_generation:
         ----------------------------
         from azureml.metrics import compute_metrics, constants
         y_pred = ["hello there general kenobi","foo bar foobar", "blue & red"]
         y_test = [["hello there general kenobi san"], ["foo bar foobar"], ["blue & green"]]
         result = compute_metrics(task_type=constants.Tasks.TEXT_GENERATION, y_test=y_test, y_pred=y_pred)
 
+        Example for code_generation:
+        ----------------------------
+        from azureml.metrics import compute_metrics, constants
+        y_test = ["assert add(2,3)==5"]
+        y_pred = [["def add(a, b): return a+b", "def add(a,b): return a*b"]]
+        result = compute_metrics(task_type=constants.Tasks.CODE_GENERATION, y_test=y_test, y_pred=y_pred)
+
         Example for object-detection:
         -------------------------------
         from azureml.metrics import compute_metrics
         y_test = [{
                 "boxes": np.array([[160, 120, 320, 240]], dtype=np.float32),
                 "classes": np.array([1])
             }]
@@ -190,302 +241,343 @@
             y_test=y_test,
             y_pred=y_pred,
             X_train=X_train,
             y_train=y_train,
             time_column_name='date',
             time_series_id_column_names=['ts_id'],
             X_test=X_test)
+
+        Example for rag-evaluation
+        --------------------------
+        from azureml.metrics import compute_metrics, constants
+
+        # Expected conversation structure
+        # rag_conversations = [
+        #     # conversation 0
+        #     [
+        #         # turn 0
+        #         [
+        #             dict(user, assitant, retrieved_documents)
+        #         ],
+        #         # turn 1
+        #         [
+        #             dict(user, assitant, retrieved_documents)
+        #         ],
+        #         # turn 2
+        #         [
+        #             dict(user, assitant, retrieved_documents)
+        #         ]
+        #     ],
+        #     # conversation 1
+        #     []
+        # ]
+
+        y_pred = [[{"user": {"content": "how are you?"},
+                    "assistant": {"content": "I'm doing good. thank you!!"},
+                    "retrieved_documents": '{"retrieved_documents": "document1"}'}]]
+
+        openai_params = {
+            "model_url": GPT4_URL,
+            "model_key": GPT4_KEY,
+            "is_chat": True,
+            "use_chat_completion": False,
+        }
+
+        result = compute_metrics(task_type=constants.Tasks.RAG_EVALUATION, y_pred=y_pred,
+                                 openai_params=openai_params, score_version="v1")
+
+        Example for chat completion
+        ---------------------------
+        from azureml.metrics import compute_metrics, constants
+
+        y_test = [
+            [
+                    {"role": "user", "content": "What is the tallest building in the world?"},
+                    {
+                        "role": "assistant",
+                        "content": "Burj Khalifa",
+                    },
+                    {"role": "user", "content": "and in Africa?"},
+                    {
+                        "role": "assistant",
+                        "content": "In Africa, the tallest building is the Carlton Centre, located in Johannesburg,",
+                    },
+                    {"role": "user", "content": "and in Europe?"},
+        ]]
+
+        y_pred = [
+            [
+                    {"role": "user", "content": "What is the tallest building in the world?"},
+                    {
+                        "role": "assistant",
+                        "content": "As of 2021, the Burj Khalifa in Dubai, United Arab Emirates is the tallest "
+                                   "building in"
+                                   " the world, standing at a height of 828 meters (2,722 feet). It was completed in"
+                                   " 2010 and has 163 floors. The Burj Khalifa is not only the tallest building in the"
+                                   " world but also holds several other records, such as the highest occupied floor, "
+                                   " highest outdoor observation deck, elevator with the longest travel distance, and "
+                                   " the tallest freestanding structure in the world.",
+                    },
+                    {"role": "user", "content": "and in Africa?"},
+                    {
+                        "role": "assistant",
+                        "content": "In Africa, the tallest building is the Carlton Centre, located in Johannesburg, "
+                                   "South Africa. It stands at a height of 50 floors and 223 meters (730 feet). The"
+                                   " CarltonDefault Centre was completed in 1973 and was the tallest building in "
+                                   "Africa for many years until the construction of the Leonardo, a 55-story "
+                                   "skyscraper in Sandton, Johannesburg, which was completed in 2019 and stands at a"
+                                   " height of 230 meters (755 feet). Other notable tall buildings in Africa include "
+                                   "the Ponte City Apartments in Johannesburg, the John Hancock Center in Lagos, "
+                                   "Nigeria, and the Alpha II Building in Abidjan, Ivory Coast",
+                    },
+                    {"role": "user", "content": "and in Europe?"},
+            ]]
+
+        result = compute_metrics(task_type=constants.Tasks.CHAT_COMPLETION, y_pred=y_pred, y_test=y_test)
+
+        Example for code-generation:
+        ---------------------------
+        from azureml.metrics import compute_metrics, constants
+        y_test = [["def add(a, b): return a+b"], ["def multiply(a, b): return a*b"]]
+        y_pred = [["def add(a, b): return a+b", "def add(a,b): return a*b"], ["def multiply(a, b): return a+b",
+                   "def multiply(a,b): return a*b"]]
+        test_cases = ["assert add(2,3)==5", "assert add(2,3)==5"]
+        result = compute_metrics(task_type=constants.Tasks.CODE_GENERATION,
+                                 y_test=y_test, y_pred=y_pred,
+                                 test_cases=test_cases,
+                                 no_of_candidates=[1, 2])
+
     """
-    # Step 1: Check either y_pred or y_pred_proba exist
-    # Step 2: Instantiate Metrics Class object on the basis of task type
-    #   and pass in necessary parameters while creating object
-    # Step 3: Call compute method of class object to compute and fetch metrics
-    if y_test is None:
-        if task_type in [constants.Tasks.FILL_MASK]:
-            metrics_list = kwargs.get("metrics", set())
-            supported_metrics_list = set(metrics_list).intersection(constants.Metric.FILL_MASK_SPECIAL_SET)
-            kwargs["metrics"] = [metric for metric in constants.Metric.FILL_MASK_SET] \
-                if len(supported_metrics_list) == 0 else supported_metrics_list
-            logger.warning(f"Computing metrics for {kwargs['metrics']} as y_test is None.")
+
+    disable_logging = str(kwargs.pop('disable_logging', False)).lower()
+    telemetry_filter.force_disabled = disable_logging in constants.TelemetryConstants.TRUTHY
+
+    if telemetry_filter.is_telemetry_disabled():
+        logger.info("Appinsights telemetry logger disabled.")
+    custom_dimensions = sanitize_custom_dims(kwargs.get('custom_dimensions', dict()))
+    formatter.reset_formatter(custom_dimensions)
+
+    logger.info(f"Run id: {custom_dimensions.run_id}")
+    with log_activity(appinsights_logger, constants.TelemetryConstants.COMPUTE_METRICS_NAME,
+                      custom_dimensions=vars(custom_dimensions)):
+        metrics = kwargs.get('metrics', None)
+        user_type = kwargs.pop('user_type', None)
+        stacktrace = [frame.function for frame in inspect.stack(context=5)][:5]
+        appinsights_logger.info(f"Compute Metrics called with task_type: {task_type}, user_metrics: "
+                                f"{metrics}, user_type: {user_type}, StackTrace: {stacktrace}. "
+                                f"Run id: {custom_dimensions.run_id}.")
+
+        # For computing perplexity: y_test is optional and it can be empty. So, we are setting this as None.
+        if y_test is not None and len(y_test) == 0:
+            logger.warning("Length of y_test is 0. Setting y_test as None.")
+            y_test = None
+
+        # validation of compute required_metrics
+        validate_compute_metrics(task_type, y_test, y_pred, y_pred_proba)
+
+        # adding y_test, y_pred to kwargs
+        kwargs["y_test"] = y_test
+        kwargs["y_pred"] = y_pred
+
+        computed_custom_prompt_metrics = utilities.compute_custom_prompt_metrics(kwargs)
+
+        # popping the custom prompt related parameters from kwargs
+        kwargs.pop("y_test", None)
+        kwargs.pop("y_pred", None)
+
+        if task_type is None:
+            computed_metrics = compute_supported_metrics(y_test, y_pred, y_pred_proba, kwargs)
         else:
-            raise Exception("y_test argument is needed for compute_metrics")
+            computed_metrics = compute_metrics_on_task_type(task_type, y_test, y_pred, y_pred_proba, kwargs)
+
+        # merge custom prompt metrics with computed metrics
+        concatenated_metrics = utilities.concatenate_calculated_metrics([
+            computed_custom_prompt_metrics, computed_metrics]
+        )
+
+        # Has deliberate delay. Flush logs only if Telemetry is enabled.
+        if not telemetry_filter.is_telemetry_disabled():
+            flush_logger(appinsights_logger)
+        return concatenated_metrics
+
+
+def compute_supported_metrics(y_test, y_pred, y_pred_proba, kwargs):
+    required_metrics = kwargs.pop("metrics", None)
+    multilabel = kwargs.pop("multilabel", False)
+    # If required_metrics is none or if required_metrics value is not a list parameter.
+    if required_metrics is None or (not isinstance(required_metrics, list)):
+        # TODO : Add a sample docstring response
+        safe_message = "Please send task_type or metrics parameter with metrics to be computed in a list."
+        raise InvalidUserInputException(safe_message, target="compute_metrics",
+                                        reference_code="azureml.required_metrics.compute_metrics",
+                                        safe_message=safe_message)
+    task_type_metrics_map = {
+        constants.Tasks.REGRESSION: constants.Metric.REGRESSION_SET,
+        constants.Tasks.FORECASTING:
+            constants.Metric.SCALAR_REGRESSION_SET | constants.Metric.FORECAST_SET,
+        constants.Tasks.TEXT_NER: constants.Metric.NER_SET,
+        constants.Tasks.TRANSLATION: constants.Metric.TRANSLATION_SET,
+        constants.Tasks.SUMMARIZATION: constants.Metric.SUMMARIZATION_SET,
+        constants.Tasks.QUESTION_ANSWERING: constants.Metric.QA_SET,
+        constants.Tasks.FILL_MASK: constants.Metric.FILL_MASK_SET,
+        constants.Tasks.TEXT_GENERATION: constants.Metric.TEXT_GENERATION_SET,
+        constants.Tasks.IMAGE_INSTANCE_SEGMENTATION: constants.Metric.IMAGE_INSTANCE_SEGMENTATION_SET,
+        constants.Tasks.IMAGE_OBJECT_DETECTION: constants.Metric.IMAGE_OBJECT_DETECTION_SET,
+        constants.Tasks.CHAT_COMPLETION: constants.Metric.CHAT_COMPLETION_SET,
+        constants.Tasks.RAG_EVALUATION: constants.Metric.RAG_EVALUATION_SET,
+        constants.Tasks.CODE_GENERATION: constants.Metric.CODE_GENERATION_SET,
+        constants.Tasks.VIDEO_MULTI_OBJECT_TRACKING: constants.Metric.VIDEO_MULTI_OBJECT_TRACKING_SET,
+    }
+    if multilabel is True:
+        task_type_metrics_map.update({
+            constants.Tasks.TEXT_CLASSIFICATION_MULTILABEL: constants.Metric.CLASSIFICATION_SET_AZURE,
+            constants.Tasks.IMAGE_CLASSIFICATION_MULTILABEL: constants.Metric.CLASSIFICATION_SET_MULTILABEL,
+            constants.Tasks.IMAGE_MULTI_LABEL_CLASSIFICATION: constants.Metric.CLASSIFICATION_SET_MULTILABEL,
+        })
+    else:
+        task_type_metrics_map.update({
+            constants.Tasks.CLASSIFICATION: constants.Metric.CLASSIFICATION_SET_AZURE,
+            constants.Tasks.TEXT_CLASSIFICATION: constants.Metric.CLASSIFICATION_SET_AZURE,
+            constants.Tasks.IMAGE_CLASSIFICATION: constants.Metric.CLASSIFICATION_SET_AZURE,
+        })
+
+    # iterate over the metric -- collect the task_type and corresponding required_metrics in a dict
+    required_task_type_metrics_map = {task_type: [] for task_type in task_type_metrics_map.keys()}
+    # collecting all required metrics
+    computed_metrics_list = []
+    for required_metric in required_metrics:
+        metric_found = False
+        # TODO: If a single metric is applicable in multiple tasks -- choose based on input data type
+        for task_type, supported_metrics in task_type_metrics_map.items():
+            # TODO: if metric is supported and validation is completed
+            # TODO : compute the metric for all the tasks based on input data validation
+            # add break statement once the metric is found if needed.
+            if required_metric in supported_metrics:
+                metric_found = True
+                required_task_type_metrics_map[task_type].append(required_metric)
+
+        if metric_found is False:
+            logger.warning("Skipping {} as it is not implemented yet.".format(required_metric))
+    # Iterate over required metrics and compute them based on task type
+    for task_type, required_metrics in required_task_type_metrics_map.items():
+        if len(required_metrics) > 0:
+            kwargs["metrics"] = required_metrics
+            try:
+                caluculated_metrics = compute_metrics_on_task_type(task_type, y_test, y_pred, y_pred_proba, kwargs)
+                computed_metrics_list.append(caluculated_metrics)
+
+            except InvalidOperationException as e:
+                logger.warning("Skipping the computation of {} for {} task due to the "
+                               "following exception : {}".format(required_metrics, task_type,
+                                                                 e.safe_message))
+
+    computed_metrics = utilities.concatenate_calculated_metrics(computed_metrics_list)
+    return computed_metrics
+
+
+def validate_compute_metrics(task_type, y_test, y_pred, y_pred_proba):
+    """Method to validate y_test and y_pred input data format."""
 
     if y_pred is None and y_pred_proba is None:
         pred_proba_msg = "Either y_pred or y_pred_proba" if task_type != constants.Tasks.REGRESSION else "y_pred"
-        raise Exception("{} should exist.".format(pred_proba_msg))
+        safe_message = "{} should exist.".format(pred_proba_msg)
+        if task_type is not None and task_type not in [constants.Tasks.CUSTOM_PROMPT_METRIC]:
+            raise InvalidUserInputException(safe_message, safe_message=safe_message)
+
+    if y_pred is not None and len(y_pred) == 0:
+        safe_message = "y_pred should not be empty."
+        logger.error(safe_message)
+        raise InvalidUserInputException(safe_message, safe_message=safe_message)
 
     if isinstance(y_test, pd.DataFrame) or isinstance(y_pred, pd.DataFrame):
         if (hasattr(y_test, "columns") and len(y_test.columns) != 1) or \
                 (hasattr(y_pred, "columns") and len(y_pred.columns) != 1):
-            exception_message = "y_test and y_pred should have only one column in the dataframe to compute metrics."
-            raise Exception(exception_message)
+            safe_message = "y_test and y_pred should have only one column in the dataframe to compute metrics."
+            raise InvalidUserInputException(safe_message, safe_message=safe_message)
 
-    # Reading common keyword arguments related to telemetry
-    custom_dimensions = kwargs.pop('custom_dimensions', None)
-    log_activity = kwargs.pop('log_activity', None)
-    log_traceback = kwargs.pop('log_traceback', None)
-
-    common_args = ["custom_dimensions", "log_activity", "log_traceback"]
-
-    if task_type in [constants.Tasks.CLASSIFICATION, constants.Tasks.TEXT_CLASSIFICATION,
-                     constants.Tasks.TEXT_CLASSIFICATION_MULTILABEL]:
-        metrics_list = kwargs.pop('metrics', None)
-        class_labels = kwargs.pop('class_labels', None)
-        train_labels = kwargs.pop('train_labels', None)
-        sample_weight = kwargs.pop('sample_weight', None)
-        y_transformer = kwargs.pop('y_transformer', None)
-        use_binary = kwargs.pop('use_binary', False)
-        enable_metric_confidence = kwargs.pop('enable_metric_confidence', False)
-        multilabel = kwargs.pop('multilabel', False)
-        positive_label = kwargs.pop('positive_label', None)
-        confidence_metrics = kwargs.pop('confidence_metrics', None)
-
-        if task_type == constants.Tasks.TEXT_CLASSIFICATION_MULTILABEL:
-            multilabel = True
-
-        classification_kwargs = ["metrics", "class_labels", "train_labels", "sample_weight",
-                                 "y_transformer", "use_binary", "enable_metric_confidence",
-                                 "multilabel", "positive_label", "confidence_metrics"]
-
-        check_kwargs(kwargs, task_type, classification_kwargs, common_args)
-
-        metrics = AzureMLClassificationMetrics(
-            metrics=metrics_list,
-            class_labels=class_labels,
-            train_labels=train_labels,
-            sample_weight=sample_weight,
-            y_transformer=y_transformer,
-            use_binary=use_binary,
-            enable_metric_confidence=enable_metric_confidence,
-            multilabel=multilabel,
-            positive_label=positive_label,
-            confidence_metrics=confidence_metrics,
-            custom_dimensions=custom_dimensions,
-            log_activity=log_activity,
-            log_traceback=log_traceback,
-        )
-        computed_metrics = metrics.compute(y_test=y_test, y_pred=y_pred, y_pred_probs=y_pred_proba)
 
-    elif task_type == constants.Tasks.REGRESSION:
-        metrics_list = kwargs.pop("metrics", None)
-        y_max = kwargs.pop("y_max", None)
-        y_min = kwargs.pop("y_min", None)
-        y_std = kwargs.pop("y_std", None)
-        bin_info = kwargs.pop("bin_info", None)
-        sample_weight = kwargs.pop("sample_weight", None)
-        enable_metric_confidence = kwargs.pop("enable_metric_confidence", False)
-        confidence_metrics = kwargs.pop("confidence_metrics", None)
-
-        regression_kwargs = ["metrics", "y_max", "y_min", "y_std",
-                             "bin_info", "sample_weight", "enable_metric_confidence",
-                             "confidence_metrics"]
-
-        check_kwargs(kwargs, task_type, regression_kwargs, common_args)
-
-        metrics = AzureMLRegressionMetrics(
-            metrics=metrics_list,
-            y_max=y_max,
-            y_min=y_min,
-            y_std=y_std,
-            bin_info=bin_info,
-            sample_weight=sample_weight,
-            enable_metric_confidence=enable_metric_confidence,
-            confidence_metrics=confidence_metrics,
-            custom_dimensions=custom_dimensions,
-            log_activity=log_activity,
-            log_traceback=log_traceback,
-        )
-        computed_metrics = metrics.compute(y_test=y_test, y_pred=y_pred)
+def validate_y_test(task_type, y_test, kwargs):
+    """Validation for special metrics which can be computed when y_test is None."""
+    if y_test is None:
+        if task_type in [constants.Tasks.CHAT_COMPLETION] and kwargs.get("openai_params") is not None:
+            utilities.get_supported_metrics(kwargs, constants.Metric.CHAT_COMPLETION_SPECIAL_SET)
 
-    elif task_type == constants.Tasks.TEXT_NER:
-        label_list = kwargs.pop('label_list', None)
-        metrics_list = kwargs.pop('metrics', None)
+        elif task_type in [constants.Tasks.FILL_MASK, constants.Tasks.TEXT_GENERATION,
+                           constants.Tasks.CHAT_COMPLETION]:
+            utilities.get_supported_metrics(kwargs, constants.Metric.FILL_MASK_SPECIAL_SET)
 
-        ner_kwargs = ["label_list", "metrics"]
+        elif task_type in [constants.Tasks.RAG_EVALUATION]:
+            utilities.get_supported_metrics(kwargs, constants.Metric.RAG_EVALUATION_SET)
 
-        check_kwargs(kwargs, task_type, ner_kwargs, common_args)
+        elif task_type in [constants.Tasks.CODE_GENERATION]:
+            utilities.get_supported_metrics(kwargs, constants.Metric.CODE_GENERATION_SPECIAL_SET)
 
-        if label_list is None:
-            label_list = list({label for row in y_test for label in row})
+        elif task_type in [constants.Tasks.QUESTION_ANSWERING]:
+            utilities.get_supported_metrics(kwargs, constants.Metric.QA_SPECIAL_SET)
+
+        elif task_type in [constants.Tasks.CUSTOM_PROMPT_METRIC]:
+            logger.warning("y_test can be optional for custom prompt based metric")
+
+        else:
+            raise DataErrorException("y_test argument is needed for compute_metrics")
+
+
+def compute_metrics_on_task_type(task_type, y_test, y_pred, y_pred_proba, kwargs):
+    """Computes the metrics based on provided task_type"""
+    validate_y_test(task_type, y_test, kwargs)
+
+    task_type_compute_metrics_function_map = {
+        constants.Tasks.CLASSIFICATION: compute_metrics_classification,
+        constants.Tasks.TEXT_CLASSIFICATION: compute_metrics_classification,
+        constants.Tasks.TEXT_CLASSIFICATION_MULTILABEL: compute_metrics_classification,
+        constants.Tasks.REGRESSION: compute_metrics_regression,
+        constants.Tasks.FORECASTING: compute_metrics_forecasting,
+        constants.Tasks.TEXT_NER: compute_metrics_ner,
+        constants.Tasks.TRANSLATION: compute_metrics_translation,
+        constants.Tasks.SUMMARIZATION: compute_metrics_summarization,
+        constants.Tasks.QUESTION_ANSWERING: compute_metrics_qa,
+        constants.Tasks.CUSTOM_PROMPT_METRIC: compute_metrics_custom_prompt,
+        constants.Tasks.QUESTION_ANSWERING_MULTIPLE_GROUND_TRUTH: compute_metrics_qa,
+        constants.Tasks.FILL_MASK: compute_metrics_fill_mask,
+        constants.Tasks.TEXT_GENERATION: compute_metrics_text_generation,
+        constants.Tasks.CHAT_COMPLETION: compute_metrics_chat_completion,
+        constants.Tasks.RAG_EVALUATION: compute_metrics_rag_evaluation,
+        constants.Tasks.CODE_GENERATION: compute_metrics_code_generation,
+        constants.Tasks.IMAGE_INSTANCE_SEGMENTATION: compute_metrics_image_od_is,
+        constants.Tasks.IMAGE_OBJECT_DETECTION: compute_metrics_image_od_is,
+        constants.Tasks.IMAGE_CLASSIFICATION: compute_metrics_classification,
+        constants.Tasks.IMAGE_CLASSIFICATION_MULTILABEL: compute_metrics_classification,
+        constants.Tasks.IMAGE_MULTI_LABEL_CLASSIFICATION: compute_metrics_classification,
+        constants.Tasks.VIDEO_MULTI_OBJECT_TRACKING: compute_metrics_video_mot,
+    }
+
+    compute_metrics_function = task_type_compute_metrics_function_map.get(task_type, None)
+
+    if compute_metrics_function is None:
+        supported_tasks = list_tasks()
+        raise InvalidUserInputException(f"Invalid task type. Please choose among the following task "
+                                        f"types : {supported_tasks}")
+
+    classification_task_types = \
+        [constants.Tasks.CLASSIFICATION, constants.Tasks.TEXT_CLASSIFICATION,
+         constants.Tasks.TEXT_CLASSIFICATION_MULTILABEL, constants.Tasks.IMAGE_CLASSIFICATION,
+         constants.Tasks.IMAGE_CLASSIFICATION_MULTILABEL,
+         constants.Tasks.IMAGE_MULTI_LABEL_CLASSIFICATION]
+
+    if task_type in classification_task_types:
+        computed_metrics = compute_metrics_function(task_type, y_test, y_pred, y_pred_proba, kwargs)
 
-        metrics = AzureMLTextNERMetrics(
-            label_list=label_list,
-            metrics=metrics_list,
-            custom_dimensions=custom_dimensions,
-            log_activity=log_activity,
-            log_traceback=log_traceback,
-        )
-        computed_metrics = metrics.compute(y_test=y_test, y_pred=y_pred)
-    elif task_type == constants.Tasks.TRANSLATION:
-        metrics_list = kwargs.pop('metrics', None)
-        tokenizer = kwargs.pop('tokenizer', None)
-        smoothing = kwargs.pop('smoothing', False)
-
-        translation_kwargs = ['metrics', 'tokenizer', 'smoothing']
-        check_kwargs(kwargs, task_type, translation_kwargs, common_args)
-
-        metrics = AzureMLTranslationMetrics(
-            metrics=metrics_list,
-            tokenizer=tokenizer,
-            smoothing=smoothing,
-            custom_dimensions=custom_dimensions,
-        )
-        computed_metrics = metrics.compute(y_test=y_test, y_pred=y_pred)
-    elif task_type == constants.Tasks.SUMMARIZATION:
-        metrics_list = kwargs.pop('metrics', None)
-        tokenizer = kwargs.pop('tokenizer', None)
-        aggregator = kwargs.pop('aggregator', True)
-        stemmer = kwargs.pop('stemmer', False)
-
-        summarization_kwargs = ['metrics', 'tokenizer', 'aggregator', 'stemmer']
-        check_kwargs(kwargs, task_type, summarization_kwargs, common_args)
-
-        metrics = AzureMLSummarizationMetrics(
-            metrics=metrics_list,
-            tokenizer=tokenizer,
-            aggregator=aggregator,
-            stemmer=stemmer,
-            custom_dimensions=custom_dimensions,
-        )
-        computed_metrics = metrics.compute(y_test=y_test, y_pred=y_pred)
-    elif task_type == constants.Tasks.QUESTION_ANSWERING:
-        metrics_list = kwargs.pop('metrics', None)
-        tokenizer = kwargs.pop('tokenizer', None)
-        regexes_to_ignore = kwargs.pop('regexes_to_ignore', None)
-        ignore_case = kwargs.pop('ignore_case', False)
-        ignore_punctuation = kwargs.pop('ignore_punctuation', False)
-        ignore_numbers = kwargs.pop('ignore_numbers', False)
-
-        qa_kwargs = ['metrics', 'tokenizer', 'regexes_to_ignore', 'ignore_case',
-                     'ignore_punctuation', 'ignore_numbers']
-        check_kwargs(kwargs, task_type, qa_kwargs, common_args)
-        metrics = AzureMLQAMetrics(
-            metrics=metrics_list,
-            tokenizer=tokenizer,
-            regexes_to_ignore=regexes_to_ignore,
-            ignore_case=ignore_case,
-            ignore_punctuation=ignore_punctuation,
-            ignore_numbers=ignore_numbers,
-            custom_dimensions=custom_dimensions,
-        )
-        computed_metrics = metrics.compute(y_test=y_test, y_pred=y_pred)
-    elif task_type == constants.Tasks.FILL_MASK:
-        metrics_list = kwargs.pop("metrics", None)
-
-        # perplexity keyword arguments
-        # using gpt2 as default model_id
-        model_id = kwargs.pop("model_id", "gpt2")
-        batch_size = kwargs.pop("batch_size", 16)
-        add_start_token = kwargs.pop("add_start_token", True)
-
-        lm_kwargs = ["metrics", "model_id", "batch_size", "add_start_token"]
-        check_kwargs(kwargs, task_type, lm_kwargs, common_args)
-
-        metrics = AzureMLFillMaskMetrics(
-            metrics=metrics_list,
-            model_id=model_id,
-            batch_size=batch_size,
-            add_start_token=add_start_token,
-            custom_dimensions=custom_dimensions,
-        )
-        computed_metrics = metrics.compute(y_test=y_test, y_pred=y_pred)
-    elif task_type == constants.Tasks.TEXT_GENERATION:
-        metrics_list = kwargs.pop("metrics", None)
-
-        # bleu keyword arguments
-        tokenizer = kwargs.pop('tokenizer', None)
-        smoothing = kwargs.pop('smoothing', False)
-
-        # rouge keyword arguments
-        aggregator = kwargs.pop('aggregator', True)
-        stemmer = kwargs.pop('stemmer', False)
-
-        text_generation_kwargs = ["metrics", "tokenizer", "smoothing",
-                                  "aggregator", "stemmer"]
-        check_kwargs(kwargs, task_type, text_generation_kwargs, common_args)
-
-        metrics = AzureMLTextGenerationMetrics(
-            metrics=metrics_list,
-            tokenizer=tokenizer,
-            smoothing=smoothing,
-            aggregator=aggregator,
-            stemmer=stemmer,
-            custom_dimensions=custom_dimensions,
-        )
-        computed_metrics = metrics.compute(y_test=y_test, y_pred=y_pred)
-    elif task_type == constants.Tasks.FORECASTING:
-        # Parameters common with regression task
-        metrics_list = kwargs.pop('metrics', None)
-        sample_weight = kwargs.pop("sample_weight", None)
-        X_train = kwargs.pop("X_train", None)
-        y_train = kwargs.pop("y_train", None)
-        y_std = kwargs.pop("y_std", None)
-        # Forecasting-specific parameters
-        time_series_id_column_names = kwargs.pop("time_series_id_column_names", None)
-        aggregation_method = kwargs.pop("aggregation_method", np.mean)
-        time_column_name = kwargs.pop("time_column_name", None)
-        X_test = kwargs.pop("X_test", None)
-        y_min_dict = kwargs.pop("y_min_dict", None)
-        y_max_dict = kwargs.pop("y_max_dict", None)
-        forecasting_kwargs = ["metrics", "sample_weight",
-                              "X_train", "X_test", "y_train", "y_std",
-                              "time_series_id_column_names",
-                              "aggregation_method", "time_column_name", "y_min_dict",
-                              "y_max_dict"]
-        check_kwargs(kwargs, task_type, forecasting_kwargs)
-        metrics = AzureMLForecastingMetrics(
-            metrics=metrics_list,
-            sample_weight=sample_weight,
-            X_train=X_train,
-            y_train=y_train,
-            y_std=y_std,
-            time_series_id_column_names=time_series_id_column_names,
-            time_column_name=time_column_name,
-            aggregation_method=aggregation_method,
-            custom_dimensions=custom_dimensions,
-            y_min_dict=y_min_dict,
-            y_max_dict=y_max_dict,
-            log_activity=log_activity,
-            log_traceback=log_traceback)
-        computed_metrics = metrics.compute(y_test=y_test, y_pred=y_pred, X_test=X_test)
-    elif task_type in [constants.Tasks.IMAGE_OBJECT_DETECTION, constants.Tasks.IMAGE_INSTANCE_SEGMENTATION]:
-        metrics_list = kwargs.pop("metrics", None)
-        task_is_detection = task_type == constants.Tasks.IMAGE_OBJECT_DETECTION
-        num_classes = kwargs.pop("num_classes", None)
-        iou_threshold = kwargs.pop("iou_threshold", None)
-        if num_classes is None:
-            raise Exception("The number of classes must be specified for {} tasks.".format(task_type))
-
-        # Extract the additional image-related argument required for object detection / instance segmentation.
-        image_meta_info = kwargs.pop("image_meta_info", None)
-        if image_meta_info is None:
-            raise Exception("The image meta information must be specified for {} tasks.".format(task_type))
-
-        od_is_kwargs = ["metrics", "num_classes", "iou_threshold", "image_meta_info"]
-        check_kwargs(kwargs, task_type, od_is_kwargs, common_args)
-
-        metrics = AzureMLODISMetrics(
-            task_is_detection=task_is_detection,
-            num_classes=num_classes,
-            iou_threshold=iou_threshold,
-            metrics=metrics_list,
-        )
-        computed_metrics = metrics.compute(y_test=y_test, y_pred=y_pred, image_meta_info=image_meta_info)
     else:
-        supported_tasks = [constants.Tasks.FORECASTING, constants.Tasks.CLASSIFICATION,
-                           constants.Tasks.REGRESSION, constants.Tasks.SUMMARIZATION,
-                           constants.Tasks.TRANSLATION, constants.Tasks.FILL_MASK,
-                           constants.Tasks.QUESTION_ANSWERING, constants.Tasks.IMAGE_OBJECT_DETECTION,
-                           constants.Tasks.IMAGE_INSTANCE_SEGMENTATION] + constants.Tasks.ALL_TEXT
-        raise Exception(f"Invalid task type. Please choose among the following task types : {supported_tasks}")
+        computed_metrics = compute_metrics_function(task_type, y_test, y_pred, kwargs)
+
     return computed_metrics
 
 
 def score(*,
-          task_type: constants.TASKS,
+          task_type: constants.Tasks,
           model: Any,
           X_test: Any,
           y_test: Union[np.ndarray, pd.DataFrame, List],
           **kwargs) -> Dict[str, Dict[str, Any]]:
     """Given task type, model, y_test, y_pred or y_pred_proba compute predictions and the respective metrics.
 
         :param task_type: Accepts an argument of type constants.Tasks for which metrics have to be computed.
@@ -497,15 +589,15 @@
         :param y_test: Ground truths or references.
     """
     # Step 1: Generate predictions using model
     # Step 2: Extract whether predict proba is required, compute and add to kwargs if yes
     # Step 3: Call compute metrics method and pass appropriate kwargs to compute and fetch metrics
 
     if not (hasattr(model, "predict") and callable(getattr(model, 'predict'))):
-        raise Exception("Model should have callable predict method.")
+        raise MetricsException("Model should have callable predict method.")
 
     try:
         if hasattr(model, "forecast") and callable(getattr(model, 'forecast')):
             # In the forecast data we are not guaranteed to have the same
             # dimension of output data as the input so we have to preaggregate
             # the data here.
             if 'X_train' in kwargs and 'y_train' in kwargs:
@@ -523,43 +615,44 @@
 
         multilabel = kwargs.get("multilabel", False)
         if multilabel or (task_type in [constants.Tasks.TEXT_CLASSIFICATION_MULTILABEL,
                                         constants.Tasks.TEXT_NER]):
             y_pred = [ast.literal_eval(label) for label in y_pred]
     except Exception as e:
         exception_msg = "Error occurred while calling predict method on the model."
-        raise Exception(exception_msg + str(e))
+        raise MetricsSystemException(exception_msg + str(e))
 
     compute_probs = kwargs.get("compute_probs", False)
     if task_type in [constants.Tasks.CLASSIFICATION, constants.Tasks.REGRESSION] and \
             kwargs.get("enable_metric_confidence", False):
         compute_probs = True
     elif task_type == constants.Tasks.FORECASTING:
         kwargs['X_test'] = X_test
     if compute_probs:
         if not (hasattr(model, "predict_proba") and callable(getattr(model, 'predict_proba'))):
-            raise Exception("Model should have callable predict_proba method when compute_probs is set to True.")
+            raise MetricsException(
+                "Model should have callable predict_proba method when compute_probs is set to True.")
 
         try:
             y_pred_proba = model.predict_proba(X_test)
             kwargs["y_pred_proba"] = y_pred_proba
         except Exception as e:
             exception_msg = "Error occurred while calling predict_proba method on the model."
-            raise Exception(exception_msg + str(e))
+            raise MetricsSystemException(exception_msg + str(e))
 
     metrics = compute_metrics(task_type=task_type,
                               y_test=y_test,
                               y_pred=y_pred,
                               **kwargs)
 
     return metrics
 
 
-def list_metrics(task_type: constants.TASKS,
-                 multilabel: Optional[bool] = False) -> List[str]:
+def list_metrics(task_type: constants.Tasks,
+                 multilabel: Optional[bool] = False) -> Union[List[str], str]:
     """Get the list of supported metrics for provided task type.
 
         :param task_type: Accepts an argument of type constants.Tasks for which metrics have to be computed.
             Can accept from any of the values from constants.Tasks Ex: constants.Tasks.CLASSIFICATION,
             constants.Tasks.REGRESSION, constants.Tasks.TEXT_CLASSIFICATION,
             constants.Tasks.TEXT_CLASSIFICATION_MULTILABEL,
             constants.Tasks.TEXT_NER.
@@ -603,14 +696,19 @@
         >>>list_metrics(task_type=constants.Tasks.SUMMARIZATION)
 
         Example for question answering:
         -------------------------------
         >>>from azureml.metrics import list_metrics, constants
         >>>list_metrics(task_type=constants.Tasks.QUESTION_ANSWERING)
 
+        Example for question answering with multiple ground truth:
+        -------------------------------
+        >>>from azureml.metrics import list_metrics, constants
+        >>>list_metrics(task_type=constants.Tasks.QUESTION_ANSWERING_MULTIPLE_GROUND_TRUTH)
+
         Example for text generation:
         -------------------------------
         >>>from azureml.metrics import list_metrics, constants
         >>>list_metrics(task_type=constants.Tasks.TEXT_GENERATION)
 
         Example for language modeling:
         -------------------------------
@@ -623,59 +721,52 @@
         >>>list_metrics(task_type=constants.Tasks.IMAGE_OBJECT_DETECTION)
 
         Example for instance segmentation:
         -------------------------------
         >>>from azureml.metrics import list_metrics, constants
         >>>list_metrics(task_type=constants.Tasks.IMAGE_INSTANCE_SEGMENTATION)
     """
-    task_options = {
-        constants.Tasks.CLASSIFICATION: AzureMLClassificationMetrics,
-        constants.Tasks.REGRESSION: AzureMLRegressionMetrics,
-        constants.Tasks.TEXT_CLASSIFICATION: AzureMLClassificationMetrics,
-        constants.Tasks.TEXT_CLASSIFICATION_MULTILABEL: AzureMLClassificationMetrics,
-        constants.Tasks.TEXT_NER: AzureMLTextNERMetrics,
-        constants.Tasks.TRANSLATION: AzureMLTranslationMetrics,
-        constants.Tasks.SUMMARIZATION: AzureMLSummarizationMetrics,
-        constants.Tasks.QUESTION_ANSWERING: AzureMLQAMetrics,
-        constants.Tasks.FILL_MASK: AzureMLFillMaskMetrics,
-        constants.Tasks.TEXT_GENERATION: AzureMLTextGenerationMetrics,
-        constants.Tasks.IMAGE_OBJECT_DETECTION: AzureMLODMetrics,
-        constants.Tasks.IMAGE_INSTANCE_SEGMENTATION: AzureMLISMetrics,
-        constants.Tasks.FORECASTING: AzureMLForecastingMetrics
-    }
-
-    result = task_options.get(task_type, None)
-
-    if result is None:
-        return f"Metrics are not implemented for provided task type : {task_type}."
-    elif result == AzureMLClassificationMetrics:
-        if task_type == constants.Tasks.TEXT_CLASSIFICATION_MULTILABEL:
-            multilabel = True
-        metrics = result.list_metrics(multilabel=multilabel)
-    else:
-        metrics = result.list_metrics()
+    metrics = []
+    with default_log_activity(logger=logger,
+                              activity_type=constants.TelemetryConstants.LIST_METRICS_NAME,
+                              activity_name=constants.TelemetryConstants.LIST_METRICS_TASK_SUFFIX.format(task_type)):
+        result = get_supported_metrics(task_type)
+
+        if result is None:
+            return f"Metrics are not implemented for provided task type : {task_type}."
+        elif result == AzureMLClassificationMetrics:
+            multilabel_tasks = [constants.Tasks.TEXT_CLASSIFICATION_MULTILABEL,
+                                constants.Tasks.IMAGE_CLASSIFICATION_MULTILABEL,
+                                constants.Tasks.IMAGE_MULTI_LABEL_CLASSIFICATION]
+            if task_type in multilabel_tasks:
+                multilabel = True
+            metrics = result.list_metrics(multilabel=multilabel)
+        else:
+            metrics = result.list_metrics()
 
     return metrics
 
 
-def check_kwargs(kwargs: Dict,
-                 task_type: str,
-                 task_type_args: List[str],
-                 common_args: List[str] = None) -> None:
-    """Check for presence of any additional kwargs which are unrelated/typos.
+def list_tasks() -> List[str]:
+    """Get the list of supported task types.
 
-        :param kwargs: additional/ununsed keyword arguments.
-        :param task_type: Accepts an argument of type constants.Tasks for which metrics have to be computed.
-            Can accept from any of the values constants.Tasks.CLASSIFICATION, constants.Tasks.REGRESSION,
-            constants.Tasks.TEXT_CLASSIFICATION, constants.Tasks.TEXT_CLASSIFICATION_MULTILABEL,
-            constants.Tasks.TEXT_NER.
-        :param common_args: List of arguments which are accepted for all task_types.
-        :param task_type_args: keyword arguments based on task type.
+       Example:
+       -------
+       >>> from azureml.metrics import list_tasks
+       >>> supported_tasks = list_tasks()
     """
-    if len(kwargs) > 0:
-        if common_args is not None:
-            task_type_args += common_args
+    supported_tasks = []
+    with default_log_activity(logger=logger,
+                              activity_name=constants.TelemetryConstants.LIST_TASKS_NAME,):
+        supported_tasks = constants.TASK_TYPES
+    return supported_tasks
 
-        warning_message = f"We have unused keyword arguments : {kwargs}\n" + \
-                          f"Applicable keyword arguments for {task_type} are {task_type_args}."
 
-        logger.warning(warning_message)
+def list_prompts(task_type: constants.Tasks, metric: str = None) -> Union[List[str], str]:
+    """Get the list of supported prompts for provided task type."""
+    with default_log_activity(logger=logger,
+                              activity_name=constants.TelemetryConstants.LIST_PROMPTS):
+        result = get_supported_prompts(task_type)
+        if result is None:
+            return f"Prompt based metrics are not implemented for provided task type : {task_type}."
+        else:
+            return result.list_prompts(metric)
```

## azureml/metrics/_scoring_utilities.py

```diff
@@ -1,29 +1,35 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 """Utilities for computing model evaluation metrics."""
 import ast
 import logging
-from typing import Any, Callable, cast, Dict, Optional, Tuple, Type, Iterable, Union
-
 import numpy as np
-import sklearn.metrics
-import sklearn.preprocessing
-from sklearn.base import TransformerMixin
-
-from azureml.metrics import _classification, _forecasting, _regression, _token_classification, constants
-from azureml.metrics import _seq2seq_translation, _seq2seq_summarization, _seq2seq_qa
+from typing import Any, Callable, cast, Dict, Optional, Tuple, Type, Iterable, Union
 
-from azureml.metrics import _seq2seq_fill_mask
-from azureml.metrics._metric_base import Metric
+from azureml.metrics import constants
+from azureml.metrics.text.ner import _token_classification
+from azureml.metrics.text.classification import _classification
+from azureml.metrics.tabular.regression import _regression
+from azureml.metrics.tabular.forecasting import _forecasting
+from azureml.metrics.text.translation import _seq2seq_translation
+from azureml.metrics.text.summarization import _seq2seq_summarization
+from azureml.metrics.text.qa import _seq2seq_qa, _seq2seq_qa_multiple_ground_truth
+from azureml.metrics.text.fill_mask import _seq2seq_fill_mask
+from azureml.metrics.text.code_generation import _code_generation
+from azureml.metrics.rai.groundedness import _groundedness_qa, _groundedness_conversation,\
+    _llm_groundedness_qa
+from azureml.metrics.common._metric_base import Metric
 from azureml.metrics.constants import MetricExtrasConstants, Metric as metric_constants
-from azureml.metrics.contract import Contract
-from azureml.metrics.exceptions import DataErrorException, ResourceException
-from azureml.metrics.reference_codes import ReferenceCodes
+from azureml.metrics.common.contract import Contract
+from azureml.metrics.common.exceptions import DataErrorException, ResourceException
+from azureml.metrics.common.reference_codes import ReferenceCodes
+from azureml.metrics.common.import_utilities import load_sklearn
+from azureml.metrics.common.exceptions import MissingDependencies
 
 module_logger = logging.getLogger(__name__)
 
 
 def pad_predictions(y_pred_probs: np.ndarray,
                     train_labels: Optional[np.ndarray],
                     class_labels: Optional[np.ndarray]) -> np.ndarray:
@@ -86,59 +92,68 @@
     total_count = np.sum(counts)
     total_mean = np.sum(counts * means) / total_count
     unweighted_vars = variances + (means - total_mean) ** 2
     total_var = np.sum(counts * unweighted_vars) / total_count
     return total_var
 
 
-class LabelEncodingBinarizer(TransformerMixin):
-    """
-    Wrapper for sklearn binarizer.
-
-    This wrapper can transform floats, strings, and ints.
-    By default, sklearn does not support binarizing floats because they are not
-    standard label types. AutoML supports float class labels, so this binarizer
-    should be used in those cases.
-    """
-
-    def __init__(self):
-        """Construct a LabelEncodingBinarizer."""
-        self._encoder = sklearn.preprocessing.LabelEncoder()
-        self._binarizer = sklearn.preprocessing.LabelBinarizer()
-
-    def __repr__(self) -> str:
-        return "{}()".format(self.__class__.__name__)
-
-    def fit(self, fit_values: np.ndarray) -> None:
-        """
-        Fit the LabelEncodingBinarizer to some labels.
-
-        :param fit_values: Values on which to fit the tranformer.
-            These can be of type int, string, or float
-        """
-        self._binarizer.fit(self._encoder.fit_transform(fit_values))
-
-    def transform(self, transform_values: np.ndarray) -> np.ndarray:
-        """
-        Transform labels with the encoding binarizer.
+# create the class only when scikit-learn is available
+try:
+    from sklearn.base import TransformerMixin
 
-        :param transform_values: Values to transform to a one-hot encoding.
-        :return: One hot encoding of the values.
+    class LabelEncodingBinarizer(TransformerMixin):
         """
-        return cast(np.ndarray, self._binarizer.transform(self._encoder.transform(transform_values)))
+        Wrapper for sklearn binarizer.
 
-    def fit_transform(self, values: np.ndarray) -> np.ndarray:
+        This wrapper can transform floats, strings, and ints.
+        By default, sklearn does not support binarizing floats because they are not
+        standard label types. AutoML supports float class labels, so this binarizer
+        should be used in those cases.
         """
-        Encode and binarize labels.
 
-        :param values: Values to fit_transform.
-        :return: The transformed values.
-        """
-        encoded = self._encoder.fit_transform(values)
-        return cast(np.ndarray, self._binarizer.fit_transform(encoded))
+        def __init__(self):
+            """Construct a LabelEncodingBinarizer."""
+            sklearn = load_sklearn()
+            self._encoder = sklearn.preprocessing.LabelEncoder()
+            self._binarizer = sklearn.preprocessing.LabelBinarizer()
+
+        def __repr__(self) -> str:
+            return "{}()".format(self.__class__.__name__)
+
+        def fit(self, fit_values: np.ndarray) -> None:
+            """
+            Fit the LabelEncodingBinarizer to some labels.
+
+            :param fit_values: Values on which to fit the tranformer.
+                These can be of type int, string, or float
+            """
+            self._binarizer.fit(self._encoder.fit_transform(fit_values))
+
+        def transform(self, transform_values: np.ndarray) -> np.ndarray:
+            """
+            Transform labels with the encoding binarizer.
+
+            :param transform_values: Values to transform to a one-hot encoding.
+            :return: One hot encoding of the values.
+            """
+            return cast(np.ndarray, self._binarizer.transform(self._encoder.transform(transform_values)))
+
+        def fit_transform(self, values: np.ndarray) -> np.ndarray:
+            """
+            Encode and binarize labels.
+
+            :param values: Values to fit_transform.
+            :return: The transformed values.
+            """
+            encoded = self._encoder.fit_transform(values)
+            return cast(np.ndarray, self._binarizer.fit_transform(encoded))
+except ImportError:
+    safe_message = "Tabular packages are not available. " \
+                   "Please run pip install azureml-metrics[tabular]"
+    module_logger.debug(safe_message)
 
 
 def class_averaged_score(score_func: Callable[..., float],
                          y_test_bin: np.ndarray,
                          y_pred_proba: np.ndarray,
                          class_labels: np.ndarray,
                          test_class_labels: np.ndarray,
@@ -221,25 +236,25 @@
             y_pred_proba = y_pred_proba[:, intersection_indices]
             if ensure_contiguous:
                 # If required, make sure the projected binarized classes and predicted probabilities are memory
                 # contiguous, otherwise they cause significant slowdown in certain numpy scoring functions.
                 y_test_bin = np.ascontiguousarray(y_test_bin)
                 y_pred_proba = np.ascontiguousarray(y_pred_proba)
 
-    if metric_name == constants.NORM_MACRO_RECALL:
+    if metric_name == constants.Metric.NormMacroRecall:
         n_classes = y_test_bin.shape[1]
         return score_func(y_test_bin, y_pred_proba, n_classes=n_classes, **kwargs)
     else:
         ''' Proceed with normal metric computation for multiclass, non-classwise and average_precision metrics which
             do not suffer from metric undefined error when there are no positive and negative samples of a class or
             for classwise metrics in binary class problems with use_binary switch on.
         '''
-        metric_undefined_safe_metrics = [constants.AVERAGE_PRECISION_MICRO, constants.AVERAGE_PRECISION_MACRO,
-                                         constants.AVERAGE_PRECISION_WEIGHTED, constants.AUC_MICRO,
-                                         constants.AVERAGE_PRECISION_CLASSWISE]
+        metric_undefined_safe_metrics = [constants.Metric.AvgPrecisionMicro, constants.Metric.AvgPrecisionMacro,
+                                         constants.Metric.AvgPrecisionWeighted, constants.Metric.AUCMicro,
+                                         constants.Metric.AvgPrecisionClasswise]
         if (not multilabel and average is not None) or metric_name in metric_undefined_safe_metrics or \
                 y_test_bin.ndim == 1:
             return score_func(y_test_bin, y_pred_proba, average=average, **kwargs)
         else:
             # Identify classes which does not have positive and negative cases and remove those classes.
             # Else this will result in exception Only one class present in y_true.
             # ROC AUC score is not defined in that case.
@@ -281,75 +296,75 @@
     """
     Return the metric class based on the constant name of the metric.
 
     :param metric_name: the constant name of the metric
     :return: the class of the metric
     """
     classification_classes = {
-        constants.ACCURACY: _classification.Accuracy,
-        constants.WEIGHTED_ACCURACY: _classification.WeightedAccuracy,
-        constants.BALANCED_ACCURACY: _classification.BalancedAccuracy,
-        constants.NORM_MACRO_RECALL: _classification.NormMacroRecall,
-        constants.LOG_LOSS: _classification.LogLoss,
-        constants.AUC_BINARY: _classification.AUCBinary,
-        constants.AUC_MACRO: _classification.AUCMacro,
-        constants.AUC_MICRO: _classification.AUCMicro,
-        constants.AUC_WEIGHTED: _classification.AUCWeighted,
-        constants.AVERAGE_PRECISION_BINARY: _classification.AveragePrecisionBinary,
-        constants.AVERAGE_PRECISION_MACRO: _classification.AveragePrecisionMacro,
-        constants.AVERAGE_PRECISION_MICRO: _classification.AveragePrecisionMicro,
-        constants.AVERAGE_PRECISION_WEIGHTED: _classification.AveragePrecisionWeighted,
-        constants.MATTHEWS_CORRELATION: _classification.MatthewsCorrelation,
-        constants.F1_BINARY: _classification.F1Binary,
-        constants.F1_MACRO: _classification.F1Macro,
-        constants.F1_MICRO: _classification.F1Micro,
-        constants.F1_WEIGHTED: _classification.F1Weighted,
-        constants.PRECISION_BINARY: _classification.PrecisionBinary,
-        constants.PRECISION_MACRO: _classification.PrecisionMacro,
-        constants.PRECISION_MICRO: _classification.PrecisionMicro,
-        constants.PRECISION_WEIGHTED: _classification.PrecisionWeighted,
-        constants.RECALL_BINARY: _classification.RecallBinary,
-        constants.RECALL_MACRO: _classification.RecallMacro,
-        constants.RECALL_MICRO: _classification.RecallMicro,
-        constants.RECALL_WEIGHTED: _classification.RecallWeighted,
-        constants.ACCURACY_TABLE: _classification.AccuracyTable,
-        constants.CONFUSION_MATRIX: _classification.ConfusionMatrix,
-        constants.CLASSIFICATION_REPORT: _classification.ClassificationReport,
-        constants.IOU: _classification.IOUSamples,
-        constants.IOU_MICRO: _classification.IOUMicro,
-        constants.IOU_MACRO: _classification.IOUMacro,
-        constants.IOU_WEIGHTED: _classification.IOUWeighted,
-        constants.PRECISION_CLASSWISE: _classification.PrecisionClasswise,
-        constants.RECALL_CLASSWISE: _classification.RecallClasswise,
-        constants.F1_CLASSWISE: _classification.F1Classwise,
-        constants.IOU_CLASSWISE: _classification.IOUClasswise,
-        constants.AUC_CLASSWISE: _classification.AUCClasswise,
-        constants.AVERAGE_PRECISION_CLASSWISE: _classification.AveragePrecisionClasswise,
+        constants.Metric.Accuracy: _classification.Accuracy,
+        constants.Metric.WeightedAccuracy: _classification.WeightedAccuracy,
+        constants.Metric.BalancedAccuracy: _classification.BalancedAccuracy,
+        constants.Metric.NormMacroRecall: _classification.NormMacroRecall,
+        constants.Metric.LogLoss: _classification.LogLoss,
+        constants.Metric.AUCBinary: _classification.AUCBinary,
+        constants.Metric.AUCMacro: _classification.AUCMacro,
+        constants.Metric.AUCMicro: _classification.AUCMicro,
+        constants.Metric.AUCWeighted: _classification.AUCWeighted,
+        constants.Metric.AvgPrecisionBinary: _classification.AveragePrecisionBinary,
+        constants.Metric.AvgPrecisionMacro: _classification.AveragePrecisionMacro,
+        constants.Metric.AvgPrecisionMicro: _classification.AveragePrecisionMicro,
+        constants.Metric.AvgPrecisionWeighted: _classification.AveragePrecisionWeighted,
+        constants.Metric.MatthewsCorrelation: _classification.MatthewsCorrelation,
+        constants.Metric.F1Binary: _classification.F1Binary,
+        constants.Metric.F1Macro: _classification.F1Macro,
+        constants.Metric.F1Micro: _classification.F1Micro,
+        constants.Metric.F1Weighted: _classification.F1Weighted,
+        constants.Metric.PrecisionBinary: _classification.PrecisionBinary,
+        constants.Metric.PrecisionMacro: _classification.PrecisionMacro,
+        constants.Metric.PrecisionMicro: _classification.PrecisionMicro,
+        constants.Metric.PrecisionWeighted: _classification.PrecisionWeighted,
+        constants.Metric.RecallBinary: _classification.RecallBinary,
+        constants.Metric.RecallMacro: _classification.RecallMacro,
+        constants.Metric.RecallMicro: _classification.RecallMicro,
+        constants.Metric.RecallWeighted: _classification.RecallWeighted,
+        constants.Metric.AccuracyTable: _classification.AccuracyTable,
+        constants.Metric.ConfusionMatrix: _classification.ConfusionMatrix,
+        constants.Metric.ClassificationReport: _classification.ClassificationReport,
+        constants.Metric.IOU: _classification.IOUSamples,
+        constants.Metric.IOUMicro: _classification.IOUMicro,
+        constants.Metric.IOUMacro: _classification.IOUMacro,
+        constants.Metric.IOUWeighted: _classification.IOUWeighted,
+        constants.Metric.PrecisionClasswise: _classification.PrecisionClasswise,
+        constants.Metric.RecallClasswise: _classification.RecallClasswise,
+        constants.Metric.F1Classwise: _classification.F1Classwise,
+        constants.Metric.IOUClasswise: _classification.IOUClasswise,
+        constants.Metric.AUCClasswise: _classification.AUCClasswise,
+        constants.Metric.AvgPrecisionClasswise: _classification.AveragePrecisionClasswise,
     }  # type: Dict[str, Type[Metric]]
     regression_classes = {
-        constants.EXPLAINED_VARIANCE: _regression.ExplainedVariance,
-        constants.R2_SCORE: _regression.R2,
-        constants.SPEARMAN: _regression.Spearman,
-        constants.RMSLE: _regression.RMSLE,
-        constants.NORM_RMSLE: _regression.NormRMSLE,
-        constants.RMSE: _regression.RMSE,
-        constants.NORM_RMSE: _regression.NormRMSE,
-        constants.MEAN_ABS_ERROR: _regression.MeanAbsoluteError,
-        constants.NORM_MEAN_ABS_ERROR: _regression.NormMeanAbsoluteError,
-        constants.MEDIAN_ABS_ERROR: _regression.MedianAbsoluteError,
-        constants.NORM_MEDIAN_ABS_ERROR: _regression.NormMedianAbsoluteError,
-        constants.MAPE: _regression.MAPE,
-        constants.RESIDUALS: _regression.Residuals,
-        constants.PREDICTED_TRUE: _regression.PredictedTrue
+        constants.Metric.ExplainedVariance: _regression.ExplainedVariance,
+        constants.Metric.R2Score: _regression.R2,
+        constants.Metric.Spearman: _regression.Spearman,
+        constants.Metric.RMSLE: _regression.RMSLE,
+        constants.Metric.NormRMSLE: _regression.NormRMSLE,
+        constants.Metric.RMSE: _regression.RMSE,
+        constants.Metric.NormRMSE: _regression.NormRMSE,
+        constants.Metric.MeanAbsError: _regression.MeanAbsoluteError,
+        constants.Metric.NormMeanAbsError: _regression.NormMeanAbsoluteError,
+        constants.Metric.MedianAbsError: _regression.MedianAbsoluteError,
+        constants.Metric.NormMedianAbsError: _regression.NormMedianAbsoluteError,
+        constants.Metric.MAPE: _regression.MAPE,
+        constants.Metric.Residuals: _regression.Residuals,
+        constants.Metric.PredictedTrue: _regression.PredictedTrue
     }  # type: Dict[str, Type[Metric]]
     forecasting_classes = {
-        constants.FORECASTING_MAPE: _forecasting.ForecastMAPE,
-        constants.FORECASTING_RESIDUALS: _forecasting.ForecastResiduals,
-        constants.FORECASTING_TABLE: _forecasting.ForecastTable,
-        constants.FORECASTING_TS_ID_DISTRIBUTION_TABLE: _forecasting.ForecastTsIDDistributionTable
+        constants.Metric.ForecastMAPE: _forecasting.ForecastMAPE,
+        constants.Metric.ForecastResiduals: _forecasting.ForecastResiduals,
+        constants.Metric.ForecastTable: _forecasting.ForecastTable,
+        constants.Metric.ForecastTsIDDistributionTable: _forecasting.ForecastTsIDDistributionTable
     }
     translation_classes = {
         constants.Metric.TranslationBleu_1: _seq2seq_translation.Bleu,
         constants.Metric.TranslationBleu_2: _seq2seq_translation.Bleu,
         constants.Metric.TranslationBleu_3: _seq2seq_translation.Bleu,
         constants.Metric.TranslationBleu_4: _seq2seq_translation.Bleu
     }
@@ -357,61 +372,126 @@
         constants.Metric.SummarizationRouge1: _seq2seq_summarization.Rouge,
         constants.Metric.SummarizationRouge2: _seq2seq_summarization.Rouge,
         constants.Metric.SummarizationRougeL: _seq2seq_summarization.Rouge,
         constants.Metric.SummarizationRougeLsum: _seq2seq_summarization.Rouge,
     }
     qa_classes = {
         constants.Metric.QAExactMatch: _seq2seq_qa.ExactMatch,
-        constants.Metric.QAF1Score: _seq2seq_qa.F1Score
+        constants.Metric.QAF1Score: _seq2seq_qa.F1Score,
+        constants.Metric.AdaSimilarity: _seq2seq_qa.AdaSimilarity,
+        constants.Metric.BERTScore: _seq2seq_qa.BERTScore,
+        constants.Metric.GPTSimilarity: _seq2seq_qa.GPTSimilarity,
+        constants.Metric.GPTCoherence: _seq2seq_qa.GPTCoherence,
+        constants.Metric.GPTGroundedness: _groundedness_qa.GroundednessQA,
+        constants.Metric.GPTFluency: _seq2seq_qa.GPTFluency,
+        constants.Metric.GPTRelevance: _seq2seq_qa.GPTRelevance,
+        constants.Metric.LLMSimilarity: _seq2seq_qa.LLMSimilarity,
+        constants.Metric.LLMCoherence: _seq2seq_qa.LLMCoherence,
+        constants.Metric.LLMGroundedness: _llm_groundedness_qa.LLMGroundednessQA,
+        constants.Metric.LLMFluency: _seq2seq_qa.LLMFluency,
+        constants.Metric.LLMRelevance: _seq2seq_qa.LLMRelevance,
+    }
+    qa_multple_ground_truth_classes = {
+        constants.Metric.QAMacroAveragedExactMatch: _seq2seq_qa_multiple_ground_truth.MacroAveragedExactMatch,
+        constants.Metric.QAMacroAveragedF1: _seq2seq_qa_multiple_ground_truth.MacroAveragedF1,
+        # gpt-star metrics
+        constants.Metric.GPTSimilarity: _seq2seq_qa.GPTSimilarity,
+        constants.Metric.GPTCoherence: _seq2seq_qa.GPTCoherence,
+        constants.Metric.GPTGroundedness: _groundedness_qa.GroundednessQA,
+        constants.Metric.GPTFluency: _seq2seq_qa.GPTFluency,
+        constants.Metric.GPTRelevance: _seq2seq_qa.GPTRelevance,
+        constants.Metric.LLMSimilarity: _seq2seq_qa.LLMSimilarity,
+        constants.Metric.LLMCoherence: _seq2seq_qa.LLMCoherence,
+        constants.Metric.LLMGroundedness: _llm_groundedness_qa.LLMGroundednessQA,
+        constants.Metric.LLMFluency: _seq2seq_qa.LLMFluency,
+        constants.Metric.LLMRelevance: _seq2seq_qa.LLMRelevance,
     }
     lm_classes = {
         constants.Metric.FMPerplexity: _seq2seq_fill_mask.Perplexity,
     }
+    chat_completion_classes = {
+        constants.Metric.ConversationGroundingScore: _groundedness_conversation.GroundednessConversation,
+    }
 
+    code_generation_classes = {
+        constants.Metric.CodeGenerationPassRateScore: _code_generation.CodeEval,
+    }
     class_map = dict()  # type: Dict[str, Type[Metric]]
     class_map.update(classification_classes)
     class_map.update(regression_classes)
     class_map.update(forecasting_classes)
     class_map.update(translation_classes)
     class_map.update(summarization_classes)
     class_map.update(qa_classes)
+    class_map.update(qa_multple_ground_truth_classes)
     class_map.update(lm_classes)
+    class_map.update(chat_completion_classes)
+    class_map.update(code_generation_classes)
 
     if metric_name not in class_map:
         raise DataErrorException(
             "Metric class {} was not found in Metric.get_metric_class.".format(metric_name),
             target="metric_name", reference_code="_scoring_utilities.get_metric_class",
             has_pii=True, safe_message="Metric class was not found in Metric.get_metric_class.")
     return class_map[metric_name]
 
 
 def get_metric_class_text_ner(metric_name):
     text_ner_classes = {
-        constants.ACCURACY: _token_classification.Accuracy,
-        constants.F1_MACRO: _token_classification.F1Macro,
-        constants.F1_MICRO: _token_classification.F1Micro,
-        constants.F1_WEIGHTED: _token_classification.F1Weighted,
-        constants.PRECISION_MACRO: _token_classification.PrecisionMacro,
-        constants.PRECISION_MICRO: _token_classification.PrecisionMicro,
-        constants.PRECISION_WEIGHTED: _token_classification.PrecisionWeighted,
-        constants.RECALL_MACRO: _token_classification.RecallMacro,
-        constants.RECALL_MICRO: _token_classification.RecallMicro,
-        constants.RECALL_WEIGHTED: _token_classification.RecallWeighted,
+        constants.Metric.Accuracy: _token_classification.Accuracy,
+        constants.Metric.F1Macro: _token_classification.F1Macro,
+        constants.Metric.F1Micro: _token_classification.F1Micro,
+        constants.Metric.F1Weighted: _token_classification.F1Weighted,
+        constants.Metric.PrecisionMacro: _token_classification.PrecisionMacro,
+        constants.Metric.PrecisionMicro: _token_classification.PrecisionMicro,
+        constants.Metric.PrecisionWeighted: _token_classification.PrecisionWeighted,
+        constants.Metric.RecallMacro: _token_classification.RecallMacro,
+        constants.Metric.RecallMicro: _token_classification.RecallMicro,
+        constants.Metric.RecallWeighted: _token_classification.RecallWeighted,
     }
     class_map = dict()  # type: Dict[str, Type[Metric]]
     class_map.update(text_ner_classes)
 
     if metric_name not in class_map:
         raise DataErrorException(
             "Metric class {} was not found in Metric.get_metric_class_text_ner.".format(metric_name),
             target="metric_name", reference_code="_scoring_utilities.get_metric_class_text_ner",
             has_pii=True, safe_message="Metric class was not found in Metric.get_metric_class_text_ner.")
     return class_map[metric_name]
 
 
+def get_metric_class_rag_evaluation(metric_name):
+    """
+    Helps to identify the mapping between metric names and implementation for RAG based metrics.
+
+    Created as a separate helper method as same metric names are used for question answering task type.
+    """
+    try:
+        from azureml.metrics.text.rag_evaluation import _rag_evaluation
+    except MissingDependencies:
+        message = "rag-evaluation packages are not available. " \
+                  "Please run pip install azureml-metrics[rag-evaluation]"
+        module_logger.info(message)
+
+    rag_evaluation_classes = {
+        constants.Metric.RAG_GPTGroundedness: _rag_evaluation.GroundingScore,
+        constants.Metric.RAG_GPTRelevance: _rag_evaluation.GenerationScore,
+        constants.Metric.RAG_GPTRetrieval: _rag_evaluation.RetrievalScore,
+    }
+    class_map = dict()  # type: Dict[str, Type[Metric]]
+    class_map.update(rag_evaluation_classes)
+
+    if metric_name not in class_map:
+        raise DataErrorException(
+            "Metric class {} was not found in Metric.get_metric_class_rag_evaluation.".format(metric_name),
+            target="metric_name", reference_code="_scoring_utilities.get_metric_class_rag_evaluation",
+            has_pii=True, safe_message="Metric class was not found in Metric.get_metric_class_rag_evaluation.")
+    return class_map[metric_name]
+
+
 def make_json_safe(o: Any) -> Any:
     """
     Convert a value into something that is safe to parse into JSON.
 
     :param o: Object to make JSON safe.
     :return: New object
     """
@@ -432,15 +512,15 @@
             return o.item()
         except Exception:
             safe_message = "Cannot encode type {}".format(type(o))
             raise DataErrorException(safe_message, target="metric_name",
                                      reference_code="_scoring_utilities.make_json_safe", has_pii=False)
 
 
-def classification_label_decode(y_transformer: Optional[TransformerMixin],
+def classification_label_decode(y_transformer: Optional[Any],
                                 y_test: np.ndarray,
                                 y_pred: np.ndarray,
                                 class_labels: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:
     """
     Decode classification labels if a y_transformer is passed.
 
     This is important for non-scalar metrics, which require the actual labels so that charts
@@ -472,14 +552,15 @@
     This allows sklearn to operate on integer labels which is the most common format.
     :param y_test: Actual targets.
     :param y_pred: Predicted targets.
     :param class_labels: All classes found in the full dataset.
     :param positive_label: The class treated as positive class for binary classification metrics
     :return: The labels that have been encoded as a tuple.
     """
+    sklearn = load_sklearn()
     metrics_transformer = sklearn.preprocessing.LabelEncoder()
     metrics_transformer.fit(class_labels)
     y_test_encoded = metrics_transformer.transform(y_test)
     y_pred_encoded = metrics_transformer.transform(y_pred)
     class_labels_encoded = metrics_transformer.transform(class_labels)
     if positive_label in class_labels:
         positive_label_encoded = metrics_transformer.transform([positive_label])[0]
@@ -519,18 +600,26 @@
             self,
             y_test: np.ndarray,
             y_pred: Optional[np.ndarray],
             y_pred_probs: Optional[np.ndarray],
             class_labels: np.ndarray,
             train_labels: np.ndarray,
             sample_weight: Optional[np.ndarray] = None,
-            y_transformer: Optional[TransformerMixin] = None,
+            y_transformer: Optional[Any] = None,
             multilabel: Optional[bool] = False,
             positive_label: Optional[Any] = None
     ):
+        try:
+            from sklearn.base import TransformerMixin
+        except ImportError:
+            safe_message = "Tabular packages are not available. " \
+                           "Please run pip install azureml-metrics[tabular]"
+            raise MissingDependencies(
+                safe_message, safe_message=safe_message
+            )
         if y_pred_probs is not None:
             # Some metrics use an eps of 1e-15 by default, which results in nans for float32.
             if y_pred_probs.dtype == np.float32:
                 y_pred_probs = y_pred_probs.astype(np.float64)
 
             # Pad the predictions with 0 columns in case the model wasn't fit on the entire set of class labels
             y_pred_probs_padded = pad_predictions(y_pred_probs, train_labels, class_labels)
@@ -672,14 +761,15 @@
             metric_name, score, clipped))
     return clipped
 
 
 def _get_debug_stats(y_test: np.ndarray, y_pred: np.ndarray,
                      class_labels: np.ndarray, y_pred_proba: np.ndarray,
                      sample_weight: Optional[np.ndarray] = None) -> Dict[str, Any]:
+    sklearn = load_sklearn()
     y_type, _, _ = sklearn.metrics._classification._check_targets(y_test, y_pred)
     y_test_in_labels = sum(1 if val in class_labels else 0 for val in y_test)
     return {
         'y_true_type': str(y_test.dtype),
         'y_pred_type': str(y_pred.dtype),
         'labels_type': str(class_labels.dtype),
         'y_type': y_type,
```

## azureml/metrics/_version.py

```diff
@@ -1,2 +1,2 @@
-ver = "0.0.9"
-selfver = "0.0.9"
+ver = "47.0.0"
+selfver = "47.0.0"
```

## azureml/metrics/constants.py

```diff
@@ -3,14 +3,16 @@
 # ---------------------------------------------------------
 """Metrics constants."""
 import sys
 from enum import Enum
 
 import numpy as np
 
+import pkg_resources
+
 
 class TrainingResultsType:
     """Defines potential results from runners class."""
 
     # Metrics
     TRAIN_METRICS = "train"
     VALIDATION_METRICS = "validation"
@@ -38,18 +40,36 @@
 class MetricExtrasConstants:
     """Define internal values of Confidence Intervals."""
 
     UPPER_95_PERCENTILE = "upper_ci_95"
     LOWER_95_PERCENTILE = "lower_ci_95"
     VALUE = "value"
 
-    # Confidence Interval metric name format
+    # Confidence Interval metric metric_name format
     MetricExtrasSuffix = "_extras"
     MetricExtrasFormat = "{}" + MetricExtrasSuffix
 
+    # Aggregation logic extra suffix
+    MeanExtrasPrefix = "mean_"
+    MeanExtrasFormat = MeanExtrasPrefix + "{}"
+    MeanExtrasDictFormat = MeanExtrasPrefix + "{}_{}"
+
+    MedianExtrasPrefix = "median_"
+    MedianExtrasFormat = MedianExtrasPrefix + "{}"
+
+    # Custom prompt metric metric_name suffix
+    CustomPromptMetricSuffix = "{}" + "_custom_prompt_metric"
+
+
+class RetryConstants:
+    """Define constants to be used in retry logic."""
+
+    MAX_ATTEMPTS = 3
+    DELAY_TIME = 10
+
 
 class Metric:
     """Defines all metrics supported by classification and regression."""
 
     # Scalar & non scalar segregation key constants
     Metrics = "metrics"  # Scalar
     Artifacts = "artifacts"  # Non-Scalar
@@ -79,14 +99,29 @@
     AvgPrecisionBinary = "average_precision_score_binary"
     AvgPrecisionMicro = "average_precision_score_micro"
     AvgPrecisionMacro = "average_precision_score_macro"
     AvgPrecisionWeighted = "average_precision_score_weighted"
     AccuracyTable = "accuracy_table"
     ConfusionMatrix = "confusion_matrix"
     MatthewsCorrelation = "matthews_correlation"
+    ClassificationReport = "classification_report"
+
+    # Multilabel classification
+    IOU = "iou"
+    IOUMicro = "iou_micro"
+    IOUMacro = "iou_macro"
+    IOUWeighted = "iou_weighted"
+
+    # classwise metrics
+    PrecisionClasswise = "precision_score_classwise"
+    RecallClasswise = "recall_score_classwise"
+    F1Classwise = "f1_score_classwise"
+    AUCClasswise = "AUC_classwise"
+    AvgPrecisionClasswise = "average_precision_score_classwise"
+    IOUClasswise = "iou_classwise"
 
     # Regression
     ExplainedVariance = "explained_variance"
     R2Score = "r2_score"
     Spearman = "spearman_correlation"
     MAPE = "mean_absolute_percentage_error"
     SMAPE = "symmetric_mean_absolute_percentage_error"
@@ -98,18 +133,18 @@
     NormMedianAbsError = "normalized_median_absolute_error"
     NormRMSE = "normalized_root_mean_squared_error"
     NormRMSLE = "normalized_root_mean_squared_log_error"
     Residuals = "residuals"
     PredictedTrue = "predicted_true"
 
     # Forecast
-    ForecastMAPE = 'forecast_mean_absolute_percentage_error'
-    ForecastSMAPE = 'forecast_symmetric_mean_absolute_percentage_error'
-    ForecastResiduals = 'forecast_residuals'
-    ForecastTable = 'forecast_table'
+    ForecastMAPE = "forecast_mean_absolute_percentage_error"
+    ForecastSMAPE = "forecast_symmetric_mean_absolute_percentage_error"
+    ForecastResiduals = "forecast_residuals"
+    ForecastTable = "forecast_table"
     ForecastTsIDDistributionTable = "forecast_time_series_id_distribution_table"
 
     # Sequence to Sequence Metrics
     # Seq2Seq Translation
     TranslationBleu_1 = "bleu_1"
     TranslationBleu_2 = "bleu_2"
     TranslationBleu_3 = "bleu_3"
@@ -120,36 +155,69 @@
     SummarizationRouge2 = "rouge2"
     SummarizationRougeL = "rougeL"
     SummarizationRougeLsum = "rougeLsum"
 
     # QA
     QAExactMatch = "exact_match"
     QAF1Score = "f1_score"
+    # QA multiple ground truth
+    QAMacroAveragedF1 = "macro_averaged_f1"
+    QAMacroAveragedExactMatch = "macro_averaged_exact_match"
+
+    # Text Similarity metrics for Question Answering
+    AdaSimilarity = "ada_similarity"
+    BERTScore = "bertscore"
+    GPTSimilarity = "gpt_similarity"
+    GPTCoherence = "gpt_coherence"
+    GPTRelevance = "gpt_relevance"
+    GPTGroundedness = "gpt_groundedness"
+    GPTFluency = "gpt_fluency"
+    # LLM based metrics for Question Answering
+    LLMSimilarity = "llm_similarity"
+    LLMCoherence = "llm_coherence"
+    LLMRelevance = "llm_relevance"
+    LLMGroundedness = "llm_groundedness"
+    LLMFluency = "llm_fluency"
+
+    # RAG Evaluation metrics
+    RAG_GPTGroundedness = "gpt_groundedness"
+    RAG_GPTRelevance = "gpt_relevance"
+    RAG_GPTRetrieval = "gpt_retrieval_score"
 
-    # Fill Masking Metrics
-    FMPerplexity = "perplexities"
+    # Chat Completion metrics
+    ConversationGroundingScore = "conversation_groundedness_score"
 
-    # Image multilabel classification
-    IOU = "iou"  # Intersection Over Union
+    # Code Generation metrics
+    CodeGenerationPassRateScore = "code_eval"  # Pass@k
+
+    # Fill Masking Metrics
+    FMPerplexity = "perplexity"
 
     # Image object detection and instance segmentation
     MEAN_AVERAGE_PRECISION = "mean_average_precision"
     AVERAGE_PRECISION = "average_precision"
     PRECISION = "precision"
     RECALL = "recall"
     PER_LABEL_METRICS = "per_label_metrics"
     IMAGE_LEVEL_BINARY_CLASSIFIER_METRICS = "image_level_binary_classsifier_metrics"
     CONFUSION_MATRICES_PER_SCORE_THRESHOLD = "confusion_matrices_per_score_threshold"
-    MEAN_AVERAGE_PRECISION = "mean_average_precision"
-    AVERAGE_PRECISION = "average_precision"
-    PRECISION = "precision"
-    RECALL = "recall"
-    PER_LABEL_METRICS = "per_label_metrics"
-    IMAGE_LEVEL_BINARY_CLASSIFIER_METRICS = "image_level_binary_classsifier_metrics"
-    CONFUSION_MATRICES_PER_SCORE_THRESHOLD = "confusion_matrices_per_score_threshold"
+
+    # Video object tracking
+    IDF1 = "IDF1"
+    MOTA = "MOTA"
+    MOTP = "MOTP"
+    IDSW = "IDSw"
+    FP = "FP"  # False Positive
+    FN = "FN"  # False Negative
+    FM = "FM"  # False Match
+    ML = "ML"  # Mostly Lost
+    MT = "MT"  # Mostly Tracked
+    PT = "PT"  # Partially Tracked
+    TRACKING_PRECISION = "Tracking_Precision"
+    TRACKING_RECALL = "Tracking_Recall"
 
     SCALAR_CLASSIFICATION_SET = {
         AUCBinary,
         AUCMacro,
         AUCMicro,
         AUCWeighted,
         Accuracy,
@@ -172,36 +240,46 @@
         AvgPrecisionBinary,
         AvgPrecisionMicro,
         AvgPrecisionMacro,
         AvgPrecisionWeighted,
         MatthewsCorrelation,
     }
 
-    SCALAR_CLASSIFICATION_SET_MULTILABEL = {
+    IOU_CLASSIFICATION_SET_MULTILABEL = {
+        IOU,
+        IOUMacro,
+        IOUMicro,
+        IOUWeighted,
+    }
+
+    SCALAR_CLASSIFICATION_BINARY_SET = {
         AUCBinary,
+        F1Binary,
+        PrecisionBinary,
+        RecallBinary,
+        AvgPrecisionBinary,
+    }
+
+    SCALAR_CLASSIFICATION_SET_MULTILABEL = {
         AUCMacro,
         AUCMicro,
         AUCWeighted,
         Accuracy,
         NormMacroRecall,
         BalancedAccuracy,
         LogLoss,
-        F1Binary,
         F1Micro,
         F1Macro,
         F1Weighted,
-        PrecisionBinary,
         PrecisionMicro,
         PrecisionMacro,
         PrecisionWeighted,
-        RecallBinary,
         RecallMicro,
         RecallMacro,
         RecallWeighted,
-        AvgPrecisionBinary,
         AvgPrecisionMicro,
         AvgPrecisionMacro,
         AvgPrecisionWeighted,
     }
 
     CLASSIFICATION_PROB_REQUIRED_SET = {
         AUCBinary,
@@ -213,30 +291,95 @@
         AvgPrecisionMicro,
         AvgPrecisionWeighted,
         LogLoss,
         AccuracyTable,
         NormMacroRecall,
     }
 
-    NONSCALAR_CLASSIFICATION_SET = {AccuracyTable, ConfusionMatrix}
+    NONSCALAR_CLASSIFICATION_SET = {
+        AccuracyTable,
+        ConfusionMatrix,
+        ClassificationReport,
+    }
+
+    NONSCALAR_CLASSIFICATION_SET_MULTILABEL = {AccuracyTable, ConfusionMatrix}
 
     CLASSIFICATION_BINARY_SET = {
         AUCBinary,
         F1Binary,
         PrecisionBinary,
         RecallBinary,
         AvgPrecisionBinary,
     }
 
-    CLASSIFICATION_SET = SCALAR_CLASSIFICATION_SET | NONSCALAR_CLASSIFICATION_SET
+    CLASSIFICATION_CLASSWISE_SET = {
+        PrecisionClasswise,
+        RecallClasswise,
+        F1Classwise,
+        IOUClasswise,
+        AvgPrecisionClasswise,
+        AUCClasswise,
+    }
+
+    CLASSIFICATION_SET = (
+        SCALAR_CLASSIFICATION_SET
+        | NONSCALAR_CLASSIFICATION_SET
+        | CLASSIFICATION_CLASSWISE_SET
+        | IOU_CLASSIFICATION_SET_MULTILABEL
+    )
+    # classification set for the azuremlclassification file
+    CLASSIFICATION_SET_AZURE = (
+        SCALAR_CLASSIFICATION_SET | NONSCALAR_CLASSIFICATION_SET_MULTILABEL
+    )
 
     CLASSIFICATION_SET_MULTILABEL = (
-        SCALAR_CLASSIFICATION_SET_MULTILABEL | NONSCALAR_CLASSIFICATION_SET
+        SCALAR_CLASSIFICATION_SET_MULTILABEL
+        | NONSCALAR_CLASSIFICATION_SET_MULTILABEL
+        | IOU_CLASSIFICATION_SET_MULTILABEL
+        | SCALAR_CLASSIFICATION_BINARY_SET
+    )
+
+    CLASSIFICATION_PRIMARY_SET = {
+        Accuracy,
+        AUCWeighted,
+        NormMacroRecall,
+        AvgPrecisionWeighted,
+        PrecisionWeighted,
+    }
+
+    CLASSIFICATION_BALANCED_SET = {
+        # this is for metrics where we would recommend using class_weights
+        BalancedAccuracy,
+        AUCMacro,
+        NormMacroRecall,
+        AvgPrecisionMacro,
+        PrecisionMacro,
+        F1Macro,
+        RecallMacro,
+    }
+
+    UNSUPPORTED_CLASSIFICATION_TABULAR_SET = (
+        CLASSIFICATION_CLASSWISE_SET
+        | IOU_CLASSIFICATION_SET_MULTILABEL
+        | {ClassificationReport}
     )
 
+    TEXT_CLASSIFICATION_SET = {
+        Accuracy,
+        AUCWeighted,
+        PrecisionMicro,
+        PrecisionWeighted,
+    }
+
+    TEXT_CLASSIFICATION_MULTILABEL_SET = {
+        Accuracy,
+        F1Macro,
+        F1Micro,
+    }
+
     SCALAR_REGRESSION_SET = {
         ExplainedVariance,
         R2Score,
         Spearman,
         MAPE,
         MeanAbsError,
         MedianAbsError,
@@ -248,75 +391,111 @@
         NormRMSLE,
     }
 
     NONSCALAR_REGRESSION_SET = {Residuals, PredictedTrue}
 
     REGRESSION_SET = SCALAR_REGRESSION_SET | NONSCALAR_REGRESSION_SET
 
-    CLASSIFICATION_PRIMARY_SET = {
-        Accuracy,
-        AUCWeighted,
-        NormMacroRecall,
-        AvgPrecisionWeighted,
-        PrecisionWeighted,
-    }
-
-    CLASSIFICATION_BALANCED_SET = {
-        # this is for metrics where we would recommend using class_weights
-        BalancedAccuracy,
-        AUCMacro,
-        NormMacroRecall,
-        AvgPrecisionMacro,
-        PrecisionMacro,
-        F1Macro,
-        RecallMacro,
+    REGRESSION_NORMALIZED_SET = {
+        NormMeanAbsError,
+        NormMedianAbsError,
+        NormRMSE,
+        NormRMSLE,
     }
 
     REGRESSION_PRIMARY_SET = {Spearman, NormRMSE, R2Score, NormMeanAbsError}
 
     IMAGE_CLASSIFICATION_PRIMARY_SET = {Accuracy}
 
     IMAGE_CLASSIFICATION_MULTILABEL_PRIMARY_SET = {IOU}
 
     IMAGE_OBJECT_DETECTION_PRIMARY_SET = {MEAN_AVERAGE_PRECISION}
 
-    IMAGE_OBJECT_DETECTION_SET = {
-        MEAN_AVERAGE_PRECISION, RECALL, PRECISION, PER_LABEL_METRICS,
-        IMAGE_LEVEL_BINARY_CLASSIFIER_METRICS, CONFUSION_MATRICES_PER_SCORE_THRESHOLD
+    SCALAR_IMAGE_OBJECT_DETECTION_SET = {MEAN_AVERAGE_PRECISION, RECALL, PRECISION}
+    NONSCALAR_IMAGE_OBJECT_DETECTION_SET = {
+        IMAGE_LEVEL_BINARY_CLASSIFIER_METRICS,
+        CONFUSION_MATRICES_PER_SCORE_THRESHOLD,
+        PER_LABEL_METRICS,
     }
 
-    IMAGE_INSTANCE_SEGMENTATION_SET = {
-        MEAN_AVERAGE_PRECISION, RECALL, PRECISION, PER_LABEL_METRICS
+    IMAGE_OBJECT_DETECTION_SET = (
+        SCALAR_IMAGE_OBJECT_DETECTION_SET | NONSCALAR_IMAGE_OBJECT_DETECTION_SET
+    )
+    IMAGE_OBJECT_DETECTION_CLASSWISE_SET = {PER_LABEL_METRICS}
+
+    SCALAR_IMAGE_INSTANCE_SEGMENTATION_SET = {MEAN_AVERAGE_PRECISION, RECALL, PRECISION}
+    IMAGE_INSTANCE_SEGMENTATION_CLASSWISE_SET = {PER_LABEL_METRICS}
+
+    IMAGE_INSTANCE_SEGMENTATION_SET = (
+        SCALAR_IMAGE_INSTANCE_SEGMENTATION_SET
+        | IMAGE_INSTANCE_SEGMENTATION_CLASSWISE_SET
+    )
+
+    SCALAR_VIDEO_MULTI_OBJECT_TRACKING_SET = {
+        MOTA,
+        MOTP,
+        IDF1,
+        PRECISION,
+        RECALL,
+        TRACKING_PRECISION,
+        TRACKING_RECALL,
+        IDSW,
+        FP,
+        FN,
+        FM,
+        ML,
+        MT,
+        PT,
     }
 
+    NONSCALAR_VIDEO_MULTI_OBJECT_TRACKING_SET = set()
+
+    VIDEO_MULTI_OBJECT_TRACKING_SET = (
+        SCALAR_VIDEO_MULTI_OBJECT_TRACKING_SET
+        | NONSCALAR_VIDEO_MULTI_OBJECT_TRACKING_SET
+    )
+
     SAMPLE_WEIGHTS_UNSUPPORTED_SET = {
         WeightedAccuracy,
         Spearman,
         MedianAbsError,
         NormMedianAbsError,
     }
 
     TEXT_CLASSIFICATION_PRIMARY_SET = {Accuracy, AUCWeighted, PrecisionWeighted}
 
     TEXT_CLASSIFICATION_MULTILABEL_PRIMARY_SET = {Accuracy}
 
     TEXT_NER_PRIMARY_SET = {Accuracy}
 
+    NER_SET = {
+        Accuracy,
+        F1Macro,
+        F1Micro,
+        F1Weighted,
+        PrecisionMicro,
+        PrecisionMacro,
+        PrecisionWeighted,
+        RecallMicro,
+        RecallMacro,
+        RecallWeighted,
+    }
+
     NONSCALAR_FORECAST_SET = {
-        ForecastMAPE, ForecastResiduals,
-        ForecastTable, ForecastTsIDDistributionTable
+        ForecastMAPE,
+        ForecastResiduals,
+        ForecastTable,
+        ForecastTsIDDistributionTable,
     }
 
-    FORECAST_SET = (NONSCALAR_FORECAST_SET)
+    FORECAST_SET = NONSCALAR_FORECAST_SET
 
     # The set of non scalar metrics allowed even if the
     # training set was not provided.
-    FORECASTING_NONSCALAR_SET_NO_TRAINING = {
-        ForecastTsIDDistributionTable
-    }
+    FORECASTING_NONSCALAR_SET_NO_TRAINING = {ForecastTsIDDistributionTable}
 
     # Metrics set for Sequence to Sequence Tasks
     SCALAR_TRANSLATION_SET = {
         TranslationBleu_1,
         TranslationBleu_2,
         TranslationBleu_3,
         TranslationBleu_4,
@@ -336,519 +515,352 @@
         SummarizationRouge2,
         SummarizationRougeL,
         SummarizationRougeLsum,
     }
 
     SUMMARIZATION_SET = SCALAR_SUMMARIZATION_SET
 
-    SCALAR_QA_SET = {QAExactMatch, QAF1Score}
+    SCALAR_QA_SET = set()
+
+    NONSCALAR_QA_SET = {
+        QAExactMatch,
+        QAF1Score,
+        BERTScore,
+        AdaSimilarity,
+        GPTSimilarity,
+        GPTCoherence,
+        GPTGroundedness,
+        GPTFluency,
+        GPTRelevance,
+        LLMSimilarity,
+        LLMCoherence,
+        LLMGroundedness,
+        LLMFluency,
+        LLMRelevance,
+    }
+
+    SCALAR_CODE_GENERATION_SET = {CodeGenerationPassRateScore}
 
-    QA_SET = SCALAR_QA_SET
+    QA_SET = SCALAR_QA_SET | NONSCALAR_QA_SET
+
+    # QA metrics that don't need groundtruths.
+    QA_SPECIAL_SET = {
+        GPTCoherence,
+        GPTGroundedness,
+        GPTFluency,
+        GPTRelevance,
+        LLMCoherence,
+        LLMGroundedness,
+        LLMFluency,
+        LLMRelevance,
+    }
+
+    QA_GPT_METRICS_SET = {
+        GPTCoherence,
+        GPTGroundedness,
+        GPTFluency,
+        GPTRelevance,
+        GPTSimilarity,
+        AdaSimilarity,
+    }
+
+    QA_GPT_STAR_METRICS_SET = {
+        GPTCoherence,
+        GPTGroundedness,
+        GPTFluency,
+        GPTRelevance,
+        GPTSimilarity,
+    }
+    QA_LLM_METRICS_SET = {
+        LLMCoherence,
+        LLMGroundedness,
+        LLMFluency,
+        LLMRelevance,
+        LLMSimilarity,
+    }
+
+    # QA metrics with multiple ground truths
+    SCALAR_QA_MULTIPLE_GROUND_TRUTH_SET = {QAMacroAveragedF1, QAMacroAveragedExactMatch}
+    NON_SCALAR_QA_MULTIPLE_GROUND_TRUTH_SET = set()
+    QA_MULTIPLE_GROUND_TRUTH_SET = (
+        SCALAR_QA_MULTIPLE_GROUND_TRUTH_SET | NON_SCALAR_QA_MULTIPLE_GROUND_TRUTH_SET
+        | QA_GPT_STAR_METRICS_SET | QA_LLM_METRICS_SET
+    )
 
     # Fill Masking Metrics
     SCALAR_FILL_MASK_SET = set()
     NONSCALAR_FILL_MASK_SET = {FMPerplexity}
 
     # Fill Masking metrics that do not need groundtruths
     FILL_MASK_SPECIAL_SET = {FMPerplexity}
 
     FILL_MASK_SET = SCALAR_FILL_MASK_SET | NONSCALAR_FILL_MASK_SET
 
     # Text generation metrics
     SCALAR_TEXT_GENERATION_SET = SCALAR_SUMMARIZATION_SET | SCALAR_TRANSLATION_SET
-    TEXT_GENERATION_SET = SCALAR_TEXT_GENERATION_SET
+    NONSCALAR_TEXT_GENERATION_SET = NONSCALAR_FILL_MASK_SET
+    TEXT_GENERATION_SET = SCALAR_TEXT_GENERATION_SET | NONSCALAR_TEXT_GENERATION_SET
+
+    # Code Generation Metrics
+    CODE_GENERATION_SET = SCALAR_CODE_GENERATION_SET | SCALAR_TEXT_GENERATION_SET
+    CODE_GENERATION_SPECIAL_SET = {CodeGenerationPassRateScore}
+
+    # RAG evaluation metrics
+    NONSCALAR_RAG_EVALUATION_SET = {
+        RAG_GPTGroundedness,
+        RAG_GPTRelevance,
+        RAG_GPTRetrieval,
+    }
+    RAG_EVALUATION_SET = NONSCALAR_RAG_EVALUATION_SET
+
+    # Chat completion metrics
+    CONVERSATION_RAI_SET = {ConversationGroundingScore}
+    # TODO: Enable F1 Score and Exact Match metrics for chat completion
+    SCALAR_CHAT_COMPLETION_SET = SCALAR_TEXT_GENERATION_SET
+    NONSCALAR_CHAT_COMPLETION_SET = (
+        NONSCALAR_FILL_MASK_SET | CONVERSATION_RAI_SET | NONSCALAR_RAG_EVALUATION_SET
+    )
+    CHAT_COMPLETION_SET = NONSCALAR_CHAT_COMPLETION_SET | SCALAR_CHAT_COMPLETION_SET
+    CHAT_COMPLETION_NONGPT_SET = SCALAR_CHAT_COMPLETION_SET | NONSCALAR_FILL_MASK_SET
+    # Chat Completion metrics that doesn't need ground-truths
+    CHAT_COMPLETION_SPECIAL_SET = {FMPerplexity, ConversationGroundingScore}
 
     SCALAR_SEQ2SEQ_SET = (
-        SCALAR_TRANSLATION_SET | SCALAR_SUMMARIZATION_SET | SCALAR_QA_SET | SCALAR_FILL_MASK_SET
+        SCALAR_TRANSLATION_SET
+        | SCALAR_SUMMARIZATION_SET
+        | SCALAR_QA_SET
+        | SCALAR_FILL_MASK_SET
         | SCALAR_TEXT_GENERATION_SET
+        | SCALAR_CHAT_COMPLETION_SET
     )
 
     FULL_SET = CLASSIFICATION_SET | REGRESSION_SET | IMAGE_OBJECT_DETECTION_SET
-    NONSCALAR_FULL_SET = NONSCALAR_CLASSIFICATION_SET | NONSCALAR_REGRESSION_SET
-    SCALAR_FULL_SET = SCALAR_CLASSIFICATION_SET | SCALAR_REGRESSION_SET
+    NONSCALAR_FULL_SET = (
+        NONSCALAR_CLASSIFICATION_SET
+        | NONSCALAR_REGRESSION_SET
+        | NONSCALAR_QA_SET
+        | NONSCALAR_RAG_EVALUATION_SET
+        | NONSCALAR_TEXT_GENERATION_SET
+        | NONSCALAR_CHAT_COMPLETION_SET
+    )
+    SCALAR_FULL_SET = (
+        SCALAR_CLASSIFICATION_SET
+        | SCALAR_REGRESSION_SET
+        | SCALAR_QA_MULTIPLE_GROUND_TRUTH_SET
+        | SCALAR_SEQ2SEQ_SET
+    )
 
     SCALAR_FULL_SET_TIME = SCALAR_FULL_SET | TrainingResultsType.ALL_TIME
 
-    # TODO: These types will be removed when the artifact-backed
-    # metrics are defined with protobuf
-    # Do not use these constants except in artifact-backed metrics
-    SCHEMA_TYPE_ACCURACY_TABLE = "accuracy_table"
-    SCHEMA_TYPE_CONFUSION_MATRIX = "confusion_matrix"
-    SCHEMA_TYPE_RESIDUALS = "residuals"
-    SCHEMA_TYPE_PREDICTIONS = "predictions"
-    SCHEMA_TYPE_MAPE = "mape_table"
-    SCHEMA_TYPE_SMAPE = "smape_table"
+    # Metrics that need to be aggregated
+    NON_AGGREGATED_METRICS = (
+        {FMPerplexity, BERTScore, QAExactMatch, QAF1Score}
+        | QA_GPT_METRICS_SET
+        | QA_LLM_METRICS_SET
+    )
 
 
 class Tasks:
     """Defines types of machine learning tasks supported by automated ML."""
 
     CLASSIFICATION = "classification"
     REGRESSION = "regression"
     FORECASTING = "forecasting"
 
     # Sequence to Sequence Tasks
     TRANSLATION = "translation"
     SUMMARIZATION = "summarization"
     QUESTION_ANSWERING = "qa"
+    QUESTION_ANSWERING_MULTIPLE_GROUND_TRUTH = "qa_multiple_ground_truth"
     FILL_MASK = "fill-mask"
     TEXT_GENERATION = "text-generation"
 
+    # Chat Completion task type
+    CHAT_COMPLETION = "chat-completion"
+
+    # RAG Evaluation task type
+    RAG_EVALUATION = "rag-evaluation"
+
+    # Code Generation
+    CODE_GENERATION = "code-generation"
+
     IMAGE_CLASSIFICATION = "image-classification"
     IMAGE_CLASSIFICATION_MULTILABEL = "image-classification-multilabel"
     IMAGE_MULTI_LABEL_CLASSIFICATION = (
         "image-multi-labeling"  # for temporary backward-compatibility
     )
     IMAGE_OBJECT_DETECTION = "image-object-detection"
     IMAGE_INSTANCE_SEGMENTATION = "image-instance-segmentation"
-    ALL_IMAGE_CLASSIFICATION = [
+    _ALL_IMAGE_CLASSIFICATION = [
         IMAGE_CLASSIFICATION,
         IMAGE_CLASSIFICATION_MULTILABEL,
         IMAGE_MULTI_LABEL_CLASSIFICATION,
     ]
-    ALL_IMAGE_OBJECT_DETECTION = [IMAGE_OBJECT_DETECTION, IMAGE_INSTANCE_SEGMENTATION]
-    ALL_IMAGE = [
+    # Custom prompt metric
+    CUSTOM_PROMPT_METRIC = "custom-prompt-metric"
+
+    IMAGE_CLASSIFICATION = 'image-classification'
+    IMAGE_CLASSIFICATION_MULTILABEL = 'image-classification-multilabel'
+    IMAGE_MULTI_LABEL_CLASSIFICATION = 'image-multi-labeling'  # for temporary backward-compatibility
+    IMAGE_OBJECT_DETECTION = 'image-object-detection'
+    IMAGE_INSTANCE_SEGMENTATION = 'image-instance-segmentation'
+    _ALL_IMAGE_CLASSIFICATION = [IMAGE_CLASSIFICATION, IMAGE_CLASSIFICATION_MULTILABEL,
+                                 IMAGE_MULTI_LABEL_CLASSIFICATION]
+
+    _ALL_IMAGE_OBJECT_DETECTION = [IMAGE_OBJECT_DETECTION, IMAGE_INSTANCE_SEGMENTATION]
+    _ALL_IMAGE = [
         IMAGE_CLASSIFICATION,
         IMAGE_CLASSIFICATION_MULTILABEL,
         IMAGE_MULTI_LABEL_CLASSIFICATION,
         IMAGE_OBJECT_DETECTION,
         IMAGE_INSTANCE_SEGMENTATION,
     ]
+    VIDEO_MULTI_OBJECT_TRACKING = "video-multi-object-tracking"
+
     TEXT_CLASSIFICATION = "text-classification"
     TEXT_CLASSIFICATION_MULTILABEL = "text-classification-multilabel"
     TEXT_NER = "text-ner"
-    ALL_TEXT = [TEXT_CLASSIFICATION, TEXT_CLASSIFICATION_MULTILABEL, TEXT_NER]
-    ALL_DNN = ALL_IMAGE + ALL_TEXT
-    ALL_MIRO = [CLASSIFICATION, REGRESSION]
-    ALL = ALL_MIRO + ALL_IMAGE + ALL_TEXT
+
+    _ALL_CLASSIFICATION_TASKS = [
+        CLASSIFICATION,
+        TEXT_CLASSIFICATION,
+        TEXT_CLASSIFICATION_MULTILABEL,
+        IMAGE_CLASSIFICATION,
+        IMAGE_CLASSIFICATION_MULTILABEL,
+        IMAGE_MULTI_LABEL_CLASSIFICATION,
+    ]
+
+    _ALL_TEXT = [TEXT_CLASSIFICATION, TEXT_CLASSIFICATION_MULTILABEL, TEXT_NER]
+    _ALL_DNN = _ALL_IMAGE + _ALL_TEXT
+    _ALL = _ALL_IMAGE + _ALL_TEXT
 
 
 class ImageTask(Enum):
     """Available Image task types."""
 
     IMAGE_CLASSIFICATION = Tasks.IMAGE_CLASSIFICATION
     IMAGE_CLASSIFICATION_MULTILABEL = Tasks.IMAGE_CLASSIFICATION_MULTILABEL
     IMAGE_OBJECT_DETECTION = Tasks.IMAGE_OBJECT_DETECTION
     IMAGE_INSTANCE_SEGMENTATION = Tasks.IMAGE_INSTANCE_SEGMENTATION
+    VIDEO_MULTI_OBJECT_TRACKING = Tasks.VIDEO_MULTI_OBJECT_TRACKING
 
 
-# Task Types
-CLASSIFICATION = "classification"
-REGRESSION = "regression"
-FORECASTING = "forecasting"
-TRANSLATION = "translation"
-SUMMARIZATION = "summarization"
-QUESTION_ANSWERING = "qa"
-FILL_MASK = "fill-mask"
-TEXT_GENERATION = "text-generation"
-IMAGE_CLASSIFICATION = "image-classification"
-IMAGE_CLASSIFICATION_MULTILABEL = "image-classification-multilabel"
-IMAGE_MULTI_LABEL_CLASSIFICATION = "image-multi-labeling"
-IMAGE_OBJECT_DETECTION = "image-object-detection"
-IMAGE_INSTANCE_SEGMENTATION = "image-instance-segmentation"
-TEXT_CLASSIFICATION = "text-classification"
-TEXT_CLASSIFICATION_MULTILABEL = "text-classification-multilabel"
-TEXT_NER = "text-ner"
-
-TASKS = {
-    CLASSIFICATION,
-    REGRESSION,
-    IMAGE_CLASSIFICATION,
-    IMAGE_CLASSIFICATION_MULTILABEL,
-    IMAGE_MULTI_LABEL_CLASSIFICATION,
-    IMAGE_OBJECT_DETECTION,
-    IMAGE_INSTANCE_SEGMENTATION,
-    TEXT_CLASSIFICATION,
-    TEXT_CLASSIFICATION_MULTILABEL,
-    TEXT_NER,
-    TRANSLATION,
-    SUMMARIZATION,
-    QUESTION_ANSWERING,
-    FILL_MASK,
-    TEXT_GENERATION,
-}
-
-# Classification Metrics
-
-ACCURACY = "accuracy"
-WEIGHTED_ACCURACY = "weighted_accuracy"
-BALANCED_ACCURACY = "balanced_accuracy"
-NORM_MACRO_RECALL = "norm_macro_recall"
-LOG_LOSS = "log_loss"
-AUC_BINARY = "AUC_binary"
-AUC_MACRO = "AUC_macro"
-AUC_MICRO = "AUC_micro"
-AUC_WEIGHTED = "AUC_weighted"
-F1_BINARY = "f1_score_binary"
-F1_MACRO = "f1_score_macro"
-F1_MICRO = "f1_score_micro"
-F1_WEIGHTED = "f1_score_weighted"
-PRECISION_BINARY = "precision_score_binary"
-PRECISION_MACRO = "precision_score_macro"
-PRECISION_MICRO = "precision_score_micro"
-PRECISION_WEIGHTED = "precision_score_weighted"
-RECALL_BINARY = "recall_score_binary"
-RECALL_MACRO = "recall_score_macro"
-RECALL_MICRO = "recall_score_micro"
-RECALL_WEIGHTED = "recall_score_weighted"
-AVERAGE_PRECISION_BINARY = "average_precision_score_binary"
-AVERAGE_PRECISION_MACRO = "average_precision_score_macro"
-AVERAGE_PRECISION_MICRO = "average_precision_score_micro"
-AVERAGE_PRECISION_WEIGHTED = "average_precision_score_weighted"
-MATTHEWS_CORRELATION = "matthews_correlation"
-ACCURACY_TABLE = "accuracy_table"
-CONFUSION_MATRIX = "confusion_matrix"
-CLASSIFICATION_REPORT = "classification_report"
-# multilabel metrics
-IOU = "iou"
-IOU_MICRO = "iou_micro"
-IOU_MACRO = "iou_macro"
-IOU_WEIGHTED = "iou_weighted"
-IOU_CLASSWISE = "iou_classwise"
-# classwise metrics
-PRECISION_CLASSWISE = "precision_score_classwise"
-RECALL_CLASSWISE = "recall_score_classwise"
-F1_CLASSWISE = "f1_score_classwise"
-AUC_CLASSWISE = "AUC_classwise"
-AVERAGE_PRECISION_CLASSWISE = "average_precision_score_classwise"
-
-CLASSIFICATION_SCALAR_SET = {
-    ACCURACY,
-    WEIGHTED_ACCURACY,
-    BALANCED_ACCURACY,
-    NORM_MACRO_RECALL,
-    LOG_LOSS,
-    AUC_BINARY,
-    AUC_MACRO,
-    AUC_MICRO,
-    AUC_WEIGHTED,
-    F1_BINARY,
-    F1_MACRO,
-    F1_MICRO,
-    F1_WEIGHTED,
-    PRECISION_BINARY,
-    PRECISION_MACRO,
-    PRECISION_MICRO,
-    PRECISION_WEIGHTED,
-    RECALL_BINARY,
-    RECALL_MACRO,
-    RECALL_MICRO,
-    RECALL_WEIGHTED,
-    AVERAGE_PRECISION_BINARY,
-    AVERAGE_PRECISION_MACRO,
-    AVERAGE_PRECISION_MICRO,
-    AVERAGE_PRECISION_WEIGHTED,
-    MATTHEWS_CORRELATION,
-}
-
-CLASSIFICATION_PROB_REQUIRED_SET = {
-    AUC_BINARY,
-    AUC_MACRO,
-    AUC_MICRO,
-    AUC_WEIGHTED,
-    AVERAGE_PRECISION_BINARY,
-    AVERAGE_PRECISION_MACRO,
-    AVERAGE_PRECISION_MICRO,
-    AVERAGE_PRECISION_WEIGHTED,
-}
-
-CLASSIFICATION_BINARY_SET = {
-    AUC_BINARY,
-    F1_BINARY,
-    PRECISION_BINARY,
-    RECALL_BINARY,
-    AVERAGE_PRECISION_BINARY,
-}
-
-CLASSIFICATION_MULTILABEL_SET = {IOU, IOU_MICRO, IOU_MACRO, IOU_WEIGHTED}
-
-CLASSIFICATION_NLP_MULTILABEL_SET = {
-    ACCURACY,
-    BALANCED_ACCURACY,
-    NORM_MACRO_RECALL,
-    LOG_LOSS,
-    AUC_MACRO,
-    AUC_MICRO,
-    AUC_WEIGHTED,
-    F1_MACRO,
-    F1_MICRO,
-    F1_WEIGHTED,
-    PRECISION_MACRO,
-    PRECISION_MICRO,
-    PRECISION_WEIGHTED,
-    RECALL_MACRO,
-    RECALL_MICRO,
-    RECALL_WEIGHTED,
-    AVERAGE_PRECISION_MACRO,
-    AVERAGE_PRECISION_MICRO,
-    AVERAGE_PRECISION_WEIGHTED,
-}
-
-CLASSIFICATION_NLP_NER_SET = {
-    ACCURACY,
-    F1_MACRO,
-    F1_MICRO,
-    F1_WEIGHTED,
-    PRECISION_MACRO,
-    PRECISION_MICRO,
-    PRECISION_WEIGHTED,
-    RECALL_MACRO,
-    RECALL_MICRO,
-    RECALL_WEIGHTED,
-}
-
-CLASSIFICATION_CLASSWISE_SET = {
-    PRECISION_CLASSWISE,
-    RECALL_CLASSWISE,
-    F1_CLASSWISE,
-    IOU_CLASSWISE,
-    AVERAGE_PRECISION_CLASSWISE,
-    AUC_CLASSWISE,
-}
-
-CLASSIFICATION_NONSCALAR_SET = {ACCURACY_TABLE, CONFUSION_MATRIX, CLASSIFICATION_REPORT}
-
-CLASSIFICATION_SET = (
-    CLASSIFICATION_SCALAR_SET
-    | CLASSIFICATION_NONSCALAR_SET
-    | CLASSIFICATION_CLASSWISE_SET
-    | CLASSIFICATION_MULTILABEL_SET
-)
-
-UNSUPPORTED_CLASSIFICATION_TABULAR_SET = (
-    CLASSIFICATION_CLASSWISE_SET
-    | CLASSIFICATION_MULTILABEL_SET
-    | {CLASSIFICATION_REPORT}
-)
-
-CLASSIFICATION_PRIMARY_SET = {
-    ACCURACY,
-    AUC_WEIGHTED,
-    NORM_MACRO_RECALL,
-    AVERAGE_PRECISION_WEIGHTED,
-    PRECISION_WEIGHTED,
-}
-
-CLASSIFICATION_BALANCED_SET = {
-    # Metrics for which class_weights are recommended
-    BALANCED_ACCURACY,
-    AUC_MACRO,
-    NORM_MACRO_RECALL,
-    AVERAGE_PRECISION_WEIGHTED,
-    PRECISION_MACRO,
-    F1_MACRO,
-    RECALL_MACRO,
-}
-
-# Regression Metrics
-
-EXPLAINED_VARIANCE = "explained_variance"
-R2_SCORE = "r2_score"
-SPEARMAN = "spearman_correlation"
-MAPE = "mean_absolute_percentage_error"
-MEAN_ABS_ERROR = "mean_absolute_error"
-NORM_MEAN_ABS_ERROR = "normalized_mean_absolute_error"
-MEDIAN_ABS_ERROR = "median_absolute_error"
-NORM_MEDIAN_ABS_ERROR = "normalized_median_absolute_error"
-RMSE = "root_mean_squared_error"
-NORM_RMSE = "normalized_root_mean_squared_error"
-RMSLE = "root_mean_squared_log_error"
-NORM_RMSLE = "normalized_root_mean_squared_log_error"
-RESIDUALS = "residuals"
-PREDICTED_TRUE = "predicted_true"
-
-# Fill Mask Metric
-FMPerplexity = "perplexities"
-
-REGRESSION_SCALAR_SET = {
-    EXPLAINED_VARIANCE,
-    R2_SCORE,
-    SPEARMAN,
-    MAPE,
-    MEAN_ABS_ERROR,
-    NORM_MEAN_ABS_ERROR,
-    MEDIAN_ABS_ERROR,
-    NORM_MEDIAN_ABS_ERROR,
-    RMSE,
-    NORM_RMSE,
-    RMSLE,
-    NORM_RMSLE,
-}
-
-REGRESSION_NORMALIZED_SET = {
-    NORM_MEAN_ABS_ERROR,
-    NORM_MEDIAN_ABS_ERROR,
-    NORM_RMSE,
-    NORM_RMSLE,
-}
-
-REGRESSION_NONSCALAR_SET = {RESIDUALS, PREDICTED_TRUE}
-
-REGRESSION_SET = REGRESSION_SCALAR_SET | REGRESSION_NONSCALAR_SET
-
-REGRESSION_PRIMARY_SET = {R2_SCORE, SPEARMAN, NORM_RMSE, NORM_MEAN_ABS_ERROR}
+class SubTaskType:
+    """Available Sub-task types of Main tasks."""
 
-# Forecasting metrics
+    TEXT_GENERATION_SUBTASK_CODE = "code"
 
-FORECASTING_MAPE = 'forecast_mean_absolute_percentage_error'
-FORECASTING_RESIDUALS = 'forecast_residuals'
-FORECASTING_TABLE = 'forecast_table'
-FORECASTING_TS_ID_DISTRIBUTION_TABLE = "forecast_time_series_id_distribution_table"
 
-FORECASTING_NONSCALAR_SET = {
-    FORECASTING_MAPE,
-    FORECASTING_RESIDUALS,
-    FORECASTING_TABLE,
-    FORECASTING_TS_ID_DISTRIBUTION_TABLE
+# All tasks
+TASK_TYPES = {
+    # Tabular task types
+    Tasks.CLASSIFICATION,
+    Tasks.REGRESSION,
+    Tasks.FORECASTING,
+    # Image/vision task types
+    Tasks.IMAGE_CLASSIFICATION,
+    Tasks.IMAGE_CLASSIFICATION_MULTILABEL,
+    Tasks.IMAGE_MULTI_LABEL_CLASSIFICATION,
+    Tasks.IMAGE_OBJECT_DETECTION,
+    Tasks.IMAGE_INSTANCE_SEGMENTATION,
+    # Text task types
+    Tasks.TEXT_CLASSIFICATION,
+    Tasks.TEXT_CLASSIFICATION_MULTILABEL,
+    Tasks.TEXT_NER,
+    Tasks.TRANSLATION,
+    Tasks.SUMMARIZATION,
+    Tasks.QUESTION_ANSWERING,
+    Tasks.QUESTION_ANSWERING_MULTIPLE_GROUND_TRUTH,
+    Tasks.FILL_MASK,
+    Tasks.TEXT_GENERATION,
+    Tasks.CHAT_COMPLETION,
+    Tasks.RAG_EVALUATION,
+    Tasks.CODE_GENERATION,
+    Tasks.CUSTOM_PROMPT_METRIC,
 }
 
-
-FORECASTING_SET = FORECASTING_NONSCALAR_SET
-
-# Image Classification Metrics
-
-IMAGE_CLASSIFICATION_SET = {ACCURACY}
-
-IMAGE_CLASSIFICATION_MULTILABEL_CLASSIFICATION_SET = {IOU}
-
-# Image Object Detection Metrics
-MEAN_AVERAGE_PRECISION = "mean_average_precision"
-AVERAGE_PRECISION = "average_precision"
-PRECISION = "precision"
-RECALL = "recall"
-PER_LABEL_METRICS = "per_label_metrics"
-IMAGE_LEVEL_BINARY_CLASSIFIER_METRICS = "image_level_binary_classsifier_metrics"
-CONFUSION_MATRICES_PER_SCORE_THRESHOLD = "confusion_matrices_per_score_threshold"
-
-IMAGE_OBJECT_DETECTION_SCALAR_SET = {
-    MEAN_AVERAGE_PRECISION, RECALL, PRECISION
-}
-
-IMAGE_OBJECT_DETECTION_CLASSWISE_SET = {PER_LABEL_METRICS}
-
-IMAGE_OBJECT_DETECTION_NONSCALAR_SET = {
-    IMAGE_LEVEL_BINARY_CLASSIFIER_METRICS, CONFUSION_MATRICES_PER_SCORE_THRESHOLD
-}
-
-IMAGE_OBJECT_DETECTION_SET = (
-    IMAGE_OBJECT_DETECTION_SCALAR_SET | IMAGE_OBJECT_DETECTION_CLASSWISE_SET | IMAGE_OBJECT_DETECTION_NONSCALAR_SET
-)
-
-IMAGE_INSTANCE_SEGMENTATION_SCALAR_SET = {
-    MEAN_AVERAGE_PRECISION, RECALL, PRECISION
-}
-
-IMAGE_INSTANCE_SEGMENTATION_CLASSWISE_SET = {PER_LABEL_METRICS}
-
-IMAGE_INSTANCE_SEGMENTATION_SET = (IMAGE_INSTANCE_SEGMENTATION_SCALAR_SET | IMAGE_INSTANCE_SEGMENTATION_CLASSWISE_SET)
-
-# Text Classification Metrics
-
-TEXT_CLASSIFICATION_SET = {
-    ACCURACY,
-    AUC_WEIGHTED,
-    PRECISION_MICRO,
-    PRECISION_WEIGHTED,
-}
-
-# Text Classification Multilabel Metrics
-
-TEXT_CLASSIFICATION_MULTILABEL_SET = {
-    ACCURACY,
-    F1_MACRO,
-    F1_MICRO,
-}
-
-# Text NER Metrics
-
-TEXT_NER_SET = {
-    ACCURACY,
-    F1_MACRO,
-    F1_MICRO,
-    F1_WEIGHTED,
-    PRECISION_MACRO,
-    PRECISION_MICRO,
-    PRECISION_WEIGHTED,
-    RECALL_MACRO,
-    RECALL_MICRO,
-    RECALL_WEIGHTED,
-}
-
-FILL_MASK_NONSCALAR_SET = {FMPerplexity}
-
 # All Metrics
-
 FULL_SET = (
-    CLASSIFICATION_SET
-    | REGRESSION_SET
-    | IMAGE_OBJECT_DETECTION_SET
-    | IMAGE_INSTANCE_SEGMENTATION_SET
-    | FORECASTING_NONSCALAR_SET
+    Metric.CLASSIFICATION_SET
+    | Metric.REGRESSION_SET
+    | Metric.IMAGE_OBJECT_DETECTION_SET
+    | Metric.IMAGE_INSTANCE_SEGMENTATION_SET
+    | Metric.FORECAST_SET
     | Metric.TRANSLATION_SET
     | Metric.SUMMARIZATION_SET
     | Metric.QA_SET
     | Metric.FILL_MASK_SET
     | Metric.TEXT_GENERATION_SET
+    | Metric.CHAT_COMPLETION_SET
+    | Metric.RAG_EVALUATION_SET
+    | Metric.CODE_GENERATION_SET
 )
 
 FULL_CLASSWISE_SET = (
-    CLASSIFICATION_CLASSWISE_SET | IMAGE_OBJECT_DETECTION_CLASSWISE_SET | IMAGE_INSTANCE_SEGMENTATION_CLASSWISE_SET
+    Metric.CLASSIFICATION_CLASSWISE_SET
+    | Metric.IMAGE_OBJECT_DETECTION_CLASSWISE_SET
+    | Metric.IMAGE_INSTANCE_SEGMENTATION_CLASSWISE_SET
 )
 
 FULL_NONSCALAR_SET = (
-    CLASSIFICATION_NONSCALAR_SET
-    | REGRESSION_NONSCALAR_SET
-    | FILL_MASK_NONSCALAR_SET
-    | FORECASTING_NONSCALAR_SET
-    | IMAGE_OBJECT_DETECTION_NONSCALAR_SET
+    Metric.NONSCALAR_CLASSIFICATION_SET
+    | Metric.NONSCALAR_REGRESSION_SET
+    | Metric.NONSCALAR_FILL_MASK_SET
+    | Metric.NONSCALAR_FORECAST_SET
+    | Metric.NONSCALAR_IMAGE_OBJECT_DETECTION_SET
+    | Metric.NONSCALAR_VIDEO_MULTI_OBJECT_TRACKING_SET
+    | Metric.NONSCALAR_QA_SET
+    | Metric.NONSCALAR_RAG_EVALUATION_SET
+    | Metric.CONVERSATION_RAI_SET
 )
 
 FULL_SCALAR_SET = (
-    CLASSIFICATION_SCALAR_SET
-    | REGRESSION_SCALAR_SET
-    | IMAGE_OBJECT_DETECTION_SCALAR_SET
-    | IMAGE_INSTANCE_SEGMENTATION_SCALAR_SET
+    Metric.SCALAR_CLASSIFICATION_SET
+    | Metric.SCALAR_REGRESSION_SET
+    | Metric.SCALAR_QA_SET
+    | Metric.SCALAR_QA_MULTIPLE_GROUND_TRUTH_SET
+    | Metric.SCALAR_CODE_GENERATION_SET
+    | Metric.SCALAR_IMAGE_OBJECT_DETECTION_SET
+    | Metric.SCALAR_IMAGE_INSTANCE_SEGMENTATION_SET
+    | Metric.SCALAR_VIDEO_MULTI_OBJECT_TRACKING_SET
+    | Metric.SCALAR_SEQ2SEQ_SET  # TODO: has repeat values
+    | Metric.IOU_CLASSIFICATION_SET_MULTILABEL
 )
 
 METRICS_TASK_MAP = {
-    CLASSIFICATION: CLASSIFICATION_SET,
-    REGRESSION: REGRESSION_SET,
-    FORECASTING: FORECASTING_SET,
-    IMAGE_CLASSIFICATION: IMAGE_CLASSIFICATION_SET,
-    IMAGE_CLASSIFICATION_MULTILABEL: IMAGE_CLASSIFICATION_MULTILABEL_CLASSIFICATION_SET,
-    IMAGE_MULTI_LABEL_CLASSIFICATION: IMAGE_CLASSIFICATION_MULTILABEL_CLASSIFICATION_SET,
-    IMAGE_OBJECT_DETECTION: IMAGE_OBJECT_DETECTION_SET,
-    IMAGE_INSTANCE_SEGMENTATION: IMAGE_INSTANCE_SEGMENTATION_SET,
-    TEXT_CLASSIFICATION: TEXT_CLASSIFICATION_SET,
-    TEXT_CLASSIFICATION_MULTILABEL: TEXT_CLASSIFICATION_MULTILABEL_SET,
-    TEXT_NER: TEXT_NER_SET,
-    TRANSLATION: Metric.TRANSLATION_SET,
-    SUMMARIZATION: Metric.SUMMARIZATION_SET,
-    QUESTION_ANSWERING: Metric.QA_SET,
-    FILL_MASK: Metric.FILL_MASK_SET,
-    TEXT_GENERATION: Metric.TEXT_GENERATION_SET,
+    Tasks.CLASSIFICATION: Metric.CLASSIFICATION_SET,
+    Tasks.REGRESSION: Metric.REGRESSION_SET,
+    Tasks.FORECASTING: Metric.FORECAST_SET,
+    Tasks.IMAGE_CLASSIFICATION: Metric.IMAGE_CLASSIFICATION_PRIMARY_SET,
+    # why are 2 tasks mapping to the same metric functions
+    Tasks.IMAGE_CLASSIFICATION_MULTILABEL: Metric.IMAGE_CLASSIFICATION_MULTILABEL_PRIMARY_SET,
+    Tasks.IMAGE_MULTI_LABEL_CLASSIFICATION: Metric.IMAGE_CLASSIFICATION_MULTILABEL_PRIMARY_SET,
+    Tasks.IMAGE_OBJECT_DETECTION: Metric.IMAGE_OBJECT_DETECTION_SET,
+    Tasks.IMAGE_INSTANCE_SEGMENTATION: Metric.IMAGE_INSTANCE_SEGMENTATION_SET,
+    Tasks.TEXT_CLASSIFICATION: Metric.TEXT_CLASSIFICATION_SET,
+    Tasks.TEXT_CLASSIFICATION_MULTILABEL: Metric.TEXT_CLASSIFICATION_MULTILABEL_SET,
+    Tasks.TEXT_NER: Metric.NER_SET,
+    Tasks.TRANSLATION: Metric.TRANSLATION_SET,
+    Tasks.SUMMARIZATION: Metric.SUMMARIZATION_SET,
+    Tasks.QUESTION_ANSWERING: Metric.QA_SET,
+    Tasks.QUESTION_ANSWERING_MULTIPLE_GROUND_TRUTH: Metric.QA_MULTIPLE_GROUND_TRUTH_SET,
+    Tasks.FILL_MASK: Metric.FILL_MASK_SET,
+    Tasks.TEXT_GENERATION: Metric.TEXT_GENERATION_SET,
+    Tasks.CHAT_COMPLETION: Metric.CHAT_COMPLETION_SET,
+    Tasks.RAG_EVALUATION: Metric.RAG_EVALUATION_SET,
+    Tasks.CODE_GENERATION: Metric.CODE_GENERATION_SET,
 }
 
 SAMPLE_WEIGHTS_UNSUPPORTED_SET = {
-    SPEARMAN,
-    WEIGHTED_ACCURACY,
-    MEDIAN_ABS_ERROR,
-    NORM_MEDIAN_ABS_ERROR,
+    Metric.Spearman,
+    Metric.WeightedAccuracy,
+    Metric.MedianAbsError,
+    Metric.NormMedianAbsError,
 }
 
-# Time Metrics
-
-TRAIN_TIME = "train time"
-FIT_TIME = "fit_time"
-PREDICT_TIME = "predict_time"
-
-ALL_TIME = {TRAIN_TIME, FIT_TIME, PREDICT_TIME}
-
-FULL_SCALAR_SET_TIME = FULL_SCALAR_SET | ALL_TIME
-
 # Schema Types
 
 # These types will be removed when the artifact-backed
 # metrics are defined with protobuf
 # Do not use these constants except in artifact-backed metrics
 SCHEMA_TYPE_ACCURACY_TABLE = "accuracy_table"
 SCHEMA_TYPE_FORECAST_HORIZON_TABLE = "forecast_horizon_table"
@@ -862,176 +874,179 @@
 # Ranges
 
 SCORE_UPPER_BOUND = sys.float_info.max
 
 MULTILABEL_PREDICTION_THRESHOLD = 0.5
 
 CLASSIFICATION_RANGES = {
-    ACCURACY: (0.0, 1.0),
-    WEIGHTED_ACCURACY: (0.0, 1.0),
-    NORM_MACRO_RECALL: (0.0, 1.0),
-    BALANCED_ACCURACY: (0.0, 1.0),
-    LOG_LOSS: (0.0, SCORE_UPPER_BOUND),
-    AUC_BINARY: (0.0, 1.0),
-    AUC_MACRO: (0.0, 1.0),
-    AUC_MICRO: (0.0, 1.0),
-    AUC_WEIGHTED: (0.0, 1.0),
-    F1_BINARY: (0.0, 1.0),
-    F1_MACRO: (0.0, 1.0),
-    F1_MICRO: (0.0, 1.0),
-    F1_WEIGHTED: (0.0, 1.0),
-    PRECISION_BINARY: (0.0, 1.0),
-    PRECISION_MACRO: (0.0, 1.0),
-    PRECISION_MICRO: (0.0, 1.0),
-    PRECISION_WEIGHTED: (0.0, 1.0),
-    RECALL_BINARY: (0.0, 1.0),
-    RECALL_MACRO: (0.0, 1.0),
-    RECALL_MICRO: (0.0, 1.0),
-    RECALL_WEIGHTED: (0.0, 1.0),
-    AVERAGE_PRECISION_BINARY: (0.0, 1.0),
-    AVERAGE_PRECISION_MACRO: (0.0, 1.0),
-    AVERAGE_PRECISION_MICRO: (0.0, 1.0),
-    AVERAGE_PRECISION_WEIGHTED: (0.0, 1.0),
-    ACCURACY_TABLE: (np.nan, np.nan),
-    CONFUSION_MATRIX: (np.nan, np.nan),
-    MATTHEWS_CORRELATION: (-1.0, 1.0),
-    IOU: (0.0, 1.0),
-    IOU_MICRO: (0.0, 1.0),
-    IOU_MACRO: (0.0, 1.0),
-    IOU_WEIGHTED: (0.0, 1.0),
-    CLASSIFICATION_REPORT: (np.nan, np.nan),
-    PRECISION_CLASSWISE: (np.nan, np.nan),
-    RECALL_CLASSWISE: (np.nan, np.nan),
-    F1_CLASSWISE: (np.nan, np.nan),
-    IOU_CLASSWISE: (np.nan, np.nan),
-    AVERAGE_PRECISION_CLASSWISE: (np.nan, np.nan),
-    AUC_CLASSWISE: (np.nan, np.nan),
+    Metric.Accuracy: (0.0, 1.0),
+    Metric.WeightedAccuracy: (0.0, 1.0),
+    Metric.NormMacroRecall: (0.0, 1.0),
+    Metric.BalancedAccuracy: (0.0, 1.0),
+    Metric.LogLoss: (0.0, SCORE_UPPER_BOUND),
+    Metric.AUCBinary: (0.0, 1.0),
+    Metric.AUCMacro: (0.0, 1.0),
+    Metric.AUCMicro: (0.0, 1.0),
+    Metric.AUCWeighted: (0.0, 1.0),
+    Metric.F1Binary: (0.0, 1.0),
+    Metric.F1Macro: (0.0, 1.0),
+    Metric.F1Micro: (0.0, 1.0),
+    Metric.F1Weighted: (0.0, 1.0),
+    Metric.PrecisionBinary: (0.0, 1.0),
+    Metric.PrecisionMacro: (0.0, 1.0),
+    Metric.PrecisionMicro: (0.0, 1.0),
+    Metric.PrecisionWeighted: (0.0, 1.0),
+    Metric.RecallBinary: (0.0, 1.0),
+    Metric.RecallMacro: (0.0, 1.0),
+    Metric.RecallMicro: (0.0, 1.0),
+    Metric.RecallWeighted: (0.0, 1.0),
+    Metric.AvgPrecisionBinary: (0.0, 1.0),
+    Metric.AvgPrecisionMacro: (0.0, 1.0),
+    Metric.AvgPrecisionMicro: (0.0, 1.0),
+    Metric.AvgPrecisionWeighted: (0.0, 1.0),
+    Metric.AccuracyTable: (np.nan, np.nan),
+    Metric.ConfusionMatrix: (np.nan, np.nan),
+    Metric.MatthewsCorrelation: (-1.0, 1.0),
+    Metric.IOU: (0.0, 1.0),
+    Metric.IOUMicro: (0.0, 1.0),
+    Metric.IOUMacro: (0.0, 1.0),
+    Metric.IOUWeighted: (0.0, 1.0),
+    Metric.ClassificationReport: (np.nan, np.nan),
+    Metric.PrecisionClasswise: (np.nan, np.nan),
+    Metric.RecallClasswise: (np.nan, np.nan),
+    Metric.F1Classwise: (np.nan, np.nan),
+    Metric.IOUClasswise: (np.nan, np.nan),
+    Metric.AvgPrecisionClasswise: (np.nan, np.nan),
+    Metric.AUCClasswise: (np.nan, np.nan),
 }
 
 REGRESSION_RANGES = {
-    EXPLAINED_VARIANCE: (-SCORE_UPPER_BOUND, 1.0),
-    R2_SCORE: (-1.0, 1.0),  # Clipped at -1 for Miro
-    SPEARMAN: (-1.0, 1.0),
-    MEAN_ABS_ERROR: (0.0, SCORE_UPPER_BOUND),
-    NORM_MEAN_ABS_ERROR: (0.0, 1),  # Intentionally clipped at 1 for Miro
-    MEDIAN_ABS_ERROR: (0.0, SCORE_UPPER_BOUND),
-    NORM_MEDIAN_ABS_ERROR: (0.0, 1),  # Intentionally clipped at 1 for Miro
-    RMSE: (0.0, SCORE_UPPER_BOUND),
-    NORM_RMSE: (0.0, 1),  # Intentionally clipped at 1 for Miro
-    RMSLE: (0.0, SCORE_UPPER_BOUND),
-    NORM_RMSLE: (0.0, 1),  # Intentionally clipped at 1 for Miro
-    MAPE: (0.0, SCORE_UPPER_BOUND),
-    RESIDUALS: (np.nan, np.nan),
-    PREDICTED_TRUE: (np.nan, np.nan),
+    Metric.ExplainedVariance: (-SCORE_UPPER_BOUND, 1.0),
+    Metric.R2Score: (-1.0, 1.0),  # Clipped at -1 for Miro
+    Metric.Spearman: (-1.0, 1.0),
+    Metric.MeanAbsError: (0.0, SCORE_UPPER_BOUND),
+    Metric.NormMeanAbsError: (0.0, 1),  # Intentionally clipped at 1 for Miro
+    Metric.MedianAbsError: (0.0, SCORE_UPPER_BOUND),
+    Metric.NormMedianAbsError: (0.0, 1),  # Intentionally clipped at 1 for Miro
+    Metric.RMSE: (0.0, SCORE_UPPER_BOUND),
+    Metric.NormRMSE: (0.0, 1),  # Intentionally clipped at 1 for Miro
+    Metric.RMSLE: (0.0, SCORE_UPPER_BOUND),
+    Metric.NormRMSLE: (0.0, 1),  # Intentionally clipped at 1 for Miro
+    Metric.MAPE: (0.0, SCORE_UPPER_BOUND),
+    Metric.Residuals: (np.nan, np.nan),
+    Metric.PredictedTrue: (np.nan, np.nan),
 }
 
 RANGES_TASK_MAP = {
-    CLASSIFICATION: CLASSIFICATION_RANGES,
-    REGRESSION: REGRESSION_RANGES,
+    Tasks.CLASSIFICATION: CLASSIFICATION_RANGES,
+    Tasks.REGRESSION: REGRESSION_RANGES,
 }
 
 # Objectives
 
 MAXIMIZE = "maximize"
 MINIMIZE = "minimize"
 NA = "NA"
 
 OBJECTIVES = {MAXIMIZE, MINIMIZE, NA}
 
 CLASSIFICATION_OBJECTIVES = {
-    ACCURACY: MAXIMIZE,
-    WEIGHTED_ACCURACY: MAXIMIZE,
-    NORM_MACRO_RECALL: MAXIMIZE,
-    BALANCED_ACCURACY: MAXIMIZE,
-    LOG_LOSS: MINIMIZE,
-    AUC_BINARY: MAXIMIZE,
-    AUC_MACRO: MAXIMIZE,
-    AUC_MICRO: MAXIMIZE,
-    AUC_WEIGHTED: MAXIMIZE,
-    F1_BINARY: MAXIMIZE,
-    F1_MACRO: MAXIMIZE,
-    F1_MICRO: MAXIMIZE,
-    F1_WEIGHTED: MAXIMIZE,
-    PRECISION_BINARY: MAXIMIZE,
-    PRECISION_MACRO: MAXIMIZE,
-    PRECISION_MICRO: MAXIMIZE,
-    PRECISION_WEIGHTED: MAXIMIZE,
-    RECALL_BINARY: MAXIMIZE,
-    RECALL_MACRO: MAXIMIZE,
-    RECALL_MICRO: MAXIMIZE,
-    RECALL_WEIGHTED: MAXIMIZE,
-    AVERAGE_PRECISION_BINARY: MAXIMIZE,
-    AVERAGE_PRECISION_MACRO: MAXIMIZE,
-    AVERAGE_PRECISION_MICRO: MAXIMIZE,
-    AVERAGE_PRECISION_WEIGHTED: MAXIMIZE,
-    ACCURACY_TABLE: NA,
-    CONFUSION_MATRIX: NA,
-    TRAIN_TIME: MINIMIZE,
-    MATTHEWS_CORRELATION: MAXIMIZE,
-    IOU: MAXIMIZE,
-    IOU_MICRO: MAXIMIZE,
-    IOU_MACRO: MAXIMIZE,
-    IOU_WEIGHTED: MAXIMIZE,
-    CLASSIFICATION_REPORT: NA,
-    PRECISION_CLASSWISE: NA,
-    RECALL_CLASSWISE: NA,
-    F1_CLASSWISE: NA,
-    IOU_CLASSWISE: NA,
-    AVERAGE_PRECISION_CLASSWISE: NA,
-    AUC_CLASSWISE: NA,
+    Metric.Accuracy: MAXIMIZE,
+    Metric.WeightedAccuracy: MAXIMIZE,
+    Metric.NormMacroRecall: MAXIMIZE,
+    Metric.BalancedAccuracy: MAXIMIZE,
+    Metric.LogLoss: MINIMIZE,
+    Metric.AUCBinary: MAXIMIZE,
+    Metric.AUCMacro: MAXIMIZE,
+    Metric.AUCMicro: MAXIMIZE,
+    Metric.AUCWeighted: MAXIMIZE,
+    Metric.F1Binary: MAXIMIZE,
+    Metric.F1Macro: MAXIMIZE,
+    Metric.F1Micro: MAXIMIZE,
+    Metric.F1Weighted: MAXIMIZE,
+    Metric.PrecisionBinary: MAXIMIZE,
+    Metric.PrecisionMacro: MAXIMIZE,
+    Metric.PrecisionMicro: MAXIMIZE,
+    Metric.PrecisionWeighted: MAXIMIZE,
+    Metric.RecallBinary: MAXIMIZE,
+    Metric.RecallMacro: MAXIMIZE,
+    Metric.RecallMicro: MAXIMIZE,
+    Metric.RecallWeighted: MAXIMIZE,
+    Metric.AvgPrecisionBinary: MAXIMIZE,
+    Metric.AvgPrecisionMacro: MAXIMIZE,
+    Metric.AvgPrecisionMicro: MAXIMIZE,
+    Metric.AvgPrecisionWeighted: MAXIMIZE,
+    Metric.AccuracyTable: NA,
+    Metric.ConfusionMatrix: NA,
+    TrainingResultsType.TRAIN_TIME: MINIMIZE,
+    Metric.MatthewsCorrelation: MAXIMIZE,
+    Metric.IOU: MAXIMIZE,
+    Metric.IOUMicro: MAXIMIZE,
+    Metric.IOUMacro: MAXIMIZE,
+    Metric.IOUWeighted: MAXIMIZE,
+    Metric.ClassificationReport: NA,
+    Metric.PrecisionClasswise: NA,
+    Metric.RecallClasswise: NA,
+    Metric.F1Classwise: NA,
+    Metric.IOUClasswise: NA,
+    Metric.AvgPrecisionClasswise: NA,
+    Metric.AUCClasswise: NA,
 }
 
 REGRESSION_OBJECTIVES = {
-    EXPLAINED_VARIANCE: MAXIMIZE,
-    R2_SCORE: MAXIMIZE,
-    SPEARMAN: MAXIMIZE,
-    MEAN_ABS_ERROR: MINIMIZE,
-    NORM_MEAN_ABS_ERROR: MINIMIZE,
-    MEDIAN_ABS_ERROR: MINIMIZE,
-    NORM_MEDIAN_ABS_ERROR: MINIMIZE,
-    RMSE: MINIMIZE,
-    NORM_RMSE: MINIMIZE,
-    RMSLE: MINIMIZE,
-    NORM_RMSLE: MINIMIZE,
-    MAPE: MINIMIZE,
-    RESIDUALS: NA,
-    PREDICTED_TRUE: NA,
-    TRAIN_TIME: MINIMIZE,
+    Metric.ExplainedVariance: MAXIMIZE,
+    Metric.R2Score: MAXIMIZE,
+    Metric.Spearman: MAXIMIZE,
+    Metric.MeanAbsError: MINIMIZE,
+    Metric.NormMeanAbsError: MINIMIZE,
+    Metric.MedianAbsError: MINIMIZE,
+    Metric.NormMedianAbsError: MINIMIZE,
+    Metric.RMSE: MINIMIZE,
+    Metric.NormRMSE: MINIMIZE,
+    Metric.RMSLE: MINIMIZE,
+    Metric.NormRMSLE: MINIMIZE,
+    Metric.MAPE: MINIMIZE,
+    Metric.Residuals: NA,
+    Metric.PredictedTrue: NA,
+    TrainingResultsType.TRAIN_TIME: MINIMIZE,
 }
 
+# Note: using the same objectives as regression as both of them are having same metrics
+FORECASTING_OBJECTIVES = REGRESSION_OBJECTIVES
+
 IMAGE_CLASSIFICATION_OBJECTIVES = {
-    ACCURACY: MAXIMIZE,
+    Metric.Accuracy: MAXIMIZE,
 }
 
 IMAGE_CLASSIFICATION_MULTILABEL_OBJECTIVES = {
-    IOU: MAXIMIZE,
+    Metric.IOU: MAXIMIZE,
 }
 
 IMAGE_OBJECT_DETECTION_OBJECTIVES = {
-    MEAN_AVERAGE_PRECISION: MAXIMIZE,
+    Metric.MEAN_AVERAGE_PRECISION: MAXIMIZE,
 }
 
 TEXT_CLASSIFICATION_OBJECTIVES = {
-    ACCURACY: MAXIMIZE,
-    AUC_WEIGHTED: MAXIMIZE,
-    PRECISION_MICRO: MAXIMIZE,
-    PRECISION_WEIGHTED: MAXIMIZE,
+    Metric.Accuracy: MAXIMIZE,
+    Metric.AUCWeighted: MAXIMIZE,
+    Metric.PrecisionMicro: MAXIMIZE,
+    Metric.PrecisionWeighted: MAXIMIZE,
 }
 
 TEXT_CLASSIFICATION_MULTILABEL_OBJECTIVES = {
-    ACCURACY: MAXIMIZE,
-    F1_MACRO: MAXIMIZE,
-    F1_MICRO: MAXIMIZE,
+    Metric.Accuracy: MAXIMIZE,
+    Metric.F1Macro: MAXIMIZE,
+    Metric.F1Micro: MAXIMIZE,
 }
 
 TEXT_NER_OBJECTIVES = {
-    ACCURACY: MAXIMIZE,
-    F1_MICRO: MAXIMIZE,
-    PRECISION_MICRO: MAXIMIZE,
-    RECALL_MICRO: MAXIMIZE,
+    Metric.Accuracy: MAXIMIZE,
+    Metric.F1Micro: MAXIMIZE,
+    Metric.PrecisionMicro: MAXIMIZE,
+    Metric.RecallMicro: MAXIMIZE,
 }
 
 TRANSLATION_OBJECTIVES = {
     Metric.TranslationBleu_1: MAXIMIZE,
     Metric.TranslationBleu_2: MAXIMIZE,
     Metric.TranslationBleu_3: MAXIMIZE,
     Metric.TranslationBleu_4: MAXIMIZE,
@@ -1043,78 +1058,134 @@
     Metric.SummarizationRougeL: MAXIMIZE,
     Metric.SummarizationRougeLsum: MAXIMIZE,
 }
 
 QUESTION_ANSWERING_OBJECTIVES = {
     Metric.QAExactMatch: MAXIMIZE,
     Metric.QAF1Score: MAXIMIZE,
+    Metric.BERTScore: MAXIMIZE,
+    Metric.GPTSimilarity: MAXIMIZE,
+    Metric.GPTCoherence: MAXIMIZE,
+    Metric.GPTGroundedness: MAXIMIZE,
+    Metric.GPTFluency: MAXIMIZE,
+    Metric.GPTRelevance: MAXIMIZE,
+    Metric.LLMSimilarity: MAXIMIZE,
+    Metric.LLMCoherence: MAXIMIZE,
+    Metric.LLMGroundedness: MAXIMIZE,
+    Metric.LLMFluency: MAXIMIZE,
+    Metric.LLMRelevance: MAXIMIZE,
+}
+
+QUESTION_ANSWERING_MULTIPLE_GROUND_TRUTH_OBJECTIVES = {
+    Metric.QAMacroAveragedExactMatch: MAXIMIZE,
+    Metric.QAMacroAveragedF1: MAXIMIZE,
 }
 
 FILL_MASK_OBJECTIVES = {
     Metric.FMPerplexity: MINIMIZE,
 }
 
 TEXT_GENERATION_OBJECTIVES = {
     Metric.SummarizationRouge1: MAXIMIZE,
     Metric.SummarizationRouge2: MAXIMIZE,
     Metric.SummarizationRougeL: MAXIMIZE,
     Metric.SummarizationRougeLsum: MAXIMIZE,
+    Metric.TranslationBleu_1: MAXIMIZE,
+    Metric.TranslationBleu_2: MAXIMIZE,
+    Metric.TranslationBleu_3: MAXIMIZE,
+    Metric.TranslationBleu_4: MAXIMIZE,
+}
 
+CHAT_COMPLETION_OBJECTIVES = {
+    Metric.SummarizationRouge1: MAXIMIZE,
+    Metric.SummarizationRouge2: MAXIMIZE,
+    Metric.SummarizationRougeL: MAXIMIZE,
+    Metric.SummarizationRougeLsum: MAXIMIZE,
     Metric.TranslationBleu_1: MAXIMIZE,
     Metric.TranslationBleu_2: MAXIMIZE,
     Metric.TranslationBleu_3: MAXIMIZE,
     Metric.TranslationBleu_4: MAXIMIZE,
+    Metric.QAExactMatch: MAXIMIZE,
+    Metric.QAF1Score: MAXIMIZE,
 }
 
+RAG_EVALUATION_OBJECTIVES = {
+    Metric.RAG_GPTGroundedness: MAXIMIZE,
+    Metric.RAG_GPTRelevance: MAXIMIZE,
+    Metric.RAG_GPTRetrieval: MAXIMIZE,
+}
+
+CODE_GENERATION_OBJECTIVES = {Metric.CodeGenerationPassRateScore: MAXIMIZE}
+
 FULL_OBJECTIVES = {
     **CLASSIFICATION_OBJECTIVES,
     **REGRESSION_OBJECTIVES,
+    **FORECASTING_OBJECTIVES,
     **IMAGE_CLASSIFICATION_OBJECTIVES,
     **IMAGE_CLASSIFICATION_MULTILABEL_OBJECTIVES,
     **IMAGE_OBJECT_DETECTION_OBJECTIVES,
     **TEXT_CLASSIFICATION_MULTILABEL_OBJECTIVES,
     **TEXT_CLASSIFICATION_OBJECTIVES,
     **TEXT_NER_OBJECTIVES,
     **TRANSLATION_OBJECTIVES,
     **SUMMARIZATION_OBJECTIVES,
     **QUESTION_ANSWERING_OBJECTIVES,
+    **QUESTION_ANSWERING_MULTIPLE_GROUND_TRUTH_OBJECTIVES,
     **FILL_MASK_OBJECTIVES,
     **TEXT_GENERATION_OBJECTIVES,
+    **CHAT_COMPLETION_OBJECTIVES,
+    **RAG_EVALUATION_OBJECTIVES,
+    **CODE_GENERATION_OBJECTIVES,
 }
 
 OBJECTIVES_TASK_MAP = {
-    CLASSIFICATION: CLASSIFICATION_OBJECTIVES,
-    REGRESSION: REGRESSION_OBJECTIVES,
-    IMAGE_CLASSIFICATION: IMAGE_CLASSIFICATION_OBJECTIVES,
-    IMAGE_CLASSIFICATION_MULTILABEL: IMAGE_CLASSIFICATION_MULTILABEL_OBJECTIVES,
-    IMAGE_MULTI_LABEL_CLASSIFICATION: IMAGE_CLASSIFICATION_MULTILABEL_OBJECTIVES,
-    IMAGE_OBJECT_DETECTION: IMAGE_OBJECT_DETECTION_OBJECTIVES,
-    IMAGE_INSTANCE_SEGMENTATION: IMAGE_OBJECT_DETECTION_OBJECTIVES,
-    TEXT_CLASSIFICATION: TEXT_CLASSIFICATION_OBJECTIVES,
-    TEXT_CLASSIFICATION_MULTILABEL: TEXT_CLASSIFICATION_MULTILABEL_OBJECTIVES,
-    TEXT_NER: TEXT_NER_OBJECTIVES,
-    TRANSLATION: TRANSLATION_OBJECTIVES,
-    SUMMARIZATION: SUMMARIZATION_OBJECTIVES,
-    QUESTION_ANSWERING: QUESTION_ANSWERING_OBJECTIVES,
-    FILL_MASK: FILL_MASK_OBJECTIVES,
-    TEXT_GENERATION: TEXT_GENERATION_OBJECTIVES,
+    Tasks.CLASSIFICATION: CLASSIFICATION_OBJECTIVES,
+    Tasks.REGRESSION: REGRESSION_OBJECTIVES,
+    Tasks.FORECASTING: FORECASTING_OBJECTIVES,
+    Tasks.IMAGE_CLASSIFICATION: IMAGE_CLASSIFICATION_OBJECTIVES,
+    Tasks.IMAGE_CLASSIFICATION_MULTILABEL: IMAGE_CLASSIFICATION_MULTILABEL_OBJECTIVES,
+    Tasks.IMAGE_MULTI_LABEL_CLASSIFICATION: IMAGE_CLASSIFICATION_MULTILABEL_OBJECTIVES,
+    Tasks.IMAGE_OBJECT_DETECTION: IMAGE_OBJECT_DETECTION_OBJECTIVES,
+    Tasks.IMAGE_INSTANCE_SEGMENTATION: IMAGE_OBJECT_DETECTION_OBJECTIVES,
+    Tasks.TEXT_CLASSIFICATION: TEXT_CLASSIFICATION_OBJECTIVES,
+    Tasks.TEXT_CLASSIFICATION_MULTILABEL: TEXT_CLASSIFICATION_MULTILABEL_OBJECTIVES,
+    Tasks.TEXT_NER: TEXT_NER_OBJECTIVES,
+    Tasks.TRANSLATION: TRANSLATION_OBJECTIVES,
+    Tasks.SUMMARIZATION: SUMMARIZATION_OBJECTIVES,
+    Tasks.QUESTION_ANSWERING: QUESTION_ANSWERING_OBJECTIVES,
+    Tasks.QUESTION_ANSWERING_MULTIPLE_GROUND_TRUTH: QUESTION_ANSWERING_MULTIPLE_GROUND_TRUTH_OBJECTIVES,
+    Tasks.FILL_MASK: FILL_MASK_OBJECTIVES,
+    Tasks.TEXT_GENERATION: TEXT_GENERATION_OBJECTIVES,
+    Tasks.CHAT_COMPLETION: CHAT_COMPLETION_OBJECTIVES,
+    Tasks.RAG_EVALUATION: RAG_EVALUATION_OBJECTIVES,
+    Tasks.CODE_GENERATION: CODE_GENERATION_OBJECTIVES,
 }
 
 # Pipeline constants
 
 DEFAULT_PIPELINE_SCORE = float("NaN")
 
 # Metric restrictions
 
 MINIMUM_METRIC_NAME_LENGTH = 3  # This is an arbitrary limit for validation.
 MAXIMUM_METRIC_NAME_LENGTH = (
     50  # Check Run History restrictions before extending this limit.
 )
 
 
+class ExceptionTypes:
+    """AzureML Exception Types."""
+
+    User = "User"
+    System = "System"
+    Service = "Service"
+    Unclassified = "Unclassified"
+    All = {User, System, Service, Unclassified}
+
+
 class TelemetryConstants:
     """Define telemetry constants."""
 
     COMPONENT_NAME = "automl"
 
     # Spans that are shared across different child run types
     # Formatting for span name: <Component_Name>.<Span_Name> e.g. automl.Training
@@ -1168,15 +1239,31 @@
     ScriptRunStarting = "ScriptRunStarting"
 
     # Spans specific to Confidence Interval
     COMPUTE_CONFIDENCE_METRICS = "ComputeConfidenceMetrics"
     BOOTSTRAP_STEPS = "BootstrapSteps"
 
     # TODO: refactor / organize below and use compatible telemetry constants for activity logger and RH tracing
+    AZUREML_METRICS_DISABLE_LOGGING = "AZUREML_METRICS_DISABLE_LOGGING"
+    APP_NAME = "azureml-metrics"
+    DEFAULT_VERSION = pkg_resources.get_distribution("azureml-metrics").version
+    LOGGER_NAME = "azureml_metrics_package"
+    NON_PII_MESSAGE = '[Hidden as it may contain PII]'
+    TRUTHY = ['true', '1', 'yes', 'y', 't', True]
+    LOGGING_FMT = '%(asctime)s [{}] [{}] [%(module)s] %(funcName)s +%(lineno)s: %(levelname)-8s ' + \
+                  '[%(process)d] %(message)s \n'
+
     COMPUTE_METRICS_NAME = "ComputeMetrics"
+    COMPUTE_METRICS_TASK_SUFFIX = "compute_metrics-{}"
+    LIST_METRICS_NAME = "ListMetrics"
+    LIST_METRICS_TASK_SUFFIX = "list_metrics-{}"
+
+    LIST_TASKS_NAME = "ListTasks"
+    LIST_PROMPTS = "ListPrompts"
+
     DOWNLOAD_ENSEMBLING_MODELS = "DownloadEnsemblingModels"
     DOWNLOAD_MODEL = "DownloadModel"
     FAILURE = "Failure"
     FIT_ITERATION_NAME = "FitIteration"
     GET_BEST_CHILD = "GetBestChild"
     GET_CHILDREN = "GetChildren"
     GET_OUTPUT = "GetOutput"
@@ -1199,11 +1286,56 @@
     TIME_FIT_INPUT = "TimeFitInput"
     TIME_FIT_NAME = "TimeFit"
 
 
 class _TimeSeriesInternal:
     """Define the time series constants"""
 
-    DUMMY_GRAIN_COLUMN = '_automl_dummy_grain_col'
-    DUMMY_TARGET_COLUMN = '_automl_target_col'
-    HORIZON_NAME = 'horizon_origin'
-    FORECAST_ORIGIN_COLUMN_NAME = '_automl_forecast_origin'
+    DUMMY_GRAIN_COLUMN = "_automl_dummy_grain_col"
+    DUMMY_TARGET_COLUMN = "_automl_target_col"
+    HORIZON_NAME = "horizon_origin"
+    FORECAST_ORIGIN_COLUMN_NAME = "_automl_forecast_origin"
+
+
+class ChatCompletionConstants:
+    """Define chatcompletion metric constants"""
+
+    CONVERSATION_NUMBER = "conversation_number"
+    TURN_NUMBER = "turn_number"
+    # rag_evaluation constants
+    SCORE_PER_TURN = "score_per_turn"
+    SCORE_PER_CONVERSATION = "score_per_conversation"
+    REASON = "reason"
+    # chat completion persona strings
+    USER_PERSONA = "user"
+    ASSISTANT_PERSONA = "assistant"
+    # default response in case of error for RAG based metrics
+    DEFAULT_GPT_SCORE = float("nan")
+    DEFAULT_GPT_REASON = ""
+    MAX_THREADS_PER_METRIC = 6
+    # retry constants
+    MAX_RETRIES = 6
+    DELAY_FACTOR = 4
+    MAX_DELAY = 10
+
+
+class CodeGenerationConstants:
+    """constants needed for code generation metrics"""
+
+    CODE_GENERATION_PREFIX = "pass@"
+
+
+class ConcurrencyConstants:
+    """constants needed for concurrency tasks"""
+    MAX_CONCURRENT_REQUESTS = 4
+
+
+class DefaultValues:
+    # hardcoded custom system prompt for all gpt-star metrics
+    DEFAULT_SYSTEM_PROMPT = "You are an AI assistant. You will be given the definition of an " \
+                            "evaluation metric for assessing the quality of an answer in a " \
+                            "question-answering task. Your job is to compute an accurate evaluation " \
+                            "score using the provided evaluation metric."
+    DEFAULT_CUSTOM_PROMPT_METRIC_NAME = "custom_prompt_metric"
+    DEFAULT_OPENAI_SEED = 123
+    DEFAULT_MAX_TOKENS_CUSTOM_METRIC = 1
+    DEFAULT_GPT_MODEL = "gpt-35-turbo"
```

## Comparing `azureml/metrics/_classification.py` & `azureml/metrics/text/classification/_classification.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,24 +1,23 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 """Definitions for classification metrics."""
 import logging
+import numpy as np
+
 from abc import abstractmethod
 from itertools import chain
 from typing import cast, Any, Dict, List, Optional, Iterable
 
-import numpy as np
-import sklearn
-import sklearn.metrics
-from sklearn.base import TransformerMixin
-
 from azureml.metrics import _scoring_utilities, constants
-from azureml.metrics._metric_base import Metric, NonScalarMetric, ScalarMetric, ClassMetric
-from azureml.metrics.exceptions import DataErrorException, ClientException
+from azureml.metrics.common._metric_base import Metric, NonScalarMetric, ScalarMetric, ClassMetric
+from azureml.metrics.common.exceptions import DataErrorException, ClientException
+from azureml.metrics.common.import_utilities import load_sklearn
+
 
 _logger = logging.getLogger(__name__)
 
 
 class ClassificationMetric(Metric):
     """Abstract class for classification metrics."""
 
@@ -35,15 +34,15 @@
                  y_pred_proba: Optional[np.ndarray],
                  y_test_bin: np.ndarray,
                  y_pred: np.ndarray,
                  class_labels: np.ndarray,
                  sample_weight: Optional[np.ndarray] = None,
                  use_binary: bool = False,
                  multilabel: Optional[bool] = False,
-                 y_transformer: Optional[TransformerMixin] = None,
+                 y_transformer: Optional[Any] = None,
                  positive_label_encoded: Optional[int] = None,
                  ensure_contiguous: bool = False) -> None:
         """
         Initialize the classification metric class.
 
         :param y_test: True labels for the test set.
         :param y_pred_proba: Predicted probabilities for each sample and class.
@@ -95,36 +94,39 @@
 
 
 class Accuracy(ClassificationMetric, ScalarMetric):
     """Wrapper class for accuracy."""
 
     def compute(self):
         """Compute the score for the metric."""
+        sklearn = load_sklearn()
         return sklearn.metrics.accuracy_score(y_true=self._y_test, y_pred=self._y_pred,
                                               sample_weight=self._sample_weight)
 
 
 class WeightedAccuracy(ClassificationMetric, ScalarMetric):
     """Accuracy weighted by number of elements for each class."""
 
     def compute(self):
         """Compute the score for the metric."""
+        sklearn = load_sklearn()
         updated_weights = np.ones(self._y_test.shape[0])
         for idx, i in enumerate(np.bincount(self._y_test.ravel())):
             updated_weights[self._y_test.ravel() == idx] *= (i / float(self._y_test.ravel().shape[0]))
 
         return sklearn.metrics.accuracy_score(y_true=self._y_test, y_pred=self._y_pred,
                                               sample_weight=updated_weights)
 
 
 class BalancedAccuracy(ClassificationMetric, ScalarMetric):
     """Wrapper class for balanced accuracy."""
 
     def compute(self):
         """Compute the score for the metric."""
+        sklearn = load_sklearn()
         average_type = ClassificationMetric.MACRO_AVERAGE
         return sklearn.metrics.recall_score(y_true=self._y_test,
                                             y_pred=self._y_pred,
                                             average=average_type,
                                             sample_weight=self._sample_weight,
                                             zero_division=0)
 
@@ -142,14 +144,15 @@
     """
 
     def _norm_macro_recall(self, y_test_bin, y_pred_proba, n_classes,
                            sample_weight=None, **kwargs):
         # need to use the actual prediction not the matrix here but need
         # the matrix passed to utilities.class_averaged_score
         # if we start doing calibration we need to change this
+        sklearn = load_sklearn()
         if y_test_bin.shape[1] > 1:
             y_test_bin = np.argmax(y_test_bin, 1)
 
         # Binarize the predicted probabilities with a static cutoff
         binary_cutoff = .5
         if y_pred_proba.ndim == 1:
             y_pred = np.array(y_pred_proba > binary_cutoff, dtype=int)
@@ -167,26 +170,27 @@
         return max(0.0, (np.mean(cmat.diagonal() / cmat.sum(axis=1)) - R) / (1 - R))
 
     def compute(self):
         """Compute the score for the metric."""
         use_true_class = self._use_binary and self._class_labels.shape[0] == 2
         y_pred_proba = self._y_pred_proba[:, 1] if use_true_class else self._y_pred_proba
         average_type = ClassificationMetric.MACRO_AVERAGE
-        name = constants.NORM_MACRO_RECALL
+        name = constants.Metric.NormMacroRecall
         return _scoring_utilities.class_averaged_score(
             self._norm_macro_recall, self._y_test_bin, y_pred_proba,
             self._class_labels, self._test_labels, average_type, name,
             sample_weight=self._sample_weight)
 
 
 class LogLoss(ClassificationMetric, ScalarMetric):
     """Wrapper class for log loss."""
 
     def compute(self):
         """Compute the score for the metric."""
+        sklearn = load_sklearn()
         use_true_class = self._use_binary and self._class_labels.shape[0] == 2
         y_pred_proba = self._y_pred_proba[:, 1] if use_true_class else self._y_pred_proba
         if not self._multilabel:
             return sklearn.metrics.log_loss(y_true=self._y_test, y_pred=y_pred_proba,
                                             labels=self._class_labels,
                                             sample_weight=self._sample_weight)
         else:
@@ -200,14 +204,15 @@
     def __init__(self, average_type, *args, **kwargs):
         """Initialize F1."""
         self._average_type = average_type
         super().__init__(*args, **kwargs)
 
     def compute(self):
         """Compute the score for the metric."""
+        sklearn = load_sklearn()
         return sklearn.metrics.f1_score(y_true=self._y_test,
                                         y_pred=self._y_pred,
                                         average=self._average_type,
                                         sample_weight=self._sample_weight,
                                         zero_division=0)
 
 
@@ -216,14 +221,15 @@
 
     def __init__(self, *args, **kwargs):
         """Initialize F1Binary."""
         super().__init__(ClassificationMetric.BINARY, *args, **kwargs)
 
     def compute(self):
         """Compute the score for the metric"""
+        sklearn = load_sklearn()
         if self._positive_label is None:
             return ClassificationMetric.NOT_CALCULATED
         else:
             y_true = self._y_test == self._positive_label
             y_pred = self._y_pred == self._positive_label
             return sklearn.metrics.f1_score(y_true=y_true, y_pred=y_pred,
                                             average=self._average_type, sample_weight=self._sample_weight)
@@ -258,14 +264,15 @@
 
     def __init__(self, *args, **kwargs):
         """Initialize F1 Classwise."""
         super().__init__(*args, **kwargs)
 
     def compute(self):
         """Compute the score for the metric."""
+        sklearn = load_sklearn()
         classwise_f1_score = sklearn.metrics.f1_score(y_true=self._y_test,
                                                       y_pred=self._y_pred,
                                                       average=ClassificationMetric.NO_AVERAGE,
                                                       sample_weight=self._sample_weight)
         string_labels = [str(label) for label in self._class_labels]
         f1_score_dict = dict()
         for label, f1_score in zip(string_labels, classwise_f1_score):
@@ -279,14 +286,15 @@
     def __init__(self, average_type, *args, **kwargs):
         """Initialize Precision."""
         self._average_type = average_type
         super().__init__(*args, **kwargs)
 
     def compute(self):
         """Compute the score for the metric."""
+        sklearn = load_sklearn()
         return sklearn.metrics.precision_score(y_true=self._y_test,
                                                y_pred=self._y_pred,
                                                average=self._average_type,
                                                sample_weight=self._sample_weight,
                                                zero_division=0)
 
 
@@ -295,14 +303,15 @@
 
     def __init__(self, *args, **kwargs):
         """Initialize PrecisionBinary."""
         super().__init__(ClassificationMetric.BINARY, *args, **kwargs)
 
     def compute(self):
         """Compute the score for the metric"""
+        sklearn = load_sklearn()
         if self._positive_label is None:
             return ClassificationMetric.NOT_CALCULATED
         else:
             y_true = self._y_test == self._positive_label
             y_pred = self._y_pred == self._positive_label
             return sklearn.metrics.precision_score(y_true=y_true, y_pred=y_pred, average=self._average_type,
                                                    sample_weight=self._sample_weight)
@@ -338,14 +347,15 @@
 
     def __init__(self, *args, **kwargs):
         """Initialize Precision Classwise."""
         super().__init__(*args, **kwargs)
 
     def compute(self):
         """Compute the score for the metric."""
+        sklearn = load_sklearn()
         classwise_precision_score = sklearn.metrics.precision_score(y_true=self._y_test,
                                                                     y_pred=self._y_pred,
                                                                     average=ClassificationMetric.NO_AVERAGE,
                                                                     sample_weight=self._sample_weight)
         string_labels = [str(label) for label in self._class_labels]
         precision_score_dict = dict()
         for label, precision in zip(string_labels, classwise_precision_score):
@@ -359,14 +369,15 @@
     def __init__(self, average_type, *args, **kwargs):
         """Initialize Recall."""
         self._average_type = average_type
         super().__init__(*args, **kwargs)
 
     def compute(self):
         """Compute the score for the metric."""
+        sklearn = load_sklearn()
         return sklearn.metrics.recall_score(y_true=self._y_test,
                                             y_pred=self._y_pred,
                                             average=self._average_type,
                                             sample_weight=self._sample_weight,
                                             zero_division=0)
 
 
@@ -375,14 +386,15 @@
 
     def __init__(self, *args, **kwargs):
         """Initialize RecallBinary."""
         super().__init__(ClassificationMetric.BINARY, *args, **kwargs)
 
     def compute(self):
         """Compute the score for the metric"""
+        sklearn = load_sklearn()
         if self._positive_label is None:
             return ClassificationMetric.NOT_CALCULATED
         else:
             y_true = self._y_test == self._positive_label
             y_pred = self._y_pred == self._positive_label
             return sklearn.metrics.recall_score(y_true=y_true,
                                                 y_pred=y_pred,
@@ -420,14 +432,15 @@
 
     def __init__(self, *args, **kwargs):
         """Initialize Recall Classwise."""
         super().__init__(*args, **kwargs)
 
     def compute(self):
         """Compute the score for the metric."""
+        sklearn = load_sklearn()
         classwise_recall_score = sklearn.metrics.recall_score(y_true=self._y_test,
                                                               y_pred=self._y_pred,
                                                               average=ClassificationMetric.NO_AVERAGE,
                                                               sample_weight=self._sample_weight,
                                                               zero_division=0)
 
         string_labels = [str(label) for label in self._class_labels]
@@ -444,14 +457,15 @@
         """Initialize AveragePrecision."""
         self._average_type = average_type
         self._name = name
         super().__init__(*args, **kwargs)
 
     def compute(self):
         """Compute the score for the metric."""
+        sklearn = load_sklearn()
         use_true_class = self._use_binary and self._class_labels.shape[0] == 2
         y_pred_proba = self._y_pred_proba[:, 1] if use_true_class else self._y_pred_proba
         y_test_bin = self._y_test_bin[:, 1] if use_true_class else self._y_test_bin
         return _scoring_utilities.class_averaged_score(
             sklearn.metrics.average_precision_score, y_test_bin, y_pred_proba,
             self._class_labels, self._test_labels, self._average_type, self._name,
             sample_weight=self._sample_weight, multilabel=self._multilabel,
@@ -461,21 +475,22 @@
 class AveragePrecisionBinary(AveragePrecision):
     """Wrapper class for binary classification average precision."""
 
     def __init__(self, *args, **kwargs):
         """Initialize AveragePrecisionBinary."""
         super().__init__(
             ClassificationMetric.NO_AVERAGE,
-            constants.AVERAGE_PRECISION_BINARY,
+            constants.Metric.AvgPrecisionBinary,
             *args,
             **kwargs
         )
 
     def compute(self):
         """Compute the score for the metric"""
+        sklearn = load_sklearn()
         if self._positive_label is None:
             return ClassificationMetric.NOT_CALCULATED
         else:
             y_test_bin = self._y_test_bin[:, self._positive_label]
             y_pred_proba = self._y_pred_proba[:, self._positive_label]
             class_labels = np.array([0, 1])
             test_labels = np.array([0, 1])
@@ -488,56 +503,57 @@
 class AveragePrecisionMacro(AveragePrecision):
     """Wrapper class for macro-averaged average precision."""
 
     def __init__(self, *args, **kwargs):
         """Initialize AveragePrecisionMacro."""
         super().__init__(
             ClassificationMetric.MACRO_AVERAGE,
-            constants.AVERAGE_PRECISION_MACRO,
+            constants.Metric.AvgPrecisionMacro,
             *args,
             **kwargs
         )
 
 
 class AveragePrecisionMicro(AveragePrecision):
     """Wrapper class for micro-averaged average precision."""
 
     def __init__(self, *args, **kwargs):
         """Initialize AveragePrecisionMicro."""
         super().__init__(
             ClassificationMetric.MICRO_AVERAGE,
-            constants.AVERAGE_PRECISION_MICRO,
+            constants.Metric.AvgPrecisionMicro,
             *args,
             **kwargs
         )
 
 
 class AveragePrecisionWeighted(AveragePrecision):
     """Wrapper class for weighted-averaged average precision."""
 
     def __init__(self, *args, **kwargs):
         """Initialize AveragePrecisionWeighted."""
         super().__init__(
             ClassificationMetric.WEIGHTED_AVERAGE,
-            constants.AVERAGE_PRECISION_WEIGHTED,
+            constants.Metric.AvgPrecisionWeighted,
             *args,
             **kwargs
         )
 
 
 class AveragePrecisionClasswise(ClassificationMetric, ClassMetric):
     """Wrapper class for classwise average precision."""
 
     def __init__(self, *args, **kwargs):
         """Initialize AveragePrecision Classwise."""
-        self._name = constants.AVERAGE_PRECISION_CLASSWISE
+        self._name = constants.Metric.AvgPrecisionClasswise
         super().__init__(*args, **kwargs)
 
     def compute(self):
         """Compute the score for the metric."""
+        sklearn = load_sklearn()
         use_true_class = self._use_binary and self._class_labels.shape[0] == 2
         y_pred_proba = self._y_pred_proba[:, 1] if use_true_class else self._y_pred_proba
         y_test_bin = self._y_test_bin[:, 1] if use_true_class else self._y_test_bin
         classwise_score = _scoring_utilities.class_averaged_score(
             sklearn.metrics.average_precision_score, y_test_bin, y_pred_proba,
             self._class_labels, self._test_labels, ClassificationMetric.NO_AVERAGE, self._name,
             sample_weight=self._sample_weight, multilabel=self._multilabel, ensure_contiguous=self._ensure_contiguous)
@@ -558,14 +574,15 @@
         """Initialize AUC."""
         self._average_type = average_type
         self._name = name
         super().__init__(*args, **kwargs)
 
     def compute(self):
         """Compute the score for the metric."""
+        sklearn = load_sklearn()
         self._validate_one_class()
         use_true_class = self._use_binary and self._class_labels.shape[0] == 2
         y_pred_proba = self._y_pred_proba[:, 1] if use_true_class else self._y_pred_proba
         y_test_bin = self._y_test_bin[:, 1] if use_true_class else self._y_test_bin
         return _scoring_utilities.class_averaged_score(
             sklearn.metrics.roc_auc_score, y_test_bin, y_pred_proba,
             self._class_labels, self._test_labels, self._average_type, self._name,
@@ -592,21 +609,22 @@
 class AUCBinary(AUC):
     """Wrapper class for binary classification AUC."""
 
     def __init__(self, *args, **kwargs):
         """Initialize AUCBinary."""
         super().__init__(
             ClassificationMetric.NO_AVERAGE,
-            constants.AUC_BINARY,
+            constants.Metric.AUCBinary,
             *args,
             **kwargs
         )
 
     def compute(self):
         """Compute the score for the metric"""
+        sklearn = load_sklearn()
         if self._positive_label is None:
             return ClassificationMetric.NOT_CALCULATED
         else:
             y_test_bin = self._y_test_bin[:, self._positive_label]
             y_pred_proba = self._y_pred_proba[:, self._positive_label]
             class_labels = np.array([0, 1])
             test_labels = np.array([0, 1])
@@ -619,56 +637,57 @@
 class AUCMacro(AUC):
     """Wrapper class for macro-averaged AUC."""
 
     def __init__(self, *args, **kwargs):
         """Initialize AUCMacro."""
         super().__init__(
             ClassificationMetric.MACRO_AVERAGE,
-            constants.AUC_MACRO,
+            constants.Metric.AUCMacro,
             *args,
             **kwargs
         )
 
 
 class AUCMicro(AUC):
     """Wrapper class for micro-averaged AUC."""
 
     def __init__(self, *args, **kwargs):
         """Initialize AUCMicro."""
         super().__init__(
             ClassificationMetric.MICRO_AVERAGE,
-            constants.AUC_MICRO,
+            constants.Metric.AUCMicro,
             *args,
             **kwargs
         )
 
 
 class AUCWeighted(AUC):
     """Wrapper class for weighted-averaged AUC."""
 
     def __init__(self, *args, **kwargs):
         """Initialize AUCWeighted."""
         super().__init__(
             ClassificationMetric.WEIGHTED_AVERAGE,
-            constants.AUC_WEIGHTED,
+            constants.Metric.AUCWeighted,
             *args,
             **kwargs
         )
 
 
 class AUCClasswise(ClassificationMetric, ClassMetric):
     """Wrapper class for classwise AUC."""
 
     def __init__(self, *args, **kwargs):
         """Initialize AUC Classwise."""
-        self._name = constants.AUC_CLASSWISE
+        self._name = constants.Metric.AUCClasswise
         super().__init__(*args, **kwargs)
 
     def compute(self):
         """Compute the score for the metric."""
+        sklearn = load_sklearn()
         self._validate_one_class()
         use_true_class = self._use_binary and self._class_labels.shape[0] == 2
         y_pred_proba = self._y_pred_proba[:, 1] if use_true_class else self._y_pred_proba
         y_test_bin = self._y_test_bin[:, 1] if use_true_class else self._y_test_bin
         classwise_score = _scoring_utilities.class_averaged_score(
             sklearn.metrics.roc_auc_score, y_test_bin, y_pred_proba,
             self._class_labels, self._test_labels, ClassificationMetric.NO_AVERAGE, self._name,
@@ -705,14 +724,15 @@
     def __init__(self, average_type, *args, **kwargs):
         """Initialize IOU."""
         self._average_type = average_type
         super().__init__(*args, **kwargs)
 
     def compute(self):
         """Compute the score for the metric."""
+        sklearn = load_sklearn()
         if sklearn.__version__ >= '0.21.0':
             return sklearn.metrics.jaccard_score(y_true=self._y_test,
                                                  y_pred=self._y_pred,
                                                  average=self._average_type,
                                                  sample_weight=self._sample_weight)
         else:
             return sklearn.metrics.jaccard_similarity_score(y_true=self._y_test,
@@ -757,14 +777,15 @@
 
     def __init__(self, *args, **kwargs):
         """Initialize IOU Score."""
         super().__init__(*args, **kwargs)
 
     def compute(self):
         """Compute the score for the metric."""
+        sklearn = load_sklearn()
         if sklearn.__version__ >= '0.21.0':
             classwise_iou_score = sklearn.metrics.jaccard_score(y_true=self._y_test,
                                                                 y_pred=self._y_pred,
                                                                 average=ClassificationMetric.NO_AVERAGE,
                                                                 sample_weight=self._sample_weight)
         else:
             safe_message = "Class wise IOU score is not supported for scikit-learn versions < 0.21.0," \
@@ -781,18 +802,19 @@
 
 
 class MatthewsCorrelation(ClassificationMetric, ScalarMetric):
     """Wrapper class for Matthews Correlation."""
 
     def compute(self):
         """Compute the score for the metric."""
+        sklearn = load_sklearn()
         ret = sklearn.metrics.matthews_corrcoef(
             y_true=self._y_test, y_pred=self._y_pred,
             sample_weight=self._sample_weight)
-        name = constants.MATTHEWS_CORRELATION
+        name = constants.Metric.MatthewsCorrelation
         return _scoring_utilities.clip_score(ret, *constants.CLASSIFICATION_RANGES[name], name)
 
 
 class AccuracyTable(ClassificationMetric, NonScalarMetric):
     """
     Accuracy Table Metric.
 
@@ -917,15 +939,15 @@
     ) -> Dict[str, Any]:
         """
         Fold several scores from a computed metric together.
 
         :param scores: List of computed scores.
         :return: Aggregated score.
         """
-        if not Metric.check_aggregate_scores(scores, constants.ACCURACY_TABLE):
+        if not Metric.check_aggregate_scores(scores, constants.Metric.AccuracyTable):
             return NonScalarMetric.get_error_metric()
 
         score_data = [score[NonScalarMetric.DATA] for score in scores]
         prob_tables = [d[AccuracyTable.PROB_TABLES] for d in score_data]
         perc_tables = [d[AccuracyTable.PERC_TABLES] for d in score_data]
         data_agg = {
             AccuracyTable.PROB_TABLES: (
@@ -964,14 +986,15 @@
     def _data_to_dict(data):
         schema_type = ConfusionMatrix.SCHEMA_TYPE
         schema_version = ConfusionMatrix.SCHEMA_VERSION
         return NonScalarMetric._data_to_dict(schema_type, schema_version, data)
 
     def _compute_matrix(self, class_labels, sample_weight=None):
         """Compute the matrix from prediction data."""
+        sklearn = load_sklearn()
         if self._y_pred_proba is not None:
             if len(self._y_pred_proba.shape) > 1:
                 y_pred_indexes = np.argmax(self._y_pred_proba, axis=1)
             else:
                 y_pred_indexes = self._y_pred_proba
             y_pred_labels = class_labels[y_pred_indexes]
         else:
@@ -1021,15 +1044,15 @@
     ) -> Dict[str, Any]:
         """
         Fold several scores from a computed metric together.
 
         :param scores: List of computed scores.
         :return: Aggregated score.
         """
-        if not Metric.check_aggregate_scores(scores, constants.CONFUSION_MATRIX):
+        if not Metric.check_aggregate_scores(scores, constants.Metric.ConfusionMatrix):
             return NonScalarMetric.get_error_metric()
 
         score_data = [score[NonScalarMetric.DATA] for score in scores]
         matrices = [d[ConfusionMatrix.MATRIX] for d in score_data]
         matrix_sum = np.sum(matrices, axis=0)
         agg_class_labels = score_data[0][ConfusionMatrix.CLASS_LABELS]
         data_agg = {
@@ -1063,15 +1086,15 @@
     def _data_to_dict(data):
         schema_type = ClassificationReport.SCHEMA_TYPE
         schema_version = ClassificationReport.SCHEMA_VERSION
         return NonScalarMetric._data_to_dict(schema_type, schema_version, data)
 
     def _compute_matrix(self):
         """Compute the matrix from prediction data."""
-
+        sklearn = load_sklearn()
         try:
             if not self._multilabel:
                 encoding_binarizer = _scoring_utilities.LabelEncodingBinarizer()
                 encoding_binarizer.fit(self._class_labels)
                 y_pred_bin = encoding_binarizer.transform(self._y_pred)
                 # Augment the binarized labels for binary classification
                 # This is necessary because the binarizer drops one column if there are two labels
@@ -1126,15 +1149,15 @@
     ) -> Dict[str, Any]:
         """
         Fold several scores from a computed metric together.
 
         :param scores: List of computed scores.
         :return: Aggregated score.
         """
-        if not Metric.check_aggregate_scores(scores, constants.CLASSIFICATION_REPORT):
+        if not Metric.check_aggregate_scores(scores, constants.Metric.ClassificationReport):
             return NonScalarMetric.get_error_metric()
 
         score_data = [score[NonScalarMetric.DATA] for score in scores]
         matrices = [d[ClassificationReport.MATRIX] for d in score_data]
         values = [(matrix[:, :-1], matrix[:, -1]) for matrix in matrices]
         metric_values = np.mean([values[0] for values in values], axis=0)
         support_values = np.sum([values[1] for values in values], axis=0)
```

## Comparing `azureml/metrics/_dataset_binning.py` & `azureml/metrics/tabular/regression/_dataset_binning.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,18 +1,17 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 """Binning regression dataset targets to be used in chart metrics."""
 import logging
 import math
-from typing import Any, Dict, Tuple
-
 import numpy as np
+from typing import Any, Dict, Tuple
 
-from azureml.metrics.contract import Contract
+from azureml.metrics.common.contract import Contract
 
 logger = logging.getLogger(__name__)
 
 # Number of bins should be kept reasonable for a visualization
 _MIN_N_BINS = 1
 _MAX_N_BINS = 100
 
@@ -152,15 +151,15 @@
             last_start = (last_start * _SKEW_WEIGHT + candidate) / (_SKEW_WEIGHT + 1)
             break
 
     n_bins = 3  # n_bins = 3 works in all cases here
     return first_end, last_start, n_bins
 
 
-def _round_bin_edge(edge: float, bin_width: float, decimals: int = 2, direction: str = 'nearest') -> np.float:
+def _round_bin_edge(edge: float, bin_width: float, decimals: int = 2, direction: str = 'nearest') -> float:
     """
     Round a bin edge so that it displays well in a UI.
 
     :param edge: The float value of one bin edge
     :param bin_width: The width of bins to give the magnitude of edges
     :param direction: The direction to round
         'nearest' rounds to the nearest value
```

## Comparing `azureml/metrics/_forecasting.py` & `azureml/metrics/tabular/forecasting/_forecasting.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,30 +1,31 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 """Definitions for forecasting metrics."""
 import logging
+import numpy as np
+import pandas as pd
+
 from abc import abstractmethod
 from collections import OrderedDict
 from typing import Any, Callable, Dict, List, Optional, Sequence, Tuple, Type, Union, cast
 
-import numpy as np
-import pandas as pd
-from scipy.stats import norm
-
-from azureml.metrics import _regression, _scoring_utilities, constants
-from azureml.metrics._metric_base import Metric, NonScalarMetric, ScalarMetric
-from azureml.metrics.contract import Contract
-from azureml.metrics.exceptions import (
+from azureml.metrics import _scoring_utilities, constants
+from azureml.metrics.tabular.regression import _regression
+from azureml.metrics.common._metric_base import Metric, NonScalarMetric, ScalarMetric
+from azureml.metrics.common.contract import Contract
+from azureml.metrics.common.exceptions import (
     DataErrorException,
     ForecastMetricGrainAbsent,
     ForecastMetricValidAbsent,
     TimeseriesTableTrainAbsent,
+    MissingDependencies
 )
-from azureml.metrics.reference_codes import ReferenceCodes
+from azureml.metrics.common.reference_codes import ReferenceCodes
 
 _logger = logging.getLogger(__name__)
 
 
 class ForecastingMetric(Metric):
     """Abstract class for forecast metrics."""
 
@@ -176,15 +177,15 @@
     def aggregate(scores: List[Dict[str, Any]]) -> Dict[str, Any]:
         """
         Fold several scores from a computed metric together.
 
         :param scores: List of computed scores.
         :return: Aggregated score.
         """
-        if not Metric.check_aggregate_scores(scores, constants.FORECASTING_MAPE):
+        if not Metric.check_aggregate_scores(scores, constants.Metric.ForecastMAPE):
             return NonScalarMetric.get_error_metric()
 
         score_data = [score[NonScalarMetric.DATA] for score in scores]
         grouped_data = ForecastingMetric._group_scores_by_horizon(score_data)
 
         data = {}
         for horizon in grouped_data:
@@ -254,15 +255,15 @@
     def aggregate(scores: List[Dict[str, Any]]) -> Dict[str, Any]:
         """
         Fold several scores from a computed metric together.
 
         :param scores: List of computed scores.
         :return: Aggregated score.
         """
-        if not Metric.check_aggregate_scores(scores, constants.FORECASTING_RESIDUALS):
+        if not Metric.check_aggregate_scores(scores, constants.Metric.ForecastResiduals):
             return NonScalarMetric.get_error_metric()
 
         score_data = [score[NonScalarMetric.DATA] for score in scores]
         grouped_data = ForecastingMetric._group_scores_by_horizon(score_data)
 
         data = {}
         for horizon in grouped_data:
@@ -282,14 +283,23 @@
     MAX_CROSS_VALIDATION_FOLDS = 5
     MAX_FORECAST_TRAIN_DATA_POINTS = 20  # Showing at most 20 training data points
     MAX_FORECAST_VALID_DATA_POINTS = 80  # limited by UI, showing up to 80 validate data points per grain
     MAX_FORECAST_GRAINS = 20
 
     def compute(self) -> Dict[str, Any]:
         """ Gather train table metrics for a single fold"""
+        try:
+            from scipy.stats import norm
+        except ImportError:
+            safe_message = "Tabular packages are not available. " \
+                           "Please run pip install azureml-metrics[tabular]"
+            raise MissingDependencies(
+                safe_message, safe_message=safe_message
+            )
+
         if self._X_train is None or self._y_train is None:
             raise TimeseriesTableTrainAbsent(
                 exception_message="X_train/y_train is required to compute ForecastTable",
                 target="_train_data",
                 reference_code=ReferenceCodes._TS_METRIX_NO_TRAIN)
 
         if self._time_series_id_column_names is None:
@@ -416,15 +426,15 @@
     ) -> Dict[str, Any]:
         """
         Fold several scores from a computed metric together.
 
         :param scores: List of computed table metrics.
         :return: Aggregated table metrics.
         """
-        if not Metric.check_aggregate_scores(scores, constants.FORECASTING_TABLE):
+        if not Metric.check_aggregate_scores(scores, constants.Metric.ForecastTable):
             return NonScalarMetric.get_error_metric()
 
         score_data = [score[NonScalarMetric.DATA] for score in scores][:ForecastTable.MAX_CROSS_VALIDATION_FOLDS]
         # only store up to 5 folds data
 
         ret = NonScalarMetric._data_to_dict(
             ForecastTable.SCHEMA_TYPE,
@@ -593,15 +603,15 @@
         :param time_series_id_dict: The dictionary containing
                                     ts_id -> value columns.
         :return: The dictionary with metics.
         """
         actuals = data.pop(ForecastTsIDDistributionTable._ACTUALS).values
         predictions = data.pop(ForecastTsIDDistributionTable._PREDICTIONS).values
         metrics = {}
-        for metric_name in constants.REGRESSION_SCALAR_SET:
+        for metric_name in constants.Metric.SCALAR_REGRESSION_SET:
             metric_class = _scoring_utilities.get_metric_class(metric_name)
             metrics_inst = metric_class(
                 actuals,
                 predictions,
                 y_min=y_min,
                 y_max=y_max,
                 y_std=self._y_std,
@@ -667,12 +677,12 @@
         :return: Aggregated score.
         """
         mt_table = []
         for dt in scores:
             mt_table.extend(dt['data'])
 
         metrics_df = pd.DataFrame.from_records(mt_table)
-        index = list(set(metrics_df.columns) - constants.REGRESSION_SCALAR_SET)
+        index = list(set(metrics_df.columns) - constants.Metric.SCALAR_REGRESSION_SET)
         data = metrics_df.groupby(index, as_index=False).agg(np.nanmean)
         data_dt = data.to_dict(orient='records')
         ret = NonScalarMetric._data_to_dict(ForecastResiduals.SCHEMA_TYPE, ForecastResiduals.SCHEMA_VERSION, data_dt)
         return cast(Dict[str, Any], _scoring_utilities.make_json_safe(ret))
```

## Comparing `azureml/metrics/_metric_base.py` & `azureml/metrics/common/_metric_base.py`

 * *Files 4% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 import itertools
 import logging
 from abc import ABC, abstractmethod
 from typing import Any, Dict, List, Optional, Union, DefaultDict
 
 import numpy as np
 
-from azureml.metrics.exceptions import DataErrorException
+from azureml.metrics.common.exceptions import DataErrorException
 
 _logger = logging.getLogger(__name__)
 
 
 class Metric(ABC):
     """Abstract class for all metrics."""
 
@@ -106,14 +106,25 @@
     def _data_to_dict(schema_type, schema_version, data):
         return {
             NonScalarMetric.SCHEMA_TYPE: schema_type,
             NonScalarMetric.SCHEMA_VERSION: schema_version,
             NonScalarMetric.DATA: data
         }
 
+    def aggregate(
+            scores: List[Any]
+    ) -> Any:
+        """
+        Fold several scores from a computed metric together.
+
+        :param scores: List of computed scores.
+        :return: Aggregated score.
+        """
+        pass
+
 
 class ScalarMetric(Metric):
     """Abstract class for a metric which produces a scalar score."""
 
     @staticmethod
     def aggregate(
             scores: List[Any]
```

## Comparing `azureml/metrics/_regression.py` & `azureml/metrics/tabular/regression/_regression.py`

 * *Files 6% similar despite different names*

```diff
@@ -1,22 +1,22 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 """Definitions for regression metrics."""
 import logging
+import numpy as np
+
 from abc import abstractmethod
 from typing import Any, cast, Dict, List, Optional
 
-import numpy as np
-import scipy.stats
-import sklearn.metrics
-
-from azureml.metrics import _scoring_utilities, constants, utilities
-from azureml.metrics._metric_base import Metric, NonScalarMetric, ScalarMetric
-from azureml.metrics.exceptions import DataErrorException
+from azureml.metrics import _scoring_utilities, constants
+from azureml.metrics.common import utilities
+from azureml.metrics.common._metric_base import Metric, NonScalarMetric, ScalarMetric
+from azureml.metrics.common.exceptions import DataErrorException, MissingDependencies
+from azureml.metrics.common.import_utilities import load_sklearn
 
 _logger = logging.getLogger(__name__)
 
 
 class RegressionMetric(Metric):
     """Abstract class for regression metrics."""
 
@@ -65,19 +65,20 @@
 
 
 class ExplainedVariance(RegressionMetric, ScalarMetric):
     """Wrapper class for explained variance."""
 
     def compute(self):
         """Compute the score for the metric."""
+        sklearn = load_sklearn()
         ret = sklearn.metrics.explained_variance_score(
             self._y_test, self._y_pred,
             sample_weight=self._sample_weight, multioutput='uniform_average')
         if np.isnan(ret) or np.isinf(ret):
-            name = constants.EXPLAINED_VARIANCE
+            name = constants.Metric.ExplainedVariance
             _scoring_utilities.log_invalid_score(ret, name)
             return constants.REGRESSION_RANGES[name][0]
         return ret
 
 
 class R2(RegressionMetric, ScalarMetric):
     """Wrapper class for R^2."""
@@ -87,33 +88,42 @@
         # R^2 is a degenerate metric when passed a single value.
         # scikit-learn <=0.20 returned 1 or 0 for perfect/imperfect prediction respectively.
         # scikit-learn >0.20 returns nan and raises a warning.
         # See the following links for more details on the change:
         # - https://github.com/scikit-learn/scikit-learn/pull/12855
         # - https://scikit-learn.org/stable/whats_new/v0.21.html#changelog
         # Here we simulate the previous scikit-learn behavior.
+        sklearn = load_sklearn()
         if self._y_test.shape[0] == 1:
             return 1.0 if self._y_test == self._y_pred else 0.0
 
         ret = sklearn.metrics.r2_score(
             self._y_test, self._y_pred,
             sample_weight=self._sample_weight, multioutput='uniform_average')
-        name = constants.R2_SCORE
+        name = constants.Metric.R2Score
         if np.isnan(ret) or np.isinf(ret):
             _scoring_utilities.log_invalid_score(ret, name)
             return constants.REGRESSION_RANGES[name][0]
         return _scoring_utilities.clip_score(ret, *constants.REGRESSION_RANGES[name], name)
 
 
 class Spearman(RegressionMetric, ScalarMetric):
     """Wrapper class for spearman correlation."""
 
     def compute(self):
         """Compute the score for the metric."""
-        worst_spearman = utilities.get_worst_values(constants.REGRESSION)[constants.SPEARMAN]
+        try:
+            import scipy.stats
+        except ImportError:
+            safe_message = "Tabular packages are not available. " \
+                           "Please run pip install azureml-metrics[tabular]"
+            raise MissingDependencies(
+                safe_message, safe_message=safe_message
+            )
+        worst_spearman = utilities.get_worst_values(constants.Tasks.REGRESSION)[constants.Metric.Spearman]
         if np.unique(self._y_test).shape[0] == 1:
             _logger.warning("Skipping Spearman calculation. All targets are equal.")
             return worst_spearman
 
         if np.unique(self._y_pred).shape[0] == 1:
             _logger.warning("Skipping Spearman calculation. All predictions are equal.")
             return worst_spearman
@@ -130,27 +140,29 @@
 
 
 class MeanAbsoluteError(RegressionMetric, ScalarMetric):
     """Wrapper class for mean absolute error."""
 
     def compute(self):
         """Compute the score for the metric."""
+        sklearn = load_sklearn()
         ret = sklearn.metrics.mean_absolute_error(
             self._y_test, self._y_pred,
             sample_weight=self._sample_weight, multioutput='uniform_average')
-        name = constants.MEAN_ABS_ERROR
+        name = constants.Metric.MeanAbsError
         return _scoring_utilities.clip_score(ret, *constants.REGRESSION_RANGES[name], name)
 
 
 class NormMeanAbsoluteError(RegressionMetric, ScalarMetric):
     """Wrapper class for normalized mean absolute error."""
 
     def compute(self):
         """Compute the score for the metric."""
-        name = constants.NORM_MEAN_ABS_ERROR
+        sklearn = load_sklearn()
+        name = constants.Metric.NormMeanAbsError
         if self._y_min == self._y_max:
             warning_format = "Skipping {} calculation. All targets are equal. Returning {} score."
             if np.array_equal(self._y_test, self._y_pred):
                 _logger.warning(warning_format.format(name, 'best'))
                 return constants.REGRESSION_RANGES[name][0]
             else:
                 _logger.warning(warning_format.format(name, 'worst'))
@@ -167,25 +179,27 @@
 
 
 class MedianAbsoluteError(RegressionMetric, ScalarMetric):
     """Wrapper class for median absolute error."""
 
     def compute(self):
         """Compute the score for the metric."""
+        sklearn = load_sklearn()
         ret = sklearn.metrics.median_absolute_error(self._y_test, self._y_pred)
-        name = constants.MEDIAN_ABS_ERROR
+        name = constants.Metric.MedianAbsError
         return _scoring_utilities.clip_score(ret, *constants.REGRESSION_RANGES[name], name)
 
 
 class NormMedianAbsoluteError(RegressionMetric, ScalarMetric):
     """Wrapper class for normalized median absolute error."""
 
     def compute(self):
         """Compute the score for the metric."""
-        name = constants.NORM_MEDIAN_ABS_ERROR
+        sklearn = load_sklearn()
+        name = constants.Metric.NormMedianAbsError
         if self._y_min == self._y_max:
             warning_format = "Skipping {} calculation. All targets are equal. Returning {} score."
             if np.array_equal(self._y_test, self._y_pred):
                 _logger.warning(warning_format.format(name, 'best'))
                 return constants.REGRESSION_RANGES[name][0]
             else:
                 _logger.warning(warning_format.format(name, 'worst'))
@@ -199,30 +213,32 @@
 
 
 class RMSE(RegressionMetric, ScalarMetric):
     """Wrapper class for root mean squared error."""
 
     def compute(self):
         """Compute the score for the metric."""
+        sklearn = load_sklearn()
         ret = np.sqrt(sklearn.metrics.mean_squared_error(
             self._y_test, self._y_pred, sample_weight=self._sample_weight,
             multioutput='uniform_average'))  # type: Any
-        name = constants.RMSE
+        name = constants.Metric.RMSE
         if np.isnan(ret) or np.isinf(ret):
             _scoring_utilities.log_invalid_score(ret, name)
             return constants.REGRESSION_RANGES[name][1]
         return _scoring_utilities.clip_score(ret, *constants.REGRESSION_RANGES[name], name)
 
 
 class NormRMSE(RegressionMetric, ScalarMetric):
     """Wrapper class for normalized root mean squared error."""
 
     def compute(self):
         """Compute the score for the metric."""
-        name = constants.NORM_RMSE
+        sklearn = load_sklearn()
+        name = constants.Metric.NormRMSE
         if self._y_min == self._y_max:
             warning_format = "Skipping {} calculation. All targets are equal. Returning {} score."
             if np.array_equal(self._y_test, self._y_pred):
                 _logger.warning(warning_format.format(name, 'best'))
                 return constants.REGRESSION_RANGES[name][0]
             else:
                 _logger.warning(warning_format.format(name, 'worst'))
@@ -239,15 +255,16 @@
 
 
 class RMSLE(RegressionMetric, ScalarMetric):
     """Wrapper class for root mean squared log error."""
 
     def compute(self):
         """Compute the score for the metric."""
-        name = constants.RMSLE
+        sklearn = load_sklearn()
+        name = constants.Metric.RMSLE
         if self._has_negatives:
             _logger.warning("Skipping {} calculation. y_test/y_pred contain negative values.".format(name))
             return np.nan
 
         ret = np.sqrt(sklearn.metrics.mean_squared_log_error(
             self._y_test, self._y_pred,
             sample_weight=self._sample_weight, multioutput='uniform_average'))  # type: Any
@@ -258,15 +275,16 @@
 
 
 class NormRMSLE(RegressionMetric, ScalarMetric):
     """Wrapper class for normalized root mean squared log error."""
 
     def compute(self):
         """Compute the score for the metric."""
-        name = constants.NORM_RMSLE
+        sklearn = load_sklearn()
+        name = constants.Metric.NormRMSLE
         if self._has_negatives:
             _logger.warning("Skipping {} calculation. y_test/y_pred contain negative values.".format(name))
             return np.nan
 
         if self._y_min == self._y_max:
             warning_format = "Skipping {} calculation. All targets are equal. Returning {} score."
             if np.array_equal(self._y_test, self._y_pred):
@@ -399,15 +417,15 @@
     ) -> Dict[str, Any]:
         """
         Fold several scores from a computed metric together.
 
         :param scores: List of computed scores.
         :return: Aggregated score.
         """
-        if not Metric.check_aggregate_scores(scores, constants.RESIDUALS):
+        if not Metric.check_aggregate_scores(scores, constants.Metric.Residuals):
             return NonScalarMetric.get_error_metric()
 
         score_data = [score[NonScalarMetric.DATA] for score in scores]
         edges = [d[Residuals.EDGES] for d in score_data]
         counts = [d[Residuals.COUNTS] for d in score_data]
         agg_edges = Residuals._aggregate_edges(edges)
         agg_counts = np.sum(counts, axis=0)
@@ -527,15 +545,15 @@
     ) -> Dict[str, Any]:
         """
         Fold several scores from a computed metric together.
 
         :param scores: List of computed scores.
         :return: Aggregated score.
         """
-        if not Metric.check_aggregate_scores(scores, constants.PREDICTED_TRUE):
+        if not Metric.check_aggregate_scores(scores, constants.Metric.PredictedTrue):
             return NonScalarMetric.get_error_metric()
 
         EDGES = PredictedTrue.EDGES
         COUNTS = PredictedTrue.COUNTS
         MEANS = PredictedTrue.MEANS
         STDEVS = PredictedTrue.STDEVS
```

## Comparing `azureml/metrics/_scoring.py` & `azureml/metrics/common/_scoring.py`

 * *Files 23% similar despite different names*

```diff
@@ -1,21 +1,30 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 """Computation of AzureML model evaluation metrics."""
+import os
+import json
 import logging
+from tqdm import tqdm
 import numpy as np
 import pandas as pd
 
-from azureml.metrics import _scoring_utilities, _validation, constants, utilities
-from azureml.metrics._forecasting import _NormalizedRegressorWrapper
-from azureml.metrics._metric_base import NonScalarMetric
-from azureml.metrics.constants import MetricExtrasConstants, Metric, ALL_TIME
-from sklearn.base import TransformerMixin
 from typing import Any, Callable, Dict, List, Iterator, Optional, Sequence, Tuple, Union
+from concurrent.futures import ThreadPoolExecutor, as_completed
+
+from azureml.metrics import _scoring_utilities, constants
+from azureml.metrics.common import _validation, utilities
+from azureml.metrics.tabular.forecasting._forecasting import _NormalizedRegressorWrapper
+from azureml.metrics.common._metric_base import NonScalarMetric
+from azureml.metrics.common.exceptions import ValidationException, MetricsException
+from azureml.metrics.rai._utils import (parse_simulator_conversation_history,
+                                        parse_simulator_context,
+                                        parse_persona_name)
+from azureml.metrics.constants import MetricExtrasConstants, Metric, TrainingResultsType
 
 
 logger = logging.getLogger(__name__)
 
 
 def _score_classification(
         log_activity: Callable[[logging.Logger, str, Optional[str],
@@ -25,15 +34,15 @@
         y_test: np.ndarray,
         y_pred: Optional[np.ndarray],
         y_pred_probs: Optional[np.ndarray],
         metrics: List[str],
         class_labels: np.ndarray,
         train_labels: np.ndarray,
         sample_weight: Optional[np.ndarray] = None,
-        y_transformer: Optional[TransformerMixin] = None,
+        y_transformer: Optional = None,
         use_binary: bool = False,
         multilabel: Optional[bool] = False,
         positive_label: Optional[Any] = None,
         ensure_contiguous: bool = False
 ) -> Dict[str, Union[float, Dict[str, Any]]]:
     """
     Compute model evaluation metrics for a classification task.
@@ -52,14 +61,15 @@
     :param class_labels: All classes found in the full dataset (includes train/valid/test sets).
         These should be transformed if using a y transformer.
     :param train_labels: Classes as seen (trained on) by the trained model. These values
         should correspond to the columns of y_pred_probs in the correct order.
     :param sample_weight: Weights for the samples (Does not need
         to match sample weights on the fitted model)
     :param y_transformer: Used to inverse transform labels from `y_test`. Required for non-scalar metrics.
+        y_transformer is of type sklearn.base.TransformerMixin
     :param use_binary: Compute metrics only on the true class for binary classification.
     :param positive_label: class designed as positive class in later binary classification metrics.
     :param multilabel: Indicate if it is multilabel classification.
     :param ensure_contiguous: Whether to pass contiguous NumPy arrays to the sklearn functions computing metrics.
     :return: A dictionary mapping metric name to metric score.
     """
     if not multilabel:
@@ -80,45 +90,50 @@
                                                            train_labels,
                                                            sample_weight,
                                                            y_transformer,
                                                            multilabel=multilabel,
                                                            positive_label=positive_label)
     positive_label_encoded = scoring_dto.positive_label_encoded
 
+    num_metrics = len(metrics)
     results = {}
     skipped_metrics = []
     computed_metrics = []
-    for name in metrics:
-        if y_pred_probs is None and name in Metric.CLASSIFICATION_PROB_REQUIRED_SET:
-            skipped_metrics.append(name)
-            continue
-        try:
-            metric_class = _scoring_utilities.get_metric_class(name)
-            test_targets, pred_targets, labels, positive_label = scoring_dto.get_targets(
-                encoded=utilities.is_scalar(name),
-                classwise=utilities.is_classwise(name))
-
-            metric = metric_class(
-                test_targets, scoring_dto.y_pred_probs_padded, scoring_dto.y_test_bin,
-                pred_targets, labels, sample_weight=sample_weight, use_binary=use_binary,
-                positive_label_encoded=positive_label_encoded, multilabel=multilabel, y_transformer=y_transformer,
-                ensure_contiguous=ensure_contiguous)
+    with tqdm(total=num_metrics, desc="Computing classification metrics") as pbar:
+        for name in metrics:
+            if y_pred_probs is None and name in Metric.CLASSIFICATION_PROB_REQUIRED_SET:
+                skipped_metrics.append(name)
+                pbar.update(1)
+                continue
+            try:
+                metric_class = _scoring_utilities.get_metric_class(name)
+                test_targets, pred_targets, labels, positive_label = scoring_dto.get_targets(
+                    encoded=utilities.is_scalar(name),
+                    classwise=utilities.is_classwise(name))
 
-            results[name] = metric.compute()
-            computed_metrics.append(name)
-        except MemoryError:
-            raise
-        except Exception as e:
-            safe_name = _scoring_utilities.get_safe_metric_name(name)
-            logger.error("Scoring failed for classification metric {}".format(safe_name))
-            log_traceback(e, logger, is_critical=False)
-            if utilities.is_scalar(name):
-                results[name] = np.nan
-            else:
-                results[name] = NonScalarMetric.get_error_metric()
+                metric = metric_class(
+                    test_targets, scoring_dto.y_pred_probs_padded, scoring_dto.y_test_bin,
+                    pred_targets, labels, sample_weight=sample_weight, use_binary=use_binary,
+                    positive_label_encoded=positive_label_encoded, multilabel=multilabel, y_transformer=y_transformer,
+                    ensure_contiguous=ensure_contiguous)
+
+                results[name] = metric.compute()
+                computed_metrics.append(name)
+            except MemoryError:
+                raise
+            except Exception as e:
+                safe_name = _scoring_utilities.get_safe_metric_name(name)
+                logger.error("Scoring failed for classification metric {}".format(safe_name))
+                log_traceback(e, logger, is_critical=False)
+                if utilities.is_scalar(name):
+                    results[name] = np.nan
+                else:
+                    results[name] = NonScalarMetric.get_error_metric()
+            finally:
+                pbar.update(1)
 
     logger.info(f"Metrics computed:\n {computed_metrics}\n")
 
     if len(skipped_metrics) >= 1:
         logger.warning(f"Metrics skipped due to missing y_pred_proba:\n {skipped_metrics}")
 
     return utilities.segregate_scalar_non_scalar(results)
@@ -175,35 +190,39 @@
     _validation.validate_regression(y_test, y_pred, metrics)
     _validation.log_regression_debug(y_test, y_pred, y_min, y_max, sample_weight=sample_weight)
 
     y_min = np.min(y_test) if y_min is None else y_min
     y_max = np.max(y_test) if y_max is None else y_max
     y_std = np.std(y_test) if y_std is None else y_std
 
+    num_metrics = len(metrics)
     results = {}
-    for name in metrics:
-        safe_name = _scoring_utilities.get_safe_metric_name(name)
-        try:
-            metric_class = _scoring_utilities.get_metric_class(name)
-            metric = metric_class(y_test, y_pred, y_min=y_min, y_max=y_max, y_std=y_std,
-                                  bin_info=bin_info, sample_weight=sample_weight)
-            results[name] = metric.compute()
-
-            if utilities.is_scalar(name) and np.isinf(results[name]):
-                logger.error("Found infinite regression score for {}, setting to nan".format(safe_name))
-                results[name] = np.nan
-        except MemoryError:
-            raise
-        except Exception as e:
-            logger.error("Scoring failed for regression metric {}".format(safe_name))
-            log_traceback(e, logger, is_critical=False)
-            if utilities.is_scalar(name):
-                results[name] = np.nan
-            else:
-                results[name] = NonScalarMetric.get_error_metric()
+    with tqdm(total=num_metrics, desc="Computing regression metrics") as pbar:
+        for name in metrics:
+            safe_name = _scoring_utilities.get_safe_metric_name(name)
+            try:
+                metric_class = _scoring_utilities.get_metric_class(name)
+                metric = metric_class(y_test, y_pred, y_min=y_min, y_max=y_max, y_std=y_std,
+                                      bin_info=bin_info, sample_weight=sample_weight)
+                results[name] = metric.compute()
+
+                if utilities.is_scalar(name) and np.isinf(results[name]):
+                    logger.error("Found infinite regression score for {}, setting to nan".format(safe_name))
+                    results[name] = np.nan
+            except MemoryError:
+                raise
+            except Exception as e:
+                logger.error("Scoring failed for regression metric {}".format(safe_name))
+                log_traceback(e, logger, is_critical=False)
+                if utilities.is_scalar(name):
+                    results[name] = np.nan
+                else:
+                    results[name] = NonScalarMetric.get_error_metric()
+            finally:
+                pbar.update(1)
 
     return utilities.segregate_scalar_non_scalar(results)
 
 
 def _score_forecasting(
         log_activity: Callable[[logging.Logger, str, Optional[str],
                                 Optional[Dict[str, Any]]], Iterator[Optional[Any]]],
@@ -279,353 +298,459 @@
         y_max_dict = {}
     y_min = np.min(y_test) if not y_min_dict else np.min(list(y_min_dict.values()))
     y_max = np.max(y_test) if not y_max_dict else np.max(list(y_max_dict.values()))
     _validation.log_forecasting_debug(y_test, y_pred, y_min, y_max, sample_weight=sample_weight)
 
     y_std = np.std(y_test) if y_std is None else y_std
 
+    num_metrics = len(metrics)
     results = {}
-    for name in metrics:
-        safe_name = _scoring_utilities.get_safe_metric_name(name)
-        try:
-            metric_class = _scoring_utilities.get_metric_class(name)
-            if name in constants.FORECASTING_NONSCALAR_SET:
-                metric = metric_class(
-                    y_test=y_test,
-                    y_pred=y_pred,
-                    horizons=horizons,
-                    y_min=y_min,
-                    y_max=y_max,
-                    y_std=y_std,
-                    sample_weight=sample_weight,
-                    X_test=X_test,
-                    X_train=X_train,
-                    y_train=y_train,
-                    time_series_id_column_names=time_series_id_column_names,
-                    time_column_name=time_column_name,
-                    origin_column_name=origin_column_name,
-                    y_min_dict=y_min_dict,
-                    y_max_dict=y_max_dict
-                )
-            elif name in constants.REGRESSION_NORMALIZED_SET:
-                # Calculate the metrics by grain/time_series_id.
-                metric = _NormalizedRegressorWrapper(
-                    y_test=y_test,
-                    y_pred=y_pred,
-                    horizons=horizons,
-                    y_min_dict=y_min_dict,
-                    y_max_dict=y_max_dict,
-                    sample_weight=sample_weight,
-                    X_test=X_test,
-                    time_series_id_column_names=time_series_id_column_names,
-                    time_column_name=time_column_name,
-                    metric_class=metric_class,
-                    aggregation_function=aggregation_method)
-            else:
-                # Other regression metrics, which do not require normalization.
-                metric = metric_class(y_test, y_pred, y_min=y_min, y_max=y_max, y_std=y_std,
-                                      sample_weight=sample_weight)
-            results[name] = metric.compute()
-
-            if utilities.is_scalar(name) and np.isinf(results[name]):
-                logger.error("Found infinite forecasting score for {}, setting to nan".format(safe_name))
-                results[name] = np.nan
-        except MemoryError:
-            raise
-        except Exception as e:
-            logger.error("Scoring failed for forecasting metric {}".format(safe_name))
-            log_traceback(e, logger, is_critical=False)
-            if utilities.is_scalar(name):
-                results[name] = np.nan
-            else:
-                results[name] = NonScalarMetric.get_error_metric()
-
-    return utilities.segregate_scalar_non_scalar(results)
-
-
-def _score_text_ner(
-        log_activity: Callable[[logging.Logger, str, Optional[str],
-                                Optional[Dict[str, Any]]], Iterator[Optional[Any]]],
-        log_traceback: Callable[[BaseException, logging.Logger, Optional[str],
-                                 Optional[bool], Optional[Any]], None],
-        y_test: Union[List[List[str]], np.ndarray],
-        y_pred: Union[List[List[str]], np.ndarray],
-        metrics: List[str]
-) -> Dict[str, Union[float, Dict[str, Any]]]:
-    # We are using seqeval to calculate metrics instead of sklearn for other classification problem
-    # because seqeval supports evaluation at entity-level
-
-    _validation.validate_ner(y_test, y_pred, metrics)
-    _validation.log_ner_debug(y_test, y_pred)
-
-    results = {}
-    for name in metrics:
-        if name in constants.CLASSIFICATION_NLP_NER_SET:
+    with tqdm(total=num_metrics, desc="Computing forecasting metrics") as pbar:
+        for name in metrics:
+            safe_name = _scoring_utilities.get_safe_metric_name(name)
             try:
-                metric_class = _scoring_utilities.get_metric_class_text_ner(name)
-                metric = metric_class(y_test, y_pred)
+                metric_class = _scoring_utilities.get_metric_class(name)
+                if name in constants.Metric.NONSCALAR_FORECAST_SET:
+                    metric = metric_class(
+                        y_test=y_test,
+                        y_pred=y_pred,
+                        horizons=horizons,
+                        y_min=y_min,
+                        y_max=y_max,
+                        y_std=y_std,
+                        sample_weight=sample_weight,
+                        X_test=X_test,
+                        X_train=X_train,
+                        y_train=y_train,
+                        time_series_id_column_names=time_series_id_column_names,
+                        time_column_name=time_column_name,
+                        origin_column_name=origin_column_name,
+                        y_min_dict=y_min_dict,
+                        y_max_dict=y_max_dict
+                    )
+                elif name in constants.Metric.REGRESSION_NORMALIZED_SET:
+                    # Calculate the metrics by grain/time_series_id.
+                    metric = _NormalizedRegressorWrapper(
+                        y_test=y_test,
+                        y_pred=y_pred,
+                        horizons=horizons,
+                        y_min_dict=y_min_dict,
+                        y_max_dict=y_max_dict,
+                        sample_weight=sample_weight,
+                        X_test=X_test,
+                        time_series_id_column_names=time_series_id_column_names,
+                        time_column_name=time_column_name,
+                        metric_class=metric_class,
+                        aggregation_function=aggregation_method)
+                else:
+                    # Other regression metrics, which do not require normalization.
+                    metric = metric_class(y_test, y_pred, y_min=y_min, y_max=y_max, y_std=y_std,
+                                          sample_weight=sample_weight)
                 results[name] = metric.compute()
+
+                if utilities.is_scalar(name) and np.isinf(results[name]):
+                    logger.error("Found infinite forecasting score for {}, setting to nan".format(safe_name))
+                    results[name] = np.nan
             except MemoryError:
                 raise
             except Exception as e:
-                safe_name = _scoring_utilities.get_safe_metric_name(name)
-                logger.error("Scoring failed for NER metric {}".format(safe_name))
+                logger.error("Scoring failed for forecasting metric {}".format(safe_name))
                 log_traceback(e, logger, is_critical=False)
                 if utilities.is_scalar(name):
                     results[name] = np.nan
                 else:
                     results[name] = NonScalarMetric.get_error_metric()
-    return utilities.segregate_scalar_non_scalar(results)
-
-
-def _score_translation(
-        log_activity: Callable[[logging.Logger, str, Optional[str],
-                                Optional[Dict[str, Any]]], Iterator[Optional[Any]]],
-        log_traceback: Callable[[BaseException, logging.Logger, Optional[str],
-                                 Optional[bool], Optional[Any]], None],
-        y_test: List[Any],
-        y_pred: List[str],
-        metrics: List[str],
-        tokenizer: Any,
-        smoothing: bool):
-    """
-    Compute model evaluation metrics for a translation task.
+            finally:
+                pbar.update(1)
 
-    y_test should be a list of list of string references (even if there is only one reference)
-    y_pred should be a list of string predictions
-    tokenizer could be any function that takes input a string, and returns a list of tokens
-
-    :param y_test: Actual list of list of references
-    :param y_pred: Actual list of predictions
-    :param metrics: List of metric names for metrics to calculate.
-    :param tokenizer: function that takes input a string, and returns a list of tokens
-    :param smoothing: boolean to indicate if smoothing is required for bleu score
-    """
-    _validation.validate_translation(y_test, y_pred, metrics, tokenizer, smoothing)
-    _validation.log_translation_debug(y_test, y_pred, tokenizer, smoothing)
-
-    results = {}
-    for name in metrics:
-        safe_name = _scoring_utilities.get_safe_metric_name(name)
-        max_ngram = constants.Metric.TRANSLATION_NGRAM_MAP[name]
-        try:
-            metric_class = _scoring_utilities.get_metric_class(name)
-            metric = metric_class(y_test, y_pred, tokenizer, max_ngram, smoothing)
-            results[name] = metric.compute()
-        except MemoryError:
-            raise
-        except Exception as e:
-            logger.error("Scoring failed for translation metric {}".format(safe_name))
-            log_traceback(e, logger, is_critical=False)
-            results[name] = np.nan
     return utilities.segregate_scalar_non_scalar(results)
 
 
-def _score_summarization(
+def _score_chat_completion(
         log_activity: Callable[[logging.Logger, str, Optional[str],
                                 Optional[Dict[str, Any]]], Iterator[Optional[Any]]],
         log_traceback: Callable[[BaseException, logging.Logger, Optional[str],
                                  Optional[bool], Optional[Any]], None],
         y_test: List[Any],
-        y_pred: List[str],
+        y_pred: List[Any],
         metrics: List[str],
         tokenizer: Any,
+        smoothing: bool,
         aggregator: bool,
-        stemmer: bool):
+        stemmer: bool,
+        model_id: Optional[str],
+        batch_size: Optional[int],
+        add_start_token: Optional[bool],
+        openai_params: Optional[dict],
+        openai_api_batch_size: int,
+        use_chat_completion_api: bool,
+        llm_params: dict,
+        llm_api_batch_size: int,
+        score_version: str,
+        use_previous_conversation: bool):
     """
-    Compute model evaluation metrics for a summarization task.
+    Compute model evaluation metrics for a chat completion task.
 
-    y_test should be a list of string references
+    y_test should be a list of list of string references
     y_pred should be a list of string predictions
     tokenizer could be any function that takes input a string, and returns a list of tokens
 
     :param y_test: Actual list of list of references
     :param y_pred: Actual list of predictions
     :param metrics: List of metric names for metrics to calculate.
     :param tokenizer: function that takes input a string, and returns a list of tokens
+    :params smoothing: Boolean to indicate whether to smooth out the bleu score
     :params aggregator: Boolean to indicate whether to aggregate scores
     :params stemmer: Boolean to indicate whether to use Porter stemmer for word suffixes
-    """
-    _validation.validate_summarization(y_test, y_pred, metrics, tokenizer, aggregator, stemmer)
-    _validation.log_summarization_debug(y_test, y_pred, tokenizer, aggregator, stemmer)
-
-    results = {}
-    safe_names = []
-    for name in metrics:
-        safe_names.append(_scoring_utilities.get_safe_metric_name(name))
-    safe_names = ', '.join(safe_names)
+    :param model_id: model used for calculating Perplexity.
+                        Perplexity can only be calculated for causal language models.
+    :param batch_size (int): the batch size to run texts through the model. Defaults to 16.
+    :param add_start_token (bool): whether to add the start token to the texts,
+        so the perplexity can include the probability of the first word. Defaults to True.
+    :param openai_params: Dictionary containing credentials to initialize or setup LLM
+    :param openai_api_batch_size: number of prompts to be batched in one API call.
+    :param use_chat_completion_api: boolean flag to choose between openAI completion vs chat completion API.
+    :param llm_params: Dictionary containing credentials to initialize or setup LLM
+    :param llm_api_batch_size: number of prompts to be batched in one API call for LLM
+    :param score_version: Version of rag evaluation metrics to be computed.
+    :param use_previous_conversation: boolean value to indicate if we need to use_previous_conversation
+             for computing rag-evaluation metrics.
+    """
+    # TODO: add validation for input contract of chat completion task
+
+    # TODO: y_test (multiple ground-truths for one conversation : can be list of lists = [["hello", "hi"], ["hi"]])
+    # y_pred : last assistant response for every conversation : for computing bleu, rouge, perplexity
+
+    _validation.validate_chat_completion(y_test, y_pred, metrics, tokenizer,
+                                         smoothing, aggregator, stemmer,
+                                         model_id, batch_size, add_start_token,
+                                         openai_params, openai_api_batch_size,
+                                         use_chat_completion_api, llm_params,
+                                         llm_api_batch_size, score_version,
+                                         use_previous_conversation)
+    _validation.log_chat_completion_debug(y_test, y_pred, metrics, tokenizer,
+                                          smoothing, aggregator, stemmer,
+                                          model_id, batch_size, add_start_token,
+                                          openai_params, openai_api_batch_size,
+                                          use_chat_completion_api, llm_params,
+                                          llm_api_batch_size, score_version,
+                                          use_previous_conversation)
+
+    compute_rag_based_metrics = True
+    # containing the last response from assistant -- for computing bleu/rouge metrics
+    final_assistant_y_pred = []
+    # to accept updated chat-completion format
+    processed_y_pred = {"question": [],
+                        "model_result": [],
+                        "retrieved_documents": [],
+                        "ground_truth": []}
+
+    processed_conversation_history = []
+    processed_context = []
+    processed_persona_name = []
 
     try:
-        # NOTE: This will only work if all metrics are Rouge for summarization
-        metric_class = _scoring_utilities.get_metric_class(list(metrics)[0])
-        metric = metric_class(y_test, y_pred, metrics, tokenizer, aggregator, stemmer)
-        results = metric.compute()
-    except MemoryError:
-        raise
-    except Exception as e:
-        logger.error("Scoring failed for summarization metrics {}".format(safe_names))
-        log_traceback(e, logger, is_critical=False)
-        for name in metrics:
-            results[name] = np.nan
-    return utilities.segregate_scalar_non_scalar(results)
-
+        for conversation_num, each_conversation in enumerate(y_pred):
+            all_assistant_responses = []
 
-def _score_text_generation(
-        log_activity: Callable[[logging.Logger, str, Optional[str],
-                                Optional[Dict[str, Any]]], Iterator[Optional[Any]]],
-        log_traceback: Callable[[BaseException, logging.Logger, Optional[str],
-                                 Optional[bool], Optional[Any]], None],
-        y_test: List[Any],
-        y_pred: List[str],
-        metrics: List[str],
-        tokenizer: Any,
-        smoothing: bool,
-        aggregator: bool,
-        stemmer: bool):
-    """
-    Compute model evaluation metrics for a text generation task.
+            questions_per_conversation = []
+            model_result_per_conversation = []
+            retrieved_documents_per_conversation = []
+
+            for turn_num, each_turn in enumerate(each_conversation):
+                persona = each_turn["role"]
+                content = each_turn["content"]
+
+                if persona == "user":
+                    questions_per_conversation.append(content)
+                # collecting assistant's response
+                elif persona == "assistant":
+                    test_sample = each_turn["content"]
+                    all_assistant_responses.append(test_sample)
+                    model_result_per_conversation.append(content)
+                    if "context" in each_turn:
+                        context = each_turn["context"]
+                        if "citations" in context:
+                            retrieved_documents = json.dumps(context["citations"])
+                            retrieved_documents_per_conversation.append(retrieved_documents)
+                        else:
+                            logger.info("Contexts do not contain citations in assistant response for the"
+                                        " turn number : {} of conversation number: {}".format(turn_num + 1,
+                                                                                              conversation_num + 1))
+                    else:
+                        logger.info("Contexts are not found in the turn number : {} of conversation number: {}"
+                                    .format(turn_num + 1, conversation_num + 1))
+                else:
+                    logger.info("Found a persona/role different from user, assistant")
+                    continue
 
-    y_test should be a list of list of string references
-    y_pred should be a list of string predictions
-    tokenizer could be any function that takes input a string, and returns a list of tokens
+            if len(all_assistant_responses) > 0:
+                # picking the final assistant response for computation of bleu/rouge metrics
+                final_assistant_response = all_assistant_responses[-1]
+            else:
+                # treating empty string as response from assistant -- in case of no assistant responses
+                final_assistant_response = ""
+            # appending the final assistant response as prediction for each of conversation
+            final_assistant_y_pred.append(final_assistant_response)
+
+            # TODO: Check if we need to take the input of ground_truth separately
+            # Now, all the turns are completed in the conversation
+            ground_truth = ""
+            ground_truth_per_conversation = [ground_truth for _ in range(len(model_result_per_conversation))]
+
+            # TODO: add a check to ensure questions, model_results, retrieved_documents, ground_truth, conversation
+            #  are of similar length
+            processed_y_pred["question"].append(questions_per_conversation)
+            processed_y_pred["model_result"].append(model_result_per_conversation)
+            processed_y_pred["retrieved_documents"].append(retrieved_documents_per_conversation)
+            processed_y_pred["ground_truth"].append(ground_truth_per_conversation)
+
+            if len(model_result_per_conversation) != len(retrieved_documents_per_conversation):
+                safe_message = "Skipping rag based metrics as we need citations or " \
+                               "retrieved_documents in context key of every assistant's turn"
+                logger.warning(safe_message)
+                compute_rag_based_metrics = False
 
-    :param y_test: Actual list of list of references
-    :param y_pred: Actual list of predictions
-    :param metrics: List of metric names for metrics to calculate.
-    :param tokenizer: function that takes input a string, and returns a list of tokens
-    :params smoothing: Boolean to indicate whether to smooth out the bleu score
-    :params aggregator: Boolean to indicate whether to aggregate scores
-    :params stemmer: Boolean to indicate whether to use Porter stemmer for word suffixes
-    """
-    _validation.validate_text_generation(y_test, y_pred, metrics, tokenizer,
-                                         smoothing, aggregator, stemmer)
-    _validation.log_text_generation_debug(y_test, y_pred, tokenizer,
-                                          smoothing, aggregator, stemmer)
+    except Exception:
+        try:
+            # if not llama format, check it's dictionary with conversation simulator format
+            processed_conversation_history = [parse_simulator_conversation_history(conversation)
+                                              for conversation in y_pred]
+            processed_context = [parse_simulator_context(conversation) for conversation in y_pred]
+            processed_persona_name = [parse_persona_name(conversation) for conversation in y_pred]
+        except Exception:
+            raise MetricsException("Invalid input format for chat completion task")
 
     results = {}
     for name in metrics:
         safe_name = _scoring_utilities.get_safe_metric_name(name)
         max_ngram = constants.Metric.TRANSLATION_NGRAM_MAP.get(name, None)
         try:
-            metric_class = _scoring_utilities.get_metric_class(name)
-            if max_ngram is not None:
-                metric = metric_class(y_test, y_pred, tokenizer, max_ngram, smoothing)
+            if name in constants.Metric.RAG_EVALUATION_SET:
+                metric_class = _scoring_utilities.get_metric_class_rag_evaluation(name)
             else:
-                metric = metric_class(y_test, y_pred, [name], tokenizer, aggregator, stemmer)
-            computed_result = metric.compute()
-            results[name] = computed_result.get(name, None) \
-                if isinstance(computed_result, dict) else computed_result
-        except MemoryError:
-            raise
-        except Exception as e:
-            logger.error("Scoring failed for text generation metric {}".format(safe_name))
-            log_traceback(e, logger, is_critical=False)
-            results[name] = np.nan
-    return utilities.segregate_scalar_non_scalar(results)
+                metric_class = _scoring_utilities.get_metric_class(name)
 
+            if name == Metric.ConversationGroundingScore:
+                if openai_params is None:
+                    safe_message = "OpenAI parameters are required for ConversationGroundingScore"
+                    logger.warning(safe_message)
+                    raise ValueError(safe_message)
+                else:
+                    metric = metric_class(processed_conversation_history,
+                                          tokenizer, processed_context, processed_persona_name,
+                                          openai_params)
+            # computing bleu metric
+            elif max_ngram is not None:
+                metric = metric_class(y_test,
+                                      final_assistant_y_pred, tokenizer, max_ngram, smoothing)
+            elif name in constants.Metric.NONSCALAR_FILL_MASK_SET:
+                metric = metric_class(y_test, final_assistant_y_pred,
+                                      model_id, batch_size,
+                                      add_start_token)
+            # computing RAG based metrics
+            elif name in constants.Metric.RAG_EVALUATION_SET:
+                if compute_rag_based_metrics is True:
+                    metric = metric_class(y_test, processed_y_pred, openai_params,
+                                          openai_api_batch_size, use_chat_completion_api,
+                                          llm_params, llm_api_batch_size,
+                                          score_version, use_previous_conversation)
+                else:
+                    logger.info("Skipping computation of {} metric as context or "
+                                "citations are not available".format(name))
+                    continue
 
-def _score_qa(
-        log_activity: Callable[[logging.Logger, str, Optional[str],
-                                Optional[Dict[str, Any]]], Iterator[Optional[Any]]],
-        log_traceback: Callable[[BaseException, logging.Logger, Optional[str],
-                                 Optional[bool], Optional[Any]], None],
-        y_test: List[Any],
-        y_pred: List[str],
-        metrics: List[str],
-        tokenizer: Any,
-        regexes_to_ignore: List[str],
-        ignore_case: bool,
-        ignore_punctuation: bool,
-        ignore_numbers: bool):
-    """
-    Compute model evaluation metrics for a QA task.
+            # computing rouge metric
+            else:
+                metric = metric_class(y_test,
+                                      final_assistant_y_pred,
+                                      [name], tokenizer, aggregator, stemmer)
 
-    y_test should be a list of string references
-    y_pred should be a list of string predictions
-    tokenizer could be any function that takes input a string, and returns a
-    list of tokens
+            computed_result = metric.compute()
 
-    :param y_test: Actual list of list of references
-    :param y_pred: Actual list of predictions
-    :param metrics: List of metric names for metrics to calculate.
-    :param tokenizer: function that takes input a string, and returns a list of tokens
-    :params regexes_to_ignore: List of string regular expressions to ignore
-    :params ignore_case: Boolean to indicate whether to ignore case
-    :params ignore_punctuation: Boolean to indicate whether to ignore punctuation
-    :params ignore_numbers: Boolean to indicate whether to ignore numbers
-    """
-    _validation.validate_qa(y_test, y_pred, metrics, tokenizer, regexes_to_ignore,
-                            ignore_case, ignore_punctuation, ignore_numbers)
-    _validation.log_qa_debug(y_test, y_pred, tokenizer, regexes_to_ignore,
-                             ignore_case, ignore_punctuation, ignore_numbers)
+            if name in constants.Metric.RAG_EVALUATION_SET:
+                results[name] = computed_result
+            else:
+                results[name] = computed_result.get(name, None) \
+                    if isinstance(computed_result, dict) else computed_result
 
-    results = {}
-    for name in metrics:
-        safe_name = _scoring_utilities.get_safe_metric_name(name)
-        try:
-            metric_class = _scoring_utilities.get_metric_class(name)
-            metric = metric_class(y_test, y_pred, tokenizer, regexes_to_ignore,
-                                  ignore_case, ignore_punctuation, ignore_numbers)
-            results[name] = metric.compute()
         except MemoryError:
             raise
         except Exception as e:
-            logger.error("Scoring failed for QA metric {}".format(safe_name))
+            logger.error("Scoring failed for chat completion metric {}".format(safe_name))
             log_traceback(e, logger, is_critical=False)
             results[name] = np.nan
-    return utilities.segregate_scalar_non_scalar(results)
+    return utilities.segregate_scalar_non_scalar(results, task_type=constants.Tasks.CHAT_COMPLETION)
 
 
-def _score_fill_mask(
+def _score_rag_evaluation(
         log_activity: Callable[[logging.Logger, str, Optional[str],
                                 Optional[Dict[str, Any]]], Iterator[Optional[Any]]],
         log_traceback: Callable[[BaseException, logging.Logger, Optional[str],
                                  Optional[bool], Optional[Any]], None],
         y_test: List[Any],
         y_pred: List[str],
         metrics: List[str],
-        model_id: Optional[str],
-        batch_size: Optional[int],
-        add_start_token: Optional[bool],):
-    """
-    Compute model evaluation metrics for a LM task.
-
-    y_test should be a list of string references
-    y_pred should be a list of string predictions
-
-    :param y_test: Actual list of list of references
-    :param y_pred: Actual list of predictions
-    :param metrics: List of metric names for metrics to calculate.
-    :param metrics: Language Modeling metrics to compute point estimates
-    :param model_id: model used for calculating Perplexity.
-                        Perplexity can only be calculated for causal language models.
-    :param batch_size (int): the batch size to run texts through the model. Defaults to 16.
-    :param add_start_token (bool): whether to add the start token to the texts,
-        so the perplexity can include the probability of the first word. Defaults to True.
-    """
-    _validation.validate_fill_mask(y_test, y_pred, metrics, model_id, batch_size,
-                                   add_start_token)
-    _validation.log_fill_mask_debug(y_test, y_pred, model_id, batch_size,
-                                    add_start_token)
+        openai_params: dict,
+        openai_api_batch_size: int,
+        use_chat_completion_api: bool,
+        llm_params: dict,
+        llm_api_batch_size: int,
+        score_version: str,
+        use_previous_conversation: bool):
+    """
+    Compute model evaluation metrics for a rag evaluation task.
+
+    y_test, y_pred represent multi-turn conversations
+
+    :param metrics: RAG Evaluation Metrics to provide the score with the help of LLMs
+    :param openai_params: Dictionary containing credentials to initialize or setup LLM
+    :param openai_api_batch_size: number of prompts to be batched in one API call.
+    :param use_chat_completion_api: boolean flag to choose between openAI completion vs chat completion API.
+    :param llm_params: Dictionary containing credentials to initialize or setup LLM
+    :param llm_api_batch_size: number of prompts to be batched in one API call for LLM
+    :param score_version: Version of rag evaluation metrics to be computed.
+    :param use_previous_conversation: boolean value to indicate if we need to use_previous_conversation
+             for computing rag-evaluation metrics.
+    """
+    _validation.validate_rag_evaluation(y_test, y_pred, metrics, openai_params,
+                                        openai_api_batch_size, use_chat_completion_api,
+                                        llm_params, llm_api_batch_size,
+                                        score_version, use_previous_conversation)
+    _validation.log_rag_evaluation_debug(y_test, y_pred, metrics,
+                                         openai_params,
+                                         openai_api_batch_size,
+                                         use_chat_completion_api,
+                                         llm_params,
+                                         llm_api_batch_size,
+                                         score_version,
+                                         use_previous_conversation)
+    try:
+        # to accept legacy rag-evaluation format
+        processed_y_pred = {"question": [],
+                            "model_result": [],
+                            "retrieved_documents": [],
+                            "ground_truth": []}
+
+        for conversation_num, each_conversation in enumerate(y_pred):
+
+            questions_per_conversation = []
+            model_result_per_conversation = []
+            retrieved_documents_per_conversation = []
+            ground_truth_per_conversation = []
+
+            for turn_num, each_turn in enumerate(each_conversation):
+                question = each_turn["user"]["content"]
+                model_result = each_turn["assistant"]["content"]
+                retrieved_documents = each_turn["retrieved_documents"]
+
+                # TODO: Check if we need to take the input of ground_truth separately
+                ground_truth = ""
+
+                questions_per_conversation.append(question)
+                model_result_per_conversation.append(model_result)
+                retrieved_documents_per_conversation.append(retrieved_documents)
+                ground_truth_per_conversation.append(ground_truth)
+
+            processed_y_pred["question"].append(questions_per_conversation)
+            processed_y_pred["model_result"].append(model_result_per_conversation)
+            processed_y_pred["retrieved_documents"].append(retrieved_documents_per_conversation)
+            processed_y_pred["ground_truth"].append(ground_truth_per_conversation)
+    except Exception:
+        # to accept updated chat-completion format
+        processed_y_pred = {"question": [],
+                            "model_result": [],
+                            "retrieved_documents": [],
+                            "ground_truth": []}
+
+        for conversation_num, each_conversation in enumerate(y_pred):
+
+            questions_per_conversation = []
+            model_result_per_conversation = []
+            retrieved_documents_per_conversation = []
+
+            for turn_num, each_turn in enumerate(each_conversation):
+                # TODO: try to check if we need to add a logic for length of questions, model_results
+                #  based on number of turns in the conversation
+                persona = each_turn["role"]
+                content = each_turn["content"]
+
+                if persona == "user":
+                    questions_per_conversation.append(content)
+                elif persona == "assistant":
+                    model_result_per_conversation.append(content)
+
+                    if "context" in each_turn:
+                        context = each_turn["context"]
+                        if "citations" in context:
+                            retrieved_documents = json.dumps(context["citations"])
+                            retrieved_documents_per_conversation.append(retrieved_documents)
+                        else:
+                            logger.info("Contexts do not contain citations in assistant response for the"
+                                        " turn number : {} of conversation number: {}".format(turn_num + 1,
+                                                                                              conversation_num + 1))
+                    else:
+                        logger.info("Contexts are not found in the turn number : {} of conversation number: {}"
+                                    .format(turn_num + 1, conversation_num + 1))
+
+            # TODO: Check if we need to take the input of ground_truth separately
+            # Now, all the turns are completed in the conversation
+            ground_truth = ""
+            ground_truth_per_conversation = [ground_truth for _ in range(len(model_result_per_conversation))]
+
+            # TODO: add a check to ensure questions, model_results, retrieved_documents, ground_truth, conversation
+            #  are of similar length
+            processed_y_pred["question"].append(questions_per_conversation)
+            processed_y_pred["model_result"].append(model_result_per_conversation)
+            processed_y_pred["retrieved_documents"].append(retrieved_documents_per_conversation)
+            processed_y_pred["ground_truth"].append(ground_truth_per_conversation)
+
+            if len(model_result_per_conversation) != len(retrieved_documents_per_conversation):
+                safe_message = "Not able to compute rag evaluation metrics as we need citations or " \
+                               "retrieved_documents in context key of every assistant's turn"
+                logger.warning(safe_message)
+                raise ValidationException(safe_message, safe_message=safe_message)
 
     results = {}
-    for name in metrics:
-        safe_name = _scoring_utilities.get_safe_metric_name(name)
-        try:
-            metric_class = _scoring_utilities.get_metric_class(name)
-            metric = metric_class(y_test, y_pred, model_id,
-                                  batch_size, add_start_token)
-            results[name] = metric.compute()
-        except MemoryError:
-            raise
-        except Exception as e:
-            logger.error("Scoring failed for Fill Mask metric {}".format(safe_name))
-            log_traceback(e, logger, is_critical=False)
-            results[name] = np.nan
-    return utilities.segregate_scalar_non_scalar(results)
+    with ThreadPoolExecutor(max_workers=int(os.environ.get("MAX_THREADS_PER_METRIC", 10))) as thread_pool:
+        executors = [thread_pool.submit(_calculate_rag_metric, metric, y_test, processed_y_pred, openai_params,
+                                        openai_api_batch_size, use_chat_completion_api, llm_params, llm_api_batch_size,
+                                        score_version, use_previous_conversation, log_traceback)
+                     for metric in metrics]
+        for executor in as_completed(executors):
+            result = executor.result()
+            results.update(result)
+
+    return utilities.segregate_scalar_non_scalar(results, task_type=constants.Tasks.RAG_EVALUATION)
+
+
+def _calculate_rag_metric(metric_name, y_test, processed_y_pred,
+                          openai_params, openai_api_batch_size,
+                          use_chat_completion_api, llm_params,
+                          llm_api_batch_size, score_version,
+                          use_previous_conversation, log_traceback):
+    safe_name = _scoring_utilities.get_safe_metric_name(metric_name)
+    try:
+        metric_class = _scoring_utilities.get_metric_class_rag_evaluation(metric_name)
+        metric = metric_class(y_test, processed_y_pred, openai_params,
+                              openai_api_batch_size, use_chat_completion_api,
+                              llm_params, llm_api_batch_size,
+                              score_version, use_previous_conversation)
+        computed_result = metric.compute()
+        return {
+            metric_name: computed_result
+        }
+    except MemoryError:
+        raise
+    except Exception as e:
+        logger.error("Scoring failed for rag evaluation metric {}".format(safe_name))
+        log_traceback(e, logger, is_critical=False)
+        return {
+            metric_name: np.nan
+        }
 
 
 def _aggregate_scores(
         log_activity: Callable[[logging.Logger, str, Optional[str],
                                 Optional[Dict[str, Any]]], Iterator[Optional[Any]]],
         log_traceback: Callable[[BaseException, logging.Logger, Optional[str],
                                  Optional[bool], Optional[Any]], None],
@@ -674,13 +799,13 @@
                 means[name_extras] = means_name_extras
 
         except Exception as e:
             safe_name = _scoring_utilities.get_safe_metric_name(name)
             logger.error("Score aggregation failed for metric extras {}".format(safe_name))
             log_traceback(e, logger, is_critical=False)
 
-    for train_type in ALL_TIME:
+    for train_type in TrainingResultsType.ALL_TIME:
         train_times = [res[train_type] for res in scores if train_type in res]
         if train_times:
             means[train_type] = float(np.mean(train_times))
 
     return utilities.segregate_scalar_non_scalar(means)
```

## Comparing `azureml/metrics/_scoring_confidence.py` & `azureml/metrics/common/_scoring_confidence.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,21 +1,21 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 """Computation of AzureML model evaluation metrics."""
 import logging
 import time
-from typing import Dict, List, Optional, Any, Callable, Iterator
-
 import numpy as np
-from sklearn.base import TransformerMixin
-from sklearn.utils import resample
 
-from azureml.metrics import _scoring_utilities, _validation, constants, utilities
+from typing import Dict, List, Optional, Any, Callable, Iterator
+
+from azureml.metrics import _scoring_utilities, constants
+from azureml.metrics.common import _validation, utilities
 from azureml.metrics.constants import MetricExtrasConstants, TelemetryConstants
+from azureml.metrics.common.exceptions import MissingDependencies
 
 logger = logging.getLogger(__name__)
 
 
 def score_confidence_intervals_classification(
         log_activity: Callable[[logging.Logger, str, Optional[str],
                                 Optional[Dict[str, Any]]], Iterator[Optional[Any]]],
@@ -23,15 +23,15 @@
                                  Optional[bool], Optional[Any]], None],
         y_test: np.ndarray,
         y_pred_probs: np.ndarray,
         metrics: List[str],
         class_labels: np.ndarray,
         train_labels: np.ndarray,
         sample_weight: Optional[np.ndarray] = None,
-        y_transformer: Optional[TransformerMixin] = None,
+        y_transformer: Optional[Any] = None,
         use_binary: bool = False,
         multilabel: Optional[bool] = False,
         positive_label: Optional[Any] = None,
 ) -> Dict[str, Dict[str, Any]]:
     """
     Compute confidence interval metrics for a classification task.
 
@@ -48,14 +48,15 @@
     :param class_labels: All classes found in the full dataset (includes train/valid/test sets).
         These should be transformed if using a y transformer.
     :param train_labels: Classes as seen (trained on) by the trained model. These values
         should correspond to the columns of y_pred_probs in the correct order.
     :param sample_weight: Weights for the samples (Does not need
         to match sample weights on the fitted model)
     :param y_transformer: Used to inverse transform labels from `y_test`. Required for non-scalar metrics.
+        y_transformer is of type sklearn.base.TransformerMixin
     :param use_binary: Compute metrics only on the true class for binary classification.
     :param multilabel: Indicate if it is multilabel classification.
     :param positive_label: class designed as positive class in later binary classification metrics.
     :return: A dictionary mapping metric name to confidence interval.
     """
 
     y_test = _validation.format_1d(y_test, 'y_test')
@@ -73,15 +74,15 @@
                                                            sample_weight,
                                                            y_transformer,
                                                            multilabel=multilabel,
                                                            positive_label=positive_label)
 
     test_targets, pred_targets, labels, positive_label_encoded = scoring_dto.get_targets(encoded=True)
 
-    metrics = [metric for metric in metrics if metric in constants.CLASSIFICATION_SCALAR_SET]
+    metrics = [metric for metric in metrics if metric in constants.Metric.SCALAR_CLASSIFICATION_SET]
 
     computed_metrics = _generate_classification_confidence_intervals(log_activity,
                                                                      log_traceback,
                                                                      metrics,
                                                                      test_targets, pred_targets, labels,
                                                                      scoring_dto.y_pred_probs_padded,
                                                                      scoring_dto.y_test_bin,
@@ -101,15 +102,15 @@
         metrics: List[str],
         test_targets: np.ndarray,
         pred_targets: np.ndarray,
         labels: np.ndarray,
         y_pred_probs_padded: np.ndarray,
         y_test_bin: np.ndarray,
         sample_weight: Optional[np.ndarray] = None,
-        y_transformer: Optional[TransformerMixin] = None,
+        y_transformer: Optional[Any] = None,
         use_binary: bool = False,
         multilabel: bool = False,
         positive_label: Optional[Any] = None,
         iterations: int = 500) -> Dict[str, Dict[str, Any]]:
     """
     Bootstrap sampling on the pre-scored dataset to create confidence intervals on the metrics.
 
@@ -125,14 +126,15 @@
     :param labels: All classes found in the full dataset (includes train/valid/test sets).
         These should be transformed if using a y transformer.
     :param y_pred_probs_padded: the predicted classes padded
     :param y_test_bin: The actual class labels
     :param sample_weight: Weights for the samples (Does not need
         to match sample weights on the fitted model)
     :param y_transformer: Used to inverse transform labels from `y_test`. Required for non-scalar metrics.
+        y_transformer is of type sklearn.base.TransformerMixin
     :param use_binary: Compute metrics only on the true class for binary classification.
     :param multilabel: Indicate if it is multilabel classification.
     :param positive_label: class designed as positive class in later binary classification metrics.
     :param iterations: number of bootstrap iterations to simulate the distribution of classification metrics.
     :return: A dictionary mapping metric name to confidence interval.
     """
 
@@ -170,15 +172,15 @@
         test_targets: np.ndarray,
         pred_targets: np.ndarray,
         labels: np.ndarray,
         y_pred_probs_padded: np.ndarray,
         y_test_bin: np.ndarray,
         n_samples: Optional[int],
         sample_weight: Optional[np.ndarray] = None,
-        y_transformer: Optional[TransformerMixin] = None,
+        y_transformer: Optional[Any] = None,
         use_binary: bool = False,
         multilabel: bool = False,
         positive_label: Optional[Any] = None) -> Dict[str, List[float]]:
     """
     Use bootstrap to estimate distributions for classification metrics with given data.
 
     :param metrics: Classification metrics to compute
@@ -189,18 +191,26 @@
         These should be transformed if using a y transformer.
     :param y_pred_probs_padded: the predicted classes padded
     :param y_test_bin: The actual class labels
     :param n_samples: The number of samples to select with replacement for each bootstrap step
     :param sample_weight: Weights for the samples (Does not need
         to match sample weights on the fitted model)
     :param y_transformer: Used to inverse transform labels from `y_test`. Required for non-scalar metrics.
+        y_transformer is of type sklearn.base.TransformerMixin
     :param use_binary: Compute metrics only on the true class for binary classification.
     :param positive_label: class designed as positive class in later binary classification metrics.
     :return: A dictionary mapping metric name to its value distribution.
     """
+    try:
+        from sklearn.utils import resample
+    except ImportError:
+        safe_message = "Tabular packages are not available. Please run pip install azureml-metrics[tabular]"
+        raise MissingDependencies(
+            safe_message, safe_message=safe_message
+        )
 
     test_targets_orig = test_targets
     y_pred_probs_padded_orig = y_pred_probs_padded
     y_test_bin_orig = y_test_bin
     pred_targets_orig = pred_targets
     sample_weight_orig = sample_weight if sample_weight is not None else np.ones(test_targets.shape[0])
 
@@ -299,15 +309,15 @@
     _validation.validate_regression(y_test, y_pred, metrics)
     _validation.log_regression_debug(y_test, y_pred, y_min, y_max, sample_weight=sample_weight)
 
     y_min = np.min(y_test) if y_min is None else y_min
     y_max = np.max(y_test) if y_max is None else y_max
     y_std = np.std(y_test) if y_std is None else y_std
 
-    metrics = [metric for metric in metrics if metric in constants.REGRESSION_SCALAR_SET]
+    metrics = [metric for metric in metrics if metric in constants.Metric.SCALAR_REGRESSION_SET]
 
     computed_metrics = _generate_regression_confidence_intervals(log_activity, log_traceback, metrics,
                                                                  y_test, y_pred,
                                                                  y_max, y_min, y_std,
                                                                  sample_weight=sample_weight)
 
     return utilities.segregate_scalar_non_scalar(computed_metrics)
@@ -390,14 +400,21 @@
     :param y_max: Maximum target value.
     :param y_min: Minimum target value.
     :param y_std: Standard deviation of the targets.
     param n_samples: The number of samples to select with replacement for each bootstrap step
     :param sample_weight: Weighting of each sample in the calculation.
     :return: A dictionary mapping metric name to its value distribution.
     """
+    try:
+        from sklearn.utils import resample
+    except ImportError:
+        safe_message = "Tabular packages are not available. Please run pip install azureml-metrics[tabular]"
+        raise MissingDependencies(
+            safe_message, safe_message=safe_message
+        )
 
     y_test_orig = y_test
     y_pred_orig = y_pred
     sample_weight_orig = sample_weight if sample_weight is not None else np.ones(y_test.shape)
 
     time_for_metric_compute = 0.0
     time_for_resample = 0.0
```

## Comparing `azureml/metrics/_seq2seq_summarization.py` & `azureml/metrics/text/summarization/_seq2seq_summarization.py`

 * *Files 13% similar despite different names*

```diff
@@ -1,18 +1,20 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 
 """Definitions for Machine Translation metrics."""
+import importlib.util
 from abc import abstractmethod
 from typing import Any, List
 
-import evaluate
-
-from azureml.metrics._metric_base import Metric, ScalarMetric
+from azureml.metrics.common._metric_base import Metric, ScalarMetric
+from azureml.metrics.common.utilities import retry
+from azureml.metrics import constants
+from azureml.metrics.common.exceptions import MissingDependencies
 
 
 class Seq2SeqSummarizationMetric(Metric):
     """Base class for Sequence to Sequence Translation metric"""
 
     def __init__(self,
                  y_test: List[Any],
@@ -30,30 +32,51 @@
         """
         self.y_test = y_test
         self.y_pred = y_pred
         self.metrics = metrics
         self.tokenizer = tokenizer
         self.aggregator = aggregator
         self.stemmer = stemmer
+        super().__init__()
 
     @abstractmethod
     def compute(self) -> Any:
         """Compute the score for the metric"""
         ...
 
 
 class Rouge(Seq2SeqSummarizationMetric, ScalarMetric):
     """Wrapper class for Rouge metric for Sequence to Sequence NLG Tasks"""
 
-    hf_rouge = evaluate.load('rouge')
+    hf_rouge = None
 
     def compute(self) -> Any:
         """Compute the score for the metric."""
+        self.load_rouge()
         rouge_args = {
             'rouge_types': self.metrics,
             'use_stemmer': self.stemmer,
             'use_aggregator': self.aggregator
         }
         if self.tokenizer:
             rouge_args.update({'tokenizer': self.tokenizer})
-        return self.hf_rouge.compute(predictions=self.y_pred, references=self.y_test,
-                                     **rouge_args)
+        return Rouge.hf_rouge.compute(predictions=self.y_pred, references=self.y_test,
+                                      **rouge_args)
+
+    @retry(max_attempts=constants.RetryConstants.MAX_ATTEMPTS,
+           delay=constants.RetryConstants.DELAY_TIME)
+    def load_rouge(self):
+        try:
+            import evaluate
+            rougescore_spec = importlib.util.find_spec("rouge_score")
+
+            if rougescore_spec is None:
+                raise ImportError
+
+        except ImportError:
+            safe_message = "Text packages are not available. " \
+                           "Please run pip install azureml-metrics[text]"
+            raise MissingDependencies(
+                safe_message, safe_message=safe_message
+            )
+        if Rouge.hf_rouge is None:
+            Rouge.hf_rouge = evaluate.load("rouge")
```

## Comparing `azureml/metrics/_seq2seq_translation.py` & `azureml/metrics/text/translation/_seq2seq_translation.py`

 * *Files 16% similar despite different names*

```diff
@@ -1,16 +1,18 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 """Definitions for Machine Translation metrics."""
-import evaluate
 
 from abc import abstractmethod
 from typing import Any, List
-from azureml.metrics._metric_base import Metric, ScalarMetric
+from azureml.metrics.common._metric_base import Metric, ScalarMetric
+from azureml.metrics.common.utilities import retry
+from azureml.metrics import constants
+from azureml.metrics.common.import_utilities import load_evaluate
 
 
 class Seq2SeqTranslationMetric(Metric):
     """Base class for Sequence to Sequence Translation metric"""
 
     def __init__(self,
                  y_test: List[Any],
@@ -26,29 +28,39 @@
         :params smoothing: Boolean to indicate whether to smooth out the bleu score
         """
         self.y_test = y_test
         self.y_pred = y_pred
         self.tokenizer = tokenizer
         self.max_ngram = max_ngram
         self.smoothing = smoothing
+        super().__init__()
 
     @abstractmethod
     def compute(self) -> Any:
         """Compute the score for the metric"""
         ...
 
 
 class Bleu(Seq2SeqTranslationMetric, ScalarMetric):
     """Wrapper class for BLEU metric for Sequence to Sequence NLG Tasks"""
 
-    hf_bleu = evaluate.load('bleu')
+    hf_bleu = None
 
     def compute(self) -> Any:
         """Compute the score for the metric."""
+        self.load_bleu()
+
         bleu_args = {
             'max_order': self.max_ngram,
             'smooth': self.smoothing
         }
         if self.tokenizer:
             bleu_args.update({'tokenizer': self.tokenizer})
-        res = self.hf_bleu.compute(predictions=self.y_pred, references=self.y_test, **bleu_args)
+        res = Bleu.hf_bleu.compute(predictions=self.y_pred, references=self.y_test, **bleu_args)
         return res['bleu']
+
+    @retry(max_attempts=constants.RetryConstants.MAX_ATTEMPTS,
+           delay=constants.RetryConstants.DELAY_TIME)
+    def load_bleu(self):
+        evaluate = load_evaluate()
+        if Bleu.hf_bleu is None:
+            Bleu.hf_bleu = evaluate.load("bleu")
```

## Comparing `azureml/metrics/_token_classification.py` & `azureml/metrics/text/ner/_token_classification.py`

 * *Files 18% similar despite different names*

```diff
@@ -2,16 +2,16 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 """Definitions for text-ner metrics."""
 import logging
 from abc import abstractmethod
 from typing import Any, List
 
-from seqeval.metrics import accuracy_score, f1_score, precision_score, recall_score
-from azureml.metrics._metric_base import Metric, ScalarMetric
+from azureml.metrics.common._metric_base import Metric, ScalarMetric
+from azureml.metrics.common.exceptions import MissingDependencies
 
 _logger = logging.getLogger(__name__)
 
 
 class TextNERMetric(Metric):
     """Abstract class for classification metrics."""
 
@@ -40,27 +40,45 @@
 
 
 class Accuracy(TextNERMetric, ScalarMetric):
     """Wrapper class for accuracy."""
 
     def compute(self):
         """Compute the score for the metric."""
+        try:
+            from seqeval.metrics import accuracy_score
+        except ImportError:
+            safe_message = "Text packages are not available. Please run pip install azureml-metrics[text]"
+
+            raise MissingDependencies(
+                safe_message, safe_message=safe_message
+            )
+
         return accuracy_score(y_true=self._y_test, y_pred=self._y_pred)
 
 
 class F1(TextNERMetric, ScalarMetric):
     """Wrapper class for recall."""
 
     def __init__(self, average_type, *args, **kwargs):
         """Initialize F1."""
         self._average_type = average_type
         super().__init__(*args, **kwargs)
 
     def compute(self):
         """Compute the score for the metric."""
+        try:
+            from seqeval.metrics import f1_score
+        except ImportError:
+            safe_message = "Text packages are not available. Please run pip install azureml-metrics[text]"
+
+            raise MissingDependencies(
+                safe_message, safe_message=safe_message
+            )
+
         return f1_score(
             y_true=self._y_test, y_pred=self._y_pred, average=self._average_type
         )
 
 
 class F1Macro(F1):
     """Wrapper class for macro-averaged F1 score."""
@@ -92,14 +110,22 @@
     def __init__(self, average_type, *args, **kwargs):
         """Initialize Precision."""
         self._average_type = average_type
         super().__init__(*args, **kwargs)
 
     def compute(self):
         """Compute the score for the metric."""
+        try:
+            from seqeval.metrics import precision_score
+        except ImportError:
+            safe_message = "Text packages are not available. Please run pip install azureml-metrics[text]"
+
+            raise MissingDependencies(
+                safe_message, safe_message=safe_message
+            )
         return precision_score(
             y_true=self._y_test, y_pred=self._y_pred, average=self._average_type
         )
 
 
 class PrecisionMacro(Precision):
     """Wrapper class for macro-averaged Precision score."""
@@ -131,14 +157,22 @@
     def __init__(self, average_type, *args, **kwargs):
         """Initialize Recall."""
         self._average_type = average_type
         super().__init__(*args, **kwargs)
 
     def compute(self):
         """Compute the score for the metric."""
+        try:
+            from seqeval.metrics import recall_score
+        except ImportError:
+            safe_message = "Text packages are not available. Please run pip install azureml-metrics[text]"
+
+            raise MissingDependencies(
+                safe_message, safe_message=safe_message
+            )
         return recall_score(
             y_true=self._y_test, y_pred=self._y_pred, average=self._average_type
         )
 
 
 class RecallMacro(Recall):
     """Wrapper class for macro-averaged recall."""
```

## Comparing `azureml/metrics/_validation.py` & `azureml/metrics/common/_validation.py`

 * *Files 17% similar despite different names*

```diff
@@ -1,22 +1,24 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 """Validation for AzureML metrics."""
 import logging
 from decimal import Decimal
-from typing import Dict, List, Optional, Any, Union, Sequence
+from typing import Dict, List, Optional, Any, Sequence
 
 import numpy as np
+import json
 
-from azureml.metrics import constants, utilities
-from azureml.metrics._metric_base import NonScalarMetric
-from azureml.metrics.contract import Contract
-from azureml.metrics.exceptions import ValidationException
-from azureml.metrics.reference_codes import ReferenceCodes
+from azureml.metrics import constants
+from azureml.metrics.common import utilities
+from azureml.metrics.common._metric_base import NonScalarMetric
+from azureml.metrics.common.contract import Contract
+from azureml.metrics.common.exceptions import ValidationException
+from azureml.metrics.common.reference_codes import ReferenceCodes
 
 logger = logging.getLogger(__name__)
 
 
 def validate_classification(y_test: np.ndarray,
                             y_pred: Optional[np.ndarray],
                             y_pred_probs: Optional[np.ndarray],
@@ -33,19 +35,16 @@
     :param y_pred_probs: The predicted probabilities for all classes.
     :param metrics: Metrics to compute.
     :param class_labels: All classes found in the full dataset.
     :param train_labels: Classes as seen (trained on) by the trained model.
     :param sample_weight: Weights for the samples.
     :param multilabel: Indicate if it is multilabel classification.
     """
-    for metric in metrics:
-        Contract.assert_true(
-            metric in constants.CLASSIFICATION_SET, "Metric {} not a valid classification metric".format(metric),
-            target="metric", reference_code=ReferenceCodes._METRIC_INVALID_CLASSIFICATION_METRIC
-        )
+    _validate_metrics_list("classification", metrics, constants.Metric.CLASSIFICATION_SET,
+                           ReferenceCodes._METRIC_INVALID_CLASSIFICATION_METRIC)
 
     pred_exists = y_pred is not None or y_pred_probs is not None
     message = "y_pred and y_pred_probs cannot be None together"
     Contract.assert_true(pred_exists, message=message, log_safe=True, reference_code='validate_classification',
                          target='y_pred/y_pred_probs')
 
     _check_array_type(y_test, 'y_test', reference_code='validate_classification')
@@ -104,20 +103,14 @@
             class_label_map = {key: label for key, label in enumerate(class_labels)}
             y_pred_from_probs = np.array([class_label_map[key] for key in y_pred_from_probs])
 
             same_prediction = (y_pred == y_pred_from_probs).all()
             Contract.assert_true(same_prediction, message, log_safe=True, target="same_prediction",
                                  reference_code='validate_classification')
 
-    unique_classes = np.unique(class_labels)
-    Contract.assert_true(unique_classes.shape[0] >= 2,
-                         message="Number of classes must be at least 2 for classification (got {})".format(
-                             unique_classes.shape[0]),
-                         target="num_unique_classes", log_safe=True, reference_code="validate_classification")
-
     if sample_weight is not None:
         Contract.assert_true(sample_weight.dtype.kind in set('fiu'),
                              message="Type of sample_weight must be numeric (got type {})".format(sample_weight.dtype),
                              target="sample_weight", log_safe=True, reference_code="validate_classification")
 
         Contract.assert_true(y_test.shape[0] == sample_weight.shape[0],
                              message="Number of samples does not match in y_test ({}) and sample_weight ({})".format(
@@ -171,23 +164,23 @@
     :param train_labels: Classes as seen (trained on) by the trained model.
     :param sample_weight: Weights for the samples.
     :param multilabel: Indicate if it is multilabel classification.
     """
 
     unique_y_test = np.unique(y_test)
     debug_data = {
-        'y_test': y_test.shape,
-        'y_pred': y_pred.shape if y_pred is not None else None,
-        'y_pred_probs': y_pred_probs.shape if y_pred_probs is not None else None,
-        'unique_y_test': unique_y_test.shape,
-        'class_labels': class_labels.shape,
-        'train_labels': train_labels.shape,
+        'y_test_shape': y_test.shape,
+        'y_pred_shape': y_pred.shape if y_pred is not None else None,
+        'y_pred_probs_shape': y_pred_probs.shape if y_pred_probs is not None else None,
+        'unique_y_test_shape': unique_y_test.shape,
+        'class_labels_shape': class_labels.shape,
+        'train_labels_shape': train_labels.shape,
         'n_missing_train': np.setdiff1d(class_labels, train_labels).shape[0],
         'n_missing_valid': np.setdiff1d(class_labels, unique_y_test).shape[0],
-        'sample_weight': None if sample_weight is None else sample_weight.shape
+        'sample_weight_shape': None if sample_weight is None else sample_weight.shape
     }
 
     if not multilabel:
         unique_y_test = np.unique(y_test)
         debug_data.update({'unique_y_test': unique_y_test.shape,
                            'n_missing_valid': np.setdiff1d(class_labels, unique_y_test).shape[0]})
     else:
@@ -211,19 +204,15 @@
     :param y_pred: Target predictions.
     :param metrics: Metrics to compute.
     :param valid_metrics: The set of metrics available for the task.
     :param task: The task for which validation is performed.
     :param ref_code: The reference code used if the metrics contain metric not
                      in the valid_metrics.
     """
-    for metric in metrics:
-        Contract.assert_true(
-            metric in valid_metrics, "Metric {} not a valid {} metric".format(metric, task),
-            target="metric", reference_code=ref_code
-        )
+    _validate_metrics_list(task, metrics, valid_metrics, ref_code)
 
     _check_array_type(y_test, 'y_test', reference_code=f"validate_{task}")
     _check_array_type(y_pred, 'y_pred', reference_code=f"validate_{task}")
 
     _check_arrays_first_dim(y_test, y_pred, 'y_test', 'y_pred', reference_code=f"validate_{task}")
     _check_array_values(y_test, 'y_test', reference_code=f"validate_{task}")
     _check_array_values(y_pred, 'y_pred', reference_code=f"validate_{task}")
@@ -239,15 +228,15 @@
     :param y_pred: Target predictions.
     :param metrics: Metrics to compute.
     """
     _validate_regression_base(
         y_test=y_test,
         y_pred=y_pred,
         metrics=metrics,
-        valid_metrics=constants.REGRESSION_SET,
+        valid_metrics=constants.Metric.REGRESSION_SET,
         task=constants.Tasks.REGRESSION,
         ref_code=ReferenceCodes._METRIC_INVALID_REGRESSION_METRIC)
 
 
 def _log_regression_base_debug(y_test: np.ndarray,
                                y_pred: np.ndarray,
                                y_min: Optional[float],
@@ -262,22 +251,22 @@
     :param y_min: Minimum target value.
     :param y_max: Maximum target value.
     :param task: The task to send the log for.
     :param sample_weight: Weights for the samples.
     """
     min_max_equal = None if None in [y_min, y_max] else y_min == y_max
     debug_data = {
-        'y_test': y_test.shape,
-        'y_pred': y_pred.shape,
-        'y_test_unique': np.unique(y_test).shape[0],
-        'y_pred_unique': np.unique(y_pred).shape[0],
+        'y_test_shape': y_test.shape,
+        'y_pred_shape': y_pred.shape,
+        'y_test_unique_length': np.unique(y_test).shape[0],
+        'y_pred_unique_length': np.unique(y_pred).shape[0],
         'y_test_has_negative': (y_test < 0).sum() > 0,
         'y_pred_has_negative': (y_pred < 0).sum() > 0,
         'min_max_equal': min_max_equal,
-        'sample_weight': None if sample_weight is None else sample_weight.shape
+        'sample_weight_shape': None if sample_weight is None else sample_weight.shape
     }
 
     logger.info("{} metrics debug: {}".format(task.title(), debug_data))
 
 
 def log_regression_debug(y_test: np.ndarray,
                          y_pred: np.ndarray,
@@ -297,359 +286,232 @@
                                y_pred=y_pred,
                                y_min=y_min,
                                y_max=y_max,
                                task=constants.Tasks.REGRESSION,
                                sample_weight=sample_weight)
 
 
-def validate_translation(y_test: List[Any],
-                         y_pred: List[str],
-                         metrics: List[str],
-                         tokenizer: Any,
-                         smoothing: bool):
+def validate_chat_completion(y_test: List[Any],
+                             y_pred: List[str],
+                             metrics: List[str],
+                             tokenizer: Any,
+                             smoothing: bool,
+                             aggregator: bool,
+                             stemmer: bool,
+                             model_id: Optional[str],
+                             batch_size: Optional[int],
+                             add_start_token: Optional[bool],
+                             openai_params: dict,
+                             openai_api_batch_size: int,
+                             use_chat_completion_api: bool,
+                             llm_params: dict,
+                             llm_api_batch_size: int,
+                             score_version: str,
+                             use_previous_conversation: bool,):
     """
-    Validate the inputs for translation.
+    Validate the inputs for chat completion.
 
     :param y_test: Actual list of list of references
     :param y_pred: Actual list of predictions
     :param metrics: Metrics to compute.
     :param tokenizer: function that takes input a string, and returns a list of tokens
-    :param smoothing: boolean to indicate if smoothing is required for bleu score
-    """
-    for metric in metrics:
-        Contract.assert_true(
-            metric in constants.Metric.TRANSLATION_SET, "Metric {} not a valid translation metric".format(metric),
-            target="metric", reference_code=ReferenceCodes._METRIC_INVALID_TRANSLATION_METRIC
-        )
-    _check_seq2seq_list_of_list_of_str(y_test, 'y_test', reference_code='validate_translation')
-    _check_seq2seq_list_of_str(y_pred, 'y_pred', reference_code='validate_translation')
-    if tokenizer:  # Check for valid tokenizer only if it was passed
-        _check_seq2seq_tokenizer(tokenizer, 'tokenizer', reference_code='validate_translation')
-    _check_seq2seq_bool(smoothing, 'smoothing', reference_code='validate_translation')
-    Contract.assert_true(len(y_test) == len(y_pred), 'Number of samples in y_test and y_pred do not match',
-                         log_safe=True, reference_code='validate_translation', target='y_test')
-
-
-def log_translation_debug(y_test: List[Any],
-                          y_pred: List[str],
-                          tokenizer: Any,
-                          smoothing: bool) -> None:
-    """
-    Log shapes of translation inputs for debugging.
-
-    :param y_test: Actual list of list of references
-    :param y_pred: Actual list of predictions
-    :param tokenizer: function that takes input a string, and returns a list of tokens
-    :param smoothing: boolean to indicate if smoothing is required for bleu score
-    """
-    debug_text = 'the quick brown fox jumped over the lazy dog'
-    debug_data = {
-        'y_test': len(y_test),
-        'y_pred': len(y_pred),
-        'tokenizer_example_output': ' '.join(tokenizer(debug_text)) if tokenizer else debug_text,
-        'smoothing': smoothing
-    }
-
-    logger.info("Translation metrics debug: {}".format(debug_data))
-
-
-def validate_summarization(y_test: List[Any],
-                           y_pred: List[str],
-                           metrics: List[str],
-                           tokenizer: Any,
-                           aggregator: bool,
-                           stemmer: bool):
-    """
-    Validate the inputs for summarization.
+    :param smoothing: Boolean to indicate whether to smooth out the bleu score
+    :param aggregator: Boolean to indicate whether to aggregate scores
+    :param stemmer: Boolean to indicate whether to use Porter stemmer for word suffixes
+    :param model_id: model used for calculating Perplexity.
+        Perplexity can only be calculated for causal language models.
+    :param batch_size: (int) the batch size to run texts through the model. Defaults to 16.
+    :param add_start_token: (bool) whether to add the start token to the texts,
+        so the perplexity can include the probability of the first word. Defaults to True.
+    :param openai_params: Dictionary containing credentials to initialize or setup LLM
+    :param openai_api_batch_size: number of prompts to be batched in one API call.
+    :param use_chat_completion_api: boolean flag to choose between openAI completion vs chat completion API.
+    :param llm_params: Dictionary containing credentials to initialize or setup LLM
+    :param llm_api_batch_size: number of prompts to be batched in one API call for LLM
+    :param score_version: Version of rag evaluation metrics to be computed
+    :param use_previous_conversation: boolean value to indicate if we need to use_previous_conversation
+             for computing rag-evaluation metrics.
+    """
+    reference_code = "validate_chat_completion"
+    _validate_metrics_list("chat completion", metrics, constants.Metric.CHAT_COMPLETION_SET, reference_code)
+
+    ignore_y_test = False
+    # y_test can be None for perplexity
+    if constants.Metric.FMPerplexity in metrics:
+        ignore_y_test = True
 
-    :param y_test: Actual list of list of references
-    :param y_pred: Actual list of predictions
-    :param metrics: Metrics to compute.
-    :param tokenizer: function that takes input a string, and returns a list of tokens
-    :params aggregator: Boolean to indicate whether to aggregate scores
-    :params stemmer: Boolean to indicate whether to use Porter stemmer for word suffixes
-    """
-    for metric in metrics:
-        Contract.assert_true(
-            metric in constants.Metric.SUMMARIZATION_SET, "Metric {} not a valid summarization metric".format(metric),
-            target="metric", reference_code=ReferenceCodes._METRIC_INVALID_SUMMARIZATION_METRIC
-        )
-    _check_seq2seq_list_of_list_of_str(y_test, 'y_test', reference_code='validate_summarization')
-    _check_seq2seq_list_of_str(y_pred, 'y_pred', reference_code='validate_summarization')
     if tokenizer:
-        _check_seq2seq_tokenizer(tokenizer, 'tokenizer', reference_code='validate_summarization')
-    _check_seq2seq_bool(aggregator, 'aggregator', reference_code='validate_summarization')
-    _check_seq2seq_bool(stemmer, 'stemmer', reference_code='validate_summarization')
-    Contract.assert_true(len(y_test) == len(y_pred), 'Number of samples in y_test and y_pred do not match',
-                         log_safe=True, reference_code='validate_summarization', target='y_test')
+        _check_seq2seq_tokenizer(tokenizer, 'tokenizer', reference_code=reference_code)
+    _check_seq2seq_bool(smoothing, 'smoothing', reference_code=reference_code)
+    _check_seq2seq_bool(aggregator, 'aggregator', reference_code=reference_code)
+    _check_seq2seq_bool(stemmer, 'stemmer', reference_code=reference_code)
+    _check_seq2seq_bool(add_start_token, 'add_start_token', reference_code=reference_code)
+    _check_seq2seq_str(model_id, 'model_id', reference_code=reference_code)
+    _check_seq2seq_int(batch_size, 'batch_size', ignore_none=True, reference_code=reference_code)
+    _check_seq2seq_dict(openai_params, 'openai_params', ignore_none=True, reference_code=reference_code)
+    _check_seq2seq_int(openai_api_batch_size, 'openai_api_batch_size', reference_code=reference_code)
+    _check_seq2seq_bool(use_chat_completion_api, 'use_chat_completion_api', ignore_none=True,
+                        reference_code=reference_code)
+    _check_seq2seq_dict(llm_params, 'llm_params', ignore_none=True, reference_code=reference_code)
+    _check_seq2seq_int(llm_api_batch_size, 'llm_api_batch_size', reference_code=reference_code)
+    _check_seq2seq_str(score_version, 'score_version', reference_code=reference_code)
+    _check_seq2seq_bool(use_previous_conversation, "use_previous_conversation",
+                        reference_code=reference_code)
+    _check_seq2seq_list_of_list_of_str(y_test, 'y_test', ignore_none=ignore_y_test, reference_code=reference_code)
+    _check_chat_conversation(y_pred, 'y_pred', reference_code=reference_code)
+    if y_test is not None:
+        Contract.assert_true(len(y_test) == len(y_pred), 'Number of samples in y_test and y_pred do not match',
+                             log_safe=True, reference_code=reference_code, target='y_test')
 
 
-def log_summarization_debug(y_test: List[Any],
+def validate_rag_evaluation(y_test: List[Any],
                             y_pred: List[str],
-                            tokenizer: Any,
-                            aggregator: bool,
-                            stemmer: bool) -> None:
-    """
-    Log shapes of summarization inputs for debugging.
-
-    :param y_test: Actual list of list of references
-    :param y_pred: Actual list of predictions
-    :param tokenizer: function that takes input a string, and returns a list of tokens
-    :params aggregator: Boolean to indicate whether to aggregate scores
-    :params stemmer: Boolean to indicate whether to use Porter stemmer for word suffixes
-    """
-    debug_text = 'the quick brown fox jumped over the lazy dog'
-    debug_data = {
-        'y_test': len(y_test),
-        'y_pred': len(y_pred),
-        'tokenizer_example_output': ' '.join(tokenizer(debug_text)) if tokenizer else debug_text,
-        'aggregator': aggregator,
-        'stemmer': stemmer
-    }
-
-    logger.info("Summarization metrics debug: {}".format(debug_data))
+                            metrics: List[str],
+                            openai_params: dict,
+                            openai_api_batch_size: int,
+                            use_chat_completion_api: bool,
+                            llm_params: dict,
+                            llm_api_batch_size: int,
+                            score_version: str,
+                            use_previous_conversation: bool):
+    """
+    Validate the inputs for rag evaluation.
+
+    :param y_test: multi-turn conversation for rag-evaluation metrics
+    :param y_pred: multi-turn conversation for rag-evaluation metrics
+    :param metrics: rag-evaluation metrics to compute.
+    :param openai_params: Dictionary containing credentials to initialize or setup LLM
+    :param openai_api_batch_size: number of prompts to be batched in one API call.
+    :param use_chat_completion_api: boolean flag to choose between openAI completion vs chat completion API.
+    :param llm_params: Dictionary containing credentials to initialize or setup LLM
+    :param llm_api_batch_size: number of prompts to be batched in one API call for LLM
+    :param score_version: Version of rag evaluation metrics to be computed
+    :param use_previous_conversation: boolean value to indicate if we need to use_previous_conversation
+             for computing rag-evaluation metrics.
+    """
+    reference_code = "validate_rag_evaluation"
+    _validate_metrics_list("rag evaluation", metrics, constants.Metric.RAG_EVALUATION_SET, reference_code)
+
+    _check_seq2seq_dict(openai_params, 'openai_params', ignore_none=True, reference_code=reference_code)
+    _check_seq2seq_int(openai_api_batch_size, 'openai_api_batch_size', reference_code=reference_code)
+    _check_seq2seq_bool(use_chat_completion_api, 'use_chat_completion_api', ignore_none=True,
+                        reference_code=reference_code)
+    _check_seq2seq_dict(llm_params, 'llm_params', ignore_none=True, reference_code=reference_code)
+    _check_seq2seq_int(llm_api_batch_size, 'llm_api_batch_size', reference_code=reference_code)
+    _check_seq2seq_str(score_version, 'score_version', reference_code=reference_code)
+    _check_seq2seq_bool(use_previous_conversation, "use_previous_conversation",
+                        reference_code=reference_code)
+    # TODO: currently, we don't need y_test for computing rag_evaluation metrics
+    _check_chat_conversation(y_pred, 'y_pred', reference_code=reference_code)
 
 
-def validate_text_generation(y_test: List[Any],
+def log_rag_evaluation_debug(y_test: List[Any],
                              y_pred: List[str],
                              metrics: List[str],
-                             tokenizer: Any,
-                             smoothing: bool,
-                             aggregator: bool,
-                             stemmer: bool):
+                             openai_params: dict,
+                             openai_api_batch_size: int,
+                             use_chat_completion_api: bool,
+                             llm_params: dict,
+                             llm_api_batch_size: int,
+                             score_version: str,
+                             use_previous_conversation: bool) -> None:
+    """
+    Log shapes of rag evaluation inputs for debugging.
+
+    :param y_test: multi-turn conversation for rag-evaluation metrics
+    :param y_pred: multi-turn conversation for rag-evaluation metrics
+    :param metrics: rag-evaluation metrics to compute.
+    :param openai_params: Dictionary containing credentials to initialize or setup LLM
+    :param openai_api_batch_size: number of prompts to be batched in one API call.
+    :param use_chat_completion_api: boolean flag to choose between openAI completion vs chat completion API.
+    :param llm_params: Dictionary containing credentials to initialize or setup LLM
+    :param llm_api_batch_size: number of prompts to be batched in one API call for LLM
+    :param score_version: Version of rag evaluation metrics to be computed
+    :param use_previous_conversation: boolean value to indicate if we need to use_previous_conversation
+             for computing rag-evaluation metrics.
     """
-    Validate the inputs for text generation.
+    debug_data = {
+        'y_test_length': len(y_test) if y_test is not None else 0,
+        'y_pred_length': len(y_pred),
+        'metrics': metrics,
+        'using_openai_api': "yes" if openai_params is not None else "no",
+        'openai_api_batch_size': openai_api_batch_size,
+        'use_chat_completion_api': use_chat_completion_api,
+        'using_llm_deployment_api': "yes" if llm_params is not None else "no",
+        'llm_api_batch_size': llm_api_batch_size,
+        'score_version': score_version,
+        'use_previous_conversation': use_previous_conversation,
+    }
 
-    :param y_test: Actual list of list of references
-    :param y_pred: Actual list of predictions
-    :param metrics: Metrics to compute.
-    :param tokenizer: function that takes input a string, and returns a list of tokens
-    :params smoothing: Boolean to indicate whether to smooth out the bleu score
-    :params aggregator: Boolean to indicate whether to aggregate scores
-    :params stemmer: Boolean to indicate whether to use Porter stemmer for word suffixes
-    """
-    for metric in metrics:
-        Contract.assert_true(
-            metric in constants.Metric.TEXT_GENERATION_SET,
-            "Metric {} not a valid text generation metric".format(metric),
-            target="metric", reference_code=ReferenceCodes._METRIC_INVALID_TEXT_GENERATION_METRIC
-        )
-    _check_seq2seq_list_of_list_of_str(y_test, 'y_test', reference_code='validate_text_generation')
-    _check_seq2seq_list_of_str(y_pred, 'y_pred', reference_code='validate_text_generation')
-    if tokenizer:
-        _check_seq2seq_tokenizer(tokenizer, 'tokenizer', reference_code='validate_text_generation')
-    _check_seq2seq_bool(smoothing, 'smoothing', reference_code='validate_text_generation')
-    _check_seq2seq_bool(aggregator, 'aggregator', reference_code='validate_text_generation')
-    _check_seq2seq_bool(stemmer, 'stemmer', reference_code='validate_text_generation')
-    Contract.assert_true(len(y_test) == len(y_pred), 'Number of samples in y_test and y_pred do not match',
-                         log_safe=True, reference_code='validate_text_generation', target='y_test')
+    logger.info("rag evaluation metrics debug: {}".format(debug_data))
 
 
-def log_text_generation_debug(y_test: List[Any],
+def log_chat_completion_debug(y_test: List[Any],
                               y_pred: List[str],
+                              metrics: List[str],
                               tokenizer: Any,
                               smoothing: bool,
                               aggregator: bool,
-                              stemmer: bool) -> None:
-    """
-    Log shapes of text generation inputs for debugging.
-
-    :param y_test: Actual list of list of references
-    :param y_pred: Actual list of predictions
-    :param tokenizer: function that takes input a string, and returns a list of tokens
-    :params smoothing: Boolean to indicate whether to smooth out the bleu score
-    :params aggregator: Boolean to indicate whether to aggregate scores
-    :params stemmer: Boolean to indicate whether to use Porter stemmer for word suffixes
+                              stemmer: bool,
+                              model_id: Optional[str],
+                              batch_size: Optional[int],
+                              add_start_token: Optional[bool],
+                              openai_params: dict,
+                              openai_api_batch_size: int,
+                              use_chat_completion_api: bool,
+                              llm_params: dict,
+                              llm_api_batch_size: int,
+                              score_version: str,
+                              use_previous_conversation: bool) -> None:
     """
-    debug_text = 'the quick brown fox jumped over the lazy dog'
-    debug_data = {
-        'y_test': len(y_test),
-        'y_pred': len(y_pred),
-        'tokenizer_example_output': ' '.join(tokenizer(debug_text)) if tokenizer else debug_text,
-        'smoothing': smoothing,
-        'aggregator': aggregator,
-        'stemmer': stemmer
-    }
-
-    logger.info("Text generation metrics debug: {}".format(debug_data))
-
-
-def validate_qa(y_test: List[Any],
-                y_pred: List[str],
-                metrics: List[str],
-                tokenizer: Any,
-                regexes_to_ignore: List[str],
-                ignore_case: bool,
-                ignore_punctuation: bool,
-                ignore_numbers: bool):
-    """
-    Validate the inputs for QA.
+    Log shapes of chat completion inputs for debugging.
 
     :param y_test: Actual list of list of references
     :param y_pred: Actual list of predictions
-    :param metrics: Metrics to compute.
+    :param metrics: rag-evaluation metrics to compute.
     :param tokenizer: function that takes input a string, and returns a list of tokens
-    :params regexes_to_ignore: List of string regular expressions to ignore
-    :params ignore_case: Boolean to indicate whether to ignore case
-    :params ignore_punctuation: Boolean to indicate whether to ignore punctuation
-    :params ignore_numbers: Boolean to indicate whether to ignore numbers
-    """
-    for metric in metrics:
-        Contract.assert_true(
-            metric in constants.Metric.QA_SET, "Metric {} not a valid QA metric".format(metric),
-            target="metric", reference_code=ReferenceCodes._METRIC_INVALID_QA_METRIC
-        )
-    _check_seq2seq_list_of_str(y_test, 'y_test', reference_code='validate_qa')
-    _check_seq2seq_list_of_str(y_pred, 'y_pred', reference_code='validate_qa')
-    if tokenizer:
-        _check_seq2seq_tokenizer(tokenizer, 'tokenizer', reference_code='validate_qa')
-    if regexes_to_ignore:  # if regexes to ignore is provided, it should be a list of string
-        _check_seq2seq_list_of_str(regexes_to_ignore, 'regexes_to_ignore', reference_code='validate_qa')
-    _check_seq2seq_bool(ignore_case, 'ignore_case', reference_code='validate_qa')
-    _check_seq2seq_bool(ignore_punctuation, 'ignore_punctuation', reference_code='validate_qa')
-    _check_seq2seq_bool(ignore_numbers, 'ignore_numbers', reference_code='validate_qa')
-    Contract.assert_true(len(y_test) == len(y_pred), 'Number of samples in y_test and y_pred do not match',
-                         log_safe=True, reference_code='validate_qa', target='y_test')
-
-
-def log_qa_debug(y_test: List[Any],
-                 y_pred: List[str],
-                 tokenizer: Any,
-                 regexes_to_ignore: List[str],
-                 ignore_case: bool,
-                 ignore_punctuation: bool,
-                 ignore_numbers: bool) -> None:
-    """
-    Log shapes of QA inputs for debugging.
-
-    :param y_test: Actual list of list of references
-    :param y_pred: Actual list of predictions
-    :param tokenizer: function that takes input a string, and returns a list of tokens
-    :params regexes_to_ignore: List of string regular expressions to ignore
-    :params ignore_case: Boolean to indicate whether to ignore case
-    :params ignore_punctuation: Boolean to indicate whether to ignore punctuation
-    :params ignore_numbers: Boolean to indicate whether to ignore numbers
-    """
-    debug_text = 'the quick brown fox jumped over the lazy dog'
-    debug_data = {
-        'y_test': len(y_test),
-        'y_pred': len(y_pred),
-        'tokenizer_example_output': ' '.join(tokenizer(debug_text)) if tokenizer else debug_text,
-        'regexes_to_ignore': ' '.join(regexes_to_ignore) if regexes_to_ignore else '',
-        'ignore_case': ignore_case,
-        'ignore_punctuation': ignore_punctuation,
-        'ignore_numbers': ignore_numbers
-    }
-
-    logger.info("QA metrics debug: {}".format(debug_data))
-
-
-def validate_fill_mask(y_test: List[Any],
-                       y_pred: List[str],
-                       metrics: List[str],
-                       model_id: Optional[str],
-                       batch_size: Optional[int],
-                       add_start_token: Optional[bool], ):
-    """
-    Validate the inputs for QA.
-
-    :param y_test: Actual list of list of references
-    :param y_pred: Actual list of predictions
-    :param metrics: Metrics to compute.
+    :param smoothing: Boolean to indicate whether to smooth out the bleu score
+    :param aggregator: Boolean to indicate whether to aggregate scores
+    :param stemmer: Boolean to indicate whether to use Porter stemmer for word suffixes
     :param model_id: model used for calculating Perplexity.
         Perplexity can only be calculated for causal language models.
-    :param batch_size (int): the batch size to run texts through the model. Defaults to 16.
-    :param add_start_token (bool): whether to add the start token to the texts,
-        so the perplexity can include the probability of the first word. Defaults to True.
-    """
-    for metric in metrics:
-        Contract.assert_true(
-            metric in constants.Metric.FILL_MASK_SET, "Metric {} not a valid Fill Masking metric".format(metric),
-            target="metric", reference_code=ReferenceCodes._METRIC_INVALID_FILL_MASK_METRIC
-        )
-        # Special set metrics do not need ground truths or y_test data
-        if metric not in constants.Metric.FILL_MASK_SPECIAL_SET:
-            _check_seq2seq_list_of_str(y_test, 'y_test', reference_code='validate_fill_mask')
-            Contract.assert_true(len(y_test) == len(y_pred),
-                                 'Number of samples in y_test and y_pred do not match',
-                                 log_safe=True, reference_code='validate_fill_mask', target='y_test')
-
-    _check_seq2seq_list_of_str(y_pred, 'y_pred', reference_code='validate_fill_mask')
-    _check_seq2seq_bool(add_start_token, 'add_start_token', reference_code='validate_fill_mask')
-    _check_seq2seq_str(model_id, 'model_id', reference_code='validate_fill_mask')
-
-
-def log_fill_mask_debug(y_test: List[Any],
-                        y_pred: List[str],
-                        model_id: Optional[str],
-                        batch_size: Optional[int],
-                        add_start_token: Optional[bool], ) -> None:
-    """
-    Log shapes of LM inputs for debugging.
-
-    :param y_test: Actual list of list of references
-    :param y_pred: Actual list of predictions
-    :param model_id: model used for calculating Perplexity.
-                        Perplexity can only be calculated for causal language models.
-    :param batch_size (int): the batch size to run texts through the model. Defaults to 16.
-    :param add_start_token (bool): whether to add the start token to the texts,
+    :param batch_size: (int) the batch size to run texts through the model. Defaults to 16.
+    :param add_start_token: (bool) whether to add the start token to the texts,
         so the perplexity can include the probability of the first word. Defaults to True.
+    :param openai_params: Dictionary containing credentials to initialize or setup LLM
+    :param openai_api_batch_size: number of prompts to be batched in one API call.
+    :param use_chat_completion_api: boolean flag to choose between openAI completion vs chat completion API.
+    :param llm_params: Dictionary containing credentials to initialize or setup LLM
+    :param llm_api_batch_size: number of prompts to be batched in one API call for LLM
+    :param score_version: Version of rag evaluation metrics to be computed
+    :param use_previous_conversation: boolean value to indicate if we need to use_previous_conversation
+             for computing rag-evaluation metrics.
     """
+    debug_text = 'computing evaluation for chat-completion task'
     debug_data = {
-        'y_test': len(y_test) if y_test is not None else 0,
-        'y_pred': len(y_pred),
+        'y_test_length': len(y_test) if y_test is not None else 0,
+        'y_pred_length': len(y_pred),
+        'metrics': metrics,
+        'tokenizer_example_output': ' '.join(tokenizer(debug_text)) if tokenizer else debug_text,
+        'smoothing': smoothing,
+        'aggregator': aggregator,
+        'stemmer': stemmer,
         'model_id': model_id,
         'batch_size': batch_size,
         'add_start_token': add_start_token,
+        'using_openai_api': "yes" if openai_params is not None else "no",
+        'openai_api_batch_size': openai_api_batch_size,
+        'use_chat_completion_api': use_chat_completion_api,
+        'using_llm_deployment_api': "yes" if llm_params is not None else "no",
+        'llm_api_batch_size': llm_api_batch_size,
+        'score_version': score_version,
+        'use_previous_conversation': use_previous_conversation,
     }
 
-    logger.info("Fill Mask metrics debug: {}".format(debug_data))
-
-
-def validate_ner(y_test: Union[List[List[str]], np.ndarray],
-                 y_pred: Union[List[List[str]], np.ndarray],
-                 metrics: List[str]) -> None:
-    """
-    Validate the inputs for scoring text named entity recognition
-
-    :param y_test: Actual list of references
-    :param y_pred: Actual list of predictions
-    :param metrics: Metrics to compute.
-    """
-    for metric in metrics:
-        Contract.assert_true(
-            metric in constants.CLASSIFICATION_NLP_NER_SET, "Metric {} not a valid text-ner metric".format(metric),
-            target="metric", reference_code=ReferenceCodes._METRIC_INVALID_NER_METRIC
-        )
-    _check_seq2seq_list_of_list_of_str(y_test, 'y_test', reference_code='validate_ner')
-    _check_seq2seq_list_of_list_of_str(y_pred, 'y_pred', reference_code='validate_ner')
-
-    Contract.assert_true(len(y_test) == len(y_pred), 'Number of samples in y_test and y_pred do not match',
-                         log_safe=True, reference_code='validate_ner', target='y_test')
-
-    for index, (test, pred) in enumerate(zip(y_test, y_pred)):
-        Contract.assert_true(len(test) == len(pred),
-                             f'Number of labels in test and pred in sample {index + 1} do not match',
-                             log_safe=True, reference_code='validate_ner', target='y_test')
-
-
-def log_ner_debug(y_test: List[List[str]],
-                  y_pred: List[List[str]]) -> None:
-    """
-    Log shapes of text-ner inputs for debugging.
-
-    :param y_test: Actual list of references
-    :param y_pred: Actual list of predictions
-    """
-    debug_data = {
-        'y_test': len(y_test),
-        'y_pred': len(y_pred),
-    }
-
-    logger.info("Text-NER metrics debug: {}".format(debug_data))
+    logger.info("Chat completion metrics debug: {}".format(debug_data))
 
 
 def validate_forecasting(y_test: np.ndarray,
                          y_pred: np.ndarray,
                          metrics: List[str]) -> None:
     """
     Validate the inputs for scoring forecasting.
@@ -719,14 +581,38 @@
     :return: y_test array converted to float, if it comprised of decimals
     """
     if y_test.dtype == object and isinstance(y_test[0], Decimal):
         y_test = y_test.astype(float)
     return y_test
 
 
+def _validate_metrics_list(task_type, metrics, default, ref_code):
+    """
+    Validate metrics list helper for task type.
+
+    :param task_type: Tasks for which metrics have to be verified.
+    :param metrics: Metrics to check.
+    :param default: Default metrics list.
+    """
+    extra_metrics = []
+    for metric in list(metrics):
+        if metric not in default:
+            extra_metrics += [metric]
+            metrics.remove(metric)
+    Contract.assert_true(
+        len(metrics) > 0,
+        "No valid metrics passed for {}. Invalid metrics passed: {}.".format(task_type, ', '.join(extra_metrics)),
+        target="metric", reference_code=ref_code
+    )
+    if len(extra_metrics) > 0:
+        logger.warning("Ignoring invalid metrics passed for {}: {}.".format(task_type, ', '.join(extra_metrics)))
+
+    return metrics
+
+
 def _check_array_values(arr: np.ndarray,
                         name: str,
                         validate_type: bool = True,
                         reference_code: str = None) -> None:
     """
     Check the array for correct types and reasonable values.
 
@@ -855,29 +741,87 @@
     if ignore_none and preds is None:
         return
 
     Contract.assert_value(preds, name, reference_code=reference_code)
     Contract.assert_true(isinstance(preds, list), message="{} must be a list".format(name),
                          target=name, log_safe=True, reference_code=reference_code)
 
+    for idx in range(len(preds)):
+        preds[idx] = _check_seq2seq_str(preds[idx], name + '_value', reference_code=reference_code,
+                                        convert_to_str=True)
+
+
+def _check_seq2seq_list_of_int(preds: Any, name: str, ignore_none: bool = False, reference_code: str = None) -> None:
+    """
+    :param preds: Predictions to validate.
+    :param name: Name of predictions to use in error message.
+    :param ignore_none: Whether to validate predictions as None-type.
+    """
+
+    if ignore_none and preds is None:
+        return
+
+    Contract.assert_value(preds, name, reference_code=reference_code)
+    Contract.assert_true(isinstance(preds, list), message="{} must be a list".format(name),
+                         target=name, log_safe=True, reference_code=reference_code)
+
     for value in preds:
-        _check_seq2seq_str(value, name + '_value', reference_code=reference_code)
+        _check_seq2seq_int(value, name + '_value', reference_code=reference_code)
 
 
-def _check_seq2seq_str(obj: Any, name: str, ignore_none: bool = False, reference_code: str = None) -> None:
+def _check_seq2seq_str(obj: Any, name: str, ignore_none: bool = False, reference_code: str = None,
+                       convert_to_str: bool = False) -> Optional[str]:
     """
     :param obj: Object to validate as string.
     :param name: Name of predictions to use in error message.
     :param ignore_none: Whether to validate predictions as None-type.
     """
     if ignore_none and obj is None:
         return
 
     Contract.assert_value(obj, name, reference_code=reference_code)
-    Contract.assert_true(isinstance(obj, str), message="{} must be a string".format(name),
+    if not convert_to_str:
+        Contract.assert_true(isinstance(obj, str), message="{} must be a string".format(name),
+                             target=name, log_safe=True, reference_code=reference_code)
+
+    if not isinstance(obj, str):
+        try:
+            logger.warning("{} must be a string. Trying to convert {} to str.".format(name, type(obj)))
+            obj = str(obj)
+        except Exception:
+            Contract.assert_true(False, message="{} must be a string".format(name),
+                                 target=name, log_safe=True, reference_code=reference_code)
+    return obj
+
+
+def _check_seq2seq_int(obj: Any, name: str, ignore_none: bool = False, reference_code: str = None) -> None:
+    """
+    :param obj: Object to validate as int.
+    :param name: Name of object to use in error message.
+    :param ignore_none: Whether to validate object as None-type.
+    """
+    if ignore_none and obj is None:
+        return
+
+    Contract.assert_value(obj, name, reference_code=reference_code)
+    Contract.assert_true(isinstance(obj, int), message="{} must be a integer".format(name),
+                         target=name, log_safe=True, reference_code=reference_code)
+
+
+def _check_seq2seq_dict(obj: Any, name: str, ignore_none: bool = False, reference_code: str = None) -> None:
+    """
+    :param obj: Object to validate as dict.
+    :param name: Name of predictions to use in error message.
+    :param ignore_none: Whether to validate predictions as None-type.
+    """
+    if ignore_none and obj is None:
+        return
+
+    Contract.assert_value(obj, name, reference_code=reference_code)
+    Contract.assert_true(isinstance(obj, dict), message="{} must be a dict".format(name),
                          target=name, log_safe=True, reference_code=reference_code)
 
 
 def _check_seq2seq_bool(obj: Any, name: str, ignore_none: bool = False, reference_code: str = None) -> None:
     """
     :param obj: Object to validate as bool.
     :param name: Name of predictions to use in error message.
@@ -902,14 +846,118 @@
     # TBD: Is this check necessary? Will it work for all tokenizers?
     # Check if tokenizer returns list of tokens for a simple text
     text = 'the quick brown fox jumped over the lazy dog'
     tokens = obj(text)
     _check_seq2seq_list_of_str(tokens, name + '_output', reference_code=reference_code)
 
 
+def _check_rag_conversation(obj: Any, name: str, ignore_none: bool = False, reference_code: str = None) -> None:
+    """
+    :param obj: Object to validate as string.
+    :param name: Name of predictions to use in error message.
+    :param ignore_none: Whether to validate predictions as None-type.
+    """
+    if ignore_none and obj is None:
+        return
+
+    Contract.assert_true(isinstance(obj, list), message="{} must be a list".format(name),
+                         target=name, log_safe=True, reference_code=reference_code)
+
+    for conversation_num, conversation in enumerate(obj):
+        Contract.assert_true(isinstance(conversation, list),
+                             message="every conversation must be a list. please check "
+                                     "conversation_number: {}".format(conversation_num + 1),
+                             target=name, log_safe=True, reference_code=reference_code)
+        for turn_num, turn in enumerate(conversation):
+            Contract.assert_true(isinstance(turn, dict),
+                                 message="each turn in the conversation must be a dict. please check "
+                                         "turn_number: {} in conversation_number: {}".format(turn_num + 1,
+                                                                                             conversation_num + 1),
+                                 target=name, log_safe=True, reference_code=reference_code)
+
+            Contract.assert_true('user' in turn and 'assistant' in turn and 'retrieved_documents' in turn,
+                                 message="please ensure to have user, assistant, retrieved_documents keys "
+                                         "in each turn of the conversation.",
+                                 target=name, log_safe=True, reference_code=reference_code)
+
+            Contract.assert_true(isinstance(turn['user'], dict) and isinstance(turn['assistant'], dict),
+                                 message="please ensure to have values of user, assistant as a dict. please check "
+                                         "turn_number: {} in conversation_number: {}".format(turn_num + 1,
+                                                                                             conversation_num + 1),
+                                 target=name, log_safe=True, reference_code=reference_code)
+
+            try:
+                json.loads(turn['retrieved_documents'])
+            except Exception:
+                Contract.assert_true(False,
+                                     message="failed to parse retrieved documents as json. please check "
+                                             "turn_number: {} in conversation_number: {}".format(turn_num + 1,
+                                                                                                 conversation_num + 1),
+                                     target=name, log_safe=True, reference_code=reference_code)
+
+
+def _check_chat_conversation(obj: Any, name: str, ignore_none: bool = False, reference_code: str = None) -> None:
+    """
+    :param obj: Object to validate as string.
+    :param name: Name of predictions to use in error message.
+    :param ignore_none: Whether to validate predictions as None-type.
+    """
+    if ignore_none and obj is None:
+        return
+
+    Contract.assert_true(isinstance(obj, list), message="{} must be a list".format(name),
+                         target=name, log_safe=True, reference_code=reference_code)
+
+    for conversation_num, conversation in enumerate(obj):
+        Contract.assert_true(isinstance(conversation, list) or isinstance(conversation, dict),
+                             message="every conversation must be a list or dictionary. please check "
+                             "conversation_number: {}".format(conversation_num + 1),
+                             target=name, log_safe=True, reference_code=reference_code)
+        # llama format
+        if isinstance(conversation, list):
+            for turn_num, turn in enumerate(conversation):
+                Contract.assert_true(isinstance(turn, dict),
+                                     message="each turn in the conversation must be a dict. please check "
+                                     "turn_number: {} in conversation_number: {}"
+                                     .format(turn_num + 1, conversation_num + 1),
+                                     target=name,
+                                     log_safe=True,
+                                     reference_code=reference_code)
+
+                Contract.assert_true('role' in turn and 'content' in turn,
+                                     message="please ensure to have role, content keys "
+                                     "in each turn of the conversation.",
+                                     target=name, log_safe=True, reference_code=reference_code)
+
+                Contract.assert_true(isinstance(turn['role'], str) and isinstance(turn['content'], str),
+                                     message="please ensure to have values of user, assistant as string. please check "
+                                     "turn_number: {} in conversation_number: {}"
+                                     .format(turn_num + 1, conversation_num + 1),
+                                     target=name,
+                                     log_safe=True,
+                                     reference_code=reference_code)
+
+                Contract.assert_true(turn["role"] in [constants.ChatCompletionConstants.USER_PERSONA,
+                                                      constants.ChatCompletionConstants.ASSISTANT_PERSONA],
+                                     message="please ensure to have only the following roles '{}' or '{}' in "
+                                     "conversation. please check turn_number: {} in "
+                                     "conversation_number: {}"
+                                     .format(constants.ChatCompletionConstants.USER_PERSONA,
+                                             constants.ChatCompletionConstants.ASSISTANT_PERSONA,
+                                             turn_num + 1, conversation_num + 1),
+                                     target=name, log_safe=True, reference_code=reference_code)
+        else:  # openai format
+            Contract.assert_true("conversation" in conversation,
+                                 message="if json format, must have conversation field",
+                                 target=name, log_safe=True, reference_code=reference_code)
+            Contract.assert_true("meta_data" in conversation,
+                                 message="if json format, must have meta_data field",
+                                 target=name, log_safe=True, reference_code=reference_code)
+
+
 def format_1d(arr: np.ndarray,
               name: str) -> np.ndarray:
     """
     Format an array as 1d if possible.
 
     :param arr: The array to reshape.
     :param name: Name of the array to reshape.
```

## Comparing `azureml/metrics/azureml_classification_metrics.py` & `azureml/metrics/text/classification/azureml_classification_metrics.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,36 +1,36 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 """Methods specific to a Classification task type."""
 
 import logging
-from typing import Any, Dict, List, Optional, Callable, Iterator, Union
-
 import numpy as np
 import pandas as pd
-from sklearn.base import TransformerMixin
-from sklearn.preprocessing import MultiLabelBinarizer
+import importlib.util
+from typing import Any, Dict, List, Optional, Callable, Iterator, Union
 
-from azureml.metrics import _scoring, _scoring_confidence, constants, utilities
-from azureml.metrics.azureml_metrics import AzureMLMetrics
-from azureml.metrics._validation import validate_multilabel_binary_format
+from azureml.metrics import constants
+from azureml.metrics.common import _scoring_confidence, _scoring, utilities
+from azureml.metrics.common.azureml_metrics import AzureMLMetrics
+from azureml.metrics.common._validation import validate_multilabel_binary_format
+from azureml.metrics.common.exceptions import MissingDependencies, MetricsException
 
 logger = logging.getLogger(__name__)
 
 
 class AzureMLClassificationMetrics(AzureMLMetrics):
     """Class for AzureML classification metrics."""
 
     def __init__(self,
                  metrics: Optional[List[str]] = None,
                  class_labels: Optional[np.ndarray] = None,
                  train_labels: Optional[np.ndarray] = None,
                  sample_weight: Optional[np.ndarray] = None,
-                 y_transformer: Optional[TransformerMixin] = None,
+                 y_transformer: Optional[Any] = None,
                  use_binary: bool = False,
                  enable_metric_confidence: bool = False,
                  multilabel: Optional[bool] = False,
                  positive_label: Optional[Any] = None,
                  confidence_metrics: Optional[List[str]] = None,
                  custom_dimensions: Optional[Dict[str, Any]] = None,
                  log_activity: Optional[Callable[[logging.Logger, str, Optional[str], Optional[Dict[str, Any]]],
@@ -45,14 +45,15 @@
         :param class_labels: All classes found in the full dataset (includes train/valid/test sets).
             These should be transformed if using a y transformer.
         :param train_labels: Classes as seen (trained on) by the trained model. These values
             should correspond to the columns of y_pred_probs in the correct order.
         :param sample_weight: Weights for the samples (Does not need
             to match sample weights on the fitted model)
         :param y_transformer: Used to inverse transform labels from `y_test`. Required for non-scalar metrics.
+        y_transformer is of type sklearn.base.TransformerMixin
         :param use_binary: Compute metrics only on the true class for binary classification.
         :param enable_metric_confidence: Allow classification metric calculation to include confidence intervals
             This is currently defaulted to False, and will have an automl config setting to enable
         :param multilabel: Indicate if it is multilabel classification.
         :param positive_label: class designed as positive class in binary classification metrics.
         :param confidence_metrics: The list of metrics to compute confidence interval.
             If None, it will take the value of `metrics`
@@ -70,15 +71,15 @@
             :param override_error_msg: The message to display that will override the current error_msg.
             :param is_critical: If is_critical, the logger will use log.critical, otherwise log.error.
             :param tb: The traceback to use for logging; if not provided,
                         the one attached to the exception is used.
         :return: None
         """
         self.metrics = metrics if metrics else constants.Metric.CLASSIFICATION_SET_MULTILABEL \
-            if multilabel else constants.Metric.CLASSIFICATION_SET
+            if multilabel else constants.Metric.CLASSIFICATION_SET_AZURE
         self.enable_metric_confidence = enable_metric_confidence
         if confidence_metrics is None and enable_metric_confidence:
             confidence_metrics = self.metrics
         self.confidence_metrics = confidence_metrics
         self.class_labels = utilities.check_and_convert_to_np(class_labels)
         self.train_labels = utilities.check_and_convert_to_np(train_labels)
         self.sample_weight = utilities.check_and_convert_to_np(sample_weight)
@@ -126,29 +127,38 @@
                                     [0.3, 0.8, 0.6],
                                     [0.1, 0.9, 0.8],
                                     [0.7, 0.1, 0.6]])
         >>>class_labels = np.array([0, 1, 2])
         >>>result = compute_metrics(task_type=constants.Tasks.CLASSIFICATION, y_test=y_test,
                                     y_pred_proba=y_pred_proba, multilabel=True)
         """
+        try:
+            sklearn_spec = importlib.util.find_spec("sklearn")
+            if sklearn_spec is None:
+                raise ImportError
+            from sklearn.preprocessing import MultiLabelBinarizer
+        except ImportError:
+            safe_message = "Tabular packages are not available. " \
+                           "Please run pip install azureml-metrics[tabular]"
+            raise MissingDependencies(
+                safe_message, safe_message=safe_message
+            )
         y_test = utilities.check_and_convert_to_np(y_test)
         y_pred = utilities.check_and_convert_to_np(y_pred)
         y_pred_probs = utilities.check_and_convert_to_np(y_pred_probs)
 
         convert_dtypes = utilities.check_for_different_dtype(y_test, y_pred)
 
         if convert_dtypes:
             y_test, y_pred, self.class_labels, self.train_labels = \
                 utilities.convert_to_same_dtype(y_test, y_pred, self.class_labels, self.train_labels)
 
-
         if y_test is not None and y_pred is not None and self.y_transformer is None:
             if self.multilabel:
-                logger.info("Multilabel is set to True, so we are calculating metrics " +
-                            "for multilabel classification")
+                logger.info("Multilabel is set to True, so we are calculating metrics for multilabel classification")
                 if (validate_multilabel_binary_format(y_test, y_pred, y_pred_probs)):
                     if self.class_labels is None:
                         self.class_labels = np.array(range(len(y_test[0])))
                 else:
                     if self.class_labels is None:
                         y_test_values = utilities.flatten_array_and_remove_duplicates(y_test)
                         y_pred_values = utilities.flatten_array_and_remove_duplicates(y_pred)
@@ -181,37 +191,41 @@
                             self.class_labels = np.array(range(len(arr[0])))
                         else:
                             self.class_labels = np.array(np.unique(y_test))
                 except Exception as e:
                     error_msg = "Unable to interpret class_labels from y_test or y_pred. " + \
                                 "Pass class_labels as additional parameter or " + \
                                 "ensure to check elements of y_test and y_pred have same datatype."
-                    raise Exception(f"{error_msg}\nFound the exception : {e}")
+                    raise MetricsException(f"{error_msg}\nFound the exception : {e}")
 
         if self.train_labels is None:
             self.train_labels = self.class_labels
 
         if (y_pred_probs is not None) and (y_pred is not None):
             if len(self.train_labels) != len(y_pred_probs[0]):
                 y_pred_probs = None
                 logger.warning("Ignoring y_pred_proba as we found mismatch in length"
                                " of class labels identified from y_test, y_pred and y_pred_proba")
 
             elif not self.multilabel:
-                y_pred_from_probs = np.argmax(y_pred_probs, axis=1)
-
-                class_label_map = {key: label for key, label in enumerate(self.class_labels)}
-                y_pred_from_probs = np.array([class_label_map[key] for key in y_pred_from_probs])
-
-                same_prediction = (y_pred == y_pred_from_probs).all()
-                if not same_prediction:
+                try:
+                    y_pred_from_probs = np.argmax(y_pred_probs, axis=1)
+                    class_label_map = {key: label for key, label in enumerate(self.class_labels)}
+                    y_pred_from_probs = np.array([class_label_map[key] for key in y_pred_from_probs])
+
+                    same_prediction = (y_pred == y_pred_from_probs).all()
+                    if not same_prediction:
+                        y_pred_probs = None
+                        logger.warning("Ignoring y_pred_proba as predictions indicated from"
+                                       " y_pred_probs do not equal y_pred. Send class_labels "
+                                       "in same order of y_pred_proba.")
+                except Exception as e:
                     y_pred_probs = None
-                    logger.warning("Ignoring y_pred_proba as predictions indicated from"
-                                   " y_pred_probs do not equal y_pred. Send class_labels "
-                                   "in same order of y_pred_proba.")
+                    logger.warning("Ignoring y_pred_proba as we are not able to parse prediction probabilities "
+                                   "because of the following exception : {}".format(e))
 
         scored_metrics = _scoring._score_classification(
             self._log_activity,
             self._log_traceback,
             y_test,
             y_pred,
             y_pred_probs,
```

## Comparing `azureml/metrics/azureml_forecasting_metrics.py` & `azureml/metrics/tabular/forecasting/azureml_forecasting_metrics.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,21 +1,23 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 """Methods specific to a Foreasting task type."""
-from typing import Any, Callable, Dict, Iterator, List, Optional, Sequence, Tuple, Union
 import logging
-
 import numpy as np
 import pandas as pd
 
-from azureml.metrics import constants, _scoring, utilities
-from azureml.metrics.azureml_metrics import AzureMLMetrics
-from azureml.metrics.contract import Contract
-from azureml.metrics.reference_codes import ReferenceCodes
+from typing import Any, Callable, Dict, Iterator, List, Optional, Sequence, Tuple, Union
+
+from azureml.metrics import constants
+from azureml.metrics.common import _scoring, utilities
+from azureml.metrics.common.azureml_metrics import AzureMLMetrics
+from azureml.metrics.common.contract import Contract
+from azureml.metrics.common.reference_codes import ReferenceCodes
+
 
 logger = logging.getLogger(__name__)
 
 
 class AzureMLForecastingMetrics(AzureMLMetrics):
     """
     Class for AzureML forecasting metrics.
@@ -221,26 +223,27 @@
         :param y_pred: Predictions for each sample.
         :param X_test: The regressors for the test data set. It must align with y_train and
                        to contain time and time series ID.
         :return: The dictionary with metrics and artifacts.
         """
         Contract.assert_true(
             X_test.shape[0] == y_test.shape[0],
-            message="The number of covariates in X_test does not match the numer of targets in y_test.",
+            message="The number of covariates in X_test does not match the number of targets in y_test.",
             target="X_test_y_test_shape", reference_code=ReferenceCodes._METRIC_VALIDATION_TEST_SHAPE_MISMATCH
         )
         y_test = utilities.check_and_convert_to_np(y_test)
         y_pred = utilities.check_and_convert_to_np(y_pred)
         drop_columns = []
         columns_set = set(X_test.columns)
         if X_test.index.names[0]:
             columns_set.update(X_test.index.names)
         old_index = X_test.index.names
         if (self._time_series_id_column_names == [constants._TimeSeriesInternal.DUMMY_GRAIN_COLUMN]):
-            if(constants._TimeSeriesInternal.DUMMY_GRAIN_COLUMN not in X_test.columns
+            if (
+               constants._TimeSeriesInternal.DUMMY_GRAIN_COLUMN not in X_test.columns
                and constants._TimeSeriesInternal.DUMMY_GRAIN_COLUMN not in X_test.index.names):
                 X_test[constants._TimeSeriesInternal.DUMMY_GRAIN_COLUMN] = \
                     constants._TimeSeriesInternal.DUMMY_GRAIN_COLUMN
                 drop_columns.append(constants._TimeSeriesInternal.DUMMY_GRAIN_COLUMN)
         X_test = self._reindex_dataframe_maybe(X_test, self._get_tsds_index(X_test))
         # Remove NaN values from X_test.
         # If predictions or actuals are None, we will raise the error later.
```

## Comparing `azureml/metrics/azureml_od_is_metrics.py` & `azureml/metrics/vision/od_is_eval/azureml_od_is_metrics.py`

 * *Files 5% similar despite different names*

```diff
@@ -3,17 +3,19 @@
 # ---------------------------------------------------------
 """Metric computation for object detection and instance segmentation."""
 
 import logging
 
 from typing import Any, Callable, Dict, Iterator, List, Optional
 
-from azureml.metrics import constants, utilities
-from azureml.metrics.azureml_metrics import AzureMLMetrics
-from azureml.metrics.od_is_eval.incremental_voc_evaluator import IncrementalVocEvaluator
+from azureml.metrics import constants
+from azureml.metrics.common import utilities
+from azureml.metrics.common.azureml_metrics import AzureMLMetrics
+
+from azureml.metrics.common.exceptions import MissingDependencies
 
 
 logger = logging.getLogger(__name__)
 
 
 class AzureMLODISMetrics(AzureMLMetrics):
     """Class for computing object detection and instance segmentation metrics.
@@ -93,14 +95,22 @@
             gt_objects_per_image=y_test,
             predicted_objects_per_image=y_pred,
             meta_info_per_image=image_meta_info,
         )
 
     def reset(self):
         """Reset the intermediate statistics."""
+        try:
+            from azureml.metrics.vision.od_is_eval.incremental_voc_evaluator import IncrementalVocEvaluator
+
+        except (ImportError, MissingDependencies):
+            safe_message = "Vision packages are not available. Please run pip install azureml-metrics[image]"
+            raise MissingDependencies(
+                safe_message, safe_message=safe_message
+            )
 
         self.incremental_voc_evaluator = IncrementalVocEvaluator(
             task_is_detection=self.task_is_detection,
             num_classes=self.num_classes,
             iou_threshold=self.iou_threshold,
         )
```

## Comparing `azureml/metrics/azureml_qa_metrics.py` & `azureml/metrics/text/chat_completion/azureml_chat_completion_metrics.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,103 +1,133 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
-"""Methods specific to Sequence to Sequence QA task type."""
+"""Methods specific to Sequence to Sequence Chat completion task type."""
 
 import logging
 from typing import Any, Dict, List, Optional, Callable, Iterator
 
-from azureml.metrics import _scoring, constants
-from azureml.metrics.azureml_metrics import AzureMLMetrics
+from azureml.metrics import constants
+from azureml.metrics.common import _scoring
+from azureml.metrics.common.azureml_metrics import AzureMLMetrics
 
 logger = logging.getLogger(__name__)
 
 
-class QASplitTokenizer:
-    def __call__(self, line):
-        """Tokenizes an input line using split() on whitespace
-
-        :param line: a segment to tokenize
-        :return: the tokenized line
-        """
-
-        return line.split()
-
-
-class AzureMLQAMetrics(AzureMLMetrics):
+class AzureMLChatCompletionMetrics(AzureMLMetrics):
     def __init__(self,
                  metrics: Optional[List[str]] = None,
                  tokenizer: Optional[Any] = None,
-                 regexes_to_ignore: Optional[List[str]] = None,
-                 ignore_case: Optional[bool] = False,
-                 ignore_punctuation: Optional[bool] = False,
-                 ignore_numbers: Optional[bool] = False,
+                 smoothing: Optional[bool] = False,
+                 aggregator: Optional[bool] = True,
+                 stemmer: Optional[bool] = False,
+                 model_id: Optional[str] = "gpt2",
+                 batch_size: Optional[int] = 16,
+                 add_start_token: Optional[bool] = True,
+                 openai_params: Optional[dict] = None,
+                 openai_api_batch_size: Optional[int] = 20,
+                 use_chat_completion_api: Optional[bool] = None,
+                 llm_params: Optional[dict] = None,
+                 llm_api_batch_size: Optional[int] = 20,
+                 score_version: Optional[str] = "v1",
+                 use_previous_conversation: Optional[bool] = False,
                  custom_dimensions: Optional[Dict[str, Any]] = None,
                  log_activity: Optional[Callable[[logging.Logger, str, Optional[str], Optional[Dict[str, Any]]],
                                                  Iterator[Optional[Any]]]] = None,
                  log_traceback: Optional[Callable[[BaseException, logging.Logger, Optional[str],
                                                    Optional[bool], Optional[Any]], None]] = None) -> None:
         """
         Given the references (groundtruth) and hypothesis (prediction),
-        generate metrics for QA task.
+        generate metrics for Text Generation task.
 
-        :param metrics: Rouge metrics to compute point estimates
+        :param metrics: Rouge and Bleu-N metrics to compute point estimates
         :param tokenizer: function that can tokenize input data
-        :params regexes_to_ignore: List of string regular expressions to ignore
-        :params ignore_case: Boolean to indicate whether to ignore case
-        :params ignore_punctuation: Boolean to indicate whether to ignore punctuation
-        :params ignore_numbers: Boolean to indicate whether to ignore numbers
-        :param custom_dimensions to report the telemetry data.
+        :params smoothing: Boolean to indicate whether to smooth out the bleu score
+        :params aggregator: Boolean to indicate whether to aggregate scores
+        :params stemmer: Boolean to indicate whether to use Porter stemmer for word suffixes
+        :param model_id: model used for calculating Perplexity.
+                         Perplexity can only be calculated for causal language models.
+        :param batch_size (int): the batch size to run texts through the model. Defaults to 16.
+        :param add_start_token (bool): whether to add the start token to the texts,
+            so the perplexity can include the probability of the first word. Defaults to True.
+        :param openai_params: Dictionary containing credentials to initialize or setup LLM
+        :param openai_api_batch_size: number of prompts to be batched in one API call.
+        :param use_chat_completion_api: boolean flag to choose between openAI completion vs chat completion API.
+        :param llm_params: Dictionary containing credentials to initialize or setup LLM
+        :param llm_api_batch_size: number of prompts to be batched in one API call for LLM
+        :param score_version: Version of rag evaluation metrics to be computed
+        :param use_previous_conversation: boolean value to indicate if we need to use_previous_conversation
+             for computing rag-evaluation metrics.
         :param log_activity is a callback to log the activity with parameters
             :param logger: logger
             :param activity_name: activity name
             :param activity_type: activity type
             :param custom_dimensions: custom dimensions
         :param log_traceback is a callback to log exception traces. with parameters
             :param exception: The exception to log.
             :param logger: The logger to use.
             :param override_error_msg: The message to display that will override the current error_msg.
             :param is_critical: If is_critical, the logger will use log.critical, otherwise log.error.
             :param tb: The traceback to use for logging; if not provided,
                         the one attached to the exception is used.
         :return: None
         """
-        self.metrics = metrics if metrics else constants.Metric.QA_SET
-        self.tokenizer = tokenizer if tokenizer else QASplitTokenizer()
-        self.regexes_to_ignore = regexes_to_ignore
-        self.ignore_case = ignore_case
-        self.ignore_punctuation = ignore_punctuation
-        self.ignore_numbers = ignore_numbers
+        self.metrics = metrics if metrics \
+            else constants.Metric.CHAT_COMPLETION_SET if openai_params is not None \
+            else constants.Metric.CHAT_COMPLETION_NONGPT_SET
+        self.tokenizer = tokenizer
+        self.smoothing = smoothing
+        self.aggregator = aggregator
+        self.stemmer = stemmer
+        self.model_id = model_id
+        self.batch_size = batch_size
+        self.add_start_token = add_start_token
+        self.openai_params = openai_params
+        self.openai_api_batch_size = openai_api_batch_size
+        self.use_chat_completion_api = use_chat_completion_api
+        self.llm_params = llm_params
+        self.llm_api_batch_size = llm_api_batch_size
+        self.score_version = score_version
+        self.use_previous_conversation = use_previous_conversation
         self.__custom_dimensions = custom_dimensions
         super().__init__(log_activity, log_traceback)
 
     def compute(self, y_test: List[Any], y_pred: List[str]) -> Dict[str, Dict[str, Any]]:
         """
-        Compute all metrics for QA task based on the config.
+        Compute all metrics for Chat completion task based on the config.
 
         :param y_test: Actual list of list of references
         :param y_pred: Actual list of predictions
         :return: Dict of computed metrics
         """
-        scored_metrics = _scoring._score_qa(
+        scored_metrics = _scoring._score_chat_completion(
             self._log_activity,
             self._log_traceback,
             y_test,
             y_pred,
             self.metrics,
             self.tokenizer,
-            self.regexes_to_ignore,
-            self.ignore_case,
-            self.ignore_punctuation,
-            self.ignore_numbers
+            self.smoothing,
+            self.aggregator,
+            self.stemmer,
+            self.model_id,
+            self.batch_size,
+            self.add_start_token,
+            self.openai_params,
+            self.openai_api_batch_size,
+            self.use_chat_completion_api,
+            self.llm_params,
+            self.llm_api_batch_size,
+            self.score_version,
+            self.use_previous_conversation
         )
 
         return scored_metrics
 
     @staticmethod
     def list_metrics():
         """Get the list of supported metrics.
 
             :return: List of supported metrics.
         """
-        supported_metrics = constants.Metric.QA_SET
+        supported_metrics = constants.Metric.CHAT_COMPLETION_SET
         return supported_metrics
```

## Comparing `azureml/metrics/azureml_regression_metrics.py` & `azureml/metrics/tabular/regression/azureml_regression_metrics.py`

 * *Files 1% similar despite different names*

```diff
@@ -1,21 +1,22 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 """Methods specific to a Regression task type."""
 
 import logging
-from typing import Any, Dict, List, Optional, Iterator, Callable, Union
-
 import numpy as np
 import pandas as pd
+from typing import Any, Dict, List, Optional, Iterator, Callable, Union
+
+from azureml.metrics import constants
+from azureml.metrics.common import _scoring_confidence, _scoring, utilities
+from azureml.metrics.tabular.regression._dataset_binning import make_dataset_bins
+from azureml.metrics.common.azureml_metrics import AzureMLMetrics
 
-from azureml.metrics import _scoring_confidence, constants, _scoring, utilities
-from azureml.metrics._dataset_binning import make_dataset_bins
-from azureml.metrics.azureml_metrics import AzureMLMetrics
 
 logger = logging.getLogger(__name__)
 
 
 class AzureMLRegressionMetrics(AzureMLMetrics):
     """Class for AzureML regression metrics."""
```

## Comparing `azureml/metrics/contract.py` & `azureml/metrics/common/contract.py`

 * *Files 2% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 """Metric contracts."""
 
 import logging
 from typing import Any, List, Optional
 
-from azureml.metrics.exceptions import InvalidOperationException, InvalidValueException
+from azureml.metrics.common.exceptions import InvalidOperationException, InvalidValueException
 
 logger = logging.getLogger(__name__)
 
 
 class Contract:
     """Class with helper methods to enforce and validate system invariants.
 
@@ -27,15 +27,15 @@
             log_safe: bool = False,
     ) -> None:
         """
         Assert that the provided condition evaluates to True.
 
         :param condition: The condition to evaluate, should result in a boolean.
         :param message: The assertion message that explains the condition when the assertion evaluates to False.
-        :param target: The name of the element (e.g. argument) that caused the error.
+        :param target: The metric_name of the element (e.g. argument) that caused the error.
         :param reference_code: A string that a developer or the user can use to get further context on the error.
         :param log_safe: If the assertion message is safe to log. Defaults to False.
         :return: None
         """
         if not condition:
             log_safe_exception_message = Contract._build_assertion_message(
                 "Invalid Operation", target, reference_code
@@ -56,15 +56,15 @@
             reference_code: Optional[str] = None,
             log_safe: bool = False,
     ) -> None:
         """
         Assert that the value is non-null, fails otherwise. For also checking for empty strings or lists.
 
         :param value: The object that should be evaluated for the null check.
-        :param name: The name of the object.
+        :param name: The metric_name of the object.
         :param valid_values: An optional list of values to verify the validity of the 'value' against.
         :param reference_code: A string that a developer or the user can use to get further context on the error.
         :param log_safe: If the assertion message is safe to log. Defaults to True.
         :return: None
         """
         assert_failed = False
         if value is None:
```

## Comparing `azureml/metrics/scoring.py` & `azureml/metrics/common/scoring.py`

 * *Files identical despite different names*

## Comparing `azureml/metrics/utilities.py` & `azureml/metrics/common/utilities.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,35 +1,41 @@
 # ---------------------------------------------------------
 # Copyright (c) Microsoft Corporation. All rights reserved.
 # ---------------------------------------------------------
 """Utilities for computing model evaluation metrics."""
-from typing import Any, Dict, List, Optional, Tuple, Union
-
 import numpy as np
 import pandas as pd
 import logging
+import time
+import uuid
+
+from typing import Any, Dict, List, Optional, Tuple, Union
+from time import gmtime, strftime
 
 from azureml.metrics import constants
-from azureml.metrics.exceptions import ClientException
+from azureml.metrics.common.azureml_custom_prompt_metric import AzureMLCustomPromptMetric
+from azureml.metrics.common.exceptions import ClientException, HFEvaluateClientException, \
+    MissingDependencies, DataErrorException
+from azureml.metrics.common._logging_utils import default_log_activity, default_log_traceback
 
 
-logger = logging.getLogger(__name__)
+logger = logging.getLogger(constants.TelemetryConstants.APP_NAME)
 
 
 def get_metric_task(metric: str) -> str:
     """
     Get the task for a given metric.
 
     :param metric: The metric to lookup.
     :return: The task type for the given metric.
     """
-    if metric in constants.CLASSIFICATION_SET:
-        return constants.CLASSIFICATION
-    elif metric in constants.REGRESSION_SET:
-        return constants.REGRESSION
+    if metric in constants.Metric.CLASSIFICATION_SET:
+        return constants.Tasks.CLASSIFICATION
+    elif metric in constants.Metric.REGRESSION_SET:
+        return constants.Tasks.REGRESSION
     safe_message = "Metric {} not found".format(metric)
     raise ClientException(safe_message, target="metric_name", reference_code="utilities.get_metric_task",
                           safe_message=safe_message)
 
 
 def minimize_or_maximize(metric: str,
                          task: Optional[str] = None) -> str:
@@ -100,15 +106,15 @@
     :return: Dictionary from metric names to the worst scores.
     """
     minimums, maximums = get_metric_ranges(task)
     task_objectives = constants.OBJECTIVES_TASK_MAP[task]
 
     worst_scores = dict()
     for metric_name, objective in task_objectives.items():
-        if metric_name == constants.TRAIN_TIME:
+        if metric_name == constants.TrainingResultsType.TRAIN_TIME:
             worst_scores[metric_name] = constants.SCORE_UPPER_BOUND
             continue
 
         if objective == constants.MAXIMIZE:
             worst_scores[metric_name] = minimums[metric_name]
         else:
             worst_scores[metric_name] = maximums[metric_name]
@@ -177,49 +183,58 @@
 def get_scalar_metrics(task: str) -> List[str]:
     """Get the scalar metrics supported for a given task.
 
     :param task: Task string, (e.g. "classification" or "regression")
     :return: List of the default metrics supported for the task
     """
     return {
-        constants.CLASSIFICATION: list(constants.CLASSIFICATION_SCALAR_SET),
-        constants.REGRESSION: list(constants.REGRESSION_SCALAR_SET),
+        constants.Tasks.CLASSIFICATION: list(constants.Metric.SCALAR_CLASSIFICATION_SET),
+        constants.Tasks.REGRESSION: list(constants.Metric.SCALAR_REGRESSION_SET),
     }[task]
 
 
 def get_default_metrics(task: str) -> List[str]:
     """Get the metrics supported for a given task as a set.
 
     :param task: Task string, (e.g. "classification" or "regression")
     :return: List of the default metrics supported for the task
     """
     return {
-        constants.CLASSIFICATION: list(constants.CLASSIFICATION_SET
-                                       - constants.UNSUPPORTED_CLASSIFICATION_TABULAR_SET),
-        constants.REGRESSION: list(constants.REGRESSION_SET),
+        constants.Tasks.CLASSIFICATION: list(constants.Metric.CLASSIFICATION_SET
+                                             - constants.Metric.UNSUPPORTED_CLASSIFICATION_TABULAR_SET),
+        constants.Tasks.REGRESSION: list(constants.Metric.REGRESSION_SET),
     }[task]
 
 
-def is_scalar(metric_name: str) -> bool:
+def is_scalar(metric_name: str, metric_value: Any = None) -> bool:
     """
     Check whether a given metric is scalar or nonscalar.
 
     :param metric_name: the name of the metric found in constants.py
+    :param metric_value: the value of metric computed
     :return: boolean for if the metric is scalar
     """
     if metric_name.endswith(constants.MetricExtrasConstants.MetricExtrasSuffix):
         metric_name = metric_name[:-len(constants.MetricExtrasConstants.MetricExtrasSuffix)]
-    if metric_name in constants.FULL_SCALAR_SET or \
-            metric_name in constants.CLASSIFICATION_MULTILABEL_SET or \
-            metric_name in constants.Metric.SCALAR_SEQ2SEQ_SET:
+    if metric_name in constants.FULL_SCALAR_SET:
+        # only scalar values are expected in "metrics" and non scalar values can be in "artifacts"
+        if metric_value is not None and isinstance(metric_value, List):
+            return False
+        return True
+    # accepting pass@k metrics as scalar metrics.
+    # added the condition check as 'k' value can be variable.
+    elif constants.CodeGenerationConstants.CODE_GENERATION_PREFIX in metric_name:
         return True
     elif metric_name in constants.FULL_NONSCALAR_SET:
         return False
     elif metric_name in constants.FULL_CLASSWISE_SET:
         return False
+    elif metric_name in [constants.ChatCompletionConstants.CONVERSATION_NUMBER,
+                         constants.ChatCompletionConstants.TURN_NUMBER]:
+        return False
     safe_message = "{} metric is not supported".format(metric_name)
     raise ClientException(safe_message, target="metric_name", reference_code="utilities.is_scalar",
                           safe_message=safe_message)
 
 
 def is_classwise(metric_name: str) -> bool:
     """
@@ -233,33 +248,75 @@
     else:
         return False
     safe_message = "{} metric is not supported".format(metric_name)
     raise ClientException(safe_message, target="metric_name", reference_code="utilities.is_classwise",
                           safe_message=safe_message)
 
 
-def segregate_scalar_non_scalar(metrics: Dict[str, Any]) -> Dict[str, Dict[str, Any]]:
+def segregate_scalar_non_scalar(metrics: Dict[str, Any], task_type: str = None) -> Dict[str, Dict[str, Any]]:
     metrics_result: Dict[str, Dict[str, Any]] = {
         constants.Metric.Metrics: dict(),
         constants.Metric.Artifacts: dict()
     }
     for metric_name, metric_value in metrics.items():
-        if is_scalar(metric_name):
+        try:
+            # Metrics to be aggregated
+            aggregate_metric_scores(metric_name, metric_value, metrics_result, task_type)
+        except Exception as e:
+            logger.warning("Failed to aggregate the scores for metric : {} "
+                           "with the following exception : {}".format(metric_name, e))
+
+        if is_scalar(metric_name, metric_value):
             metrics_result[constants.Metric.Metrics][metric_name] = metric_value
         else:
             metrics_result[constants.Metric.Artifacts][metric_name] = metric_value
     return metrics_result
 
 
+def aggregate_metric_scores(metric_name, metric_value, metrics_result, task_type=None):
+    """Helper function to aggregate the possible artifact metrics"""
+    if metric_name in constants.Metric.NONSCALAR_RAG_EVALUATION_SET and \
+            task_type in [constants.Tasks.CHAT_COMPLETION, constants.Tasks.RAG_EVALUATION]:
+        if isinstance(metric_value, dict):
+            mean_metric_name = constants.MetricExtrasConstants.MeanExtrasFormat.format(metric_name)
+            metrics_result[constants.Metric.Metrics][mean_metric_name] = np.nanmean(
+                metric_value[constants.ChatCompletionConstants.SCORE_PER_CONVERSATION])
+
+    elif metric_name in constants.Metric.NON_AGGREGATED_METRICS:
+        if isinstance(metric_value, list):
+            first_element = metric_value[0] if metric_value else None
+            if isinstance(first_element, str):  # convert list of string to list of numbers
+                metric_value = [float(x) for x in metric_value if x.replace(".", "", 1).isdigit()]
+            mean_metric_name = constants.MetricExtrasConstants.MeanExtrasFormat.format(metric_name)
+            median_metric_name = constants.MetricExtrasConstants.MedianExtrasFormat.format(metric_name)
+            metrics_result[constants.Metric.Metrics][mean_metric_name] = np.nanmean(metric_value)
+            metrics_result[constants.Metric.Metrics][median_metric_name] = np.nanmedian(metric_value)
+        elif isinstance(metric_value, dict):
+            for key, value in metric_value.items():
+                if isinstance(value, list):
+                    mean_metric_name = constants.MetricExtrasConstants.MeanExtrasDictFormat.format(metric_name, key)
+                    metrics_result[constants.Metric.Metrics][mean_metric_name] = np.nanmean(value)
+
+
 def amalgamate_scalar_non_scalar(metrics: Dict[str, Dict[str, Any]]) -> Dict[str, Any]:
     if constants.Metric.Metrics in metrics and constants.Metric.Artifacts in metrics:
         return {**metrics[constants.Metric.Metrics], **metrics[constants.Metric.Artifacts]}
     return {}
 
 
+def concatenate_calculated_metrics(calculated_metrics_list: List[Dict]) -> Dict[str, Any]:
+    computed_metrics = {"metrics": {}, "artifacts": {}}
+
+    for calculated_metric in calculated_metrics_list:
+        for key, value in calculated_metric.items():
+            computed_metrics[key].update(value)
+
+    return computed_metrics
+
+
 def check_and_convert_to_np(arr: Optional[Union[np.ndarray, pd.DataFrame, List]]):
     if arr is not None:
         if isinstance(arr, pd.DataFrame):
             if len(arr.columns) == 1:
                 return arr.iloc[:, 0].to_numpy()
             else:
                 return arr.to_numpy()
@@ -281,15 +338,15 @@
     if ((isinstance(y_test, np.ndarray) and len(y_test) >= 1)
             and (isinstance(y_pred, np.ndarray) and len(y_pred) >= 1)):
 
         y_test_dtype = check_homogeneous_type(y_test)
         y_pred_dtype = check_homogeneous_type(y_pred)
 
         if y_test_dtype is False or y_pred_dtype is False:
-            raise Exception("y_test or y_pred are having mix of labels with different datatype.")
+            raise DataErrorException("y_test or y_pred are having mix of labels with different datatype.")
 
         elif y_test_dtype != y_pred_dtype and y_pred.ndim == 1:
             return True
 
     return False
 
 
@@ -331,7 +388,109 @@
                 if value is not None:
                     values_list.append(value)
         elif row is not None:
             values_list.append(row)
 
     values = set(values_list)
     return values
+
+
+def get_supported_metrics(kwargs, special_metric_set):
+    metrics_list = kwargs.get("metrics", set())
+    supported_metrics_list = set(metrics_list).intersection(special_metric_set)
+    kwargs["metrics"] = [metric for metric in special_metric_set] \
+        if len(supported_metrics_list) == 0 else supported_metrics_list
+    logger.warning(f"Computing metrics for {kwargs['metrics']} as y_test is None.")
+
+
+def retry(max_attempts, delay):
+    def decorator_retry(func):
+        def wrapper_retry(*args, **kwargs):
+            attempts = 0
+            while attempts < max_attempts:
+                try:
+                    result = func(*args, **kwargs)
+                    return result
+                except MissingDependencies:
+                    # safe_message = "required packages are not available in the current environment."
+                    # raise MissingDependencies(
+                    #     safe_message, safe_message=safe_message
+                    # )
+                    raise
+                except Exception as e:
+                    logger.warning("Failed to load metric from HuggingFace Evaluate: {}. "
+                                   "Trying again in {} seconds. Remaining {} "
+                                   "attempts".format(str(e), delay, max_attempts - attempts - 1))
+                    attempts += 1
+                    time.sleep(delay)
+            safe_message = "Failed to load metric from Hugging Face Evaluate after maximum retry " \
+                           "attempts. Please try again after sometime."
+            raise HFEvaluateClientException(safe_message, target="metric_name", reference_code="utilities.retry",
+                                            safe_message=safe_message)
+        return wrapper_retry
+    return decorator_retry
+
+
+def check_kwargs(kwargs: Dict, task_type: constants.Tasks, task_type_args: List[str]) -> None:
+    """Check for presence of any additional kwargs which are unrelated/typos.
+
+        :param kwargs: additional/ununsed keyword arguments.
+        :param task_type: Accepts an argument of type constants.Tasks for which metrics have to be computed.
+            Can accept from any of the values constants.Tasks.CLASSIFICATION, constants.Tasks.REGRESSION,
+            constants.Tasks.TEXT_CLASSIFICATION, constants.Tasks.TEXT_CLASSIFICATION_MULTILABEL,
+            constants.Tasks.TEXT_NER.
+        :param task_type_args: keyword arguments based on task type.
+    """
+    if len(kwargs) > 0:
+        unused_keys = list(kwargs.keys())
+        warning_message = f"We have unused keyword arguments : {unused_keys}\n" + \
+                          f"Applicable keyword arguments for {task_type} are {task_type_args}."
+
+        logger.warning(warning_message)
+
+
+def extract_common_kwargs(kwargs, task_type=None):
+    metrics_run_id = str(uuid.uuid4())
+    current_timestamp = strftime("%Y-%m-%d %H:%M:%S", gmtime())
+
+    # Reading common keyword arguments related to telemetry
+    metrics_custom_dimensions = {
+        "app_name": constants.TelemetryConstants.APP_NAME,
+        "task_type": task_type,
+        "azureml_metrics_run_id": metrics_run_id,
+        "current_timestamp": current_timestamp,
+    }
+
+    custom_dimensions = kwargs.pop('custom_dimensions', metrics_custom_dimensions)
+    # TODO: use only default_log_activity and default_log_traceback
+    # log_activity = kwargs.pop('log_activity', default_log_activity)
+    # log_traceback = kwargs.pop('log_traceback', default_log_traceback)
+    common_args = ["custom_dimensions", "log_activity", "log_traceback"]
+    return common_args, custom_dimensions, default_log_activity, default_log_traceback
+
+
+def compute_custom_prompt_metrics(kwargs):
+    """Helper method to compute custom prompt metrics"""
+    metrics_list = kwargs.get("metrics", None)
+    custom_prompt_metric_results = []
+
+    if metrics_list is None or not isinstance(metrics_list, list):
+        return {}
+    elif len(metrics_list) == 0:
+        return {}
+
+    custom_prompt_metrics = [metric for metric in metrics_list if isinstance(metric, AzureMLCustomPromptMetric)]
+
+    # remove custom prompt metrics from the metrics list
+    metrics_list = [metric for metric in metrics_list if not isinstance(metric, AzureMLCustomPromptMetric)]
+    kwargs["metrics"] = metrics_list
+
+    # return empty dict if no custom prompt metrics are present
+    if len(custom_prompt_metrics) == 0:
+        return {}
+
+    else:
+        for metric in custom_prompt_metrics:
+            current_metric_results = metric.compute(**kwargs)
+            custom_prompt_metric_results.append(current_metric_results)
+
+    return concatenate_calculated_metrics(custom_prompt_metric_results)
```

## Comparing `azureml/metrics/od_is_eval/incremental_voc_evaluator.py` & `azureml/metrics/vision/od_is_eval/incremental_voc_evaluator.py`

 * *Files 3% similar despite different names*

```diff
@@ -7,16 +7,25 @@
 import itertools
 import logging
 import numpy as np
 
 from typing import Any, Dict, List
 
 from azureml.metrics.constants import Metric as MetricsLiterals
-from azureml.metrics.od_is_eval.metric_computation_utils import calculate_confusion_matrices, \
-    calculate_pr_metrics, match_objects, EPSILON, UNASSIGNED
+from azureml.metrics.common.exceptions import MissingDependencies
+
+try:
+    from azureml.metrics.vision.od_is_eval.metric_computation_utils import calculate_confusion_matrices, \
+        calculate_pr_metrics, match_objects, EPSILON, UNASSIGNED
+
+except ImportError:
+    safe_message = "Vision packages are not available. Please run pip install azureml-metrics[image]"
+    raise MissingDependencies(
+        safe_message, safe_message=safe_message
+    )
 
 
 logger = logging.getLogger(__name__)
 
 
 class IncrementalVocEvaluator:
     """
@@ -221,23 +230,28 @@
 
         if self._task_is_detection:
             # Image level metrics and confusion matrices for object detection.
 
             # Calculate the image level metrics.
             image_level_metrics = {
                 MetricsLiterals.IMAGE_LEVEL_BINARY_CLASSIFIER_METRICS: calculate_pr_metrics(
-                    self._num_images_with_gt_objects, np.concatenate(all_tp_fp_labels), np.concatenate(all_scores),
-                    np.concatenate(all_image_indexes), False, self.UNDEFINED_METRIC_VALUE
+                    self._num_images_with_gt_objects,
+                    np.concatenate([np.zeros((0,), dtype=np.uint8)] + all_tp_fp_labels),
+                    np.concatenate([np.zeros((0,))] + all_scores),
+                    np.concatenate([np.zeros((0,), dtype=np.uint32)] + all_image_indexes),
+                    False,
+                    self.UNDEFINED_METRIC_VALUE
                 )
             }
 
             # Calculate the confusion matrices at representative scores.
             confusion_matrix_metrics = {
                 MetricsLiterals.CONFUSION_MATRICES_PER_SCORE_THRESHOLD: calculate_confusion_matrices(
-                    self._num_gt_objects_per_class, np.concatenate(self._all_matched_classes_and_scores)
+                    self._num_gt_objects_per_class,
+                    np.concatenate([np.zeros((0, 3), dtype=np.float32)] + self._all_matched_classes_and_scores)
                 )
             }
 
         else:
             # No image level metrics or confusion matrices for instance segmentation.
             image_level_metrics = {}
             confusion_matrix_metrics = {}
```

## Comparing `azureml/metrics/od_is_eval/metric_computation_utils.py` & `azureml/metrics/vision/od_is_eval/metric_computation_utils.py`

 * *Files 2% similar despite different names*

```diff
@@ -3,18 +3,17 @@
 # ---------------------------------------------------------
 
 """Implementation details: mAP score computation functions."""
 
 import logging
 import numpy as np
 
-from pycocotools import mask as pycoco_mask
-
 from azureml.metrics.constants import Metric as MetricsLiterals
-from azureml.metrics.exceptions import ValidationException
+from azureml.metrics.common.exceptions import ValidationException
+from azureml.metrics.common.exceptions import MissingDependencies
 
 
 # Codes for TP, FP, other.
 _TP_CODE, _FP_CODE, _OTHER_CODE = 1, 0, 2
 
 # Score thresholds at which to compute confusion matrices.
 _SCORE_THRESHOLDS = [(i / 10.0) for i in range(10)]
@@ -133,14 +132,22 @@
     :type predicted_scores: numpy.ndarray of shape (n)
     :param iou_threshold: IOU threshold for deciding whether two objects match.
     :type iou_threshold: float
     :return: For each predicted object, a TP/FP/other label and the index of the assigned ground truth object/an
         invalid index if unassigned.
     :rtype: two numpy.ndarray's of shape (n) with int codes
     """
+    try:
+        from pycocotools import mask as pycoco_mask
+
+    except ImportError:
+        safe_message = "Vision packages are not available. Please run pip install azureml-metrics[image]"
+        raise MissingDependencies(
+            safe_message, safe_message=safe_message
+        )
 
     # Get the number of ground truth and predicted objects.
     m, n = len(gt_supports), len(predicted_supports)
 
     # Initialize the TP/FP/other label vector to all FP and the ground truth index vector to all invalid.
     tp_fp_labels = _FP_CODE * np.ones((n,), dtype=np.uint8)
     predicted_assignment = UNASSIGNED * np.ones((n,), dtype=np.int32)
```

## Comparing `azureml_metrics-0.0.9.dist-info/LICENSE.txt` & `azureml_metrics-47.0.0.dist-info/LICENSE.txt`

 * *Files identical despite different names*

