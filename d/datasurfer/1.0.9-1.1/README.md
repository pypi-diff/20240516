# Comparing `tmp/datasurfer-1.0.9-py2.py3-none-any.whl.zip` & `tmp/datasurfer-1.1-py2.py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,8 +1,8 @@
-Zip file size: 151600 bytes, number of entries: 50
+Zip file size: 171165 bytes, number of entries: 65
 -rw-rw-rw-  2.0 fat    40406 b- defN 24-Jan-15 14:20 datastructure/Plot_Collections.py
 -rw-rw-rw-  2.0 fat    27117 b- defN 24-Feb-27 17:24 datastructure/Plot_IDIADA.py
 -rw-rw-rw-  2.0 fat      259 b- defN 24-Mar-06 09:10 datastructure/__init__.py
 -rw-rw-rw-  2.0 fat    29177 b- defN 24-Mar-06 09:10 datastructure/datainterface.py
 -rw-rw-rw-  2.0 fat    10271 b- defN 24-Mar-06 09:10 datastructure/datalake.py
 -rw-rw-rw-  2.0 fat    56915 b- defN 24-Feb-08 14:05 datastructure/dataobjects.py
 -rw-rw-rw-  2.0 fat    48434 b- defN 24-Mar-06 09:10 datastructure/datapool.py
@@ -14,39 +14,54 @@
 -rw-rw-rw-  2.0 fat     3021 b- defN 24-Feb-27 17:24 datastructure/lib_objects/data_object.py
 -rw-rw-rw-  2.0 fat     2211 b- defN 24-Feb-27 17:24 datastructure/lib_objects/finance_object.py
 -rw-rw-rw-  2.0 fat     2862 b- defN 24-Feb-27 17:24 datastructure/lib_objects/matlab_object.py
 -rw-rw-rw-  2.0 fat     6114 b- defN 24-Mar-06 09:10 datastructure/lib_objects/mdf_object.py
 -rw-rw-rw-  2.0 fat     1624 b- defN 24-Feb-27 17:24 datastructure/lib_objects/pandas_object.py
 -rw-rw-rw-  2.0 fat    40406 b- defN 24-Mar-06 13:39 datasurfer/Plot_Collections.py
 -rw-rw-rw-  2.0 fat    27117 b- defN 24-Mar-06 13:39 datasurfer/Plot_IDIADA.py
--rw-rw-rw-  2.0 fat      306 b- defN 24-Apr-03 09:04 datasurfer/__init__.py
--rw-rw-rw-  2.0 fat    33171 b- defN 24-Mar-21 20:31 datasurfer/datainterface.py
--rw-rw-rw-  2.0 fat    16163 b- defN 24-Apr-03 09:04 datasurfer/datalake.py
--rw-rw-rw-  2.0 fat    51607 b- defN 24-Apr-03 12:56 datasurfer/datapool.py
--rw-rw-rw-  2.0 fat    15464 b- defN 24-Apr-03 15:20 datasurfer/datautils.py
--rw-rw-rw-  2.0 fat     2453 b- defN 24-Apr-03 14:00 datasurfer/lib_mlearn/__init__.py
--rw-rw-rw-  2.0 fat      227 b- defN 24-Apr-03 12:52 datasurfer/lib_mlearn/preproc.py
--rw-rw-rw-  2.0 fat    29556 b- defN 24-Apr-03 09:04 datasurfer/lib_objects/__init__.py
--rw-rw-rw-  2.0 fat     5503 b- defN 24-Apr-03 20:43 datasurfer/lib_objects/amedata_object.py
--rw-rw-rw-  2.0 fat     4037 b- defN 24-Apr-03 09:04 datasurfer/lib_objects/amegp_object.py
--rw-rw-rw-  2.0 fat     7723 b- defN 24-Apr-03 18:53 datasurfer/lib_objects/ameres_object.py
--rw-rw-rw-  2.0 fat     8510 b- defN 24-Apr-03 09:04 datasurfer/lib_objects/asammdf_object.py
+-rw-rw-rw-  2.0 fat     5456 b- defN 24-May-08 08:06 datasurfer/__init__.py
+-rw-rw-rw-  2.0 fat    35899 b- defN 24-May-15 09:09 datasurfer/datainterface.py
+-rw-rw-rw-  2.0 fat    18028 b- defN 24-May-16 12:16 datasurfer/datalake.py
+-rw-rw-rw-  2.0 fat    63805 b- defN 24-May-16 12:16 datasurfer/datapool.py
+-rw-rw-rw-  2.0 fat    16710 b- defN 24-May-14 12:31 datasurfer/datautils.py
+-rw-rw-rw-  2.0 fat        0 b- defN 24-May-07 21:28 datasurfer/lib_dlearn/__init__.py
+-rw-rw-rw-  2.0 fat     4391 b- defN 24-May-07 21:28 datasurfer/lib_mlearn/__init__.py
+-rw-rw-rw-  2.0 fat     1866 b- defN 24-May-07 21:28 datasurfer/lib_mlearn/clustering.py
+-rw-rw-rw-  2.0 fat      220 b- defN 24-May-07 21:28 datasurfer/lib_mlearn/preproc.py
+-rw-rw-rw-  2.0 fat        0 b- defN 24-May-07 21:28 datasurfer/lib_objects/__init__.py
+-rw-rw-rw-  2.0 fat     5529 b- defN 24-May-07 21:28 datasurfer/lib_objects/amedata_object.py
+-rw-rw-rw-  2.0 fat     4058 b- defN 24-May-07 21:28 datasurfer/lib_objects/amegp_object.py
+-rw-rw-rw-  2.0 fat     8009 b- defN 24-May-08 10:34 datasurfer/lib_objects/ameres_object.py
+-rw-rw-rw-  2.0 fat     8657 b- defN 24-May-08 15:16 datasurfer/lib_objects/asammdf_object.py
 -rw-rw-rw-  2.0 fat     3028 b- defN 24-Apr-03 09:04 datasurfer/lib_objects/data_object.py
--rw-rw-rw-  2.0 fat     2229 b- defN 24-Apr-03 09:04 datasurfer/lib_objects/finance_object.py
--rw-rw-rw-  2.0 fat     1292 b- defN 24-Apr-03 09:04 datasurfer/lib_objects/json_object.py
--rw-rw-rw-  2.0 fat     3188 b- defN 24-Apr-03 09:04 datasurfer/lib_objects/matlab_object.py
--rw-rw-rw-  2.0 fat     6040 b- defN 24-Apr-03 09:04 datasurfer/lib_objects/mdf_object.py
--rw-rw-rw-  2.0 fat     1852 b- defN 24-Apr-03 09:04 datasurfer/lib_objects/pandas_object.py
--rw-rw-rw-  2.0 fat     2426 b- defN 24-Apr-03 21:02 datasurfer/lib_objects/xkf_object.py
--rw-rw-rw-  2.0 fat    11502 b- defN 24-Apr-03 09:04 datasurfer/lib_plots/__init__.py
--rw-rw-rw-  2.0 fat    40380 b- defN 24-Apr-03 12:24 datasurfer/lib_plots/plot_collection.py
--rw-rw-rw-  2.0 fat    41548 b- defN 24-Apr-03 09:04 datasurfer/lib_plots/plot_utils.py
--rw-rw-rw-  2.0 fat     4982 b- defN 24-Apr-03 15:59 datasurfer/lib_stats/__init__.py
+-rw-rw-rw-  2.0 fat     2831 b- defN 24-May-08 14:58 datasurfer/lib_objects/femke_object.py
+-rw-rw-rw-  2.0 fat     2271 b- defN 24-Apr-19 11:51 datasurfer/lib_objects/finance_object.py
+-rw-rw-rw-  2.0 fat     1363 b- defN 24-May-08 19:53 datasurfer/lib_objects/json_object.py
+-rw-rw-rw-  2.0 fat     3241 b- defN 24-May-16 11:52 datasurfer/lib_objects/matlab_object.py
+-rw-rw-rw-  2.0 fat     6218 b- defN 24-May-08 15:18 datasurfer/lib_objects/mdf_object.py
+-rw-rw-rw-  2.0 fat     1004 b- defN 24-Apr-19 13:37 datasurfer/lib_objects/multisheet_object.py
+-rw-rw-rw-  2.0 fat     3629 b- defN 24-May-08 08:04 datasurfer/lib_objects/numpy_object.py
+-rw-rw-rw-  2.0 fat     4515 b- defN 24-May-15 10:55 datasurfer/lib_objects/pandas_object.py
+-rw-rw-rw-  2.0 fat      984 b- defN 24-May-13 12:39 datasurfer/lib_objects/pdf_object.py
+-rw-rw-rw-  2.0 fat     5357 b- defN 24-May-07 21:28 datasurfer/lib_objects/string_object.py
+-rw-rw-rw-  2.0 fat     2428 b- defN 24-Apr-04 15:12 datasurfer/lib_objects/xkf_object.py
+-rw-rw-rw-  2.0 fat    23773 b- defN 24-May-15 12:56 datasurfer/lib_plots/__init__.py
+-rw-rw-rw-  2.0 fat    47643 b- defN 24-May-14 12:15 datasurfer/lib_plots/plot_collection.py
+-rw-rw-rw-  2.0 fat    42922 b- defN 24-May-07 21:28 datasurfer/lib_plots/plot_utils.py
+-rw-rw-rw-  2.0 fat        0 b- defN 24-May-07 21:28 datasurfer/lib_poolobjects/__init__.py
+-rw-rw-rw-  2.0 fat     1007 b- defN 24-May-07 21:28 datasurfer/lib_poolobjects/multisheet_object.py
+-rw-rw-rw-  2.0 fat     6998 b- defN 24-May-14 12:36 datasurfer/lib_signals/__init__.py
+-rw-rw-rw-  2.0 fat     3056 b- defN 24-May-14 12:44 datasurfer/lib_signals/distrib_methods.py
+-rw-rw-rw-  2.0 fat      277 b- defN 24-May-08 13:17 datasurfer/lib_signals/filter_methods.py
+-rw-rw-rw-  2.0 fat     1900 b- defN 24-May-07 21:28 datasurfer/lib_signals/interp_methods.py
+-rw-rw-rw-  2.0 fat        0 b- defN 24-May-07 21:28 datasurfer/lib_stats/__init__.py
 -rw-rw-rw-  2.0 fat      667 b- defN 24-Apr-03 09:04 datasurfer/lib_stats/distrib_methods.py
 -rw-rw-rw-  2.0 fat     1955 b- defN 24-Apr-03 09:04 datasurfer/lib_stats/interp_methods.py
--rw-rw-rw-  2.0 fat      164 b- defN 24-Apr-04 07:09 datasurfer-1.0.9.dist-info/AUTHORS.rst
--rw-rw-rw-  2.0 fat     1530 b- defN 24-Apr-04 07:09 datasurfer-1.0.9.dist-info/LICENSE
--rw-rw-rw-  2.0 fat     2636 b- defN 24-Apr-04 07:09 datasurfer-1.0.9.dist-info/METADATA
--rw-rw-rw-  2.0 fat      110 b- defN 24-Apr-04 07:09 datasurfer-1.0.9.dist-info/WHEEL
--rw-rw-rw-  2.0 fat       11 b- defN 24-Apr-04 07:09 datasurfer-1.0.9.dist-info/top_level.txt
--rw-rw-r--  2.0 fat     4526 b- defN 24-Apr-04 07:09 datasurfer-1.0.9.dist-info/RECORD
-50 files, 625797 bytes uncompressed, 144332 bytes compressed:  76.9%
+-rw-rw-rw-  2.0 fat    12865 b- defN 24-May-07 21:28 datasurfer/util_config/__init__.py
+-rw-rw-rw-  2.0 fat     7628 b- defN 24-May-14 07:15 datasurfer/util_multiproc/__init__.py
+-rw-rw-rw-  2.0 fat      164 b- defN 24-May-16 12:38 datasurfer-1.1.dist-info/AUTHORS.rst
+-rw-rw-rw-  2.0 fat     1530 b- defN 24-May-16 12:38 datasurfer-1.1.dist-info/LICENSE
+-rw-rw-rw-  2.0 fat     2673 b- defN 24-May-16 12:38 datasurfer-1.1.dist-info/METADATA
+-rw-rw-rw-  2.0 fat      110 b- defN 24-May-16 12:38 datasurfer-1.1.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat       11 b- defN 24-May-16 12:38 datasurfer-1.1.dist-info/top_level.txt
+?rw-rw-r--  2.0 fat     5929 b- defN 24-May-16 12:38 datasurfer-1.1.dist-info/RECORD
+65 files, 691616 bytes uncompressed, 161635 bytes compressed:  76.6%
```

## zipnote {}

```diff
@@ -66,17 +66,23 @@
 
 Filename: datasurfer/datapool.py
 Comment: 
 
 Filename: datasurfer/datautils.py
 Comment: 
 
+Filename: datasurfer/lib_dlearn/__init__.py
+Comment: 
+
 Filename: datasurfer/lib_mlearn/__init__.py
 Comment: 
 
+Filename: datasurfer/lib_mlearn/clustering.py
+Comment: 
+
 Filename: datasurfer/lib_mlearn/preproc.py
 Comment: 
 
 Filename: datasurfer/lib_objects/__init__.py
 Comment: 
 
 Filename: datasurfer/lib_objects/amedata_object.py
@@ -90,62 +96,101 @@
 
 Filename: datasurfer/lib_objects/asammdf_object.py
 Comment: 
 
 Filename: datasurfer/lib_objects/data_object.py
 Comment: 
 
+Filename: datasurfer/lib_objects/femke_object.py
+Comment: 
+
 Filename: datasurfer/lib_objects/finance_object.py
 Comment: 
 
 Filename: datasurfer/lib_objects/json_object.py
 Comment: 
 
 Filename: datasurfer/lib_objects/matlab_object.py
 Comment: 
 
 Filename: datasurfer/lib_objects/mdf_object.py
 Comment: 
 
+Filename: datasurfer/lib_objects/multisheet_object.py
+Comment: 
+
+Filename: datasurfer/lib_objects/numpy_object.py
+Comment: 
+
 Filename: datasurfer/lib_objects/pandas_object.py
 Comment: 
 
+Filename: datasurfer/lib_objects/pdf_object.py
+Comment: 
+
+Filename: datasurfer/lib_objects/string_object.py
+Comment: 
+
 Filename: datasurfer/lib_objects/xkf_object.py
 Comment: 
 
 Filename: datasurfer/lib_plots/__init__.py
 Comment: 
 
 Filename: datasurfer/lib_plots/plot_collection.py
 Comment: 
 
 Filename: datasurfer/lib_plots/plot_utils.py
 Comment: 
 
+Filename: datasurfer/lib_poolobjects/__init__.py
+Comment: 
+
+Filename: datasurfer/lib_poolobjects/multisheet_object.py
+Comment: 
+
+Filename: datasurfer/lib_signals/__init__.py
+Comment: 
+
+Filename: datasurfer/lib_signals/distrib_methods.py
+Comment: 
+
+Filename: datasurfer/lib_signals/filter_methods.py
+Comment: 
+
+Filename: datasurfer/lib_signals/interp_methods.py
+Comment: 
+
 Filename: datasurfer/lib_stats/__init__.py
 Comment: 
 
 Filename: datasurfer/lib_stats/distrib_methods.py
 Comment: 
 
 Filename: datasurfer/lib_stats/interp_methods.py
 Comment: 
 
-Filename: datasurfer-1.0.9.dist-info/AUTHORS.rst
+Filename: datasurfer/util_config/__init__.py
+Comment: 
+
+Filename: datasurfer/util_multiproc/__init__.py
+Comment: 
+
+Filename: datasurfer-1.1.dist-info/AUTHORS.rst
 Comment: 
 
-Filename: datasurfer-1.0.9.dist-info/LICENSE
+Filename: datasurfer-1.1.dist-info/LICENSE
 Comment: 
 
-Filename: datasurfer-1.0.9.dist-info/METADATA
+Filename: datasurfer-1.1.dist-info/METADATA
 Comment: 
 
-Filename: datasurfer-1.0.9.dist-info/WHEEL
+Filename: datasurfer-1.1.dist-info/WHEEL
 Comment: 
 
-Filename: datasurfer-1.0.9.dist-info/top_level.txt
+Filename: datasurfer-1.1.dist-info/top_level.txt
 Comment: 
 
-Filename: datasurfer-1.0.9.dist-info/RECORD
+Filename: datasurfer-1.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## datasurfer/__init__.py

```diff
@@ -1,11 +1,188 @@
 """Top-level package for Data Structure."""
 
 __author__ = """Wei Yu"""
 __email__ = 'yuwei2005@gmail.com'
 
-from datasurfer.datapool import Data_Pool
-from datasurfer.datalake import Data_Lake
-from datasurfer.lib_objects import DataInterface
+from datasurfer.datapool import DataPool
+from datasurfer.datalake import DataLake
+from datasurfer.datainterface import DataInterface
+from datasurfer.datainterface import list_interfaces
 
 
-__all__ = ['Data_Pool', 'Data_Lake', 'DataInterface']
+__all__ = ['DataPool', 'DataLake', 'DataInterface', 'list_interfaces']
+
+#%%
+
+def interface_pool(*keys):
+    """
+    Returns a list of interfaces based on the provided keys.
+    
+    Parameters:
+        *keys: Variable number of keys used to filter the interfaces.
+        
+    Returns:
+        A list of interfaces that match the provided keys.
+    """
+    return list_interfaces()['class'][list(keys)]
+
+#%%
+def __getattr__(name):
+    
+    interfaces = list_interfaces()
+    if name in interfaces.index:
+        return interfaces['class'][name]
+    else:
+        raise AttributeError(f"module {__name__} has no attribute {name}")
+
+#%%
+def read_string(s, name, **kwargs):
+    """
+    Reads a string and returns a StringObject.
+
+    Args:
+        s (str): The input string.
+        name (str): The name of the string object.
+        **kwargs: Additional keyword arguments.
+
+    Returns:
+        StringObject: The created StringObject.
+
+    """
+    from datasurfer.lib_objects.string_object import StringObject
+    
+    return StringObject(s, name, **kwargs)
+
+#%%
+
+def df2object(df, name, **kwargs):
+    """
+    Convert a pandas DataFrame to a NumpyObject.
+
+    Parameters:
+        df (pd.DataFrame): The input data as a pandas DataFrame.
+        name (str): The name of the data object.
+        **kwargs: Additional keyword arguments to be passed to the NumpyObject constructor.
+
+    Returns:
+        NumpyObject: The converted data object.
+
+    Raises:
+        AssertionError: If the input data is not a pandas DataFrame.
+    """
+    import pandas as pd
+    from datasurfer.lib_objects.numpy_object import NumpyObject
+
+    assert isinstance(df, pd.DataFrame), "The input data must be a pandas DataFrame."
+
+    return NumpyObject(df, name=name, **kwargs)
+
+#%%
+def read_multisheets_excel(input, **kwargs):
+    """
+    Reads data from multiple sheets in an Excel file and returns an ExcelDataPool object.
+
+    Parameters:
+    - input: The input data source. It can be a DataInterface object, a DataPool object, or a file path.
+    - **kwargs: Additional keyword arguments to customize the reading process.
+
+    Returns:
+    - An ExcelDataPool object containing the data from the input source.
+
+    Example usage:
+    ```
+    data = read_multisheets_excel('data.xlsx', sheet_names=['Sheet1', 'Sheet2'], header_row=1)
+    ```
+
+    """
+    from datasurfer.lib_poolobjects.multisheet_object import ExcelDataPool
+    
+    if isinstance(input, DataInterface):
+        
+        return ExcelDataPool(input.path, **kwargs)
+    
+    elif isinstance(input, DataPool):
+        
+        return DataLake([ExcelDataPool(path, **kwargs) for path in input.paths()])
+    
+    else:
+        return ExcelDataPool(input, **kwargs)
+    
+    
+
+#%%
+
+def set_default_interface(ext, path, cls):
+    """
+    Sets the default interface for a given file extension.
+
+    Parameters:
+    - ext (str): The file extension.
+    - path (str): The path to the module containing the interface class.
+    - cls (str): The name of the interface class.
+
+    Returns:
+    - dict: The updated dictionary mapping file extensions to interface information.
+    """
+    import importlib
+    import json
+    from pathlib import Path 
+
+    json_file = Path(__file__).parent / 'map_interface.json'
+
+    if json_file.is_file():       
+        dict_map = json.load(open(json_file, 'r'))
+    else:
+        dict_map = {}   
+
+    getattr(importlib.import_module(f'datasurfer.{path}'), cls)
+
+    dict_map[ext] = [path, cls]
+
+    json.dump(dict_map, open(json_file, 'w'), indent=4)
+
+    return dict_map
+
+#%%
+
+def ProcessPool(n_workers=4, threads_per_worker=1, memory_limit='8GB'):
+    """
+    Initializes a new instance of the ProcessPool class.
+
+    Args:
+        n_workers (int, optional): The number of workers to use. Defaults to 4.
+        threads_per_worker (int, optional): The number of threads per worker. Defaults to 1.
+        memory_limit (str, optional): The memory limit per worker. Defaults to '8GB'.
+
+    Returns:
+        ProcessPool: The created ProcessPool object.
+    """
+    from datasurfer.util_multiproc import MultiProc
+
+    return MultiProc(db=None, n_workers=n_workers, threads_per_worker=threads_per_worker, memory_limit=memory_limit)
+
+#%%
+def ignore_error(fun, *args, **kwargs):
+    """
+    Calls a function and ignores any errors that occur.
+
+    Parameters:
+    - fun: The function to call.
+    - *args: Positional arguments to pass to the function.
+    - **kwargs: Keyword arguments to pass to the function.
+
+    Returns:
+    - The result of the function call, or None if an error occurs.
+    """
+    import traceback
+    import warnings
+    def wrapper(*args, **kwargs):
+        try:
+            return fun(*args, **kwargs)
+        except Exception as err:
+
+            errname = err.__class__.__name__
+            tb = traceback.format_exc(limit=0, chain=False)
+            warnings.warn(f'Exception "{errname}" is raised while processing "{fun.__name__}": "{tb}"')
+            
+    return wrapper
+#%%
```

## datasurfer/datainterface.py

```diff
@@ -1,162 +1,66 @@
-# -*- coding: utf-8 -*-
-
-
-#%% Import Libraries
-
 import os
 import re
 import pandas as pd
 import numpy as np
-import json
 import warnings
 import traceback
 
-from abc import abstractmethod
-
+from abc import ABC, abstractmethod
 from pathlib import Path
-
 from difflib import SequenceMatcher
 from itertools import chain, zip_longest
-from functools import wraps
-
+from datasurfer.datautils import parse_config, translate_config, extract_channels
 
-
-
-#%% Extract channels
-
-def extract_channels(newconfig=None):
+#%% Data_Interface
+def list_interfaces():
     """
-    A decorator that extracts channels from the given configuration and passes them as arguments to the decorated function.
+    Returns a DataFrame containing information about the DataInterface classes in the datasurfer.lib_objects module.
     
-    Args:
-        newconfig (dict, optional): A dictionary containing the mapping of channel names. Defaults to None.
+    The DataFrame has the following columns:
+    - name: The name of the DataInterface class.
+    - class: The DataInterface class object.
+    - doc: The docstring of the DataInterface class.
     
     Returns:
-        function: The decorated function.
+    DataFrame: A DataFrame containing information about the DataInterface classes.
     """
-    def decorator(func):
+    import importlib
+    import inspect
     
-        @wraps(func)
-        def wrapper(self, *keys, **kwargs):
-            
-            mapping = dict() if newconfig is None else newconfig
-            
-            config = mapping if self.config is None else self.config
-
-            foo = lambda k: config[k] if k in config else k
-            newkeys = [foo(k) for k in keys]
-            
-            channels = self.channels if hasattr(self, 'channels') else self.df.columns
-            
-            outkeys = []
-            
-            for k in newkeys:
-
-                if isinstance(k, str): 
-                    
-                    if k in channels:
-                        
-                        outkeys.append(k)
+    out = dict()
+    
+    for pth in (Path(__file__).parent/'lib_objects').glob('*.py'):
+        
+        mdlname = pth.stem        
+        try:
+            mdl = importlib.import_module(f'datasurfer.lib_objects.{mdlname}')
+        except ImportError:
+            warnings.warn(f'Cannot import module "{mdlname}".')
+            continue
+        
+        for item in dir(mdl):
+            cls = getattr(mdl, item)
+
+            if isinstance(cls, type):               
+                names = [c.__name__ for c in inspect.getmro(cls)]
+                if 'DataInterface' in names and cls.__name__ != 'DataInterface':
+                    if hasattr(cls, 'exts'):
+                        exts = sorted(cls.exts)
                     else:
-                        
-                        warnings.warn(f'"{k}" not found.')
-                else:
+                        exts = []
+                    out[cls.__name__] = (cls, cls.__doc__, exts)
                     
-                    for kk in k:
-                        
-                        if kk in channels:
-                            
-                            outkeys.append(kk)
-                            break
-                    else:
-                        warnings.warn(f'"{k}" not found.')
-                        
-            return func(self, *outkeys, **kwargs)             
-            
-        return wrapper
-    
-    return decorator
-
-#%% Translate Config
-
-def translate_config(newconfig=None):
-    """
-    A decorator function that translates column names in the output of a decorated function based on a configuration dictionary.
-    
-    Args:
-        newconfig (dict, optional): A dictionary that maps the original column names to the desired translated column names. 
-            If not provided, the decorator will use the `config` attribute of the decorated object.
+    df = pd.DataFrame(out, index=['class', 'doc', 'file extension']).T
+    df.index.name = 'name'
     
-    Returns:
-        function: The decorated function.
-    """
-    
-    def decorator(func):
-    
-        @wraps(func)
-        def wrapper(self, *keys, **kwargs):
-                        
-            if (hasattr(self, 'config') and self.config is not None) or newconfig is not None:
-                
-                config = newconfig if newconfig is not None else self.config
-                                             
-                res = func(self, *keys, **kwargs)
-                
-                if isinstance(res, pd.DataFrame):
-                    
-                    for k, v in config.items():
-                        
-                        if isinstance(v, str):
-                        
-                            res.columns = res.columns.str.replace(v, k, regex=False)
-                            
-                        elif isinstance(v, (list, tuple, set)):
-                            
-                            for vv in v:
-                                
-                                res.columns = res.columns.str.replace(vv, k, regex=False)
-
-                return res
-            
-            else: 
-                
-                return func(self, *keys, **kwargs)
+    return df
 
-        return wrapper
-    
-    return decorator
 
 #%%
-def parse_config(config):
-    
-    if isinstance(config, (str, Path)):
-        if str(config).lower().endswith('.json'):
-            config = json.load(open(config))
-        elif str(config).lower().endswith('.yaml') or str(config).lower().endswith('.yml'):
-            import yaml
-            config = yaml.safe_load(open(config))
-        else:
-            raise IOError('Unknown config format, expect json or yaml.')
-    elif isinstance(config, (list, tuple, set)):
-        if all(isinstance(s, str) for s in config):
-            config = dict((v, v) for v in config)
-        elif all(isinstance(s, dict) for s in config):
-            from datasurfer.datapool import combine_configs
-            config = combine_configs(*list(config))
-        else:
-            raise TypeError('Can not handle config type.')
-    elif (not isinstance(config, dict)) and (config is not None):
-
-        raise TypeError('Unknown config format, expect dict')
-    
-    return config
-
-#%% Data_Interface
-
 class DataInterface(object):
     """
     A class representing parent class of all data interfaces.
 
     Parameters:
     - path (str or Path): The path to the data file.
     - config (str, Path, list, tuple, set, or dict): The configuration for the data object.
@@ -246,15 +150,27 @@
         self.close()
         
         if exc_type:
             
             return False
         
         return True
-
+    
+    def __eq__(self, other):
+        
+        return self.__hash__() == other.__hash__()
+        
+    def __hash__(self):
+        
+        if hasattr(self, '_df'):
+            h = pd.util.hash_pandas_object(self.df, index=True).sum()
+            return hash((self.path, self.name, h, self.__class__))
+        else:
+            return hash((self.path, self.name, self.__class__))
+    
     def __repr__(self):
         
         return f'<{self.__class__.__name__}@{self.name}>'   
 
     def __str__(self):
         
         return self.__repr__()
@@ -271,38 +187,42 @@
         
         else:  
             
             if isinstance(name, str):
                 res = self.df[name]
             else:
                 res = self.get(*name)
-
-        
+       
         return res
     
     def __setitem__(self, name, value):
         
         self.df[name] = value
         
     def __contains__(self, name):
         
         return name in self.df.columns  
     
     def __iter__(self):
         
         return self.df.items()
     
+    def __rshift__(self, cls):
+                
+        return self.to_object(cls)
+    
     @property
     def config(self):
         return self._config
+    
     @config.setter
-    def config(self, val):
-        
-                
+    def config(self, val):                
         self._config = parse_config(val)  
+        if hasattr(self, '_df'):
+            del self._df
     
     def apply(self, name, value):
         """
         Applies the given value to the specified column name in the DataFrame.
 
         Args:
             name (str): The name of the column to apply the value to.
@@ -346,21 +266,21 @@
             self: The modified DataInterface object with the index reset.
         """
         self.df.reset_index(inplace=True, drop=drop)
         return self
 
     @property
     def index(self):
-            """
-            Returns the index of the DataFrame as a NumPy array.
+        """
+        Returns the index of the DataFrame as a NumPy array.
 
-            Returns:
-                numpy.ndarray: The index of the DataFrame.
-            """
-            return np.asarray(self.df.index)
+        Returns:
+            numpy.ndarray: The index of the DataFrame.
+        """
+        return self.df.index
     
     @property
     def meta_info(self):
         """
         Returns a dictionary containing metadata information about the data interface object.
 
         Returns:
@@ -407,52 +327,73 @@
         if not hasattr(self, '_df'):
             
             self._df = self.get_df()
             
         return self._df 
     
     @property
+    def dataframe(self):
+        return self.df
+    
+    @property
     def name(self):
         
         if self._name is None:
             
             assert self.path is not None, 'Expect a name for data object.'
             return self.path.stem
         else:
             return self._name
         
     @name.setter
     def name(self, val):
         
         self._name = val
         
-    @abstractmethod
+
     def get_df(self):
-        pass
         
-    def initialize(self):
+        raise NotImplementedError('Method is not implemented.')
+    
+    def to_object(self, cls, name=None):
+        
+        if hasattr(cls, 'from_other'):
+            obj = cls.from_other(self)
+            obj.name = name or self.name
+            return obj
+        else:
+            raise NotImplementedError('Convert method is not implemented.')
+        
+    def initialize(self, buffer=None):
         """
         Initializes the data interface by retrieving the data frame.
         
         Returns:
             self: The initialized data interface object.
         """
-        self._df = self.get_df()
+        if buffer is not None:
+            self._df = buffer
+        elif not hasattr(self, '_df'):
+            self._df = self.get_df()
         
         return self
     
     def keys(self):
         """
         Returns a list of column names in the DataFrame.
 
         Returns:
             list: A list of column names.
         """
+
         return list(self.df.columns)
     
+    list_signals = keys
+
+    
     def describe(self):
         """
         Returns a statistical summary of the DataFrame.
 
         Returns:
             pandas.DataFrame: A DataFrame containing various statistical measures such as count, mean, standard deviation, minimum, maximum, and quartiles.
         """
@@ -479,15 +420,15 @@
             pandas.DataFrame or pandas.Series
                 The requested data from the DataFrame.
 
         """
         if len(names) == 1:
             signame, = names
 
-            if signame.lower() == 't' or signame.lower() == 'time' or signame.lower() == 'index':
+            if signame not in self.df.columns and signame.lower() == 'index':
                 return pd.DataFrame(np.asarray(self.df.index), index=self.df.index)
 
         return self.df[list(names)]
     
     
     def search(self, patt, ignore_case=True, raise_error=False):
         """
@@ -531,15 +472,15 @@
             
             
         except ValueError:
             pass
                 
         return list(found)
 
-
+    search_signal = search
     
     def memory_usage(self):
         """
         Returns the memory usage of the DataFrame.
 
         Returns:
             pandas.Series: A Series containing the memory usage of each column in the DataFrame.
@@ -637,18 +578,15 @@
                             config[key].append(k)
                             break
                         except (IndexError, ValueError):
                             print('Invalid input, try again')
                             continue
 
         return self.config
-        
-
-    
-    
+           
     def drop(self, *names, nonexist_ok=True):
         """
         Drop columns from the DataFrame.
 
         Args:
             *names: Variable length argument list of column names to be dropped.
             nonexist_ok (bool, optional): If True, ignore columns that do not exist. If False, raise KeyError for non-existent columns. Defaults to True.
@@ -667,14 +605,42 @@
             elif not nonexist_ok:
                 raise KeyError(f'"{name}" does not exist in "{self.name}".')
 
         self.df.drop(columns=keys, inplace=True)
 
         return self
     
+    def select_rows(self, conds):
+        """
+        Selects rows from the DataFrame based on the given conditions.
+
+        Parameters:
+        - conds: A callable or a sequence of boolean values.
+                 If a callable is provided, it should take the DataFrame as input and return a boolean Series or DataFrame.
+                 If a sequence is provided, it should be a boolean sequence with the same length as the DataFrame.
+
+        Raises:
+        - ValueError: If the provided condition is invalid.
+
+        Returns:
+        - None
+
+        """
+        
+        from collections import abc
+        if hasattr(conds, '__call__'):
+            self._df = self.df[conds(self.df)]
+        elif isinstance(conds, abc.Sequence) or isinstance(conds, pd.Series) or isinstance(conds, np.ndarray):
+            self._df = self.df.loc[conds]
+
+        else:
+            raise ValueError('Invalid condition.')
+        
+        return self
+    
     def search_get(self, patt, ignore_case=False, raise_error=False):
         """
         Returns the subset of the DataFrame that matches the given pattern.
 
         Args:
             patt (str): The pattern to search for.
             ignore_case (bool, optional): Whether to ignore case when searching. Defaults to False.
@@ -682,27 +648,32 @@
 
         Returns:
             pandas.DataFrame: The subset of the DataFrame that matches the pattern.
         """
         return self.df[self.search(patt, ignore_case, raise_error)]
 
     
-    def load(self, *keys, mapping=None):
+    def load(self, *keys, **mapping):
         """
         Load data from the specified keys into the data object.
         
         Args:
             keys: Variable number of keys to load data from.
             mapping: Optional mapping configuration for data extraction.
             
         Returns:
             The loaded data as a dictionary.
         """
-        if not keys:       
-            keys = mapping.values()
+        #mapping = mapping or dict()
+        
+        for key in keys:           
+            if key not in mapping:           
+                mapping[key] = key  
+            
+        keys = mapping.values()
             
         @translate_config(mapping)
         @extract_channels(mapping)
         def get(self, *keys):
             return self.get(*keys)
 
         df = get(self, *keys)
@@ -720,30 +691,27 @@
         Returns:
             self: The instance of the DataInterface class.
         """
         if hasattr(self, '_df'):
             del self._df
         return self
    
-    def merge(self, obj0, reset_index=False):
+    def merge(self, obj0):
         """
         Merges the columns of another object into the current object.
 
         Parameters:
         - obj0: Another object to merge with.
 
         Returns:
         - self: The merged object.
         """
         keys = obj0.df.columns.difference(self.df.columns)
         
         if len(keys):
-            if reset_index:
-                self.reset_index()
-                obj0.reset_index()
                 
             self._df[keys] = obj0[keys]
                     
         return self
     
     def squeeze(self, *keys):
         """
@@ -763,43 +731,71 @@
             
         except KeyError:
             new_keys = list(set(self._df.columns) & set(keys))
             self._df = self.df[new_keys]
             
         return self
     
-    @classmethod
-    def pipeline(self, *funs, ignore_error=True):
+    def select_cols(self, keys):
+        return self.squeeze(*keys)
+
+    @staticmethod
+    def pipeline(*funs, hook=None, ignore_error=True, asiterator=True):
         """
         Executes a series of functions on an object in a pipeline fashion.
 
         Args:
             *funs: Variable number of functions to be executed on the object.
+            hook (str, optional): Path to a hook file containing functions to be executed. If provided, the functions 
+                                  passed as arguments will be ignored. Defaults to None.
             ignore_error (bool, optional): Flag to indicate whether to ignore errors raised during execution. 
-                                            Defaults to True.
+                                            If set to True, any exceptions raised during execution will be caught and 
+                                            a warning will be issued. If set to False, the exception will be raised 
+                                            and the execution will stop. Defaults to True.
 
         Raises:
-            Exception: If ignore_error is False and an error is raised during execution.
+            ValueError: If the input values are not callable functions.
+            ValueError: If no callable functions are provided.
 
         Returns:
-            None
+            A generator that yields the results of executing the functions on the object.
         """
-        def wrapper(obj):
-            for fun in funs:
-                assert hasattr(fun, '__call__'), 'Input value must be callable.'
+        if not hook and len(funs)==1 and (isinstance(funs[0], (str, Path)) and Path(funs[0]).is_file()):
+            hook = funs[0]
+            funs = []   
 
-                try:
-                    yield fun(obj)
-                except Exception as err:
-                    if ignore_error:
-                        errname = err.__class__.__name__
-                        tb = traceback.format_exc(limit=0, chain=False)
-                        warnings.warn(f'Exception "{errname}" is raised while processing "{obj.name}": "{tb}"')
-                    else:
-                        raise
+        if funs and not all(hasattr(fun, '__call__') for fun in funs):
+            raise ValueError('Input values must be callable.')
+
+        elif not funs and hook and Path(hook).is_file():
+
+            from datasurfer.datautils import parse_hook_file           
+            funs = parse_hook_file(hook)
+
+        if not funs:
+            raise ValueError('No callable functions provided.')
+
+        def wrapper(obj):
+            def run():
+                for fun in funs:
+                    try:
+                        yield fun(obj)
+                    except Exception as err:
+                        if ignore_error:
+                            errname = err.__class__.__name__
+                            tb = traceback.format_exc(limit=0, chain=False)
+                            warnings.warn(f'Exception "{errname}" is raised while processing "{obj.name}": "{tb}"')
+                            yield None
+                        else:
+                            raise
+            if asiterator:
+                return run()
+            else:
+                return list(run())            
+            
         return wrapper
 
     
     def rename(self, **kwargs):
         """
         Renames the columns of the DataFrame using the provided key-value pairs.
 
@@ -829,17 +825,18 @@
         to the new_index values.
 
         Parameters:
         - new_index (array-like, optional): The new index values to interpolate the columns to.
                                             If not provided, the original DataFrame is returned.
 
         Returns:
-        - new_obj (DATA_OBJECT): A new instance of the DATA_OBJECT class with the resampled DataFrame.
+        - new_obj (NumpyObject): A new instance of the NumpyObject class with the resampled DataFrame.
         """
-        from datasurfer import DATA_OBJECT
+        from datasurfer.lib_objects.numpy_object import NumpyObject
+        
         if new_index is not None:
             new_index = np.asarray(new_index)
 
             if new_index.size == 1:
                 idx = self.df.index
                 new_index = np.arange(min(idx), max(idx)+new_index, new_index)
 
@@ -851,15 +848,15 @@
                     col = col.astype(float)
                     df_out[colname] = np.interp(new_index, self.df.index, col)
                 except (TypeError, ValueError):
                     warnings.warn(f'"{colname}" can not be resampled.')
         else:
             df_out = self.df
 
-        new_obj = DATA_OBJECT(path=str(self.path), config=self.config,
+        new_obj = NumpyObject(path=str(self.path), config=self.config,
                               name=self.name,
                               comment=self.comment, df=df_out)
 
         return new_obj
     
     def fill_missing_keys(self, config=None):
         """
@@ -885,14 +882,20 @@
                 for k, vs in config.items():
                     
                     if sig in vs and k in self.df.columns:
                         self.df[mk] = self.df[k]
             
         return self
     
+    def to_clipboard(self, decimal='.'):
+        from datasurfer.lib_objects.string_object import StringObject
+        
+        self.to_object(StringObject).to_clipboard(decimal=decimal)
+        return self
+    
     def to_numpy(self):
         """
         Converts the data to a NumPy array.
 
         Returns:
             numpy.ndarray: The data as a NumPy array.
         """
@@ -907,15 +910,15 @@
         """
         out = dict()
         
         out['path'] = str(self.path)
         out['config'] = self.config
         out['comment'] = self.comment  
         out['name'] = self.name
-        out['df'] = self.df.to_numpy()
+        out['df'] = self.df.values
         out['index'] = self.df.index
         out['columns'] = self.df.columns
         
         return out
     
     def to_csv(self, name=None, overwrite=True):
         """
@@ -955,17 +958,17 @@
         
         return self
     
     def save(self, name, overwrite=True):
         
         if overwrite or not Path(name).is_file():
             
-            from datasurfer import DATA_OBJECT
+            from datasurfer.lib_objects.numpy_object import NumpyObject
             
-            dobj = DATA_OBJECT(path=self.path, config=self.config, name=self.name, 
+            dobj = NumpyObject(path=self.path, config=self.config, name=self.name, 
                            comment=self.comment, df=self.df)
             dobj.save(name)
         
         return self
     
     def clean(self):
         """
@@ -987,13 +990,88 @@
         """
         if hasattr(self, '_fhandler') and hasattr(self._fhandler, 'close'):
             self._fhandler.close()
             del self._fhandler
 
         if clean:
             self.clean()
+            
+        return self
+    
+
+    
+    def link_library(self, lib, link_name=None):
+        """
+        Links a library to the data interface.
+
+        Args:
+            lib: The library to be linked.
+            link_name (optional): The name to be used for the linked library. If not provided, the library's __name__ attribute will be used.
+
+        Returns:
+            The updated data interface object.
+
+        """
+        link_name = link_name or lib.__name__
+        setattr(self, link_name, lib(self))
+        return self
+   
     @property
-    def plot(self):        
+    def plot(self):
+        """
+        Generate a plot instance using the Plots class.
+
+        Returns:
+            Stat_Plots: An instance of the Plots class.
+        """
         from datasurfer.lib_plots import Plots
         
         return Plots(self)
-# %%
+    
+    @property
+    def signals(self):
+        """
+        Generate statistic instance for the datapool objects.
+
+        Returns:
+            Stats: An instance of the Stats class.
+        """
+        from datasurfer.lib_signals import Signal
+        
+        return Signal(self)
+
+    
+    @property
+    def mlearn(self):
+        """
+        This method initializes and returns an instance of the MLearn(machine learning) class.
+
+        Returns:
+            MLearn: An instance of the MLearn class.
+        """
+        from datasurfer.lib_mlearn import MLearn
+        
+        return MLearn(self)
+    
+    @property
+    def multiprocessor(self):
+        
+        if not hasattr(self, '_multiproc'):   
+                
+            from datasurfer.util_multiproc import MultiProc       
+            self._multiproc = MultiProc(self)
+            
+        return self._multiproc
+ 
+    mlp = multiprocessor
+    
+    @property
+    def configurator(self):
+        
+        if not hasattr(self, '_configurator'):
+            from datasurfer.util_config import Config        
+            self._configurator = Config(self)
+            
+        return self._configurator
+
+    cfg = configurator
+
```

## datasurfer/datalake.py

```diff
@@ -1,20 +1,20 @@
 import re
 import pandas as pd
 
 from collections import abc
 from itertools import chain
 from pathlib import Path
-from datasurfer.datapool import Data_Pool
+from datasurfer.datapool import DataPool
 from difflib import SequenceMatcher
 
 from datasurfer.datautils import collect_dirs, show_pool_progress
 
 #%%
-class Data_Lake(object):
+class DataLake(object):
     """
     Represents a data lake that contains multiple data pools.
 
     Parameters:
     - root: The root directory of the data lake.
     - **kwargs: Additional keyword arguments.
         - pattern: A regular expression pattern used to filter the data pools. Defaults to '.*'.
@@ -34,28 +34,32 @@
         """
         patts = kwargs.pop('pattern', r'.*')
         config = kwargs.pop('config', None)
         self.name = kwargs.pop('name', None)
 
         if not isinstance(patts, (list, tuple, set)):
             patts = [patts]
-        if isinstance(root, str):
+               
+        if isinstance(root, (str, Path)):
             founds = sorted(collect_dirs(root, *patts))
-            objs = [Data_Pool([d/f for f in fs], name=d.stem, config=config) for d, fs in founds]
+            objs = [DataPool([d/f for f in fs], name=d.stem, config=config, **kwargs) for d, fs in founds]
 
             for obj, (d, _) in zip(objs, founds):
                 obj.path = d
             self.path = Path(root)
             if self.name is None:
                 self.name = self.path.stem
             
-        elif isinstance(root, abc.Sequence) and all(isinstance(r, Data_Pool) for r in root):
+        elif isinstance(root, abc.Sequence) and all(isinstance(r, DataPool) for r in root):
+            
             objs = root
+            
         elif root is None:
             objs = []
+            
         else:
             raise ValueError('root must be a string or a sequence of DataPool objects.')
 
         self.objs = [obj for obj in objs if len(obj)]
         assert all(self.keys()), 'Data pool names must be unique.'
         
     def __repr__(self):
@@ -70,15 +74,15 @@
         """
         Adds a data pool to the data lake.
 
         Args:
             name (str): The name of the data pool.
             obj (DataPool): The data pool to be added.
         """
-        assert isinstance(obj, Data_Pool), 'The object must be a DataPool object.'
+        assert isinstance(obj, DataPool), 'The object must be a DataPool object.'
         obj.name = name
         self.objs.append(obj)    
         
     def __getitem__(self, inval):
         """
         Retrieve an item from the datalake.
 
@@ -89,15 +93,15 @@
             The retrieved item(s) from the datalake.
 
         Raises:
             KeyError: If the specified key(s) do not exist in the datalake.
         """
         if isinstance(inval, str):
             if '*' in inval:
-                if inval.strip()[0] in '#@%':
+                if inval.strip()[0] in '#@%$&§':
                     patt = inval.strip()[1:]
                     out =  sorted(set(chain(*[obj.search_signal(patt) for obj in self.objs])))
                 else:
                     out = self.__class__([self.get_pool(name) for name in self.search(inval)])
             else:
                 out = self.get_pool(inval)
                 
@@ -116,14 +120,24 @@
         """
         return iter(self.objs)
     
     def __len__(self):
         
         return len(self.objs)
     
+    def __sub__(self, dlk0):
+        
+        if isinstance(dlk0, DataPool) and dlk0.name in self.keys():
+            return self.__class__(list(set(self.objs).difference([dlk0])))
+            
+        
+        objs = list(set(self.objs).difference(dlk0.objs))
+        
+        return self.__class__(objs)
+    @property
     def size(self):
         """
         Returns the total size of the objects in the datalake.
 
         Returns:
             int: The total size of the objects in the datalake.
         """
@@ -151,19 +165,21 @@
 
         Returns:
         - A list of strings representing the paths to the data pools.
         """
         return [obj.path for obj in self.objs]
     
     def signals(self):
+        """
+        Returns a sorted set of signals from all the objects in the datalake.
 
-        return sorted(set(chain(*[obj.signals() for obj in self.objs])))
-
-
-
+        Returns:
+            set: A sorted set of signals.
+        """
+        return sorted(set(chain(*[obj.list_signals() for obj in self.objs])))
 
     def get_pool(self, name):
         """
         Retrieves the data pool with the specified name from the data lake.
 
         Parameters:
         - name: The name of the data pool to retrieve.
@@ -176,29 +192,66 @@
         """
         for obj in self.objs:
             if obj.name == name:
                 return obj
         else:
             raise NameError(f'Can not find any "{name}"')
         
-    def get_signals(self, *signals):
+    def get_object(self, name):
+        """
+        Retrieves an object from the data lake based on its name.
+
+        Parameters:
+            name (str): The name of the object to retrieve.
+
+        Returns:
+            DataPool: A DataPool object containing the found objects.
+
+        """
+        from datasurfer.lib_objects.numpy_object import NumpyObject
+        founds = [dp.get_object(name).to_object(cls=NumpyObject, name=dp.name) for dp in self.objs if name in dp.names()]
         
-        out = dict((obj.name, obj.get_signals(*signals)) for obj in self.objs)
+        return DataPool(founds)
+
         
+    def get_signals(self, *signals):
+        """
+        Retrieves signals from the data objects in the datalake.
+
+        Args:
+            *signals: Variable number of signals to retrieve.
+
+        Returns:
+            dict: A dictionary containing the retrieved signals, where the keys are the names of the data objects and the values are the corresponding signals.
+
+        """
+        out = dict((obj.name, obj.get_signals(*signals)) for obj in self.objs)
         return out
     
+    
     def get_signal1Ds(self, *signals, as_df=True):
-        
+        """
+        Retrieves the signal1Ds for the specified signals.
+
+        Args:
+            *signals: Variable number of signals to retrieve.
+            as_df (bool): Flag indicating whether to return the result as a DataFrame.
+
+        Returns:
+            dict or DataFrame: If `as_df` is True, returns a DataFrame with the signal1Ds.
+                               Otherwise, returns a dictionary with the signal1Ds.
+
+        """
         out = dict((obj.name, obj.get_signal1Ds(*signals)) for obj in self.objs)
-        
+
         if as_df:
             reform = {(outerKey, innerKey): values for outerKey, innerDict 
                       in out.items() for innerKey, values in innerDict.items()}
             out = pd.DataFrame(reform)
-        
+
         return out
         
     def iterobjs(self):
         """
         Returns an iterator that yields all objects in the datalake.
         """
         return chain(*self.items())
@@ -311,38 +364,39 @@
             >>> df3 = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})
             >>> df4 = pd.DataFrame({'A': [1, 2, 3], 'B': [7, 8, 9]})
             >>> compare_value(df3, df4)
             False
         """
         return this.df.equals(that.df, **kwargs)
     
-    def to_pool(self, name=None, raise_error=False):
+    def to_datapool(self, name=None, raise_error=False):
         """
         Merge multiple data objects in the pool.
 
         Args:
             raise_error (bool, optional): Whether to raise an error if there are duplicated data objects. 
                 Defaults to False.
 
         Returns:
             DataObject: The merged data object.
 
         Raises:
             ValueError: If there are duplicated data objects and `raise_error` is True.
         """
-        out = Data_Pool()
+        out = DataPool()
         
         for obj in self.objs:
             try:   
                 out = out.merge(obj, raise_error=raise_error)
             except ValueError:
                 objname = set(out.names()) & set(obj.names())
                 raise ValueError(f'Cannot merge "{obj.name}" with "{out.name}" because of duplicated data object "{objname}".')    
         out.name = name 
-        out.path = self.path.parent
+        
+        out.path = self.path.parent if hasattr(self, 'path') else None
 
         return out
     
     def pop(self, name):
         """
         Removes and returns the object with the given name from the datalake.
 
@@ -353,15 +407,15 @@
             object: The removed object.
 
         Raises:
             ValueError: If the object with the given name does not exist in the datalake.
         """
         return self.objs.pop(self.objs.index(self.get_pool(name)))
     
-    def save_def(self, name=None):
+    def save_def(self, name=None, save_comment=True):
         """
         Save the definition of the data objects in the datalake to a file.
 
         Args:
             name (str): The name of the file to save the definition to. If not provided, the definition will not be saved.
 
         Returns:
@@ -377,15 +431,15 @@
         out = dict()
 
         for dp in self.objs:
             out[dp.name] = dict()
             for obj in dp:
                 out[dp.name][obj.name] = dict()
                 out[dp.name][obj.name]['path'] = str(obj.path)
-                if obj.comment:
+                if save_comment and obj.comment:
                     out[dp.name][obj.name]['comment'] = obj.comment
 
         if name:
             if name.lower().endswith('.json'):
                 import json
                 with open(name, 'w') as file:
                     json.dump(out, file, indent=4)
@@ -394,23 +448,23 @@
                 with open(name, 'w') as file:
                     yaml.safe_dump(out, file)
         return out
     
     @staticmethod
     def from_def(path, **kwargs):
         """
-        Load data definition from a file or a dictionary and create a Data_Lake object.
+        Load data definition from a file or a dictionary and create a DataLake object.
 
         Args:
             path (str or dict): The path to the file containing the data definition in JSON or YAML format,
                                 or a dictionary representing the data definition.
-            **kwargs: Additional keyword arguments to be passed to the Data_Pool.load_def method.
+            **kwargs: Additional keyword arguments to be passed to the DataPool.load_def method.
 
         Returns:
-            Data_Lake: A Data_Lake object containing the loaded data definition.
+            DataLake: A DataLake object containing the loaded data definition.
 
         Raises:
             ValueError: If the input value is not a string or a dictionary.
 
         """
         if isinstance(path, str):
             
@@ -425,41 +479,40 @@
                     data = yaml.safe_load(file)
                     
         elif isinstance(path, dict):
             data = path
         else:
             raise ValueError('Input value must be a string or a dictionary.')
         
-        dlk = Data_Lake()    
+        dlk = DataLake()    
         for name, values in data.items():
-            dp = Data_Pool.from_def(values, name=name, **kwargs)
+            dp = DataPool.from_def(values, name=name, **kwargs)
             dlk.objs.append(dp)
             
         return dlk
 
     @staticmethod
-    def pipeline(*funs, pbar=True, ignore_error=True, asiterator=True):
+    def pipeline(*funs, hook=None, pbar=True, ignore_error=True, asiterator=True):
         """
         Applies a series of functions to each object in the data pool and yields the result.
 
         Args:
             *funs: Variable number of functions to be applied to each object.
 
         Yields:
             The modified object after applying all the functions.
         """
-        if not all(hasattr(fun, '__call__') for fun in funs):
-            raise ValueError('Input values must be callable.')    
-        
+   
         def wrapper(dlk):
+            
             @show_pool_progress('Processing', show=pbar)
             def fun(dlk):
                 for dp in dlk.objs:   
 
-                    yield Data_Pool.pipeline(*funs, pbar=False, ignore_error=ignore_error, asiterator=False)(dp)
+                    yield DataPool.pipeline(*funs, hook=hook, pbar=False, ignore_error=ignore_error, asiterator=False)(dp)
                     
             if asiterator:
                 return fun(dlk)
             else:
                 return list(fun(dlk))
             
         return wrapper
```

### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

## datasurfer/datapool.py

```diff
@@ -14,23 +14,22 @@
 import gc
 import traceback
 
 from pathlib import Path
 from itertools import chain
 from functools import reduce
 
-from datasurfer.lib_objects import DataInterface
 from datasurfer.datautils import collect_files, combine_configs, show_pool_progress
     
 random.seed()
 
   
 #%% Data Pool
 
-class Data_Pool(object):
+class DataPool(object):
     """
     A class representing a data pool to process datasets.
     
     Attributes:
         Mapping_Interfaces (dict): A dictionary mapping file extensions to corresponding data interface objects.
         
     Methods:
@@ -87,16 +86,18 @@
             sys.path.insert(0, Path(__file__).parent / '..')
             map_interface = json.load(open(Path(__file__).parent.joinpath('map_interface.json'), 'r', encoding='utf8')) 
         else:
             map_interface = dict()
 
         
         self.silent = kwargs.pop('silent', False)
-        self.name = kwargs.pop('name', None)
+        self.name = kwargs.pop('name', None)       
         comments = kwargs.pop('comments', {})
+        if isinstance(comments, (pd.DataFrame, pd.Series)):
+            comments = comments.to_dict()
         
         
         if isinstance(datobjects, (str, Path)): 
             
             dpath = Path(datobjects)
             
             if dpath.is_dir():
@@ -123,24 +124,26 @@
                 raise IOError(f'Can not find the dir or file "{dpath}".')    
                 
         elif isinstance(datobjects, (list, set, tuple)):
             
             if all(isinstance(s, (str, Path)) for s in datobjects) and all(Path(s).is_dir() for s in datobjects):
                 
                 datobjects = reduce(lambda x, y: 
-                                    Data_Pool(x, config=config, interface=interface, **kwargs)
-                                    + Data_Pool(y, config=config, interface=interface,  **kwargs), datobjects)    
+                                    DataPool(x, config=config, interface=interface, **kwargs)
+                                    + DataPool(y, config=config, interface=interface,  **kwargs), datobjects)    
         elif datobjects is not None:
                 datobjects = [datobjects]
         
         if datobjects is None or len(datobjects)==0:
             datobjects = []
             
+
+            
         objs = []
-        
+        from datasurfer import DataInterface
         for obj in datobjects:
             
             if isinstance(obj, DataInterface):
                 
                 if config:               
                     obj.config = config
                 
@@ -152,22 +155,28 @@
                     obj.config = config     
                 objs.extend(obj.objs)        
                 
                                
             elif isinstance(interface, type) and issubclass(interface, DataInterface):
                 objs.append(interface(obj, config=config, **kwargs))
                 
+            elif isinstance(interface, str):
+                from datasurfer import list_interfaces
+                itfs = list_interfaces()
+                interface_ = itfs['class'][interface]
+                objs.append(interface_(obj, config=config, **kwargs))
+                
             elif isinstance(obj, (str, Path)):
                 key = Path(obj).suffix.lower()               
                 if key in map_interface:
                     module, cls = map_interface[key]
                     cls = getattr(importlib.import_module(f'datasurfer.{module}'), cls)               
                     objs.append(cls(obj, config=config, **kwargs))
                 else:
-                    raise ValueError(f'Can not find any interface for "{obj}"')
+                    warnings.warn(f'Can not find any interface for "{obj}"')
       
         self.objs = sorted(set(objs), key=lambda x:x.name)
         self.apply_comments(**comments)
         
         self.initialized = False
         
 
@@ -233,61 +242,72 @@
     
     def __sub__(self, pool0):
         
         objs = list(set(self.objs).difference(pool0.objs))
         
         return self.__class__(objs)
     
+    def __hash__(self):
+        
+
+        return hash(tuple([obj.__hash__() for obj in self.objs ]))
+    
     def __eq__(self, pool0):
         
         return all(obj in pool0.objs for obj in self.objs) and all(obj in self.objs for obj in pool0.objs)
     
+    def __rshift__(self, cls):
+        
+        return self.convert(cls)   
     
     def __getitem__(self, inval):
         """
         Retrieve an item from the datapool.
 
         Parameters:
             inval (str, list, tuple, set, function, np.ndarray, pd.Series, pd.DataFrame): The key or keys to retrieve from the datapool.
 
         Returns:
             object: The retrieved item(s) from the datapool.
         """
+        
         if isinstance(inval, str):
             
             if '*' in inval:
                 
-                if inval.strip()[0] in '#@%':
+                if inval.strip()[0] in '#@%$&§':
                     
-                    patt = inval.strip()[1:]
-                    
-                    out = self.search_signal(patt, ignore_case=True)
+                    patt = inval.strip()[1:]      
+                    if inval.strip()[0] == '#':
+                        out = self.search_signal(patt, ignore_case=False)
+                    else:        
+                        out = self.search_signal(patt, ignore_case=True)
                 else:
                 
                     out = self.__class__([self.get_object(name) for name in self.search_object(inval)])
             else:
                 if inval in self.keys():
                     out = self.get_object(inval)                    
                 else:
                     out = self.get_signal(inval.strip())
                     
             
-        elif isinstance(inval, (list, tuple, set)):
+        elif isinstance(inval, (list, tuple, set)) and len(inval):
             
             
             if all(na in self.keys() for na in inval):
                 
                 out = self.__class__([self.get_object(n) for n in inval])
                 
             else:
                 out = self.get_signal1Ds(*inval)
             
             
         elif hasattr(inval, '__call__'):
-            
+            from datasurfer import DataInterface
             if isinstance(inval, type) and issubclass(inval, DataInterface):
                 
                 out = self.__class__([obj for obj in self.objs if isinstance(obj, inval)])
             else:
                 out = self.__class__(self.select(inval))
 
         
@@ -345,15 +365,20 @@
         """
         for obj in self.objs:
             if hasattr(obj, '_df'):
                 del obj._df
                 gc.collect()
             
             obj.config = value
-            
+    
+    @property
+    def size(self):
+        return self.__len__()
+    
+    
     def describe(self, verbose=False, pbar=False):
         """
         Generates a summary DataFrame containing information about the data pool.
 
         Parameters:
             pbar (bool): Whether to display a progress bar during memory usage calculation. Default is False.
 
@@ -368,32 +393,37 @@
                 - Size: Size of the data pool file in megabytes.
                 - Date: Date of the data pool file.
                 - Path: File path of the data pool file.
         """
         path = self.paths()
         itype = pd.Series([obj.__class__.__name__ for obj in self.objs], 
                           index=self.names(), name='Interface')
-        ftype = pd.Series([Path(p).suffix for p in self.paths()], index=self.names(), name='File Type')
-        date = self.file_date() 
-        size = (self.file_size() / 1e6).round(4)     
+        try:
+            ftype = pd.Series([Path(p).suffix for p in self.paths()], index=self.names(), name='File Type')
+            date  = self.file_date() 
+            size  = (self.file_size() / 1e6).round(4)     
+        except FileNotFoundError:
+            ftype = pd.Series(np.nan*np.ones(len(self.objs)), name='File Type')
+            date = pd.Series(np.nan*np.ones(len(self.objs)), name='File Date')
+            size = pd.Series(np.nan*np.ones(len(self.objs)), name='File Size')
            
         if verbose:
             signal = self.signal_count(pbar=False)
             length = pd.Series([obj.__len__() for obj in self.objs], 
                             index=self.names(), name='Signal Length')
-            count = self.count(pbar=False)
+            count = self.count_signal_size(pbar=False)
             
             memory = (self.memory_usage(pbar=pbar) / 1e6).round(4) 
             comments = pd.Series(self.comments(), name='Comment')      
         
             df = pd.concat([comments, signal, length, count, memory, itype, ftype, size, date, path], axis=1)
         else:
             df = pd.concat([itype, ftype, size, date, path], axis=1)
                     
-        return df
+        return df.dropna(how='all')
                 
     def memory_usage(self, pbar=True):
         """
         Calculate the memory usage of each object in the datapool.
 
         Parameters:
         - pbar (bool): Whether to show a progress bar during calculation. Default is True.
@@ -464,70 +494,77 @@
     def paths(self):
         """
         Returns a pandas Series containing the file paths of the objects in the datapool.
 
         Returns:
             pd.Series: A pandas Series object with the file paths as values and object names as index.
         """
-        return pd.Series([str(obj.path) for obj in self.objs], index=self.names(), name='File Path')
+        return pd.Series([obj.path for obj in self.objs], index=self.names(), name='File Path')
 
     def file_size(self):
         """
         Calculate the file size for each file in the datapool.
 
         Returns:
             pd.Series: A pandas Series object containing the file sizes, with the file names as the index.
         """
-        return pd.Series(dict(zip(self.names(), map(os.path.getsize, self.paths().values))), name='File Size')
+        
+        return pd.Series(dict((name, path.stat().st_size) for name, path in self.paths().items()), name='File Size')
    
     def file_date(self):
         """
         Returns a pandas Series containing the file modification dates of the objects in the datapool.
         
         Returns:
             pd.Series: A pandas Series with the file modification dates.
         """
+
         ctimes = [datetime.datetime.fromtimestamp(os.path.getmtime(obj.path)) 
                   for obj in self.objs]
         return pd.Series(ctimes, index=self.names(), name='File Date')
     
-    def comments(self):
+    def comments(self, pbar=True):
         """
         Returns a DataFrame containing the names and comments of the objects in the datapool.
         """
-        return pd.Series(dict((obj.name, obj.comment) for obj in self.objs), name='Comment')
+        @show_pool_progress('Processing', show=pbar)
+        def get(self):
+            for obj in self.objs:
+                yield obj.name, obj.comment
+                
+        return pd.Series(dict((name, comment) for name, comment in get(self)), name='Comment')
     
     def apply_comments(self, **comments):
         """
         Apply comments to the objects in the datapool.
 
         Args:
             **comments: Keyword arguments mapping object names to comments.
 
         Returns:
             self: The modified datapool object.
         """
         for name, comment in comments.items():
             try:
                 if comment:
-                    self.get_object(name).comment = comment
-            except NameError:
+                    self.get_object(name)._comment = comment
+            except (NameError, AttributeError):
                 pass
         return self
     
     def configs(self):
         """
         Returns a DataFrame containing the configurations of all objects in the datapool.
         
         Returns:
             pandas.DataFrame: A DataFrame with object names as columns and their corresponding configurations as values.
         """
         return pd.DataFrame(dict((obj.name, obj.config) for obj in self.objs))
         
-    def signals(self, count=None, pbar=False):
+    def list_signals(self, count=None, pbar=True):
         """
         Returns a list of unique keys from the objects in the datapool.
 
         Args:
             count (int, optional): The maximum number of objects to consider. If not specified, all objects are considered.
             pbar (bool, optional): Whether to show a progress bar during processing. Default is False.
 
@@ -567,15 +604,15 @@
         @show_pool_progress('Processing', show=pbar)
         def get(self):
             for obj in self.objs:
                 yield obj.name, len(obj.keys())
                 
         return pd.Series(dict(get(self)), name='Signal Count')
     
-    def count(self, pbar=True):
+    def count_signal_size(self, pbar=True):
         """
         Count the signal size for each object in the datapool.
 
         Args:
             pbar (bool, optional): Whether to show a progress bar. Defaults to True.
 
         Returns:
@@ -585,14 +622,30 @@
         def get(self):
             for obj in self.objs:
                 yield obj.name, obj.count().sum()
                 
         return pd.Series(dict(get(self)), name='Signal Size')
     
     
+    def mlp_initialize(self, **kwargs):
+        """
+        Initializes the datapool for multiprocessing.
+
+        Args:
+            n_workers (int, optional): The number of workers to use for multiprocessing. Defaults to None.
+
+        Returns:
+            self: The initialized datapool object.
+        """
+        objs = self.mlp.map(lambda x: x.initialize(**kwargs))
+        
+        self.__init__(objs)
+        self.initialized = True
+        return self
+    
     def initialize(self, buffer=None, pbar=True):
         """
         Initializes the datapool by calling the `initialize` method on each object in the datapool.
 
         Args:
             pbar (bool, optional): Whether to show a progress bar during initialization. Defaults to True.
         """
@@ -604,14 +657,73 @@
                 yield
                 
         buffer = [] if buffer is None else buffer
         list(get(self))
 
         return self
     
+    def append(self, obj):
+        """
+        Appends an object to the datapool.
+
+        Args:
+            obj: The object to append.
+
+        Returns:
+            self: The updated datapool object.
+        """
+        from datasurfer import DataInterface
+        assert isinstance(obj, DataInterface), 'Input object must be a DataInterface object.'
+
+        if obj in self.objs:
+            self.objs.pop(self.objs.index(obj))
+            warnings.warn(f'Object "{obj.name}" is already in the datapool.')
+            
+        self.objs.append(obj)
+        return self
+    
+    def extend(self, dp):
+        """
+        Extends the datapool with a list of DataInterface objects.
+
+        Args:
+            objs (list): A list of DataInterface objects to be added to the datapool.
+
+        Returns:
+            self: The updated datapool object.
+
+        Raises:
+            AssertionError: If any of the input objects is not an instance of DataInterface.
+        """
+        assert isinstance(dp, DataPool), 'Input objects must be Data Pool object.'
+        
+        for obj in dp.objs:
+            
+            self.append(obj)
+
+        return self
+    
+    def extend(self, objs):
+        """
+        Extends the datapool with a list of DataInterface objects.
+
+        Args:
+            objs (list): A list of DataInterface objects to be added to the datapool.
+
+        Returns:
+            self: The updated datapool object.
+
+        Raises:
+            AssertionError: If any of the input objects is not an instance of DataInterface.
+        """
+        from datasurfer import DataInterface
+        assert all(isinstance(obj, DataInterface) for obj in objs), 'Input objects must be DataInterface objects.'
+        self.objs.extend(objs)
+        return self
+    
     def load_signals(self, *keys, mapping=None, pbar=True):
         """
         Load signals from the data pool.
 
         Args:
             *keys: Variable length argument list of keys to load.
             mapping: Optional mapping object to apply to the loaded signals.
@@ -633,15 +745,15 @@
             for obj in self.objs:
                 obj.load(*keys, mapping=mapping)
                 yield
 
         list(get(self))
         return self
 
-    @show_pool_progress('Processing', show=False, set_init=True)
+    #@show_pool_progress('Processing', show=False, set_init=True)
     def iter_signal(self, signame, ignore_error=True, mask=None):
         '''
         Iterates over the data objects in the datapool and yields data frames for a given signal name.
 
         Parameters
         ----------
         signame : str
@@ -658,19 +770,16 @@
         Yields
         ------
         pandas.DataFrame
             A data frame containing the data for the specified signal name.
 
         Examples
         --------
-        >>> dp = DataPool()
-        >>> dp.add_data_object(obj1)
-        >>> dp.add_data_object(obj2)
-        >>> dp.add_data_object(obj3)
-
+        >>> dp = DataPool([obj1, obj2, obj3])
+    
         >>> for df in dp.iter_signal('temperature'):
         ...     print(df)
         ...
         # Output:
         #    obj1
         # 0  25.0
         # 1  26.0
@@ -682,46 +791,100 @@
         # 2  32.0
         #
         #    obj3
         # 0  35.0
         # 1  36.0
         # 2  37.0
         '''
-
-        for idx, obj in enumerate(self.objs):
+        if mask is not None:
+            assert len(mask) == len(self.objs), 'Mask length must match the number of objects.'
+            objs = [obj for obj, msk in zip(self.objs, mask) if msk]
+        else:
+            objs = self.objs
             
-            try:
-                
-                if (mask is None) or (mask is not None and mask[idx]):
+        for obj in objs:
+            
+            try:                
+                                            
+                df = obj.get(signame)
                     
-                        
-                    df = obj.get(signame)
-                        
-                    df.columns = [obj.name]                      
-                    df.index = np.arange(0, len(df))
+                df.columns = [obj.name]                      
+                df.index = np.arange(0, len(df))
 
-                    yield df
+                yield df
                 
             except Exception as err:
                 
                 if ignore_error:     
                     
                     errname = err.__class__.__name__
                     tb = traceback.format_exc(limit=0, chain=False)
                     warnings.warn(f'Exception "{errname}" is raised while processing "{obj.name}": "{tb}"')
 
                     df = pd.DataFrame(np.nan * np.ones(obj.__len__()), columns=[obj.name])                        
-                    df.index = np.arange(0, obj.__len__())                    
+                    df.index = np.arange(0, obj.__len__())       
+       
                     yield df
                     
                 else:
                     raise
+    
+    def iter_objsignals(self, *signames, ignore_error=True):
+        """
+        Iterates over the objects in the datapool and returns a DataFrame for each specified signal name.
 
+        Args:
+            *signames: Variable length argument list of signal names.
+            ignore_error (bool, optional): If True, ignores any errors encountered during iteration. Defaults to True.
 
-    
+        Yields:
+            tuple: A tuple containing the object name and the corresponding DataFrame for each specified signal name.
+
+        """
+        for idx, obj in enumerate(self.objs):
+            msk = ~np.ones(len(self.objs), dtype=bool)
+            msk[idx] = True
+            vals = [next(self.iter_signal(signame, ignore_error=ignore_error, mask=msk)) for signame in signames]
+            df = pd.concat(vals, axis=1)
+            df.columns = signames
+            yield obj.name, df
+        
+    def get_row(self, row, columns=None, ignore_error=True, pbar=True):    
+        
+        @show_pool_progress('Processing', pbar)
+        def get(self):
+
+            for name, df in self.iter_objsignals(*columns, ignore_error=ignore_error):
+                try: 
+                    res = df.loc[row]
+                    
+                    ds = pd.Series(res, index=columns)
+                    ds.name = name
+                        
+                except KeyError as err:
+                    if ignore_error:     
+                        
+                        errname = err.__class__.__name__
+                        tb = traceback.format_exc(limit=0, chain=False)
+                        warnings.warn(f'Exception "{errname}" is raised while processing "{name}": "{tb}"')
+
+                        ds = pd.Series(np.nan * np.ones(columns.__len__()), index=columns)                        
+                        ds.name = name       
+                        
+                    else:
+                        raise
+                finally:
+                    yield ds  
+        columns = columns or self.list_signals()            
+        rows = list(get(self))
+        df = pd.concat(rows, axis=1).T
+        return df                    
+                
+            
+   
     def get_signal(self, signame, ignore_error=True, mask=None):
         """
         Retrieves the data for a given signal name.
 
         Args:
             signame (str): The name of the signal to retrieve.
             ignore_error (bool, optional): Whether to ignore errors if the signal is not found. Defaults to True.
@@ -772,32 +935,41 @@
 
         Returns:
         - DataFrame: A pandas DataFrame containing the retrieved signal.
         """
         dats = list(self.iter_signal(
             signame, ignore_error=ignore_error, mask=mask))
 
-        out = pd.DataFrame(np.concatenate(dats, axis=0), columns=[signame])
+        cols = [signame]   
+        out = pd.DataFrame(np.concatenate(dats, axis=0), columns=cols)
 
         if reindex:
             out.index = np.arange(len(out))
 
         return out
     
     def get_signal1Ds(self, *signals, ignore_error=True, mask=None):
+        """
+        Retrieves multiple 1D signals from the datapool.
+
+        Args:
+            *signals: Variable length argument list of signal names to retrieve.
+            ignore_error (bool, optional): Whether to ignore errors when retrieving signals. Defaults to True.
+            mask (array-like, optional): Mask to apply to the retrieved signals. Defaults to None.
+
+        Returns:
+            pandas.DataFrame: A DataFrame containing the retrieved signals concatenated along the columns.
+        """
         out = []
-        for sig in signals:
-            
+        for sig in signals:          
             out.append(self.get_signal1D(sig, ignore_error=ignore_error, mask=mask))
             
         out = pd.concat(out, axis=1)
         return out
     
-
-    
     def get_object(self, name):
         """
         Retrieve an object from the datapool by its name.
 
         Args:
             name (str): The name of the object to retrieve.
 
@@ -890,19 +1062,71 @@
         Args:
             key: The key to sort the objects by.
 
         Returns:
             None. The objects in the datapool are sorted in-place.
         """
         return list(self.objs[:]).sort(key=lambda obj: obj.key)
+    
     def sort_objects(self, key):
-        
+        """
+        Sorts the objects in the datapool based on the specified key.
+
+        Args:
+            key (str): The key to sort the objects by.
+
+        Returns:
+            list: A sorted list of objects.
+
+        """
+        return list(self.objs[:]).sort(key=lambda obj: obj.key)
+    
+    def sort_objects(self, key):
+        """
+        Sorts the objects in the datapool based on the specified key.
+
+        Args:
+            key: The key to sort the objects by.
+
+        Returns:
+            A sorted list of objects.
+
+        """
         return list(self.objs[:]).sort(key=lambda obj:obj.key)
     
+    def map(self, func, ignore_error=True, pbar=True):
+        """
+        Apply a function to each object in the datapool and return the results.
+
+        Args:
+            func (function): The function to apply to each object.
+            ignore_error (bool, optional): Whether to ignore any exceptions raised during processing. Defaults to True.
+            pbar (bool, optional): Whether to show a progress bar during processing. Defaults to True.
+
+        Returns:
+            list: A list of the results of applying the function to each object.
+        """
+        @show_pool_progress('Processing', pbar)
+        def get(self):
+            for obj in self.objs:
+                try:
+                    yield func(obj)
+                except Exception as err:
+                    if ignore_error:
+                        errname = err.__class__.__name__
+                        tb = traceback.format_exc(limit=0, chain=False)
+                        warnings.warn(f'Exception "{errname}" is raised while processing "{obj.name}": "{tb}"')
+                        yield None
+                    else:
+                        raise
 
+        return list(get(self))
+        
+
+        
     def apply(self, signame, methode, ignore_error=True, pbar=True):
         """
         Apply a given method to each object in the datapool.
 
         Args:
             signame (str): The name of the signal to be modified.
             methode (callable): The method to be applied to each object.
@@ -928,31 +1152,35 @@
                         raise
 
                 yield True
 
         list(get(self))
         return self
 
-    def merge(self, pool0, raise_error=False):  
+    def merge(self, pool0, only_data=True, pbar=True):  
         """
         Merges the objects from another datapool into the current datapool.
 
         Args:
             pool0 (DataPool): The datapool to merge.
 
         Returns:
             DataPool: The merged datapool.
         """
-        names = [obj.name for obj in self.objs]
-
-        for obj in pool0.objs:
-            if obj.name not in names:
-                self.objs.append(obj)
-            elif raise_error:
-                raise ValueError(f'Object "{obj.name}" already exists in the datapool.')    
+        names = self.names()
+        @show_pool_progress('Merging', pbar)
+        def get(pool0):
+            for obj in pool0.objs:
+                if not only_data and obj.name not in names:
+                    self.objs.append(obj)
+                elif obj.name in names:
+                    self.get_object(obj.name).merge(obj)
+                yield
+                
+        list(get(pool0))
 
         return self
     
     def merge_data(self, pool0):
         """
         Merges the data from another datapool into the current datapool.
 
@@ -1007,14 +1235,34 @@
         @show_pool_progress('Processing', pbar)
         def get(self):
             for obj in self.objs:
                 obj.squeeze(*keys)
                 yield
         list(get(self))
         return self
+    
+    def convert(self, cls, pbar=True):
+        """
+        Converts all the objects in the DataPool to a different class.
+
+        Args:
+            cls (class): The class to convert the objects to.
+            pbar (bool, optional): Whether to show a progress bar. Defaults to True.
+
+        Returns:
+            DataPool: A new DataPool object with the converted objects.
+        """
+        
+        @show_pool_progress('Converting', show=pbar)
+        def get(self):
+            for obj in self.objs:
+                new_obj = obj.to_object(cls)
+                yield new_obj
+        
+        return DataPool(list(get(self)), config=self.config, name=self.name)
         
     def select(self, mask_array):
         
         '''
             return data objects from pool according to mask.
         '''
         if isinstance(mask_array, (dict, pd.Series)):
@@ -1023,81 +1271,75 @@
         elif hasattr(mask_array, '__call__'):
 
             out = [obj for obj in self if mask_array(obj)]
         else:
             assert len(mask_array) == len(self.objs), "The length of the mask array does not match the number of data objects."
             
             out = [obj for obj, msk in zip(self.objs, mask_array) if msk]
-        return out
+        return self.__class__(out)
     
     @staticmethod
-    def pipeline(*funs, pbar=True, ignore_error=True, asiterator=True):
+    def pipeline(*funs, hook=None, pbar=True, ignore_error=True, asiterator=False):
         """
         Applies a series of functions to each object in the data pool and yields the result.
 
         Args:
             *funs: Variable number of functions to be applied to each object.
 
         Yields:
             The modified object after applying all the functions.
         """
-        if not all(hasattr(fun, '__call__') for fun in funs):
-            raise ValueError('Input values must be callable.')
+        from datasurfer import DataInterface
         if asiterator: pbar=False
         
         def wrapper(dp):
             @show_pool_progress('Processing', show=pbar)
             def fun(dp):
                 for obj in dp.objs:                            
-                    # for fun in funs: 
-                    #     try:
-                    #         fun(obj)
-                    #     except Exception as err:
-                    #         if ignore_error:
-                    #             errname = err.__class__.__name__
-                    #             tb = traceback.format_exc(limit=0, chain=False)
-                    #             warnings.warn(f'Exception "{errname}" is raised while processing "{obj.name}": "{tb}"')
-                    #         else:
-                    #             raise
-                    list(DataInterface.pipeline(*funs, ignore_error=ignore_error)(obj))
+                    list(DataInterface.pipeline(*funs, hook=hook, ignore_error=ignore_error)(obj))
                     yield obj
                     
             if asiterator:
                 return fun(dp)
             else:
                 return list(fun(dp))
-        return wrapper      
+        return wrapper  
+    
+    def mlp_deepcopy(self, **kwargs):
+        from datasurfer.lib_objects.pandas_object import PandasObject
+        objs = self.mlp.map(lambda x: x.to_object(PandasObject))
+        
+        dp = DataPool(objs, **kwargs)
+        return dp            
                 
-    def deepcopy(self, pbar=True):
+    def deepcopy(self, *pipeline, pbar=True):
         """
         Create a deep copy of the DataPool object.
 
         Parameters:
         - pbar (bool): Whether to show a progress bar during the copy process. Default is True.
 
         Returns:
         - DataPool: A new DataPool object that is a deep copy of the original object.
         """
+        from datasurfer import DataInterface
+        from datasurfer.lib_objects.pandas_object import PandasObject
         
-        from .lib_objects import DATA_OBJECT
         @show_pool_progress('Copying', show=pbar)
-        def fun(self):            
-            for name, dat in self.iter_dict():
-                df = pd.DataFrame(dat['df'], index=dat['index'], columns=dat['columns'])
-                obj = DATA_OBJECT(path=dat['path'],
-                                    config=dat['config'],
-                                    comment=dat['comment'],
-                                    name=dat['name'],
-                                    df=df)                
+        def fun(self):           
+            for obj in self.objs:
+                obj = obj.to_object(PandasObject)
+                if pipeline:
+                    list(DataInterface.pipeline(*pipeline)(obj))
+                              
                 yield obj
-                
-                
+                                
         objs = list(fun(self))
-                
-        return self.__class__(objs)
+                           
+        return self.__class__(datobjects=objs)
     
     def iter_dict(self):
         """
         Iterate over the objects in the datapool and yield a dictionary for each object.
         
         Returns:
             A generator that yields a tuple containing the object name and a dictionary
@@ -1112,21 +1354,31 @@
             out['df'] = obj.df.to_numpy()
             out['index'] = obj.df.index
             out['columns'] = obj.df.columns
             
             yield obj.name, out
     
     def rename(self, **kwargs):
+        """
+        Renames objects in the datapool.
+
+        Args:
+            **kwargs: Keyword arguments where the key is the new name and the value is the current name of the object.
+
+        Returns:
+            self: The updated datapool object.
+
+        """
         for key, val in kwargs.items():
             try:
                 self.get_object(val).name = key
             except NameError:
                 pass
                 
-        return self 
+        return self
                
     def rename_signals(self, **kwargs):
         """
         Renames signals in the datapool.
 
         Args:
             **kwargs: Additional keyword arguments to be passed to the `rename` method of each signal object.
@@ -1142,58 +1394,67 @@
                 obj.rename(**kwargs)
                 yield
 
         list(get(self))
 
         return self
     
-    def to_json(self):
-        
+    def def2json(self):
+        """
+        Convert the data in the datapool to a JSON string.
+
+        Returns:
+            str: A JSON string representation of the datapool data.
+        """
         out = dict()
-        
+
         for name, feature in (('path', self.paths()),
-                             ('comment', self.comments())):
-            
+                              ('comment', self.comments())):
+
             for key, value in feature.items():
                 out.setdefault(key, dict())[name] = value
-        
-        out = json.dumps(out, indent=4)        
+
+        out = json.dumps(out, indent=4)
         return out
     
-    def to_dataframe(self, columns=None, pbar=True):
+    def to_dataframe(self, *names, pbar=True):
         """
         Convert the objects in the datapool to a pandas DataFrame.
 
         Args:
             columns (list, optional): List of column names to include in the DataFrame. Defaults to None.
             pbar (bool, optional): Whether to show a progress bar. Defaults to True.
 
         Returns:
             pandas.DataFrame: The combined DataFrame of all objects in the datapool.
         """
         
         @show_pool_progress('Processing', show=pbar)
         def fun(self):
             
-            for obj in self.objs:
-                
-                df = obj.df.reset_index()
-                
-                if columns is not None:
-                    
-                    df = df[columns]
-                
-                index = pd.MultiIndex.from_product([[obj.name], df.columns])
+            for objname, df in self.iter_objsignals(*names):
+                                
+                index = pd.MultiIndex.from_product([[objname], df.columns])
                 
                 df.columns = index
                                 
                 yield df
 
+        if not names:
+            
+            names = self.list_signals()
+            
         dfs = list(fun(self))
         return pd.concat(dfs, axis=1)
+    
+    def mlp_to_csvs(self, wdir):
+        
+        self.mlp.map(lambda x: x.df.to_csv(Path(wdir) / (x.name+'.csv')))
+        
+        return self
                 
     def to_csvs(self, wdir, pbar=True):
         """
         Save the data from each object in the datapool to separate CSV files.
 
         Args:
             wdir (str): The directory path where the CSV files will be saved.
@@ -1234,35 +1495,81 @@
             for obj in self.objs:
                 obj.df.to_excel(wdir / (obj.name+'.xlsx'))
                 yield True
             
         list(fun(self))        
         return self
 
-    def to_excel(self, name, pbar=True):
+    def to_summary_excel(self, name, keys=None, pbar=True):
         """
         Save the data pool to an Excel file.
 
         Parameters:
         - name (str): The name of the Excel file to save.
         - pbar (bool): Whether to show a progress bar while saving. Default is True.
 
         Returns:
         - self: The data pool object.
 
         """
         with pd.ExcelWriter(name) as writer:
+            
             @show_pool_progress('Saving', show=pbar)
             def fun(self):       
-                for obj in self.objs:        
-                    obj.df.to_excel(writer, sheet_name=obj.name)
-                    yield True            
+                for name, df in self.iter_objsignals(*keys):        
+                    df.to_excel(writer, sheet_name=name)
+                    yield True  
+                    
+            keys = keys or self.list_signals()              
             list(fun(self))        
             return self
-            
+    
+    def to_datalake(self, *hooks, **condis):
+        """
+        Converts the data in the DataPool to a DataLake based on the given conditions.
+
+        Parameters:
+        - condis (keyword arguments): Conditions to filter the data. Each condition should be a callable function.
+
+        Returns:
+        - dlk (DataLake): The resulting DataLake object.
+
+        Raises:
+        - AssertionError: If the value of any condition is not a callable function.
+        """
+
+        from datasurfer import DataLake
+        from datasurfer.datautils import parse_hook_file
+
+        out = dict()
+        
+        for hook in hooks:
+            for func in parse_hook_file(hook):
+                assert hasattr(func, '__call__'), 'The value of the condition must be a callable function.'
+                for obj in self.objs:
+                    if func(obj):
+                        out.setdefault(func.__name__, []).append(obj) 
+        
+
+        for name, func in condis.items():
+            assert hasattr(func, '__call__'), 'The value of the condition must be a callable function.'
+
+            for obj in self.objs:
+                if func(obj):
+                    out.setdefault(name, []).append(obj)
+
+        pools = [DataPool(objs, name=name) for name, objs in out.items() if len(objs)]
+
+        if not len(condis):
+            pools = [self]
+                   
+        dlk = DataLake(pools)
+
+        return dlk
+               
     def save(self, name, pbar=True):
         """
         Save the data pool to a file.
 
         Parameters:
         - name (str): The name of the file to save the data pool to.
         - pbar (bool): Whether to show a progress bar during the saving process. Default is True.
@@ -1277,57 +1584,60 @@
                 yield res
                
         out = dict(list(fun(self)))                
         np.savez(name, **out)
         self.initialized = True
         return self
     
-    def save_def(self, name=None):
+    def save_def(self, name=None, pbar=True, save_comment=True):
         """
         Save the definitions of objects in the datapool to a file.
 
         Args:
             name (str): The name of the file to save the definitions to. If not provided, the definitions will not be saved.
 
         Returns:
             dict: A dictionary containing the saved definitions.
 
         Raises:
             None
 
         """
         out = dict()
-
-        for obj in self.objs:
-            out[obj.name] = dict()
-            out[obj.name]['path'] = str(obj.path)
-            if obj.comment:
-                out[obj.name]['comment'] = obj.comment
+        @show_pool_progress('Exporting', show=pbar)
+        def get(self):
+            for obj in self.objs:
+                out[obj.name] = dict()
+                out[obj.name]['path'] = str(obj.path)
+                if save_comment and obj.comment:
+                    out[obj.name]['comment'] = obj.comment
+                yield
+        list(get(self))
         if name:   
             if name.lower().endswith('.json'):
                 with open(name, 'w') as file:
                     json.dump(out, file, indent=4)
             elif name.lower().endswith('.yaml') or name.lower().endswith('.yml'):
                 import yaml
                 with open(name, 'w') as file:
                     yaml.safe_dump(out, file)
 
         return out
     
     @staticmethod
     def from_def(path, **kwargs):
         """
-        Load data from a JSON file and create a Data_Pool object.
+        Load data from a JSON file and create a DataPool object.
 
         Parameters:
         - name (str): The name of the JSON file to load.
-        - **kwargs: Additional keyword arguments to pass to the Data_Pool constructor.
+        - **kwargs: Additional keyword arguments to pass to the DataPool constructor.
 
         Returns:
-        - dp (Data_Pool): The Data_Pool object created from the loaded data.
+        - dp (DataPool): The DataPool object created from the loaded data.
         """
         if isinstance(path, str):
             if path.lower().endswith('.json'):
                 with open(path, 'r') as file:
                     data = json.load(file)
             elif path.lower().endswith('.yaml') or path.lower().endswith('.yml'):
                 import yaml
@@ -1339,35 +1649,39 @@
             data = path.to_dict()
         else:
             raise ValueError('Input value must be a string or a dictionary.')
             
         _, values = zip(*data.items())
         
         paths = [val['path'] for val in values]
-        comments = dict((key, val.get('comment', None)) for key, val in data.items())
-        
-        dp = Data_Pool(paths, comments=comments, **kwargs)    
+        comments = (dict((key, val.get('comment', None)) for key, val in data.items()) 
+                    if kwargs.pop('apply_comments', True) else dict())
+
+        dp = DataPool(paths, comments=comments, **kwargs)    
 
         return dp
-        
-    def load(self, name, keys=None, pbar=True, count=None):
+    
+
+    @staticmethod    
+    def load_numpy(name, keys=None, pbar=True, count=None):
         """
-        Load data from a numpy .npz file and create DATA_OBJECT instances.
+        Load data from a numpy .npz file and create NumpyObject instances.
 
         Parameters:
             name (str): The name of the .npz file to load.
             keys (list, optional): A list of keys to load from the .npz file. If None, all keys will be loaded. Default is None.
             pbar (bool, optional): Whether to show a progress bar during loading. Default is True.
             count (int, optional): The maximum number of objects to load. If None, all objects will be loaded. Default is None.
 
         Returns:
             self: The updated instance of the class.
 
         """
-        from datasurfer import DATA_OBJECT
+        from datasurfer.lib_objects.numpy_object import NumpyObject
+        
         with np.load(name, allow_pickle=True) as npz:
             npzkeys = npz.keys()
             
             if count is None:
                 num = len(npzkeys)
             else:
                 num = count
@@ -1375,25 +1689,25 @@
             @show_pool_progress('Loading', show=pbar, count=num)
             def fun(self):
                 ncount = 0
                 for k in npzkeys:
                     if (keys is None) or (k in keys):
                         dat = npz[k].item()            
                         df = pd.DataFrame(dat['df'], index=dat['index'], columns=dat['columns'])
-                        obj = DATA_OBJECT(path=dat['path'],
+                        obj = NumpyObject(path=dat['path'],
                                           config=dat['config'],
                                           comment=dat['comment'],
                                           name=dat['name'],
                                           df=df)
                         yield obj
                         ncount = ncount + 1
                         if ncount >= num:
                             break
-        
-            self.objs = list(fun(self))                
+                        
+            self = DataPool(list(fun(None)))              
             self.initialized = True
             
             del npz.f
 
         return self
 
     def split_pool(self, chunk=2, shuffle=True):
@@ -1403,27 +1717,31 @@
         Args:
             chunk (int): The number of chunks to split the pool into. Default is 2.
             shuffle (bool): Whether to shuffle the objects before splitting. Default is True.
 
         Returns:
             list: A list of DataPool instances, each containing a chunk of objects from the original pool.
         """
+        
+        
         out = dict()
         objs = self.objs[:]
 
         if shuffle:
             random.shuffle(objs)
 
         while objs:
             for k in range(chunk):
                 if not objs:
                     break
-                out.setdefault(k, []).append(objs.pop())
+                key = f'Pool_{k:02d}'
+                out.setdefault(key, []).append(objs.pop())
 
         return [self.__class__(v) for v in out.values()]
+
             
 
     
     def close(self, clean=True, pbar=True):
         """
         Closes the datapool.
 
@@ -1463,45 +1781,82 @@
             for obj in self.objs:               
                 obj.fill_missing_keys(config=config)
                 yield
         
         list(get(self))
         return self
     
+    def link_library(self, lib, link_name=None):
+        """
+        Links the datapool to a library.
+
+        Args:
+            lib (Library): The library to link the datapool to.
+
+        Returns:
+            self: The updated datapool object.
+            
+        """
+        link_name = link_name or lib.__name__
+        setattr(self, link_name, lib(self))
+        return self
+    
     @property
     def plot(self):
         """
         Generate a statistical plot using the Stat_Plots class.
 
         Returns:
             Stat_Plots: An instance of the Stat_Plots class.
         """
         from datasurfer.lib_plots import Plots
         
         return Plots(self)
     
     @property
-    def stats(self):
+    def signals(self):
         """
         Generate statistical summaries for the datapool objects.
 
         Returns:
             Stats: An instance of the Stats class.
         """
-        from datasurfer.lib_stats import Stats
+        from datasurfer.lib_signals import Signal
         
-        return Stats(self)
+        return Signal(self)
     
     @property
     def mlearn(self):
         
         from datasurfer.lib_mlearn import MLearn
         
         return MLearn(self)
+    
+    @property
+    def multiprocessor(self):
+        
+        if not hasattr(self, '_multiproc'):   
+                
+            from datasurfer.util_multiproc import MultiProc       
+            self._multiproc = MultiProc(self)
+            
+        return self._multiproc
+ 
+    mlp = multiprocessor
+    
+    @property
+    def configurator(self):
+        
+        if not hasattr(self, '_configurator'):
+            from datasurfer.util_config import Configurator        
+            self._configurator = Configurator(self)
+            
+        return self._configurator
 
+    cfg = configurator
 
 
 #%% Main Loop
 
 if __name__ == '__main__':
     
     pass
```

### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

## datasurfer/datautils.py

```diff
@@ -9,14 +9,37 @@
 from pathlib import Path
 from itertools import chain
 from collections import abc
 from tqdm import tqdm
 
 
 #%%
+def parse_hook_file(hook):
+    """
+    Parse a hook file and return a list of callable objects defined in the file.
+
+    Args:
+        hook (str): The path to the hook file.
+
+    Returns:
+        list: A list of callable objects defined in the hook file.
+    """
+    import ast
+    
+    callables = [n.name for n in ast.parse(open(hook).read()).body if 
+                    isinstance(n, ast.FunctionDef) or 
+                    isinstance(n, ast.ClassDef) and hasattr(n, '__call__')]
+    
+    mdl = __import__(Path(hook).stem)
+    funs = [getattr(mdl, name) for name in callables]
+    
+    return funs
+
+
+#%%
 def collect_files(root, *patts, warn_if_double=True, ignore_double=False):
     '''
     Gather files from the data directory that match patterns
     
     Parameters:
         root (str): The root directory to start searching for files.
         *patts (str): Variable number of patterns in the format of regular expressions.
@@ -50,15 +73,15 @@
                     yield path
                     
                 found.setdefault(f, []).append(r)
                 
                 
                 
 #%% Show_Pool_Progress_bar
-def show_pool_progress(msg, show=False, set_init=True, count=None):
+def show_pool_progress(msg, show=False, set_init=True, count=None, leave=True):
     """
     Decorator function that adds progress bar functionality to a method in a data pool object.
 
     Parameters:
     - msg (str): The message to display in the progress bar.
     - show (bool): Whether to show the progress bar or not. Default is False.
     - set_init (bool): Whether to set the 'initialized' attribute of the data pool object to True after the method is executed. Default is True.
@@ -81,15 +104,15 @@
                 num = len(self.objs)
             else:
                 num = count
                 
             rng = range(num)
             
             if flag_pbar:
-                pbar = tqdm(rng)
+                pbar = tqdm(rng, leave=leave)
                 iterator = pbar
             else:
                 iterator = rng
              
             for idx in iterator:
                 
                 if flag_pbar: 
@@ -350,100 +373,102 @@
     patt_filter = patt_filter or [r'^\..*']
 
     if isinstance(root, (list, tuple, set)):
         root = chain(*root)
 
     for r, _, fs in os.walk(root):
         d = Path(r).stem
-        ismatch = (any(re.match(patt, d) for patt in patts) 
-                    and (not any(re.match(patt, d) for patt in patt_filter)))
+        
+        fs = [f for f in fs if (any(re.match(patt, os.path.join(d, f)) for patt in patts) and 
+                               (not any(re.match(patt, os.path.join(d, f)) for patt in patt_filter)))]
 
-        if ismatch:
-            path = Path(r)
-            if fs:
-                yield path, fs
+        path = Path(r)
+        if fs:
+            yield path, fs
                 
-#%%
-def arghisto(data, bins):
-    """
-    Compute the histogram of the input data based on the given bins.
-
-    Parameters:
-    data (ndarray): Input data array.
-    bins (ndarray): Bins for computing the histogram.
-
-    Returns:
-    list: List of arrays containing the indices of data points falling into each bin.
-    """
-    out = []
-    dat = data.ravel()
-       
-    for idx in range(0, len(bins)-1):
-        if idx == 0:
-            out.append(np.where((bins[idx]<=dat) & (bins[idx+1]>=dat))[0])
-        else:
-            out.append(np.where((bins[idx]<dat) & (bins[idx+1]>=dat))[0])
-        
-    return out
 
 #%%
-def parse_data(func):   
+def parse_data(*argnames, add_labels=True, label_keys=None):   
     """
     A decorator function that parses the input data before passing it to the decorated function.
 
     Args:
         func (function): The function to be decorated.
 
     Returns:
         function: The decorated function.
 
     Raises:
         ValueError: If the keys are not strings or numpy arrays.
 
     """
-    @wraps(func)
-    def wrapper(self, *keys, **kwargs):
-        
-        def get(keys):
-            out = []
-            lbls = []
-            for key in keys:
-                if isinstance(key, str):
-                    out.append(self.dp[[key]].dropna().to_numpy().ravel())
-                    lbls.append(key)
-                elif isinstance(key, pd.Series):
-                    out.append(key.dropna().to_numpy())
-                    lbls.append(key.name)
-                elif isinstance(key, pd.DataFrame):
-                    out.extend(key.dropna().to_numpy().T)
-                    lbls.extend(key.columns)
-                elif isinstance(key, np.ndarray):
-                    out.append(key)
-                    lbls.append(None)
-                elif isinstance(key, abc.Sequence):
-                    o, ls = get(key)
-                    out.append(o)
-                    lbls.extend(ls)
-                else:
-                    raise ValueError('keys must be strings or numpy arrays')
+    def decorator(func):
+        @wraps(func)
+        def wrapper(self, *keys, **kwargs):
+            
+            def get(keys):
+                out = []
+                lbls = []
+                for key in keys:
+                    if isinstance(key, str):
+                        out.append(buffer[key].values.ravel())
+                        lbls.append(key)
+                    elif isinstance(key, pd.Series):
+                        out.append(key.dropna().values)
+                        lbls.append(key.name)
+                    elif isinstance(key, pd.DataFrame):
+                        out.extend(key.dropna().values.T)
+                        lbls.extend(key.columns)
+                    elif isinstance(key, np.ndarray):
+                        out.append(key)
+                        lbls.append(None)
+                    elif isinstance(key, abc.Sequence):
+                        o, ls = get(key)
+                        out.append(o)
+                        lbls.extend(ls)
+                    else:
+                        out.append(key)
+                        lbls.append(None)
+                    
+                return out, lbls
+            
+            
+            buffer_keys = ([key for key in keys if isinstance(key, str)] 
+                         + [key for key in [kwargs.get(k, None) for k in argnames]])
+            
+            buffer_keys = [key for key in buffer_keys if (key is not None) and isinstance(key, str)] 
+            
+            if len(buffer_keys):
+                buffer = self.db[buffer_keys].dropna() 
+            else:
+                buffer = pd.DataFrame()
+
+            if len(keys) and all(isinstance(key, str) for key in keys):
+                out = buffer[list(keys)].to_numpy().T    
+                lbls = keys
+            else:        
+                out, lbls = get(keys)
                 
-            return out, lbls
-        
-        if all(isinstance(key, str) for key in keys):
-            out = self.dp[keys].dropna().to_numpy().T    
-            lbls = keys
-        else:        
-            out, lbls = get(keys)
-        
-        if ('labels' not in kwargs) and all(lbl is not None for lbl in lbls) :
-            kwargs['labels'] = lbls     
+            lbls = list(lbls)
+
+            for key in argnames:
+                if key in kwargs:
+                    out_, lbls_ = get([kwargs[key]])
+                    kwargs[key] = out_[0]
+                    if label_keys and key in label_keys:
+                        lbls.extend(lbls_)
+
+            
+            if add_labels and ('labels' not in kwargs) and all(lbl is not None for lbl in lbls) :
+                kwargs['labels'] = lbls     
+            
+            return func(self, *out, **kwargs)        
+        return wrapper
+    return decorator
 
-        return func(self, *out, **kwargs)
-    
-    return wrapper
 
 #%%
 
 class bcolors:
     """
     A class that defines ANSI escape codes for text colors and styles.
     
@@ -463,7 +488,18 @@
     OKCYAN = '\033[96m'
     OKGREEN = '\033[92m'
     WARNING = '\033[93m'
     FAIL = '\033[91m'
     ENDC = '\033[0m'
     BOLD = '\033[1m'
     UNDERLINE = '\033[4m'
+    
+#%%
+def str2df(s, **kwargs):
+    
+    from io import StringIO
+    
+    df = pd.read_csv(StringIO(s), **kwargs)
+    
+    return df
+
+#%%
```

## datasurfer/lib_mlearn/__init__.py

```diff
@@ -1,37 +1,104 @@
 import numpy as np
 from functools import wraps
 from datasurfer.datautils import parse_data
-#%%
-def output_control(func):   
 
+#%%
+def output_switcher(func):   
+    """
+    Decorator function that allows switching the output of a function.
+    
+    Args:
+        func (function): The function to be decorated.
+        
+    Returns:
+        function: The decorated function.
+    """
     @wraps(func)
     def wrapper(self, *args, **kwargs):
         
         return_model = kwargs.pop('return_model', False)
         
         mdl, foo = func(self, *args, **kwargs)
         
         if return_model:
             return mdl
         else:
             return foo()
         
     return wrapper
-        
+#%%
+              
         
 
 #%%
 class MLearn(object):
-    
-    def __init__(self, dp=None):
+    """
+    The MLearn class provides functionality for machine learning tasks.
+
+    Parameters:
+    dp: object, optional
+        The data preprocessing object.
+
+    Attributes:
+    dp: object
+        The data preprocessing object.
+
+    Methods:
+    display_decision: Display the decision boundary of a machine learning model.
+    detect_outliers: Detect outliers in the given data.
+    """
+
+    def __init__(self, db=None):
         
-        self.dp = dp
-    
+        self.db = db
+        
+    @property
+    def clustering(self):
+        from datasurfer.lib_mlearn.clustering import Cluster
+        return Cluster()
+        
+    def create_features(self, *keys, reduce_func=None):
+        """
+        Create features from the given keys.
+
+        Args:
+            *keys: Variable length argument representing the keys to retrieve data from.
+            reduce_func (function, optional): A function to reduce the retrieved data. Defaults to None.
+
+        Returns:
+            tuple: A tuple containing the names of the features and the stacked values.
+
+        Raises:
+            KeyError: If a key is not found in the retrieved data.
+
+        """
+        def get():
+            for obj in objs:
+                try:
+                    df = obj.get(*keys).dropna(axis=0)
+                    array = np.atleast_2d(df.values)
+                except KeyError:
+                    array = None
+
+                if array is not None and len(array) and reduce_func is not None:
+                    array = reduce_func(array)
+
+                if array is not None:
+                    yield obj.name, np.atleast_2d(array)
+
+        from datasurfer.datainterface import DataInterface
+
+        objs = [self.db] if isinstance(self.db, DataInterface) else self.db.objs
+
+        names, vals = zip(*get())
+
+        return names, np.vstack(vals)
     
+
     @parse_data    
     def display_decision(self, *vals, model, **kwargs):
         """
         Display the decision boundary of a machine learning model.
 
         Parameters:
         *vals: tuple
@@ -41,31 +108,29 @@
         **kwargs: dict
             Additional keyword arguments to be passed to the DecisionBoundaryDisplay class.
 
         Returns:
         ax: matplotlib.axes.Axes
             The matplotlib axes object containing the decision boundary plot.
         """
+        
         assert len(vals) == 2, "Only two inputs are supported for decision boundary display."
         from sklearn.inspection import DecisionBoundaryDisplay
 
         lbls = kwargs.pop('labels', None)
         disp = DecisionBoundaryDisplay.from_estimator(model, np.vstack(vals).T, **kwargs)
 
         ax = disp.ax_
         ax.set_xlabel(lbls[0])
         ax.set_ylabel(lbls[1])
 
         return ax
-        
-        
-       
-    @output_control 
-    @parse_data    
-    def detect_outliers(self, *vals, **kwargs):
+
+    @output_switcher  
+    def detect_outliers(self, X, **kwargs):
         """
         Detect outliers in the given data.
 
         Parameters:
         *vals : array-like
             Input data values.
 
@@ -76,22 +141,18 @@
         bool
             An array of boolean values indicating whether each data point is an outlier or not.
         """
 
         from sklearn.ensemble import IsolationForest
         kwargs.pop('labels', None)
         
-        X = np.vstack(vals).T
         clf = IsolationForest(**kwargs)
         
         clf.fit(X)
         fstar = lambda :clf.predict(X) == -1
 
         return clf, fstar
     
-    
-    
-        
-    
+
```

## datasurfer/lib_mlearn/preproc.py

```diff
@@ -1,11 +1,15 @@
-import numpy as np
+
 #%%
 def detect_outliers(X, **kwargs):
     
     from sklearn.neighbors import LocalOutlierFactor
    
     lof = LocalOutlierFactor(**kwargs)
     y_pred = lof.fit_predict(X)
     
     return y_pred
+
+#%%
+
+
```

## datasurfer/lib_objects/__init__.py

```diff
@@ -1,1848 +0,0 @@
-00000000: 696d 706f 7274 206f 730d 0a69 6d70 6f72  import os..impor
-00000010: 7420 7265 0d0a 696d 706f 7274 2070 616e  t re..import pan
-00000020: 6461 7320 6173 2070 640d 0a69 6d70 6f72  das as pd..impor
-00000030: 7420 6e75 6d70 7920 6173 206e 700d 0a69  t numpy as np..i
-00000040: 6d70 6f72 7420 7761 726e 696e 6773 0d0a  mport warnings..
-00000050: 696d 706f 7274 2074 7261 6365 6261 636b  import traceback
-00000060: 0d0a 0d0a 6672 6f6d 2061 6263 2069 6d70  ....from abc imp
-00000070: 6f72 7420 4142 432c 2061 6273 7472 6163  ort ABC, abstrac
-00000080: 746d 6574 686f 640d 0a66 726f 6d20 7061  tmethod..from pa
-00000090: 7468 6c69 6220 696d 706f 7274 2050 6174  thlib import Pat
-000000a0: 680d 0a66 726f 6d20 6469 6666 6c69 6220  h..from difflib 
-000000b0: 696d 706f 7274 2053 6571 7565 6e63 654d  import SequenceM
-000000c0: 6174 6368 6572 0d0a 6672 6f6d 2069 7465  atcher..from ite
-000000d0: 7274 6f6f 6c73 2069 6d70 6f72 7420 6368  rtools import ch
-000000e0: 6169 6e2c 207a 6970 5f6c 6f6e 6765 7374  ain, zip_longest
-000000f0: 0d0a 6672 6f6d 2064 6174 6173 7572 6665  ..from datasurfe
-00000100: 722e 6461 7461 7574 696c 7320 696d 706f  r.datautils impo
-00000110: 7274 2070 6172 7365 5f63 6f6e 6669 672c  rt parse_config,
-00000120: 2074 7261 6e73 6c61 7465 5f63 6f6e 6669   translate_confi
-00000130: 672c 2065 7874 7261 6374 5f63 6861 6e6e  g, extract_chann
-00000140: 656c 730d 0a0d 0a23 2525 2044 6174 615f  els....#%% Data_
-00000150: 496e 7465 7266 6163 650d 0a0d 0a63 6c61  Interface....cla
-00000160: 7373 2044 6174 6149 6e74 6572 6661 6365  ss DataInterface
-00000170: 2841 4243 293a 0d0a 2020 2020 2222 220d  (ABC):..    """.
-00000180: 0a20 2020 2041 2063 6c61 7373 2072 6570  .    A class rep
-00000190: 7265 7365 6e74 696e 6720 7061 7265 6e74  resenting parent
-000001a0: 2063 6c61 7373 206f 6620 616c 6c20 6461   class of all da
-000001b0: 7461 2069 6e74 6572 6661 6365 732e 0d0a  ta interfaces...
-000001c0: 0d0a 2020 2020 5061 7261 6d65 7465 7273  ..    Parameters
-000001d0: 3a0d 0a20 2020 202d 2070 6174 6820 2873  :..    - path (s
-000001e0: 7472 206f 7220 5061 7468 293a 2054 6865  tr or Path): The
-000001f0: 2070 6174 6820 746f 2074 6865 2064 6174   path to the dat
-00000200: 6120 6669 6c65 2e0d 0a20 2020 202d 2063  a file...    - c
-00000210: 6f6e 6669 6720 2873 7472 2c20 5061 7468  onfig (str, Path
-00000220: 2c20 6c69 7374 2c20 7475 706c 652c 2073  , list, tuple, s
-00000230: 6574 2c20 6f72 2064 6963 7429 3a20 5468  et, or dict): Th
-00000240: 6520 636f 6e66 6967 7572 6174 696f 6e20  e configuration 
-00000250: 666f 7220 7468 6520 6461 7461 206f 626a  for the data obj
-00000260: 6563 742e 0d0a 2020 2020 2d20 6e61 6d65  ect...    - name
-00000270: 2028 7374 7229 3a20 5468 6520 6e61 6d65   (str): The name
-00000280: 206f 6620 7468 6520 6461 7461 206f 626a   of the data obj
-00000290: 6563 742e 0d0a 2020 2020 2d20 636f 6d6d  ect...    - comm
-000002a0: 656e 7420 2873 7472 293a 2041 6464 6974  ent (str): Addit
-000002b0: 696f 6e61 6c20 636f 6d6d 656e 7420 6f72  ional comment or
-000002c0: 2064 6573 6372 6970 7469 6f6e 2066 6f72   description for
-000002d0: 2074 6865 2064 6174 6120 6f62 6a65 6374   the data object
-000002e0: 2e0d 0a0d 0a20 2020 2041 7474 7269 6275  .....    Attribu
-000002f0: 7465 733a 0d0a 2020 2020 2d20 7061 7468  tes:..    - path
-00000300: 2028 5061 7468 293a 2054 6865 2061 6273   (Path): The abs
-00000310: 6f6c 7574 6520 7061 7468 2074 6f20 7468  olute path to th
-00000320: 6520 6461 7461 2066 696c 652e 0d0a 2020  e data file...  
-00000330: 2020 2d20 636f 6e66 6967 2028 6469 6374    - config (dict
-00000340: 293a 2054 6865 2063 6f6e 6669 6775 7261  ): The configura
-00000350: 7469 6f6e 2066 6f72 2074 6865 2064 6174  tion for the dat
-00000360: 6120 6f62 6a65 6374 2e0d 0a20 2020 202d  a object...    -
-00000370: 206e 616d 6520 2873 7472 293a 2054 6865   name (str): The
-00000380: 206e 616d 6520 6f66 2074 6865 2064 6174   name of the dat
-00000390: 6120 6f62 6a65 6374 2e0d 0a20 2020 202d  a object...    -
-000003a0: 2063 6f6d 6d65 6e74 2028 7374 7229 3a20   comment (str): 
-000003b0: 4164 6469 7469 6f6e 616c 2063 6f6d 6d65  Additional comme
-000003c0: 6e74 206f 7220 6465 7363 7269 7074 696f  nt or descriptio
-000003d0: 6e20 666f 7220 7468 6520 6461 7461 206f  n for the data o
-000003e0: 626a 6563 742e 0d0a 2020 2020 2d20 6466  bject...    - df
-000003f0: 2028 4461 7461 4672 616d 6529 3a20 5468   (DataFrame): Th
-00000400: 6520 6461 7461 2073 746f 7265 6420 696e  e data stored in
-00000410: 2061 2070 616e 6461 7320 4461 7461 4672   a pandas DataFr
-00000420: 616d 652e 0d0a 0d0a 2020 2020 4d65 7468  ame.....    Meth
-00000430: 6f64 733a 0d0a 2020 2020 2d20 5f5f 656e  ods:..    - __en
-00000440: 7465 725f 5f28 293a 2045 6e74 6572 206d  ter__(): Enter m
-00000450: 6574 686f 6420 666f 7220 636f 6e74 6578  ethod for contex
-00000460: 7420 6d61 6e61 6765 6d65 6e74 2e0d 0a20  t management... 
-00000470: 2020 202d 205f 5f65 7869 745f 5f28 6578     - __exit__(ex
-00000480: 635f 7479 7065 2c20 6578 635f 7661 6c75  c_type, exc_valu
-00000490: 652c 2065 7863 5f74 7261 6365 6261 636b  e, exc_traceback
-000004a0: 293a 2045 7869 7420 6d65 7468 6f64 2066  ): Exit method f
-000004b0: 6f72 2063 6f6e 7465 7874 206d 616e 6167  or context manag
-000004c0: 656d 656e 742e 0d0a 2020 2020 2d20 5f5f  ement...    - __
-000004d0: 7265 7072 5f5f 2829 3a20 5265 7475 726e  repr__(): Return
-000004e0: 7320 6120 7374 7269 6e67 2072 6570 7265  s a string repre
-000004f0: 7365 6e74 6174 696f 6e20 6f66 2074 6865  sentation of the
-00000500: 2064 6174 6120 6f62 6a65 6374 2e0d 0a20   data object... 
-00000510: 2020 202d 205f 5f73 7472 5f5f 2829 3a20     - __str__(): 
-00000520: 5265 7475 726e 7320 6120 7374 7269 6e67  Returns a string
-00000530: 2072 6570 7265 7365 6e74 6174 696f 6e20   representation 
-00000540: 6f66 2074 6865 2064 6174 6120 6f62 6a65  of the data obje
-00000550: 6374 2e0d 0a20 2020 202d 205f 5f6c 656e  ct...    - __len
-00000560: 5f5f 2829 3a20 5265 7475 726e 7320 7468  __(): Returns th
-00000570: 6520 6e75 6d62 6572 206f 6620 726f 7773  e number of rows
-00000580: 2069 6e20 7468 6520 6461 7461 206f 626a   in the data obj
-00000590: 6563 742e 0d0a 2020 2020 2d20 5f5f 6765  ect...    - __ge
-000005a0: 7469 7465 6d5f 5f28 6e61 6d65 293a 2052  titem__(name): R
-000005b0: 6574 7572 6e73 2061 2063 6f6c 756d 6e20  eturns a column 
-000005c0: 6f72 2073 7562 7365 7420 6f66 2063 6f6c  or subset of col
-000005d0: 756d 6e73 2066 726f 6d20 7468 6520 6461  umns from the da
-000005e0: 7461 206f 626a 6563 742e 0d0a 2020 2020  ta object...    
-000005f0: 2d20 5f5f 7365 7469 7465 6d5f 5f28 6e61  - __setitem__(na
-00000600: 6d65 2c20 7661 6c75 6529 3a20 5365 7473  me, value): Sets
-00000610: 2074 6865 2076 616c 7565 206f 6620 6120   the value of a 
-00000620: 636f 6c75 6d6e 2069 6e20 7468 6520 6461  column in the da
-00000630: 7461 206f 626a 6563 742e 0d0a 2020 2020  ta object...    
-00000640: 2d20 696e 6465 7828 293a 2052 6574 7572  - index(): Retur
-00000650: 6e73 2074 6865 2069 6e64 6578 206f 6620  ns the index of 
-00000660: 7468 6520 6461 7461 206f 626a 6563 742e  the data object.
-00000670: 0d0a 2020 2020 2d20 6d65 7461 5f69 6e66  ..    - meta_inf
-00000680: 6f28 293a 2052 6574 7572 6e73 206d 6574  o(): Returns met
-00000690: 6164 6174 6120 696e 666f 726d 6174 696f  adata informatio
-000006a0: 6e20 6162 6f75 7420 7468 6520 6461 7461  n about the data
-000006b0: 206f 626a 6563 742e 0d0a 2020 2020 2d20   object...    - 
-000006c0: 7369 7a65 2829 3a20 5265 7475 726e 7320  size(): Returns 
-000006d0: 7468 6520 7369 7a65 206f 6620 7468 6520  the size of the 
-000006e0: 6461 7461 2066 696c 6520 696e 2062 7974  data file in byt
-000006f0: 6573 2e0d 0a20 2020 202d 2063 6f6d 6d65  es...    - comme
-00000700: 6e74 2829 3a20 5265 7475 726e 7320 7468  nt(): Returns th
-00000710: 6520 636f 6d6d 656e 7420 6f72 2064 6573  e comment or des
-00000720: 6372 6970 7469 6f6e 206f 6620 7468 6520  cription of the 
-00000730: 6461 7461 206f 626a 6563 742e 0d0a 2020  data object...  
-00000740: 2020 2d20 636f 6d6d 656e 7428 7661 6c75    - comment(valu
-00000750: 6529 3a20 5365 7473 2074 6865 2063 6f6d  e): Sets the com
-00000760: 6d65 6e74 206f 7220 6465 7363 7269 7074  ment or descript
-00000770: 696f 6e20 6f66 2074 6865 2064 6174 6120  ion of the data 
-00000780: 6f62 6a65 6374 2e0d 0a20 2020 202d 2064  object...    - d
-00000790: 6628 293a 2052 6574 7572 6e73 2074 6865  f(): Returns the
-000007a0: 2064 6174 6120 7374 6f72 6564 2069 6e20   data stored in 
-000007b0: 6120 7061 6e64 6173 2044 6174 6146 7261  a pandas DataFra
-000007c0: 6d65 2e0d 0a20 2020 202d 206e 616d 6528  me...    - name(
-000007d0: 293a 2052 6574 7572 6e73 2074 6865 206e  ): Returns the n
-000007e0: 616d 6520 6f66 2074 6865 2064 6174 6120  ame of the data 
-000007f0: 6f62 6a65 6374 2e0d 0a20 2020 202d 206e  object...    - n
-00000800: 616d 6528 7661 6c75 6529 3a20 5365 7473  ame(value): Sets
-00000810: 2074 6865 206e 616d 6520 6f66 2074 6865   the name of the
-00000820: 2064 6174 6120 6f62 6a65 6374 2e0d 0a20   data object... 
-00000830: 2020 202d 2069 6e69 7469 616c 697a 6528     - initialize(
-00000840: 293a 2049 6e69 7469 616c 697a 6573 2074  ): Initializes t
-00000850: 6865 2064 6174 6120 6f62 6a65 6374 2062  he data object b
-00000860: 7920 6c6f 6164 696e 6720 7468 6520 6461  y loading the da
-00000870: 7461 2069 6e74 6f20 6120 4461 7461 4672  ta into a DataFr
-00000880: 616d 652e 0d0a 2020 2020 2d20 6b65 7973  ame...    - keys
-00000890: 2829 3a20 5265 7475 726e 7320 6120 6c69  (): Returns a li
-000008a0: 7374 206f 6620 636f 6c75 6d6e 206e 616d  st of column nam
-000008b0: 6573 2069 6e20 7468 6520 6461 7461 206f  es in the data o
-000008c0: 626a 6563 742e 0d0a 2020 2020 2d20 6465  bject...    - de
-000008d0: 7363 7269 6265 2829 3a20 5265 7475 726e  scribe(): Return
-000008e0: 7320 6465 7363 7269 7074 6976 6520 7374  s descriptive st
-000008f0: 6174 6973 7469 6373 206f 6620 7468 6520  atistics of the 
-00000900: 6461 7461 206f 626a 6563 742e 0d0a 2020  data object...  
-00000910: 2020 2d20 636f 756e 7428 293a 2052 6574    - count(): Ret
-00000920: 7572 6e73 2074 6865 206e 756d 6265 7220  urns the number 
-00000930: 6f66 206e 6f6e 2d6e 756c 6c20 7661 6c75  of non-null valu
-00000940: 6573 2069 6e20 6561 6368 2063 6f6c 756d  es in each colum
-00000950: 6e20 6f66 2074 6865 2064 6174 6120 6f62  n of the data ob
-00000960: 6a65 6374 2e0d 0a20 2020 202d 2067 6574  ject...    - get
-00000970: 282a 6e61 6d65 7329 3a20 5265 7475 726e  (*names): Return
-00000980: 7320 6120 7375 6273 6574 206f 6620 636f  s a subset of co
-00000990: 6c75 6d6e 7320 6672 6f6d 2074 6865 2064  lumns from the d
-000009a0: 6174 6120 6f62 6a65 6374 2e0d 0a20 2020  ata object...   
-000009b0: 202d 2073 6561 7263 6828 7061 7474 2c20   - search(patt, 
-000009c0: 6967 6e6f 7265 5f63 6173 653d 5472 7565  ignore_case=True
-000009d0: 2c20 7261 6973 655f 6572 726f 723d 4661  , raise_error=Fa
-000009e0: 6c73 6529 3a20 5365 6172 6368 6573 2066  lse): Searches f
-000009f0: 6f72 2063 6f6c 756d 6e73 2074 6861 7420  or columns that 
-00000a00: 6d61 7463 6820 6120 7061 7474 6572 6e2e  match a pattern.
-00000a10: 0d0a 2020 2020 2d20 6d65 6d6f 7279 5f75  ..    - memory_u
-00000a20: 7361 6765 2829 3a20 5265 7475 726e 7320  sage(): Returns 
-00000a30: 7468 6520 6d65 6d6f 7279 2075 7361 6765  the memory usage
-00000a40: 206f 6620 7468 6520 6461 7461 206f 626a   of the data obj
-00000a50: 6563 742e 0d0a 2020 2020 2d20 636c 6561  ect...    - clea
-00000a60: 6e5f 636f 6e66 6967 2829 3a20 436c 6561  n_config(): Clea
-00000a70: 6e73 2074 6865 2063 6f6e 6669 6775 7261  ns the configura
-00000a80: 7469 6f6e 2062 7920 7265 6d6f 7669 6e67  tion by removing
-00000a90: 206b 6579 7320 7468 6174 2064 6f20 6e6f   keys that do no
-00000aa0: 7420 6578 6973 7420 696e 2074 6865 2064  t exist in the d
-00000ab0: 6174 6120 6f62 6a65 6374 2e0d 0a20 2020  ata object...   
-00000ac0: 202d 2073 6561 7263 685f 7369 6d69 6c61   - search_simila
-00000ad0: 7228 6e61 6d65 293a 2053 6561 7263 6865  r(name): Searche
-00000ae0: 7320 666f 7220 636f 6c75 6d6e 206e 616d  s for column nam
-00000af0: 6573 2074 6861 7420 6172 6520 7369 6d69  es that are simi
-00000b00: 6c61 7220 746f 2074 6865 2067 6976 656e  lar to the given
-00000b10: 206e 616d 652e 0d0a 2020 2020 2d20 6472   name...    - dr
-00000b20: 6f70 282a 6e61 6d65 732c 206e 6f6e 6578  op(*names, nonex
-00000b30: 6973 745f 6f6b 3d54 7275 6529 3a20 4472  ist_ok=True): Dr
-00000b40: 6f70 7320 636f 6c75 6d6e 7320 6672 6f6d  ops columns from
-00000b50: 2074 6865 2064 6174 6120 6f62 6a65 6374   the data object
-00000b60: 2e0d 0a20 2020 202d 2073 6561 7263 685f  ...    - search_
-00000b70: 6765 7428 7061 7474 2c20 6967 6e6f 7265  get(patt, ignore
-00000b80: 5f63 6173 653d 4661 6c73 652c 2072 6169  _case=False, rai
-00000b90: 7365 5f65 7272 6f72 3d46 616c 7365 293a  se_error=False):
-00000ba0: 2052 6574 7572 6e73 2061 2073 7562 7365   Returns a subse
-00000bb0: 7420 6f66 2063 6f6c 756d 6e73 2074 6861  t of columns tha
-00000bc0: 7420 6d61 7463 6820 6120 7061 7474 6572  t match a patter
-00000bd0: 6e2e 0d0a 2020 2020 2d20 6c6f 6164 282a  n...    - load(*
-00000be0: 6b65 7973 2c20 6d61 7070 696e 673d 4e6f  keys, mapping=No
-00000bf0: 6e65 293a 204c 6f61 6473 2061 6464 6974  ne): Loads addit
-00000c00: 696f 6e61 6c20 636f 6c75 6d6e 7320 696e  ional columns in
-00000c10: 746f 2074 6865 2064 6174 6120 6f62 6a65  to the data obje
-00000c20: 6374 2e0d 0a20 2020 202d 2072 656c 6f61  ct...    - reloa
-00000c30: 6428 293a 2052 656c 6f61 6473 2074 6865  d(): Reloads the
-00000c40: 2064 6174 6120 6f62 6a65 6374 2062 7920   data object by 
-00000c50: 636c 6561 7269 6e67 2074 6865 2044 6174  clearing the Dat
-00000c60: 6146 7261 6d65 2063 6163 6865 2e0d 0a20  aFrame cache... 
-00000c70: 2020 202d 206d 6572 6765 286f 626a 3029     - merge(obj0)
-00000c80: 3a20 4d65 7267 6573 2061 6e6f 7468 6572  : Merges another
-00000c90: 2064 6174 6120 6f62 6a65 6374 2069 6e74   data object int
-00000ca0: 6f20 7468 6520 6375 7272 656e 7420 6461  o the current da
-00000cb0: 7461 206f 626a 6563 742e 0d0a 2020 2020  ta object...    
-00000cc0: 2d20 7371 7565 657a 6528 2a6b 6579 7329  - squeeze(*keys)
-00000cd0: 3a20 5265 6d6f 7665 7320 636f 6c75 6d6e  : Removes column
-00000ce0: 7320 6672 6f6d 2074 6865 2064 6174 6120  s from the data 
-00000cf0: 6f62 6a65 6374 2c20 6b65 6570 696e 6720  object, keeping 
-00000d00: 6f6e 6c79 2074 6865 2073 7065 6369 6669  only the specifi
-00000d10: 6564 2063 6f6c 756d 6e73 2e0d 0a20 2020  ed columns...   
-00000d20: 202d 2070 6970 6528 2a66 756e 7329 3a20   - pipe(*funs): 
-00000d30: 4170 706c 6965 7320 6120 7365 7269 6573  Applies a series
-00000d40: 206f 6620 6675 6e63 7469 6f6e 7320 746f   of functions to
-00000d50: 2074 6865 2064 6174 6120 6f62 6a65 6374   the data object
-00000d60: 2e0d 0a20 2020 202d 2072 656e 616d 6528  ...    - rename(
-00000d70: 2a2a 6b77 6172 6773 293a 2052 656e 616d  **kwargs): Renam
-00000d80: 6573 2063 6f6c 756d 6e73 2069 6e20 7468  es columns in th
-00000d90: 6520 6461 7461 206f 626a 6563 742e 0d0a  e data object...
-00000da0: 2020 2020 2d20 7265 7361 6d70 6c65 286e      - resample(n
-00000db0: 6577 5f69 6e64 6578 3d4e 6f6e 6529 3a20  ew_index=None): 
-00000dc0: 5265 7361 6d70 6c65 7320 7468 6520 6461  Resamples the da
-00000dd0: 7461 206f 626a 6563 7420 746f 2061 206e  ta object to a n
-00000de0: 6577 2069 6e64 6578 2e0d 0a20 2020 202d  ew index...    -
-00000df0: 2074 6f5f 6e75 6d70 7928 293a 2052 6574   to_numpy(): Ret
-00000e00: 7572 6e73 2074 6865 2064 6174 6120 6173  urns the data as
-00000e10: 2061 206e 756d 7079 2061 7272 6179 2e0d   a numpy array..
-00000e20: 0a20 2020 202d 2074 6f5f 6469 6374 2829  .    - to_dict()
-00000e30: 3a20 5265 7475 726e 7320 7468 6520 6461  : Returns the da
-00000e40: 7461 2061 7320 6120 6469 6374 696f 6e61  ta as a dictiona
-00000e50: 7279 2e0d 0a20 2020 202d 2074 6f5f 6373  ry...    - to_cs
-00000e60: 7628 6e61 6d65 3d4e 6f6e 652c 206f 7665  v(name=None, ove
-00000e70: 7277 7269 7465 3d54 7275 6529 3a20 5361  rwrite=True): Sa
-00000e80: 7665 7320 7468 6520 6461 7461 2061 7320  ves the data as 
-00000e90: 6120 4353 5620 6669 6c65 2e0d 0a20 2020  a CSV file...   
-00000ea0: 202d 2074 6f5f 6578 6365 6c28 6e61 6d65   - to_excel(name
-00000eb0: 3d4e 6f6e 652c 206f 7665 7277 7269 7465  =None, overwrite
-00000ec0: 3d54 7275 6529 3a20 5361 7665 7320 7468  =True): Saves th
-00000ed0: 6520 6461 7461 2061 7320 616e 2045 7863  e data as an Exc
-00000ee0: 656c 2066 696c 652e 0d0a 2020 2020 2d20  el file...    - 
-00000ef0: 7361 7665 286e 616d 652c 206f 7665 7277  save(name, overw
-00000f00: 7269 7465 3d54 7275 6529 3a20 5361 7665  rite=True): Save
-00000f10: 7320 7468 6520 6461 7461 206f 626a 6563  s the data objec
-00000f20: 7420 746f 2061 2066 696c 652e 0d0a 2020  t to a file...  
-00000f30: 2020 2d20 636c 6f73 6528 636c 6561 6e3d    - close(clean=
-00000f40: 5472 7565 293a 2043 6c6f 7365 7320 7468  True): Closes th
-00000f50: 6520 6461 7461 206f 626a 6563 7420 616e  e data object an
-00000f60: 6420 636c 6561 6e73 2075 7020 7265 736f  d cleans up reso
-00000f70: 7572 6365 732e 0d0a 2020 2020 2222 220d  urces...    """.
-00000f80: 0a20 2020 0d0a 2020 200d 0a20 2020 2064  .   ..   ..    d
-00000f90: 6566 205f 5f69 6e69 745f 5f28 7365 6c66  ef __init__(self
-00000fa0: 2c20 7061 7468 2c20 636f 6e66 6967 3d4e  , path, config=N
-00000fb0: 6f6e 652c 206e 616d 653d 4e6f 6e65 2c20  one, name=None, 
-00000fc0: 636f 6d6d 656e 743d 4e6f 6e65 293a 0d0a  comment=None):..
-00000fd0: 2020 2020 2020 2020 2222 220d 0a20 2020          """..   
-00000fe0: 2020 2020 2049 6e69 7469 616c 697a 6520       Initialize 
-00000ff0: 6120 4461 7461 4f62 6a65 6374 2069 6e73  a DataObject ins
-00001000: 7461 6e63 652e 0d0a 0d0a 2020 2020 2020  tance.....      
-00001010: 2020 4172 6773 3a0d 0a20 2020 2020 2020    Args:..       
-00001020: 2020 2020 2070 6174 6820 2873 7472 206f       path (str o
-00001030: 7220 5061 7468 293a 2054 6865 2070 6174  r Path): The pat
-00001040: 6820 746f 2074 6865 2064 6174 6120 6f62  h to the data ob
-00001050: 6a65 6374 2e0d 0a20 2020 2020 2020 2020  ject...         
-00001060: 2020 2063 6f6e 6669 6720 2873 7472 2c20     config (str, 
-00001070: 5061 7468 2c20 6c69 7374 2c20 7475 706c  Path, list, tupl
-00001080: 652c 2073 6574 2c20 6469 6374 2c20 6f70  e, set, dict, op
-00001090: 7469 6f6e 616c 293a 2054 6865 2063 6f6e  tional): The con
-000010a0: 6669 6775 7261 7469 6f6e 2066 6f72 2074  figuration for t
-000010b0: 6865 2064 6174 6120 6f62 6a65 6374 2e0d  he data object..
-000010c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000010d0: 2049 6620 6120 7374 7269 6e67 206f 7220   If a string or 
-000010e0: 5061 7468 2069 7320 7072 6f76 6964 6564  Path is provided
-000010f0: 2c20 6974 2069 7320 6173 7375 6d65 6420  , it is assumed 
-00001100: 746f 2062 6520 6120 7061 7468 2074 6f20  to be a path to 
-00001110: 6120 4a53 4f4e 2066 696c 6520 616e 6420  a JSON file and 
-00001120: 7769 6c6c 2062 6520 6c6f 6164 6564 2061  will be loaded a
-00001130: 7320 6120 6469 6374 696f 6e61 7279 2e0d  s a dictionary..
-00001140: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00001150: 2049 6620 6120 6c69 7374 2c20 7475 706c   If a list, tupl
-00001160: 652c 206f 7220 7365 7420 6f66 2073 7472  e, or set of str
-00001170: 696e 6773 2069 7320 7072 6f76 6964 6564  ings is provided
-00001180: 2c20 6974 2077 696c 6c20 6265 2063 6f6e  , it will be con
-00001190: 7665 7274 6564 2069 6e74 6f20 6120 6469  verted into a di
-000011a0: 6374 696f 6e61 7279 2077 6974 6820 6561  ctionary with ea
-000011b0: 6368 2073 7472 696e 6720 6173 2062 6f74  ch string as bot
-000011c0: 6820 7468 6520 6b65 7920 616e 6420 7661  h the key and va
-000011d0: 6c75 652e 0d0a 2020 2020 2020 2020 2020  lue...          
-000011e0: 2020 2020 2020 4966 2061 206c 6973 7420        If a list 
-000011f0: 6f66 2064 6963 7469 6f6e 6172 6965 7320  of dictionaries 
-00001200: 6973 2070 726f 7669 6465 642c 2074 6865  is provided, the
-00001210: 2064 6963 7469 6f6e 6172 6965 7320 7769   dictionaries wi
-00001220: 6c6c 2062 6520 636f 6d62 696e 6564 2069  ll be combined i
-00001230: 6e74 6f20 6120 7369 6e67 6c65 2064 6963  nto a single dic
-00001240: 7469 6f6e 6172 792e 0d0a 2020 2020 2020  tionary...      
-00001250: 2020 2020 2020 2020 2020 4966 2061 2064            If a d
-00001260: 6963 7469 6f6e 6172 7920 6973 2070 726f  ictionary is pro
-00001270: 7669 6465 642c 2069 7420 7769 6c6c 2062  vided, it will b
-00001280: 6520 7573 6564 2061 7320 6973 2e0d 0a20  e used as is... 
-00001290: 2020 2020 2020 2020 2020 2020 2020 2044                 D
-000012a0: 6566 6175 6c74 7320 746f 204e 6f6e 652e  efaults to None.
-000012b0: 0d0a 2020 2020 2020 2020 2020 2020 6e61  ..            na
-000012c0: 6d65 2028 7374 722c 206f 7074 696f 6e61  me (str, optiona
-000012d0: 6c29 3a20 5468 6520 6e61 6d65 206f 6620  l): The name of 
-000012e0: 7468 6520 6461 7461 206f 626a 6563 742e  the data object.
-000012f0: 2044 6566 6175 6c74 7320 746f 204e 6f6e   Defaults to Non
-00001300: 652e 0d0a 2020 2020 2020 2020 2020 2020  e...            
-00001310: 636f 6d6d 656e 7420 2873 7472 2c20 6f70  comment (str, op
-00001320: 7469 6f6e 616c 293a 2041 2063 6f6d 6d65  tional): A comme
-00001330: 6e74 206f 7220 6465 7363 7269 7074 696f  nt or descriptio
-00001340: 6e20 666f 7220 7468 6520 6461 7461 206f  n for the data o
-00001350: 626a 6563 742e 2044 6566 6175 6c74 7320  bject. Defaults 
-00001360: 746f 204e 6f6e 652e 0d0a 2020 2020 2020  to None...      
-00001370: 2020 2222 220d 0a20 2020 2020 2020 2020    """..         
-00001380: 200d 0a20 2020 2020 2020 2069 6620 7061   ..        if pa
-00001390: 7468 2069 7320 6e6f 7420 4e6f 6e65 3a0d  th is not None:.
-000013a0: 0a20 2020 2020 2020 2020 2020 2070 6174  .            pat
-000013b0: 6820 3d20 5061 7468 2870 6174 6829 2e61  h = Path(path).a
-000013c0: 6273 6f6c 7574 6528 2920 0d0a 2020 2020  bsolute() ..    
-000013d0: 2020 2020 2020 2020 0d0a 2020 2020 2020          ..      
-000013e0: 2020 7365 6c66 2e5f 6e61 6d65 203d 206e    self._name = n
-000013f0: 616d 650d 0a20 2020 2020 2020 2073 656c  ame..        sel
-00001400: 662e 7061 7468 203d 2070 6174 680d 0a20  f.path = path.. 
-00001410: 2020 2020 2020 2073 656c 662e 5f63 6f6e         self._con
-00001420: 6669 6720 3d20 7061 7273 655f 636f 6e66  fig = parse_conf
-00001430: 6967 2863 6f6e 6669 6729 0d0a 2020 2020  ig(config)..    
-00001440: 2020 2020 7365 6c66 2e5f 636f 6d6d 656e      self._commen
-00001450: 7420 3d20 636f 6d6d 656e 740d 0a20 2020  t = comment..   
-00001460: 2020 2020 200d 0a20 2020 2064 6566 205f       ..    def _
-00001470: 5f65 6e74 6572 5f5f 2873 656c 6629 3a0d  _enter__(self):.
-00001480: 0a20 2020 2020 2020 200d 0a20 2020 2020  .        ..     
-00001490: 2020 2072 6574 7572 6e20 7365 6c66 0d0a     return self..
-000014a0: 2020 2020 0d0a 2020 2020 6465 6620 5f5f      ..    def __
-000014b0: 6578 6974 5f5f 2873 656c 662c 2065 7863  exit__(self, exc
-000014c0: 5f74 7970 652c 2065 7863 5f76 616c 7565  _type, exc_value
-000014d0: 2c20 6578 635f 7472 6163 6562 6163 6b29  , exc_traceback)
-000014e0: 3a0d 0a20 2020 2020 2020 200d 0a20 2020  :..        ..   
-000014f0: 2020 2020 2073 656c 662e 636c 6f73 6528       self.close(
-00001500: 290d 0a20 2020 2020 2020 200d 0a20 2020  )..        ..   
-00001510: 2020 2020 2069 6620 6578 635f 7479 7065       if exc_type
-00001520: 3a0d 0a20 2020 2020 2020 2020 2020 200d  :..            .
-00001530: 0a20 2020 2020 2020 2020 2020 2072 6574  .            ret
-00001540: 7572 6e20 4661 6c73 650d 0a20 2020 2020  urn False..     
-00001550: 2020 200d 0a20 2020 2020 2020 2072 6574     ..        ret
-00001560: 7572 6e20 5472 7565 0d0a 2020 2020 0d0a  urn True..    ..
-00001570: 2020 2020 6465 6620 5f5f 6571 5f5f 2873      def __eq__(s
-00001580: 656c 662c 206f 7468 6572 293a 0d0a 2020  elf, other):..  
-00001590: 2020 2020 2020 0d0a 2020 2020 2020 2020        ..        
-000015a0: 7265 7475 726e 2028 7365 6c66 2e5f 5f63  return (self.__c
-000015b0: 6c61 7373 5f5f 203d 3d20 6f74 6865 722e  lass__ == other.
-000015c0: 5f5f 636c 6173 735f 5f29 2061 6e64 2028  __class__) and (
-000015d0: 7365 6c66 2e70 6174 6820 3d3d 206f 7468  self.path == oth
-000015e0: 6572 2e70 6174 6829 2061 6e64 2028 7365  er.path) and (se
-000015f0: 6c66 2e6e 616d 6520 3d3d 206f 7468 6572  lf.name == other
-00001600: 2e6e 616d 6529 0d0a 2020 2020 0d0a 2020  .name)..    ..  
-00001610: 2020 6465 6620 5f5f 6861 7368 5f5f 2873    def __hash__(s
-00001620: 656c 6629 3a0d 0a20 2020 2020 2020 2072  elf):..        r
-00001630: 6574 7572 6e20 6861 7368 2828 7365 6c66  eturn hash((self
-00001640: 2e70 6174 682c 2073 656c 662e 6e61 6d65  .path, self.name
-00001650: 2c20 7365 6c66 2e5f 5f63 6c61 7373 5f5f  , self.__class__
-00001660: 2929 0d0a 2020 2020 0d0a 2020 2020 6465  ))..    ..    de
-00001670: 6620 5f5f 7265 7072 5f5f 2873 656c 6629  f __repr__(self)
-00001680: 3a0d 0a20 2020 2020 2020 200d 0a20 2020  :..        ..   
-00001690: 2020 2020 2072 6574 7572 6e20 6627 3c7b       return f'<{
-000016a0: 7365 6c66 2e5f 5f63 6c61 7373 5f5f 2e5f  self.__class__._
-000016b0: 5f6e 616d 655f 5f7d 407b 7365 6c66 2e6e  _name__}@{self.n
-000016c0: 616d 657d 3e27 2020 200d 0a0d 0a20 2020  ame}>'   ....   
-000016d0: 2064 6566 205f 5f73 7472 5f5f 2873 656c   def __str__(sel
-000016e0: 6629 3a0d 0a20 2020 2020 2020 200d 0a20  f):..        .. 
-000016f0: 2020 2020 2020 2072 6574 7572 6e20 7365         return se
-00001700: 6c66 2e5f 5f72 6570 725f 5f28 290d 0a20  lf.__repr__().. 
-00001710: 2020 200d 0a20 2020 2064 6566 205f 5f6c     ..    def __l
-00001720: 656e 5f5f 2873 656c 6629 3a0d 0a20 2020  en__(self):..   
-00001730: 2020 2020 200d 0a20 2020 2020 2020 2072       ..        r
-00001740: 6574 7572 6e20 6c65 6e28 7365 6c66 2e64  eturn len(self.d
-00001750: 6629 0d0a 2020 2020 2020 2020 0d0a 2020  f)..        ..  
-00001760: 2020 6465 6620 5f5f 6765 7469 7465 6d5f    def __getitem_
-00001770: 5f28 7365 6c66 2c20 6e61 6d65 293a 0d0a  _(self, name):..
-00001780: 2020 2020 2020 2020 0d0a 2020 2020 2020          ..      
-00001790: 2020 6966 2069 7369 6e73 7461 6e63 6528    if isinstance(
-000017a0: 6e61 6d65 2c20 7374 7229 2061 6e64 2027  name, str) and '
-000017b0: 2a27 2069 6e20 6e61 6d65 3a0d 0a0d 0a20  *' in name:.... 
-000017c0: 2020 2020 2020 2020 2020 2072 6573 203d             res =
-000017d0: 2073 656c 662e 7365 6172 6368 286e 616d   self.search(nam
-000017e0: 6529 0d0a 2020 2020 2020 2020 0d0a 2020  e)..        ..  
-000017f0: 2020 2020 2020 656c 7365 3a20 200d 0a20        else:  .. 
-00001800: 2020 2020 2020 2020 2020 200d 0a20 2020             ..   
-00001810: 2020 2020 2020 2020 2069 6620 6973 696e           if isin
-00001820: 7374 616e 6365 286e 616d 652c 2073 7472  stance(name, str
-00001830: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
-00001840: 2020 2020 7265 7320 3d20 7365 6c66 2e64      res = self.d
-00001850: 665b 6e61 6d65 5d0d 0a20 2020 2020 2020  f[name]..       
-00001860: 2020 2020 2065 6c73 653a 0d0a 2020 2020       else:..    
-00001870: 2020 2020 2020 2020 2020 2020 7265 7320              res 
-00001880: 3d20 7365 6c66 2e67 6574 282a 6e61 6d65  = self.get(*name
-00001890: 290d 0a20 2020 2020 2020 0d0a 2020 2020  )..       ..    
-000018a0: 2020 2020 7265 7475 726e 2072 6573 0d0a      return res..
-000018b0: 2020 2020 0d0a 2020 2020 6465 6620 5f5f      ..    def __
-000018c0: 7365 7469 7465 6d5f 5f28 7365 6c66 2c20  setitem__(self, 
-000018d0: 6e61 6d65 2c20 7661 6c75 6529 3a0d 0a20  name, value):.. 
-000018e0: 2020 2020 2020 200d 0a20 2020 2020 2020         ..       
-000018f0: 2073 656c 662e 6466 5b6e 616d 655d 203d   self.df[name] =
-00001900: 2076 616c 7565 0d0a 2020 2020 2020 2020   value..        
-00001910: 0d0a 2020 2020 6465 6620 5f5f 636f 6e74  ..    def __cont
-00001920: 6169 6e73 5f5f 2873 656c 662c 206e 616d  ains__(self, nam
-00001930: 6529 3a0d 0a20 2020 2020 2020 200d 0a20  e):..        .. 
-00001940: 2020 2020 2020 2072 6574 7572 6e20 6e61         return na
-00001950: 6d65 2069 6e20 7365 6c66 2e64 662e 636f  me in self.df.co
-00001960: 6c75 6d6e 7320 200d 0a20 2020 200d 0a20  lumns  ..    .. 
-00001970: 2020 2064 6566 205f 5f69 7465 725f 5f28     def __iter__(
-00001980: 7365 6c66 293a 0d0a 2020 2020 2020 2020  self):..        
-00001990: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
-000019a0: 2073 656c 662e 6466 2e69 7465 6d73 2829   self.df.items()
-000019b0: 0d0a 2020 2020 0d0a 2020 2020 4070 726f  ..    ..    @pro
-000019c0: 7065 7274 790d 0a20 2020 2064 6566 2063  perty..    def c
-000019d0: 6f6e 6669 6728 7365 6c66 293a 0d0a 2020  onfig(self):..  
-000019e0: 2020 2020 2020 7265 7475 726e 2073 656c        return sel
-000019f0: 662e 5f63 6f6e 6669 670d 0a20 2020 2040  f._config..    @
-00001a00: 636f 6e66 6967 2e73 6574 7465 720d 0a20  config.setter.. 
-00001a10: 2020 2064 6566 2063 6f6e 6669 6728 7365     def config(se
-00001a20: 6c66 2c20 7661 6c29 3a0d 0a20 2020 2020  lf, val):..     
-00001a30: 2020 200d 0a20 2020 2020 2020 2020 2020     ..           
-00001a40: 2020 2020 200d 0a20 2020 2020 2020 2073       ..        s
-00001a50: 656c 662e 5f63 6f6e 6669 6720 3d20 7061  elf._config = pa
-00001a60: 7273 655f 636f 6e66 6967 2876 616c 2920  rse_config(val) 
-00001a70: 200d 0a20 2020 200d 0a20 2020 2064 6566   ..    ..    def
-00001a80: 2061 7070 6c79 2873 656c 662c 206e 616d   apply(self, nam
-00001a90: 652c 2076 616c 7565 293a 0d0a 2020 2020  e, value):..    
-00001aa0: 2020 2020 2222 220d 0a20 2020 2020 2020      """..       
-00001ab0: 2041 7070 6c69 6573 2074 6865 2067 6976   Applies the giv
-00001ac0: 656e 2076 616c 7565 2074 6f20 7468 6520  en value to the 
-00001ad0: 7370 6563 6966 6965 6420 636f 6c75 6d6e  specified column
-00001ae0: 206e 616d 6520 696e 2074 6865 2044 6174   name in the Dat
-00001af0: 6146 7261 6d65 2e0d 0a0d 0a20 2020 2020  aFrame.....     
-00001b00: 2020 2041 7267 733a 0d0a 2020 2020 2020     Args:..      
-00001b10: 2020 2020 2020 6e61 6d65 2028 7374 7229        name (str)
-00001b20: 3a20 5468 6520 6e61 6d65 206f 6620 7468  : The name of th
-00001b30: 6520 636f 6c75 6d6e 2074 6f20 6170 706c  e column to appl
-00001b40: 7920 7468 6520 7661 6c75 6520 746f 2e0d  y the value to..
-00001b50: 0a20 2020 2020 2020 2020 2020 2076 616c  .            val
-00001b60: 7565 3a20 5468 6520 7661 6c75 6520 746f  ue: The value to
-00001b70: 2061 7070 6c79 2074 6f20 7468 6520 636f   apply to the co
-00001b80: 6c75 6d6e 2e0d 0a0d 0a20 2020 2020 2020  lumn.....       
-00001b90: 2052 6574 7572 6e73 3a0d 0a20 2020 2020   Returns:..     
-00001ba0: 2020 2020 2020 2073 656c 663a 2054 6865         self: The
-00001bb0: 2075 7064 6174 6564 2044 6174 6149 6e74   updated DataInt
-00001bc0: 6572 6661 6365 206f 626a 6563 742e 0d0a  erface object...
-00001bd0: 0d0a 2020 2020 2020 2020 2222 220d 0a20  ..        """.. 
-00001be0: 2020 2020 2020 2073 656c 662e 6466 5b6e         self.df[n
-00001bf0: 616d 655d 203d 2076 616c 7565 0d0a 2020  ame] = value..  
-00001c00: 2020 2020 2020 7265 7475 726e 2073 656c        return sel
-00001c10: 660d 0a20 2020 2064 6566 2073 6574 5f69  f..    def set_i
-00001c20: 6e64 6578 2873 656c 662c 2063 6f6c 6e61  ndex(self, colna
-00001c30: 6d65 2c20 6e61 6d65 3d4e 6f6e 652c 2064  me, name=None, d
-00001c40: 726f 703d 4661 6c73 6529 3a0d 0a20 2020  rop=False):..   
-00001c50: 2020 2020 2022 2222 0d0a 2020 2020 2020       """..      
-00001c60: 2020 4170 706c 7920 7468 6520 7661 6c75    Apply the valu
-00001c70: 6573 206f 6620 6120 7370 6563 6966 6965  es of a specifie
-00001c80: 6420 636f 6c75 6d6e 2061 7320 7468 6520  d column as the 
-00001c90: 6e65 7720 696e 6465 7820 6f66 2074 6865  new index of the
-00001ca0: 2044 6174 6146 7261 6d65 2e0d 0a0d 0a20   DataFrame..... 
-00001cb0: 2020 2020 2020 2050 6172 616d 6574 6572         Parameter
-00001cc0: 733a 0d0a 2020 2020 2020 2020 636f 6c6e  s:..        coln
-00001cd0: 616d 6520 2873 7472 293a 2054 6865 206e  ame (str): The n
-00001ce0: 616d 6520 6f66 2074 6865 2063 6f6c 756d  ame of the colum
-00001cf0: 6e20 746f 2062 6520 7573 6564 2061 7320  n to be used as 
-00001d00: 7468 6520 6e65 7720 696e 6465 782e 0d0a  the new index...
-00001d10: 2020 2020 2020 2020 6e61 6d65 2028 7374          name (st
-00001d20: 722c 206f 7074 696f 6e61 6c29 3a20 5468  r, optional): Th
-00001d30: 6520 6e61 6d65 2074 6f20 6265 2061 7373  e name to be ass
-00001d40: 6967 6e65 6420 746f 2074 6865 206e 6577  igned to the new
-00001d50: 2069 6e64 6578 2e0d 0a0d 0a20 2020 2020   index.....     
-00001d60: 2020 2052 6574 7572 6e73 3a0d 0a20 2020     Returns:..   
-00001d70: 2020 2020 2073 656c 663a 2054 6865 206d       self: The m
-00001d80: 6f64 6966 6965 6420 4461 7461 496e 7465  odified DataInte
-00001d90: 7266 6163 6520 6f62 6a65 6374 2077 6974  rface object wit
-00001da0: 6820 7468 6520 6e65 7720 696e 6465 7820  h the new index 
-00001db0: 6170 706c 6965 642e 0d0a 2020 2020 2020  applied...      
-00001dc0: 2020 2222 220d 0a20 2020 2020 2020 2069    """..        i
-00001dd0: 6620 6472 6f70 3a20 0d0a 2020 2020 2020  f drop: ..      
-00001de0: 2020 2020 2020 7365 6c66 2e64 662e 7365        self.df.se
-00001df0: 745f 696e 6465 7828 636f 6c6e 616d 652c  t_index(colname,
-00001e00: 2069 6e70 6c61 6365 3d54 7275 6529 0d0a   inplace=True)..
-00001e10: 2020 2020 2020 2020 656c 7365 3a20 2020          else:   
-00001e20: 2020 0d0a 2020 2020 2020 2020 2020 2020    ..            
-00001e30: 7365 6c66 2e64 662e 696e 6465 7820 3d20  self.df.index = 
-00001e40: 7365 6c66 2e64 665b 636f 6c6e 616d 655d  self.df[colname]
-00001e50: 0d0a 2020 2020 2020 2020 6966 206e 616d  ..        if nam
-00001e60: 653a 0d0a 2020 2020 2020 2020 2020 2020  e:..            
-00001e70: 7365 6c66 2e64 662e 6e61 6d65 203d 206e  self.df.name = n
-00001e80: 616d 650d 0a0d 0a20 2020 2020 2020 2072  ame....        r
-00001e90: 6574 7572 6e20 7365 6c66 0d0a 2020 2020  eturn self..    
-00001ea0: 0d0a 2020 2020 6465 6620 7265 7365 745f  ..    def reset_
-00001eb0: 696e 6465 7828 7365 6c66 2c20 6472 6f70  index(self, drop
-00001ec0: 3d54 7275 6529 3a0d 0a20 2020 2020 2020  =True):..       
-00001ed0: 2022 2222 0d0a 2020 2020 2020 2020 5265   """..        Re
-00001ee0: 7365 7473 2074 6865 2069 6e64 6578 206f  sets the index o
-00001ef0: 6620 7468 6520 4461 7461 4672 616d 6520  f the DataFrame 
-00001f00: 746f 2074 6865 2064 6566 6175 6c74 2069  to the default i
-00001f10: 6e74 6567 6572 2069 6e64 6578 2e0d 0a0d  nteger index....
-00001f20: 0a20 2020 2020 2020 2041 7267 733a 0d0a  .        Args:..
-00001f30: 2020 2020 2020 2020 2020 2020 2a61 7267              *arg
-00001f40: 733a 2056 6172 6961 626c 6520 6c65 6e67  s: Variable leng
-00001f50: 7468 2061 7267 756d 656e 7420 6c69 7374  th argument list
-00001f60: 2e0d 0a20 2020 2020 2020 2020 2020 202a  ...            *
-00001f70: 2a6b 7761 7267 733a 2041 7262 6974 7261  *kwargs: Arbitra
-00001f80: 7279 206b 6579 776f 7264 2061 7267 756d  ry keyword argum
-00001f90: 656e 7473 2e0d 0a0d 0a20 2020 2020 2020  ents.....       
-00001fa0: 2052 6574 7572 6e73 3a0d 0a20 2020 2020   Returns:..     
-00001fb0: 2020 2020 2020 2073 656c 663a 2054 6865         self: The
-00001fc0: 206d 6f64 6966 6965 6420 4461 7461 496e   modified DataIn
-00001fd0: 7465 7266 6163 6520 6f62 6a65 6374 2077  terface object w
-00001fe0: 6974 6820 7468 6520 696e 6465 7820 7265  ith the index re
-00001ff0: 7365 742e 0d0a 2020 2020 2020 2020 2222  set...        ""
-00002000: 220d 0a20 2020 2020 2020 2073 656c 662e  "..        self.
-00002010: 6466 2e72 6573 6574 5f69 6e64 6578 2869  df.reset_index(i
-00002020: 6e70 6c61 6365 3d54 7275 652c 2064 726f  nplace=True, dro
-00002030: 703d 6472 6f70 290d 0a20 2020 2020 2020  p=drop)..       
-00002040: 2072 6574 7572 6e20 7365 6c66 0d0a 0d0a   return self....
-00002050: 2020 2020 4070 726f 7065 7274 790d 0a20      @property.. 
-00002060: 2020 2064 6566 2069 6e64 6578 2873 656c     def index(sel
-00002070: 6629 3a0d 0a20 2020 2020 2020 2020 2020  f):..           
-00002080: 2022 2222 0d0a 2020 2020 2020 2020 2020   """..          
-00002090: 2020 5265 7475 726e 7320 7468 6520 696e    Returns the in
-000020a0: 6465 7820 6f66 2074 6865 2044 6174 6146  dex of the DataF
-000020b0: 7261 6d65 2061 7320 6120 4e75 6d50 7920  rame as a NumPy 
-000020c0: 6172 7261 792e 0d0a 0d0a 2020 2020 2020  array.....      
-000020d0: 2020 2020 2020 5265 7475 726e 733a 0d0a        Returns:..
-000020e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000020f0: 6e75 6d70 792e 6e64 6172 7261 793a 2054  numpy.ndarray: T
-00002100: 6865 2069 6e64 6578 206f 6620 7468 6520  he index of the 
-00002110: 4461 7461 4672 616d 652e 0d0a 2020 2020  DataFrame...    
-00002120: 2020 2020 2020 2020 2222 220d 0a20 2020          """..   
-00002130: 2020 2020 2020 2020 2072 6574 7572 6e20           return 
-00002140: 6e70 2e61 7361 7272 6179 2873 656c 662e  np.asarray(self.
-00002150: 6466 2e69 6e64 6578 290d 0a20 2020 200d  df.index)..    .
-00002160: 0a20 2020 2040 7072 6f70 6572 7479 0d0a  .    @property..
-00002170: 2020 2020 6465 6620 6d65 7461 5f69 6e66      def meta_inf
-00002180: 6f28 7365 6c66 293a 0d0a 2020 2020 2020  o(self):..      
-00002190: 2020 2222 220d 0a20 2020 2020 2020 2052    """..        R
-000021a0: 6574 7572 6e73 2061 2064 6963 7469 6f6e  eturns a diction
-000021b0: 6172 7920 636f 6e74 6169 6e69 6e67 206d  ary containing m
-000021c0: 6574 6164 6174 6120 696e 666f 726d 6174  etadata informat
-000021d0: 696f 6e20 6162 6f75 7420 7468 6520 6461  ion about the da
-000021e0: 7461 2069 6e74 6572 6661 6365 206f 626a  ta interface obj
-000021f0: 6563 742e 0d0a 0d0a 2020 2020 2020 2020  ect.....        
-00002200: 5265 7475 726e 733a 0d0a 2020 2020 2020  Returns:..      
-00002210: 2020 2020 2020 6469 6374 3a20 4120 6469        dict: A di
-00002220: 6374 696f 6e61 7279 2063 6f6e 7461 696e  ctionary contain
-00002230: 696e 6720 7468 6520 666f 6c6c 6f77 696e  ing the followin
-00002240: 6720 6d65 7461 6461 7461 2069 6e66 6f72  g metadata infor
-00002250: 6d61 7469 6f6e 3a0d 0a20 2020 2020 2020  mation:..       
-00002260: 2020 2020 2020 2020 202d 2027 7061 7468           - 'path
-00002270: 273a 2054 6865 2070 6174 6820 6f66 2074  ': The path of t
-00002280: 6865 2064 6174 6120 696e 7465 7266 6163  he data interfac
-00002290: 6520 6f62 6a65 6374 2e0d 0a20 2020 2020  e object...     
-000022a0: 2020 2020 2020 2020 2020 202d 2027 6e61             - 'na
-000022b0: 6d65 273a 2054 6865 206e 616d 6520 6f66  me': The name of
-000022c0: 2074 6865 2064 6174 6120 696e 7465 7266   the data interf
-000022d0: 6163 6520 6f62 6a65 6374 2e0d 0a20 2020  ace object...   
-000022e0: 2020 2020 2020 2020 2020 2020 202d 2027               - '
-000022f0: 7369 7a65 273a 2054 6865 2073 697a 6520  size': The size 
-00002300: 6f66 2074 6865 2064 6174 6120 696e 7465  of the data inte
-00002310: 7266 6163 6520 6f62 6a65 6374 2e0d 0a20  rface object... 
-00002320: 2020 2020 2020 2020 2020 2020 2020 202d                 -
-00002330: 2027 7368 6170 6527 2028 6f70 7469 6f6e   'shape' (option
-00002340: 616c 293a 2054 6865 2073 6861 7065 206f  al): The shape o
-00002350: 6620 7468 6520 6461 7461 2069 6e74 6572  f the data inter
-00002360: 6661 6365 206f 626a 6563 7420 6966 2069  face object if i
-00002370: 7420 6861 7320 6120 4461 7461 4672 616d  t has a DataFram
-00002380: 6520 6173 736f 6369 6174 6564 2077 6974  e associated wit
-00002390: 6820 6974 2e0d 0a20 2020 2020 2020 2020  h it...         
-000023a0: 2020 2020 2020 202d 2041 6464 6974 696f         - Additio
-000023b0: 6e61 6c20 6d65 7461 6461 7461 2069 6e66  nal metadata inf
-000023c0: 6f72 6d61 7469 6f6e 2066 726f 6d20 7468  ormation from th
-000023d0: 6520 2763 6f6d 6d65 6e74 2720 6174 7472  e 'comment' attr
-000023e0: 6962 7574 652c 2069 6620 6176 6169 6c61  ibute, if availa
-000023f0: 626c 652e 0d0a 2020 2020 2020 2020 2222  ble...        ""
-00002400: 220d 0a20 2020 2020 2020 206f 7574 203d  "..        out =
-00002410: 2064 6963 7428 290d 0a20 2020 2020 2020   dict()..       
-00002420: 206f 7574 5b27 7061 7468 275d 203d 2073   out['path'] = s
-00002430: 7472 2873 656c 662e 7061 7468 290d 0a20  tr(self.path).. 
-00002440: 2020 2020 2020 206f 7574 5b27 6e61 6d65         out['name
-00002450: 275d 203d 2073 656c 662e 6e61 6d65 0d0a  '] = self.name..
-00002460: 2020 2020 2020 2020 6f75 745b 2773 697a          out['siz
-00002470: 6527 5d20 3d20 7365 6c66 2e73 697a 650d  e'] = self.size.
-00002480: 0a0d 0a20 2020 2020 2020 2074 7279 3a0d  ...        try:.
-00002490: 0a20 2020 2020 2020 2020 2020 206f 7574  .            out
-000024a0: 2e75 7064 6174 6528 7365 6c66 2e63 6f6d  .update(self.com
-000024b0: 6d65 6e74 290d 0a20 2020 2020 2020 2065  ment)..        e
-000024c0: 7863 6570 743a 0d0a 2020 2020 2020 2020  xcept:..        
-000024d0: 2020 2020 7061 7373 0d0a 0d0a 2020 2020      pass....    
-000024e0: 2020 2020 6966 2068 6173 6174 7472 2873      if hasattr(s
-000024f0: 656c 662c 2027 5f64 6627 293a 0d0a 2020  elf, '_df'):..  
-00002500: 2020 2020 2020 2020 2020 6f75 745b 2773            out['s
-00002510: 6861 7065 275d 203d 2073 656c 662e 6466  hape'] = self.df
-00002520: 2e73 6861 7065 0d0a 0d0a 2020 2020 2020  .shape....      
-00002530: 2020 7265 7475 726e 206f 7574 0d0a 2020    return out..  
-00002540: 2020 0d0a 2020 2020 4070 726f 7065 7274    ..    @propert
-00002550: 790d 0a20 2020 2064 6566 2073 697a 6528  y..    def size(
-00002560: 7365 6c66 293a 0d0a 2020 2020 2020 2020  self):..        
-00002570: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
-00002580: 206f 732e 7061 7468 2e67 6574 7369 7a65   os.path.getsize
-00002590: 2873 656c 662e 7061 7468 290d 0a20 2020  (self.path)..   
-000025a0: 200d 0a20 2020 2040 7072 6f70 6572 7479   ..    @property
-000025b0: 0d0a 2020 2020 6465 6620 636f 6d6d 656e  ..    def commen
-000025c0: 7428 7365 6c66 293a 0d0a 2020 2020 2020  t(self):..      
-000025d0: 2020 0d0a 2020 2020 2020 2020 7265 7475    ..        retu
-000025e0: 726e 2073 656c 662e 5f63 6f6d 6d65 6e74  rn self._comment
-000025f0: 0d0a 2020 2020 0d0a 2020 2020 4063 6f6d  ..    ..    @com
-00002600: 6d65 6e74 2e73 6574 7465 720d 0a20 2020  ment.setter..   
-00002610: 2064 6566 2063 6f6d 6d65 6e74 2873 656c   def comment(sel
-00002620: 662c 2076 616c 7565 293a 0d0a 2020 2020  f, value):..    
-00002630: 2020 2020 0d0a 2020 2020 2020 2020 7365      ..        se
-00002640: 6c66 2e5f 636f 6d6d 656e 7420 3d20 7661  lf._comment = va
-00002650: 6c75 650d 0a20 2020 200d 0a20 2020 2040  lue..    ..    @
-00002660: 7072 6f70 6572 7479 0d0a 2020 2020 6465  property..    de
-00002670: 6620 6466 2873 656c 6629 3a0d 0a20 2020  f df(self):..   
-00002680: 2020 2020 200d 0a20 2020 2020 2020 2069       ..        i
-00002690: 6620 6e6f 7420 6861 7361 7474 7228 7365  f not hasattr(se
-000026a0: 6c66 2c20 275f 6466 2729 3a0d 0a20 2020  lf, '_df'):..   
-000026b0: 2020 2020 2020 2020 200d 0a20 2020 2020           ..     
-000026c0: 2020 2020 2020 2073 656c 662e 5f64 6620         self._df 
-000026d0: 3d20 7365 6c66 2e67 6574 5f64 6628 290d  = self.get_df().
-000026e0: 0a20 2020 2020 2020 2020 2020 200d 0a20  .            .. 
-000026f0: 2020 2020 2020 2072 6574 7572 6e20 7365         return se
-00002700: 6c66 2e5f 6466 200d 0a20 2020 200d 0a20  lf._df ..    .. 
-00002710: 2020 2040 7072 6f70 6572 7479 0d0a 2020     @property..  
-00002720: 2020 6465 6620 6e61 6d65 2873 656c 6629    def name(self)
-00002730: 3a0d 0a20 2020 2020 2020 200d 0a20 2020  :..        ..   
-00002740: 2020 2020 2069 6620 7365 6c66 2e5f 6e61       if self._na
-00002750: 6d65 2069 7320 4e6f 6e65 3a0d 0a20 2020  me is None:..   
-00002760: 2020 2020 2020 2020 200d 0a20 2020 2020           ..     
-00002770: 2020 2020 2020 2061 7373 6572 7420 7365         assert se
-00002780: 6c66 2e70 6174 6820 6973 206e 6f74 204e  lf.path is not N
-00002790: 6f6e 652c 2027 4578 7065 6374 2061 206e  one, 'Expect a n
-000027a0: 616d 6520 666f 7220 6461 7461 206f 626a  ame for data obj
-000027b0: 6563 742e 270d 0a20 2020 2020 2020 2020  ect.'..         
-000027c0: 2020 2072 6574 7572 6e20 7365 6c66 2e70     return self.p
-000027d0: 6174 682e 7374 656d 0d0a 2020 2020 2020  ath.stem..      
-000027e0: 2020 656c 7365 3a0d 0a20 2020 2020 2020    else:..       
-000027f0: 2020 2020 2072 6574 7572 6e20 7365 6c66       return self
-00002800: 2e5f 6e61 6d65 0d0a 2020 2020 2020 2020  ._name..        
-00002810: 0d0a 2020 2020 406e 616d 652e 7365 7474  ..    @name.sett
-00002820: 6572 0d0a 2020 2020 6465 6620 6e61 6d65  er..    def name
-00002830: 2873 656c 662c 2076 616c 293a 0d0a 2020  (self, val):..  
-00002840: 2020 2020 2020 0d0a 2020 2020 2020 2020        ..        
-00002850: 7365 6c66 2e5f 6e61 6d65 203d 2076 616c  self._name = val
-00002860: 0d0a 2020 2020 2020 2020 0d0a 2020 2020  ..        ..    
-00002870: 4061 6273 7472 6163 746d 6574 686f 640d  @abstractmethod.
-00002880: 0a20 2020 2064 6566 2067 6574 5f64 6628  .    def get_df(
-00002890: 7365 6c66 293a 0d0a 2020 2020 2020 2020  self):..        
-000028a0: 7061 7373 0d0a 2020 2020 2020 2020 0d0a  pass..        ..
-000028b0: 2020 2020 6465 6620 696e 6974 6961 6c69      def initiali
-000028c0: 7a65 2873 656c 662c 2062 7566 6665 723d  ze(self, buffer=
-000028d0: 4e6f 6e65 293a 0d0a 2020 2020 2020 2020  None):..        
-000028e0: 2222 220d 0a20 2020 2020 2020 2049 6e69  """..        Ini
-000028f0: 7469 616c 697a 6573 2074 6865 2064 6174  tializes the dat
-00002900: 6120 696e 7465 7266 6163 6520 6279 2072  a interface by r
-00002910: 6574 7269 6576 696e 6720 7468 6520 6461  etrieving the da
-00002920: 7461 2066 7261 6d65 2e0d 0a20 2020 2020  ta frame...     
-00002930: 2020 200d 0a20 2020 2020 2020 2052 6574     ..        Ret
-00002940: 7572 6e73 3a0d 0a20 2020 2020 2020 2020  urns:..         
-00002950: 2020 2073 656c 663a 2054 6865 2069 6e69     self: The ini
-00002960: 7469 616c 697a 6564 2064 6174 6120 696e  tialized data in
-00002970: 7465 7266 6163 6520 6f62 6a65 6374 2e0d  terface object..
-00002980: 0a20 2020 2020 2020 2022 2222 0d0a 2020  .        """..  
-00002990: 2020 2020 2020 6966 2062 7566 6665 7220        if buffer 
-000029a0: 6973 206e 6f74 204e 6f6e 653a 0d0a 2020  is not None:..  
-000029b0: 2020 2020 2020 2020 2020 7365 6c66 2e5f            self._
-000029c0: 6466 203d 2062 7566 6665 720d 0a20 2020  df = buffer..   
-000029d0: 2020 2020 2065 6c69 6620 6e6f 7420 6861       elif not ha
-000029e0: 7361 7474 7228 7365 6c66 2c20 275f 6466  sattr(self, '_df
-000029f0: 2729 3a0d 0a20 2020 2020 2020 2020 2020  '):..           
-00002a00: 2073 656c 662e 5f64 6620 3d20 7365 6c66   self._df = self
-00002a10: 2e67 6574 5f64 6628 290d 0a20 2020 2020  .get_df()..     
-00002a20: 2020 200d 0a20 2020 2020 2020 2072 6574     ..        ret
-00002a30: 7572 6e20 7365 6c66 0d0a 2020 2020 0d0a  urn self..    ..
-00002a40: 2020 2020 6465 6620 6b65 7973 2873 656c      def keys(sel
-00002a50: 6629 3a0d 0a20 2020 2020 2020 2022 2222  f):..        """
-00002a60: 0d0a 2020 2020 2020 2020 5265 7475 726e  ..        Return
-00002a70: 7320 6120 6c69 7374 206f 6620 636f 6c75  s a list of colu
-00002a80: 6d6e 206e 616d 6573 2069 6e20 7468 6520  mn names in the 
-00002a90: 4461 7461 4672 616d 652e 0d0a 0d0a 2020  DataFrame.....  
-00002aa0: 2020 2020 2020 5265 7475 726e 733a 0d0a        Returns:..
-00002ab0: 2020 2020 2020 2020 2020 2020 6c69 7374              list
-00002ac0: 3a20 4120 6c69 7374 206f 6620 636f 6c75  : A list of colu
-00002ad0: 6d6e 206e 616d 6573 2e0d 0a20 2020 2020  mn names...     
-00002ae0: 2020 2022 2222 0d0a 2020 2020 2020 2020     """..        
-00002af0: 7265 7475 726e 206c 6973 7428 7365 6c66  return list(self
-00002b00: 2e64 662e 636f 6c75 6d6e 7329 0d0a 2020  .df.columns)..  
-00002b10: 2020 0d0a 2020 2020 6465 6620 6465 7363    ..    def desc
-00002b20: 7269 6265 2873 656c 6629 3a0d 0a20 2020  ribe(self):..   
-00002b30: 2020 2020 2022 2222 0d0a 2020 2020 2020       """..      
-00002b40: 2020 5265 7475 726e 7320 6120 7374 6174    Returns a stat
-00002b50: 6973 7469 6361 6c20 7375 6d6d 6172 7920  istical summary 
-00002b60: 6f66 2074 6865 2044 6174 6146 7261 6d65  of the DataFrame
-00002b70: 2e0d 0a0d 0a20 2020 2020 2020 2052 6574  .....        Ret
-00002b80: 7572 6e73 3a0d 0a20 2020 2020 2020 2020  urns:..         
-00002b90: 2020 2070 616e 6461 732e 4461 7461 4672     pandas.DataFr
-00002ba0: 616d 653a 2041 2044 6174 6146 7261 6d65  ame: A DataFrame
-00002bb0: 2063 6f6e 7461 696e 696e 6720 7661 7269   containing vari
-00002bc0: 6f75 7320 7374 6174 6973 7469 6361 6c20  ous statistical 
-00002bd0: 6d65 6173 7572 6573 2073 7563 6820 6173  measures such as
-00002be0: 2063 6f75 6e74 2c20 6d65 616e 2c20 7374   count, mean, st
-00002bf0: 616e 6461 7264 2064 6576 6961 7469 6f6e  andard deviation
-00002c00: 2c20 6d69 6e69 6d75 6d2c 206d 6178 696d  , minimum, maxim
-00002c10: 756d 2c20 616e 6420 7175 6172 7469 6c65  um, and quartile
-00002c20: 732e 0d0a 2020 2020 2020 2020 2222 220d  s...        """.
-00002c30: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00002c40: 7365 6c66 2e64 662e 6465 7363 7269 6265  self.df.describe
-00002c50: 2829 0d0a 2020 2020 0d0a 2020 2020 6465  ()..    ..    de
-00002c60: 6620 636f 756e 7428 7365 6c66 293a 0d0a  f count(self):..
-00002c70: 2020 2020 2020 2020 2222 220d 0a20 2020          """..   
-00002c80: 2020 2020 2052 6574 7572 6e73 2074 6865       Returns the
-00002c90: 206e 756d 6265 7220 6f66 2072 6f77 7320   number of rows 
-00002ca0: 696e 2074 6865 2044 6174 6146 7261 6d65  in the DataFrame
-00002cb0: 2e0d 0a0d 0a20 2020 2020 2020 2052 6574  .....        Ret
-00002cc0: 7572 6e73 3a0d 0a20 2020 2020 2020 2020  urns:..         
-00002cd0: 2020 2069 6e74 3a20 5468 6520 6e75 6d62     int: The numb
-00002ce0: 6572 206f 6620 726f 7773 2069 6e20 7468  er of rows in th
-00002cf0: 6520 4461 7461 4672 616d 652e 0d0a 2020  e DataFrame...  
-00002d00: 2020 2020 2020 2222 220d 0a20 2020 2020        """..     
-00002d10: 2020 2072 6574 7572 6e20 7365 6c66 2e64     return self.d
-00002d20: 662e 636f 756e 7428 290d 0a20 2020 2020  f.count()..     
-00002d30: 2020 200d 0a20 2020 2064 6566 2067 6574     ..    def get
-00002d40: 2873 656c 662c 202a 6e61 6d65 7329 3a0d  (self, *names):.
-00002d50: 0a20 2020 2020 2020 2022 2222 0d0a 2020  .        """..  
-00002d60: 2020 2020 2020 5265 7472 6965 7665 2064        Retrieve d
-00002d70: 6174 6120 6672 6f6d 2074 6865 2044 6174  ata from the Dat
-00002d80: 6146 7261 6d65 2062 6173 6564 206f 6e20  aFrame based on 
-00002d90: 7468 6520 6769 7665 6e20 636f 6c75 6d6e  the given column
-00002da0: 206e 616d 6573 2e0d 0a0d 0a20 2020 2020   names.....     
-00002db0: 2020 2050 6172 616d 6574 6572 733a 0d0a     Parameters:..
-00002dc0: 2020 2020 2020 2020 2020 2020 2a6e 616d              *nam
-00002dd0: 6573 3a20 7374 720d 0a20 2020 2020 2020  es: str..       
-00002de0: 2020 2020 2020 2020 2054 6865 206e 616d           The nam
-00002df0: 6573 206f 6620 7468 6520 636f 6c75 6d6e  es of the column
-00002e00: 7320 746f 2072 6574 7269 6576 6520 6672  s to retrieve fr
-00002e10: 6f6d 2074 6865 2044 6174 6146 7261 6d65  om the DataFrame
-00002e20: 2e0d 0a0d 0a20 2020 2020 2020 2052 6574  .....        Ret
-00002e30: 7572 6e73 3a0d 0a20 2020 2020 2020 2020  urns:..         
-00002e40: 2020 2070 616e 6461 732e 4461 7461 4672     pandas.DataFr
-00002e50: 616d 6520 6f72 2070 616e 6461 732e 5365  ame or pandas.Se
-00002e60: 7269 6573 0d0a 2020 2020 2020 2020 2020  ries..          
-00002e70: 2020 2020 2020 5468 6520 7265 7175 6573        The reques
-00002e80: 7465 6420 6461 7461 2066 726f 6d20 7468  ted data from th
-00002e90: 6520 4461 7461 4672 616d 652e 0d0a 0d0a  e DataFrame.....
-00002ea0: 2020 2020 2020 2020 2222 220d 0a20 2020          """..   
-00002eb0: 2020 2020 2069 6620 6c65 6e28 6e61 6d65       if len(name
-00002ec0: 7329 203d 3d20 313a 0d0a 2020 2020 2020  s) == 1:..      
-00002ed0: 2020 2020 2020 7369 676e 616d 652c 203d        signame, =
-00002ee0: 206e 616d 6573 0d0a 0d0a 2020 2020 2020   names....      
-00002ef0: 2020 2020 2020 6966 2073 6967 6e61 6d65        if signame
-00002f00: 2e6c 6f77 6572 2829 203d 3d20 2774 2720  .lower() == 't' 
-00002f10: 6f72 2073 6967 6e61 6d65 2e6c 6f77 6572  or signame.lower
-00002f20: 2829 203d 3d20 2774 696d 6527 206f 7220  () == 'time' or 
-00002f30: 7369 676e 616d 652e 6c6f 7765 7228 2920  signame.lower() 
-00002f40: 3d3d 2027 696e 6465 7827 3a0d 0a20 2020  == 'index':..   
-00002f50: 2020 2020 2020 2020 2020 2020 2072 6574               ret
-00002f60: 7572 6e20 7064 2e44 6174 6146 7261 6d65  urn pd.DataFrame
-00002f70: 286e 702e 6173 6172 7261 7928 7365 6c66  (np.asarray(self
-00002f80: 2e64 662e 696e 6465 7829 2c20 696e 6465  .df.index), inde
-00002f90: 783d 7365 6c66 2e64 662e 696e 6465 7829  x=self.df.index)
-00002fa0: 0d0a 0d0a 2020 2020 2020 2020 7265 7475  ....        retu
-00002fb0: 726e 2073 656c 662e 6466 5b6c 6973 7428  rn self.df[list(
-00002fc0: 6e61 6d65 7329 5d0d 0a20 2020 200d 0a20  names)]..    .. 
-00002fd0: 2020 200d 0a20 2020 2064 6566 2073 6561     ..    def sea
-00002fe0: 7263 6828 7365 6c66 2c20 7061 7474 2c20  rch(self, patt, 
-00002ff0: 6967 6e6f 7265 5f63 6173 653d 5472 7565  ignore_case=True
-00003000: 2c20 7261 6973 655f 6572 726f 723d 4661  , raise_error=Fa
-00003010: 6c73 6529 3a0d 0a20 2020 2020 2020 2022  lse):..        "
-00003020: 2222 0d0a 2020 2020 2020 2020 5365 6172  ""..        Sear
-00003030: 6368 2066 6f72 206b 6579 7320 696e 2074  ch for keys in t
-00003040: 6865 2064 6174 6120 7374 7275 6374 7572  he data structur
-00003050: 6520 7468 6174 206d 6174 6368 2061 2067  e that match a g
-00003060: 6976 656e 2070 6174 7465 726e 2e0d 0a0d  iven pattern....
-00003070: 0a20 2020 2020 2020 2050 6172 616d 6574  .        Paramet
-00003080: 6572 733a 0d0a 2020 2020 2020 2020 7061  ers:..        pa
-00003090: 7474 2028 7374 7229 3a20 5468 6520 7061  tt (str): The pa
-000030a0: 7474 6572 6e20 746f 2073 6561 7263 6820  ttern to search 
-000030b0: 666f 722e 0d0a 2020 2020 2020 2020 6967  for...        ig
-000030c0: 6e6f 7265 5f63 6173 6520 2862 6f6f 6c2c  nore_case (bool,
-000030d0: 206f 7074 696f 6e61 6c29 3a20 5768 6574   optional): Whet
-000030e0: 6865 7220 746f 2069 676e 6f72 6520 6361  her to ignore ca
-000030f0: 7365 2077 6865 6e20 6d61 7463 6869 6e67  se when matching
-00003100: 2074 6865 2070 6174 7465 726e 2e20 4465   the pattern. De
-00003110: 6661 756c 7473 2074 6f20 5472 7565 2e0d  faults to True..
-00003120: 0a20 2020 2020 2020 2072 6169 7365 5f65  .        raise_e
-00003130: 7272 6f72 2028 626f 6f6c 2c20 6f70 7469  rror (bool, opti
-00003140: 6f6e 616c 293a 2057 6865 7468 6572 2074  onal): Whether t
-00003150: 6f20 7261 6973 6520 6120 4b65 7945 7272  o raise a KeyErr
-00003160: 6f72 2069 6620 6e6f 206d 6174 6368 696e  or if no matchin
-00003170: 6720 6b65 7973 2061 7265 2066 6f75 6e64  g keys are found
-00003180: 2e20 4465 6661 756c 7473 2074 6f20 4661  . Defaults to Fa
-00003190: 6c73 652e 0d0a 0d0a 2020 2020 2020 2020  lse.....        
-000031a0: 5265 7475 726e 733a 0d0a 2020 2020 2020  Returns:..      
-000031b0: 2020 6c69 7374 3a20 4120 6c69 7374 206f    list: A list o
-000031c0: 6620 6b65 7973 2074 6861 7420 6d61 7463  f keys that matc
-000031d0: 6820 7468 6520 7061 7474 6572 6e2e 0d0a  h the pattern...
-000031e0: 2020 2020 2020 2020 2222 220d 0a20 2020          """..   
-000031f0: 2020 2020 200d 0a20 2020 2020 2020 2066       ..        f
-00003200: 6f75 6e64 203d 205b 5d0d 0a20 2020 2020  ound = []..     
-00003210: 2020 200d 0a20 2020 2020 2020 2069 6620     ..        if 
-00003220: 6967 6e6f 7265 5f63 6173 653a 2070 6174  ignore_case: pat
-00003230: 7420 3d20 7061 7474 2e6c 6f77 6572 2829  t = patt.lower()
-00003240: 0d0a 2020 2020 2020 2020 0d0a 2020 2020  ..        ..    
-00003250: 2020 2020 666f 7220 6b65 7920 696e 2073      for key in s
-00003260: 656c 662e 6b65 7973 2829 3a0d 0a20 2020  elf.keys():..   
-00003270: 2020 2020 2020 2020 200d 0a20 2020 2020           ..     
-00003280: 2020 2020 2020 2069 6620 6967 6e6f 7265         if ignore
-00003290: 5f63 6173 653a 0d0a 2020 2020 2020 2020  _case:..        
-000032a0: 2020 2020 2020 2020 0d0a 2020 2020 2020          ..      
-000032b0: 2020 2020 2020 2020 2020 6b65 7930 203d            key0 =
-000032c0: 206b 6579 2e6c 6f77 6572 2829 0d0a 2020   key.lower()..  
-000032d0: 2020 2020 2020 2020 2020 656c 7365 3a0d            else:.
-000032e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000032f0: 206b 6579 3020 3d20 6b65 790d 0a20 2020   key0 = key..   
-00003300: 2020 2020 2020 2020 200d 0a20 2020 2020           ..     
-00003310: 2020 2020 2020 2069 6620 7265 2e6d 6174         if re.mat
-00003320: 6368 2870 6174 742c 206b 6579 3029 3a0d  ch(patt, key0):.
-00003330: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00003340: 200d 0a20 2020 2020 2020 2020 2020 2020   ..             
-00003350: 2020 2066 6f75 6e64 2e61 7070 656e 6428     found.append(
-00003360: 6b65 7929 0d0a 2020 2020 2020 2020 2020  key)..          
-00003370: 2020 2020 2020 0d0a 2020 2020 2020 2020        ..        
-00003380: 2020 2020 2020 2020 0d0a 2020 2020 2020          ..      
-00003390: 2020 6966 206e 6f74 2066 6f75 6e64 2061    if not found a
-000033a0: 6e64 2072 6169 7365 5f65 7272 6f72 3a0d  nd raise_error:.
-000033b0: 0a20 2020 2020 2020 2020 2020 200d 0a20  .            .. 
-000033c0: 2020 2020 2020 2020 2020 2072 6169 7365             raise
-000033d0: 204b 6579 4572 726f 7228 6627 4361 6e6e   KeyError(f'Cann
-000033e0: 6f74 2066 696e 6420 616e 7920 7369 676e  ot find any sign
-000033f0: 616c 2077 6974 6820 7061 7474 6572 6e20  al with pattern 
-00003400: 227b 7061 7474 7d22 2e27 290d 0a20 2020  "{patt}".')..   
-00003410: 2020 2020 2020 2020 200d 0a20 2020 2020           ..     
-00003420: 2020 2074 7279 3a0d 0a20 2020 2020 2020     try:..       
-00003430: 2020 2020 200d 0a20 2020 2020 2020 2020       ..         
-00003440: 2020 2072 6174 696f 7320 3d20 5b53 6571     ratios = [Seq
-00003450: 7565 6e63 654d 6174 6368 6572 2861 3d70  uenceMatcher(a=p
-00003460: 6174 742c 2062 3d66 292e 7261 7469 6f28  att, b=f).ratio(
-00003470: 2920 666f 7220 6620 696e 2066 6f75 6e64  ) for f in found
-00003480: 5d0d 0a20 2020 2020 2020 2020 2020 200d  ]..            .
-00003490: 0a20 2020 2020 2020 2020 2020 205f 2c20  .            _, 
-000034a0: 666f 756e 6420 3d20 7a69 7028 2a73 6f72  found = zip(*sor
-000034b0: 7465 6428 7a69 7028 7261 7469 6f73 2c20  ted(zip(ratios, 
-000034c0: 666f 756e 6429 295b 3a3a 2d31 5d29 0d0a  found))[::-1])..
-000034d0: 2020 2020 2020 2020 2020 2020 0d0a 2020              ..  
-000034e0: 2020 2020 2020 2020 2020 0d0a 2020 2020            ..    
-000034f0: 2020 2020 6578 6365 7074 2056 616c 7565      except Value
-00003500: 4572 726f 723a 0d0a 2020 2020 2020 2020  Error:..        
-00003510: 2020 2020 7061 7373 0d0a 2020 2020 2020      pass..      
-00003520: 2020 2020 2020 2020 2020 0d0a 2020 2020            ..    
-00003530: 2020 2020 7265 7475 726e 206c 6973 7428      return list(
-00003540: 666f 756e 6429 0d0a 0d0a 0d0a 2020 2020  found)......    
-00003550: 0d0a 2020 2020 6465 6620 6d65 6d6f 7279  ..    def memory
-00003560: 5f75 7361 6765 2873 656c 6629 3a0d 0a20  _usage(self):.. 
-00003570: 2020 2020 2020 2022 2222 0d0a 2020 2020         """..    
-00003580: 2020 2020 5265 7475 726e 7320 7468 6520      Returns the 
-00003590: 6d65 6d6f 7279 2075 7361 6765 206f 6620  memory usage of 
-000035a0: 7468 6520 4461 7461 4672 616d 652e 0d0a  the DataFrame...
-000035b0: 0d0a 2020 2020 2020 2020 5265 7475 726e  ..        Return
-000035c0: 733a 0d0a 2020 2020 2020 2020 2020 2020  s:..            
-000035d0: 7061 6e64 6173 2e53 6572 6965 733a 2041  pandas.Series: A
-000035e0: 2053 6572 6965 7320 636f 6e74 6169 6e69   Series containi
-000035f0: 6e67 2074 6865 206d 656d 6f72 7920 7573  ng the memory us
-00003600: 6167 6520 6f66 2065 6163 6820 636f 6c75  age of each colu
-00003610: 6d6e 2069 6e20 7468 6520 4461 7461 4672  mn in the DataFr
-00003620: 616d 652e 0d0a 2020 2020 2020 2020 2222  ame...        ""
-00003630: 220d 0a20 2020 2020 2020 2072 6574 7572  "..        retur
-00003640: 6e20 7365 6c66 2e64 662e 6d65 6d6f 7279  n self.df.memory
-00003650: 5f75 7361 6765 2864 6565 703d 5472 7565  _usage(deep=True
-00003660: 290d 0a20 2020 200d 0a20 2020 2064 6566  )..    ..    def
-00003670: 2063 6c65 616e 5f63 6f6e 6669 6728 7365   clean_config(se
-00003680: 6c66 2c20 7265 706c 6163 653d 4661 6c73  lf, replace=Fals
-00003690: 6529 3a0d 0a20 2020 2020 2020 2022 2222  e):..        """
-000036a0: 0d0a 2020 2020 2020 2020 436c 6561 6e20  ..        Clean 
-000036b0: 7468 6520 636f 6e66 6967 7572 6174 696f  the configuratio
-000036c0: 6e20 6469 6374 696f 6e61 7279 2062 7920  n dictionary by 
-000036d0: 7265 6d6f 7669 6e67 2061 6e79 206b 6579  removing any key
-000036e0: 7320 7468 6174 2061 7265 206e 6f74 2070  s that are not p
-000036f0: 7265 7365 6e74 2069 6e20 7468 6520 4461  resent in the Da
-00003700: 7461 4672 616d 652e 0d0a 0d0a 2020 2020  taFrame.....    
-00003710: 2020 2020 5265 7475 726e 733a 0d0a 2020      Returns:..  
-00003720: 2020 2020 2020 2020 2020 7365 6c66 3a20            self: 
-00003730: 5468 6520 6375 7272 656e 7420 696e 7374  The current inst
-00003740: 616e 6365 206f 6620 7468 6520 6f62 6a65  ance of the obje
-00003750: 6374 2e0d 0a20 2020 2020 2020 2022 2222  ct...        """
-00003760: 0d0a 2020 2020 2020 2020 6966 2073 656c  ..        if sel
-00003770: 662e 636f 6e66 6967 2069 7320 6e6f 7420  f.config is not 
-00003780: 4e6f 6e65 3a0d 0a20 2020 2020 2020 2020  None:..         
-00003790: 2020 206e 6577 5f63 6667 203d 2064 6963     new_cfg = dic
-000037a0: 7428 290d 0a20 2020 2020 2020 2020 2020  t()..           
-000037b0: 206b 6579 7320 3d20 7365 6c66 2e64 662e   keys = self.df.
-000037c0: 6b65 7973 2829 0d0a 2020 2020 2020 2020  keys()..        
-000037d0: 2020 2020 666f 7220 6b2c 2076 2069 6e20      for k, v in 
-000037e0: 7365 6c66 2e63 6f6e 6669 672e 6974 656d  self.config.item
-000037f0: 7328 293a 0d0a 2020 2020 2020 2020 2020  s():..          
-00003800: 2020 2020 2020 6966 206b 2069 6e20 6b65        if k in ke
-00003810: 7973 3a0d 0a20 2020 2020 2020 2020 2020  ys:..           
-00003820: 2020 2020 2020 2020 206e 6577 5f63 6667           new_cfg
-00003830: 5b6b 5d20 3d20 760d 0a20 2020 2020 2020  [k] = v..       
-00003840: 2020 2020 2020 2020 2020 2020 200d 0a20               .. 
-00003850: 2020 2020 2020 2020 2020 2072 6574 7661             retva
-00003860: 6c20 3d20 7365 7428 7365 6c66 2e63 6f6e  l = set(self.con
-00003870: 6669 672e 6b65 7973 2829 2920 2d20 7365  fig.keys()) - se
-00003880: 7428 6e65 775f 6366 672e 6b65 7973 2829  t(new_cfg.keys()
-00003890: 290d 0a20 2020 2020 2020 2020 2020 2069  )..            i
-000038a0: 6620 7265 706c 6163 653a 0d0a 2020 2020  f replace:..    
-000038b0: 2020 2020 2020 2020 2020 2020 7365 6c66              self
-000038c0: 2e63 6f6e 6669 6720 3d20 6e65 775f 6366  .config = new_cf
-000038d0: 670d 0a20 2020 2020 2020 2020 2020 2020  g..             
-000038e0: 2020 2020 200d 0a20 2020 2020 2020 2072       ..        r
-000038f0: 6574 7572 6e20 736f 7274 6564 2872 6574  eturn sorted(ret
-00003900: 7661 6c29 0d0a 2020 2020 0d0a 2020 2020  val)..    ..    
-00003910: 6465 6620 7365 6172 6368 5f73 696d 696c  def search_simil
-00003920: 6172 2873 656c 662c 206e 616d 652c 2063  ar(self, name, c
-00003930: 6861 6e6e 656c 3d54 7275 6529 3a0d 0a20  hannel=True):.. 
-00003940: 2020 2020 2020 2022 2222 0d0a 2020 2020         """..    
-00003950: 2020 2020 5365 6172 6368 6573 2066 6f72      Searches for
-00003960: 206b 6579 7320 696e 2074 6865 2064 6174   keys in the dat
-00003970: 6120 7374 7275 6374 7572 6520 7468 6174  a structure that
-00003980: 2061 7265 2073 696d 696c 6172 2074 6f20   are similar to 
-00003990: 7468 6520 6769 7665 6e20 6e61 6d65 2e0d  the given name..
-000039a0: 0a20 2020 2020 2020 200d 0a20 2020 2020  .        ..     
-000039b0: 2020 2041 7267 733a 0d0a 2020 2020 2020     Args:..      
-000039c0: 2020 2020 2020 6e61 6d65 2028 7374 7229        name (str)
-000039d0: 3a20 5468 6520 6e61 6d65 2074 6f20 7365  : The name to se
-000039e0: 6172 6368 2066 6f72 2073 696d 696c 6172  arch for similar
-000039f0: 6974 6965 732e 0d0a 2020 2020 2020 2020  ities...        
-00003a00: 0d0a 2020 2020 2020 2020 5265 7475 726e  ..        Return
-00003a10: 733a 0d0a 2020 2020 2020 2020 2020 2020  s:..            
-00003a20: 6c69 7374 3a20 4120 6c69 7374 206f 6620  list: A list of 
-00003a30: 6b65 7973 2069 6e20 7468 6520 6461 7461  keys in the data
-00003a40: 2073 7472 7563 7475 7265 2074 6861 7420   structure that 
-00003a50: 6172 6520 7369 6d69 6c61 7220 746f 2074  are similar to t
-00003a60: 6865 2067 6976 656e 206e 616d 652c 2073  he given name, s
-00003a70: 6f72 7465 6420 696e 2064 6573 6365 6e64  orted in descend
-00003a80: 696e 6720 6f72 6465 7220 6f66 2073 696d  ing order of sim
-00003a90: 696c 6172 6974 792e 0d0a 2020 2020 2020  ilarity...      
-00003aa0: 2020 2222 220d 0a20 2020 2020 2020 206b    """..        k
-00003ab0: 6579 7320 3d20 7365 6c66 2e6b 6579 7328  eys = self.keys(
-00003ac0: 2920 6966 206e 6f74 2028 6861 7361 7474  ) if not (hasatt
-00003ad0: 7228 7365 6c66 2c20 2763 6861 6e6e 656c  r(self, 'channel
-00003ae0: 7327 2920 616e 6420 6368 616e 6e65 6c29  s') and channel)
-00003af0: 2065 6c73 6520 7365 6c66 2e63 6861 6e6e   else self.chann
-00003b00: 656c 730d 0a20 2020 2020 2020 200d 0a20  els..        .. 
-00003b10: 2020 2020 2020 2072 6174 696f 7320 3d20         ratios = 
-00003b20: 5b53 6571 7565 6e63 654d 6174 6368 6572  [SequenceMatcher
-00003b30: 2861 3d6e 616d 652c 2062 3d6b 292e 7261  (a=name, b=k).ra
-00003b40: 7469 6f28 2920 666f 7220 6b20 696e 206b  tio() for k in k
-00003b50: 6579 735d 0d0a 2020 2020 2020 2020 0d0a  eys]..        ..
-00003b60: 2020 2020 2020 2020 5f2c 2073 6f72 7465          _, sorte
-00003b70: 645f 6b65 7973 203d 207a 6970 282a 736f  d_keys = zip(*so
-00003b80: 7274 6564 287a 6970 2872 6174 696f 732c  rted(zip(ratios,
-00003b90: 206b 6579 7329 295b 3a3a 2d31 5d29 0d0a   keys))[::-1])..
-00003ba0: 2020 2020 2020 2020 0d0a 2020 2020 2020          ..      
-00003bb0: 2020 7265 7475 726e 2073 6f72 7465 645f    return sorted_
-00003bc0: 6b65 7973 0d0a 2020 2020 0d0a 2020 2020  keys..    ..    
-00003bd0: 6465 6620 7365 6172 6368 5f6d 6973 7369  def search_missi
-00003be0: 6e67 5f63 6f6e 6669 675f 6974 656d 7328  ng_config_items(
-00003bf0: 7365 6c66 2c20 6e75 6d3d 352c 2063 6861  self, num=5, cha
-00003c00: 6e6e 656c 3d54 7275 652c 2062 795f 6b65  nnel=True, by_ke
-00003c10: 793d 4661 6c73 6529 3a0d 0a20 2020 2020  y=False):..     
-00003c20: 2020 2022 2222 0d0a 2020 2020 2020 2020     """..        
-00003c30: 5365 6172 6368 6573 2066 6f72 206d 6973  Searches for mis
-00003c40: 7369 6e67 2063 6f6e 6669 6775 7261 7469  sing configurati
-00003c50: 6f6e 2069 7465 6d73 2069 6e20 7468 6520  on items in the 
-00003c60: 6461 7461 2069 6e74 6572 6661 6365 2e0d  data interface..
-00003c70: 0a0d 0a20 2020 2020 2020 2041 7267 733a  ...        Args:
-00003c80: 0d0a 2020 2020 2020 2020 2020 2020 6e75  ..            nu
-00003c90: 6d20 2869 6e74 293a 2054 6865 206d 6178  m (int): The max
-00003ca0: 696d 756d 206e 756d 6265 7220 6f66 2073  imum number of s
-00003cb0: 696d 696c 6172 2069 7465 6d73 2074 6f20  imilar items to 
-00003cc0: 6469 7370 6c61 7920 666f 7220 7365 6c65  display for sele
-00003cd0: 6374 696f 6e2e 2044 6566 6175 6c74 2069  ction. Default i
-00003ce0: 7320 352e 0d0a 2020 2020 2020 2020 2020  s 5...          
-00003cf0: 2020 6368 616e 6e65 6c20 2862 6f6f 6c29    channel (bool)
-00003d00: 3a20 466c 6167 2069 6e64 6963 6174 696e  : Flag indicatin
-00003d10: 6720 7768 6574 6865 7220 746f 2073 6561  g whether to sea
-00003d20: 7263 6820 666f 7220 6d69 7373 696e 6720  rch for missing 
-00003d30: 6974 656d 7320 696e 2063 6861 6e6e 656c  items in channel
-00003d40: 732e 2044 6566 6175 6c74 2069 7320 5472  s. Default is Tr
-00003d50: 7565 2e0d 0a20 2020 2020 2020 2020 2020  ue...           
-00003d60: 2062 795f 6b65 7920 2862 6f6f 6c29 3a20   by_key (bool): 
-00003d70: 466c 6167 2069 6e64 6963 6174 696e 6720  Flag indicating 
-00003d80: 7768 6574 6865 7220 746f 2073 6561 7263  whether to searc
-00003d90: 6820 666f 7220 7369 6d69 6c61 7220 6974  h for similar it
-00003da0: 656d 7320 6279 206b 6579 2e20 4465 6661  ems by key. Defa
-00003db0: 756c 7420 6973 2046 616c 7365 2e0d 0a0d  ult is False....
-00003dc0: 0a20 2020 2020 2020 2052 6574 7572 6e73  .        Returns
-00003dd0: 3a0d 0a20 2020 2020 2020 2020 2020 2064  :..            d
-00003de0: 6963 743a 2054 6865 2075 7064 6174 6564  ict: The updated
-00003df0: 2063 6f6e 6669 6775 7261 7469 6f6e 2064   configuration d
-00003e00: 6963 7469 6f6e 6172 792e 0d0a 2020 2020  ictionary...    
-00003e10: 2020 2020 2222 220d 0a0d 0a20 2020 2020      """....     
-00003e20: 2020 2063 6f6e 6669 6720 3d20 7365 6c66     config = self
-00003e30: 2e63 6f6e 6669 6720 6f72 2064 6963 7428  .config or dict(
-00003e40: 290d 0a0d 0a20 2020 2020 2020 2063 686e  )....        chn
-00003e50: 7320 3d20 7365 6c66 2e6b 6579 7328 2920  s = self.keys() 
-00003e60: 6966 206e 6f74 2028 6861 7361 7474 7228  if not (hasattr(
-00003e70: 7365 6c66 2c20 2763 6861 6e6e 656c 7327  self, 'channels'
-00003e80: 2920 616e 6420 6368 616e 6e65 6c29 2065  ) and channel) e
-00003e90: 6c73 6520 7365 6c66 2e63 6861 6e6e 656c  lse self.channel
-00003ea0: 730d 0a0d 0a20 2020 2020 2020 2066 6f72  s....        for
-00003eb0: 206b 6579 2c20 7661 6c20 696e 2063 6f6e   key, val in con
-00003ec0: 6669 672e 6974 656d 7328 293a 0d0a 0d0a  fig.items():....
-00003ed0: 2020 2020 2020 2020 2020 2020 6966 206e              if n
-00003ee0: 6f74 2069 7369 6e73 7461 6e63 6528 7661  ot isinstance(va
-00003ef0: 6c2c 2028 7475 706c 652c 206c 6973 742c  l, (tuple, list,
-00003f00: 2073 6574 2929 3a0d 0a0d 0a20 2020 2020   set)):....     
-00003f10: 2020 2020 2020 2020 2020 2076 616c 203d             val =
-00003f20: 205b 7661 6c5d 0d0a 2020 2020 2020 2020   [val]..        
-00003f30: 2020 2020 2020 2020 636f 6e66 6967 5b6b          config[k
-00003f40: 6579 5d20 3d20 7661 6c0d 0a0d 0a20 2020  ey] = val....   
-00003f50: 2020 2020 2020 2020 2069 6620 616e 7928           if any(
-00003f60: 6320 696e 2063 686e 7320 666f 7220 6320  c in chns for c 
-00003f70: 696e 2076 616c 293a 0d0a 0d0a 2020 2020  in val):....    
-00003f80: 2020 2020 2020 2020 2020 2020 636f 6e74              cont
-00003f90: 696e 7565 0d0a 0d0a 2020 2020 2020 2020  inue....        
-00003fa0: 2020 2020 656c 7365 3a0d 0a20 2020 2020      else:..     
-00003fb0: 2020 2020 2020 2020 2020 2069 6620 6279             if by
-00003fc0: 5f6b 6579 3a0d 0a20 2020 2020 2020 2020  _key:..         
-00003fd0: 2020 2020 2020 2020 2020 2066 6f75 6e64             found
-00003fe0: 203d 205b 7365 6c66 2e73 6561 7263 685f   = [self.search_
-00003ff0: 7369 6d69 6c61 7228 6b65 792c 2063 6861  similar(key, cha
-00004000: 6e6e 656c 3d63 6861 6e6e 656c 295d 0d0a  nnel=channel)]..
-00004010: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004020: 656c 7365 3a0d 0a20 2020 2020 2020 2020  else:..         
-00004030: 2020 2020 2020 2020 2020 2066 6f75 6e64             found
-00004040: 203d 205b 7365 6c66 2e73 6561 7263 685f   = [self.search_
-00004050: 7369 6d69 6c61 7228 762c 2063 6861 6e6e  similar(v, chann
-00004060: 656c 3d63 6861 6e6e 656c 2920 666f 7220  el=channel) for 
-00004070: 7620 696e 2076 616c 5d0d 0a20 2020 2020  v in val]..     
-00004080: 2020 2020 2020 2020 2020 2074 6f70 666f             topfo
-00004090: 756e 6420 3d20 6c69 7374 2863 6861 696e  und = list(chain
-000040a0: 282a 7a69 705f 6c6f 6e67 6573 7428 2a66  (*zip_longest(*f
-000040b0: 6f75 6e64 2929 295b 3a6e 756d 5d0d 0a0d  ound)))[:num]...
-000040c0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000040d0: 2077 6869 6c65 2031 3a0d 0a0d 0a20 2020   while 1:....   
-000040e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000040f0: 2073 656c 6563 7420 3d20 696e 7075 7428   select = input(
-00004100: 6627 5365 6c65 6374 206f 6e65 206f 6620  f'Select one of 
-00004110: 666f 6c6c 6f77 696e 6720 6b65 7920 666f  following key fo
-00004120: 7220 227b 6b65 797d 2220 6f72 2074 7970  r "{key}" or typ
-00004130: 6520 226e 2220 666f 7220 4e6f 6e65 3a20  e "n" for None: 
-00004140: 5c6e 5c74 270d 0a20 2020 2020 2020 2020  \n\t'..         
-00004150: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004160: 2020 2020 2020 2020 2020 2b20 275c 6e5c            + '\n\
-00004170: 7427 2e6a 6f69 6e28 6627 7b69 6478 7d3a  t'.join(f'{idx}:
-00004180: 207b 737d 2720 666f 7220 6964 782c 2073   {s}' for idx, s
-00004190: 2069 6e20 656e 756d 6572 6174 6528 746f   in enumerate(to
-000041a0: 7066 6f75 6e64 2c20 7374 6172 743d 3129  pfound, start=1)
-000041b0: 290d 0a20 2020 2020 2020 2020 2020 2020  )..             
-000041c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000041d0: 2020 2020 2020 2b20 275c 6e27 290d 0a0d        + '\n')...
-000041e0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-000041f0: 2020 2020 2069 6620 7365 6c65 6374 203d       if select =
-00004200: 3d20 276e 273a 0d0a 2020 2020 2020 2020  = 'n':..        
-00004210: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004220: 6272 6561 6b0d 0a20 2020 2020 2020 2020  break..         
-00004230: 2020 2020 2020 2020 2020 2069 6620 7365             if se
-00004240: 6c65 6374 203d 3d20 2778 273a 0d0a 2020  lect == 'x':..  
-00004250: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004260: 2020 2020 2020 7261 6973 6520 4b65 7962        raise Keyb
-00004270: 6f61 7264 496e 7465 7272 7570 740d 0a20  oardInterrupt.. 
-00004280: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004290: 2020 2065 6c73 653a 0d0a 2020 2020 2020     else:..      
-000042a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000042b0: 2020 7472 793a 0d0a 2020 2020 2020 2020    try:..        
-000042c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000042d0: 2020 2020 6964 7820 3d20 696e 7428 7365      idx = int(se
-000042e0: 6c65 6374 2920 2d20 310d 0a0d 0a20 2020  lect) - 1....   
-000042f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004300: 2020 2020 2020 2020 206b 203d 2074 6f70           k = top
-00004310: 666f 756e 645b 6964 785d 0d0a 2020 2020  found[idx]..    
-00004320: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004330: 2020 2020 2020 2020 636f 6e66 6967 5b6b          config[k
-00004340: 6579 5d2e 6170 7065 6e64 286b 290d 0a20  ey].append(k).. 
-00004350: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004360: 2020 2020 2020 2020 2020 2062 7265 616b             break
-00004370: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00004380: 2020 2020 2020 2020 2020 6578 6365 7074            except
-00004390: 2028 496e 6465 7845 7272 6f72 2c20 5661   (IndexError, Va
-000043a0: 6c75 6545 7272 6f72 293a 0d0a 2020 2020  lueError):..    
-000043b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000043c0: 2020 2020 2020 2020 7072 696e 7428 2749          print('I
-000043d0: 6e76 616c 6964 2069 6e70 7574 2c20 7472  nvalid input, tr
-000043e0: 7920 6167 6169 6e27 290d 0a20 2020 2020  y again')..     
-000043f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004400: 2020 2020 2020 2063 6f6e 7469 6e75 650d         continue.
-00004410: 0a0d 0a20 2020 2020 2020 2072 6574 7572  ...        retur
-00004420: 6e20 7365 6c66 2e63 6f6e 6669 670d 0a20  n self.config.. 
-00004430: 2020 2020 2020 200d 0a0d 0a20 2020 200d         ....    .
-00004440: 0a20 2020 200d 0a20 2020 2064 6566 2064  .    ..    def d
-00004450: 726f 7028 7365 6c66 2c20 2a6e 616d 6573  rop(self, *names
-00004460: 2c20 6e6f 6e65 7869 7374 5f6f 6b3d 5472  , nonexist_ok=Tr
-00004470: 7565 293a 0d0a 2020 2020 2020 2020 2222  ue):..        ""
-00004480: 220d 0a20 2020 2020 2020 2044 726f 7020  "..        Drop 
-00004490: 636f 6c75 6d6e 7320 6672 6f6d 2074 6865  columns from the
-000044a0: 2044 6174 6146 7261 6d65 2e0d 0a0d 0a20   DataFrame..... 
-000044b0: 2020 2020 2020 2041 7267 733a 0d0a 2020         Args:..  
-000044c0: 2020 2020 2020 2020 2020 2a6e 616d 6573            *names
-000044d0: 3a20 5661 7269 6162 6c65 206c 656e 6774  : Variable lengt
-000044e0: 6820 6172 6775 6d65 6e74 206c 6973 7420  h argument list 
-000044f0: 6f66 2063 6f6c 756d 6e20 6e61 6d65 7320  of column names 
-00004500: 746f 2062 6520 6472 6f70 7065 642e 0d0a  to be dropped...
-00004510: 2020 2020 2020 2020 2020 2020 6e6f 6e65              none
-00004520: 7869 7374 5f6f 6b20 2862 6f6f 6c2c 206f  xist_ok (bool, o
-00004530: 7074 696f 6e61 6c29 3a20 4966 2054 7275  ptional): If Tru
-00004540: 652c 2069 676e 6f72 6520 636f 6c75 6d6e  e, ignore column
-00004550: 7320 7468 6174 2064 6f20 6e6f 7420 6578  s that do not ex
-00004560: 6973 742e 2049 6620 4661 6c73 652c 2072  ist. If False, r
-00004570: 6169 7365 204b 6579 4572 726f 7220 666f  aise KeyError fo
-00004580: 7220 6e6f 6e2d 6578 6973 7465 6e74 2063  r non-existent c
-00004590: 6f6c 756d 6e73 2e20 4465 6661 756c 7473  olumns. Defaults
-000045a0: 2074 6f20 5472 7565 2e0d 0a0d 0a20 2020   to True.....   
-000045b0: 2020 2020 2052 6574 7572 6e73 3a0d 0a20       Returns:.. 
-000045c0: 2020 2020 2020 2020 2020 2073 656c 663a             self:
-000045d0: 2052 6574 7572 6e73 2074 6865 206d 6f64   Returns the mod
-000045e0: 6966 6965 6420 4461 7461 496e 7465 7266  ified DataInterf
-000045f0: 6163 6520 6f62 6a65 6374 2e0d 0a0d 0a20  ace object..... 
-00004600: 2020 2020 2020 2052 6169 7365 733a 0d0a         Raises:..
-00004610: 2020 2020 2020 2020 2020 2020 4b65 7945              KeyE
-00004620: 7272 6f72 3a20 4966 2061 206e 6f6e 2d65  rror: If a non-e
-00004630: 7869 7374 656e 7420 636f 6c75 6d6e 2069  xistent column i
-00004640: 7320 7370 6563 6966 6965 6420 616e 6420  s specified and 
-00004650: 6e6f 6e65 7869 7374 5f6f 6b20 6973 2046  nonexist_ok is F
-00004660: 616c 7365 2e0d 0a20 2020 2020 2020 2022  alse...        "
-00004670: 2222 0d0a 2020 2020 2020 2020 6b65 7973  ""..        keys
-00004680: 203d 205b 5d0d 0a0d 0a20 2020 2020 2020   = []....       
-00004690: 2066 6f72 206e 616d 6520 696e 206e 616d   for name in nam
-000046a0: 6573 3a0d 0a20 2020 2020 2020 2020 2020  es:..           
-000046b0: 2069 6620 6e61 6d65 2069 6e20 7365 6c66   if name in self
-000046c0: 2e64 663a 0d0a 2020 2020 2020 2020 2020  .df:..          
-000046d0: 2020 2020 2020 6b65 7973 2e61 7070 656e        keys.appen
-000046e0: 6428 6e61 6d65 290d 0a20 2020 2020 2020  d(name)..       
-000046f0: 2020 2020 2065 6c69 6620 6e6f 7420 6e6f       elif not no
-00004700: 6e65 7869 7374 5f6f 6b3a 0d0a 2020 2020  nexist_ok:..    
-00004710: 2020 2020 2020 2020 2020 2020 7261 6973              rais
-00004720: 6520 4b65 7945 7272 6f72 2866 2722 7b6e  e KeyError(f'"{n
-00004730: 616d 657d 2220 646f 6573 206e 6f74 2065  ame}" does not e
-00004740: 7869 7374 2069 6e20 227b 7365 6c66 2e6e  xist in "{self.n
-00004750: 616d 657d 222e 2729 0d0a 0d0a 2020 2020  ame}".')....    
-00004760: 2020 2020 7365 6c66 2e64 662e 6472 6f70      self.df.drop
-00004770: 2863 6f6c 756d 6e73 3d6b 6579 732c 2069  (columns=keys, i
-00004780: 6e70 6c61 6365 3d54 7275 6529 0d0a 0d0a  nplace=True)....
-00004790: 2020 2020 2020 2020 7265 7475 726e 2073          return s
-000047a0: 656c 660d 0a20 2020 200d 0a20 2020 2064  elf..    ..    d
-000047b0: 6566 2073 6561 7263 685f 6765 7428 7365  ef search_get(se
-000047c0: 6c66 2c20 7061 7474 2c20 6967 6e6f 7265  lf, patt, ignore
-000047d0: 5f63 6173 653d 4661 6c73 652c 2072 6169  _case=False, rai
-000047e0: 7365 5f65 7272 6f72 3d46 616c 7365 293a  se_error=False):
-000047f0: 0d0a 2020 2020 2020 2020 2222 220d 0a20  ..        """.. 
-00004800: 2020 2020 2020 2052 6574 7572 6e73 2074         Returns t
-00004810: 6865 2073 7562 7365 7420 6f66 2074 6865  he subset of the
-00004820: 2044 6174 6146 7261 6d65 2074 6861 7420   DataFrame that 
-00004830: 6d61 7463 6865 7320 7468 6520 6769 7665  matches the give
-00004840: 6e20 7061 7474 6572 6e2e 0d0a 0d0a 2020  n pattern.....  
-00004850: 2020 2020 2020 4172 6773 3a0d 0a20 2020        Args:..   
-00004860: 2020 2020 2020 2020 2070 6174 7420 2873           patt (s
-00004870: 7472 293a 2054 6865 2070 6174 7465 726e  tr): The pattern
-00004880: 2074 6f20 7365 6172 6368 2066 6f72 2e0d   to search for..
-00004890: 0a20 2020 2020 2020 2020 2020 2069 676e  .            ign
-000048a0: 6f72 655f 6361 7365 2028 626f 6f6c 2c20  ore_case (bool, 
-000048b0: 6f70 7469 6f6e 616c 293a 2057 6865 7468  optional): Wheth
-000048c0: 6572 2074 6f20 6967 6e6f 7265 2063 6173  er to ignore cas
-000048d0: 6520 7768 656e 2073 6561 7263 6869 6e67  e when searching
-000048e0: 2e20 4465 6661 756c 7473 2074 6f20 4661  . Defaults to Fa
-000048f0: 6c73 652e 0d0a 2020 2020 2020 2020 2020  lse...          
-00004900: 2020 7261 6973 655f 6572 726f 7220 2862    raise_error (b
-00004910: 6f6f 6c2c 206f 7074 696f 6e61 6c29 3a20  ool, optional): 
-00004920: 5768 6574 6865 7220 746f 2072 6169 7365  Whether to raise
-00004930: 2061 6e20 6572 726f 7220 6966 206e 6f20   an error if no 
-00004940: 6d61 7463 6865 7320 6172 6520 666f 756e  matches are foun
-00004950: 642e 2044 6566 6175 6c74 7320 746f 2046  d. Defaults to F
-00004960: 616c 7365 2e0d 0a0d 0a20 2020 2020 2020  alse.....       
-00004970: 2052 6574 7572 6e73 3a0d 0a20 2020 2020   Returns:..     
-00004980: 2020 2020 2020 2070 616e 6461 732e 4461         pandas.Da
-00004990: 7461 4672 616d 653a 2054 6865 2073 7562  taFrame: The sub
-000049a0: 7365 7420 6f66 2074 6865 2044 6174 6146  set of the DataF
-000049b0: 7261 6d65 2074 6861 7420 6d61 7463 6865  rame that matche
-000049c0: 7320 7468 6520 7061 7474 6572 6e2e 0d0a  s the pattern...
-000049d0: 2020 2020 2020 2020 2222 220d 0a20 2020          """..   
-000049e0: 2020 2020 2072 6574 7572 6e20 7365 6c66       return self
-000049f0: 2e64 665b 7365 6c66 2e73 6561 7263 6828  .df[self.search(
-00004a00: 7061 7474 2c20 6967 6e6f 7265 5f63 6173  patt, ignore_cas
-00004a10: 652c 2072 6169 7365 5f65 7272 6f72 295d  e, raise_error)]
-00004a20: 0d0a 0d0a 2020 2020 0d0a 2020 2020 6465  ....    ..    de
-00004a30: 6620 6c6f 6164 2873 656c 662c 202a 6b65  f load(self, *ke
-00004a40: 7973 2c20 6d61 7070 696e 673d 4e6f 6e65  ys, mapping=None
-00004a50: 293a 0d0a 2020 2020 2020 2020 2222 220d  ):..        """.
-00004a60: 0a20 2020 2020 2020 204c 6f61 6420 6461  .        Load da
-00004a70: 7461 2066 726f 6d20 7468 6520 7370 6563  ta from the spec
-00004a80: 6966 6965 6420 6b65 7973 2069 6e74 6f20  ified keys into 
-00004a90: 7468 6520 6461 7461 206f 626a 6563 742e  the data object.
-00004aa0: 0d0a 2020 2020 2020 2020 0d0a 2020 2020  ..        ..    
-00004ab0: 2020 2020 4172 6773 3a0d 0a20 2020 2020      Args:..     
-00004ac0: 2020 2020 2020 206b 6579 733a 2056 6172         keys: Var
-00004ad0: 6961 626c 6520 6e75 6d62 6572 206f 6620  iable number of 
-00004ae0: 6b65 7973 2074 6f20 6c6f 6164 2064 6174  keys to load dat
-00004af0: 6120 6672 6f6d 2e0d 0a20 2020 2020 2020  a from...       
-00004b00: 2020 2020 206d 6170 7069 6e67 3a20 4f70       mapping: Op
-00004b10: 7469 6f6e 616c 206d 6170 7069 6e67 2063  tional mapping c
-00004b20: 6f6e 6669 6775 7261 7469 6f6e 2066 6f72  onfiguration for
-00004b30: 2064 6174 6120 6578 7472 6163 7469 6f6e   data extraction
-00004b40: 2e0d 0a20 2020 2020 2020 2020 2020 200d  ...            .
-00004b50: 0a20 2020 2020 2020 2052 6574 7572 6e73  .        Returns
-00004b60: 3a0d 0a20 2020 2020 2020 2020 2020 2054  :..            T
-00004b70: 6865 206c 6f61 6465 6420 6461 7461 2061  he loaded data a
-00004b80: 7320 6120 6469 6374 696f 6e61 7279 2e0d  s a dictionary..
-00004b90: 0a20 2020 2020 2020 2022 2222 0d0a 2020  .        """..  
-00004ba0: 2020 2020 2020 6966 206e 6f74 206b 6579        if not key
-00004bb0: 733a 2020 2020 2020 200d 0a20 2020 2020  s:       ..     
-00004bc0: 2020 2020 2020 206b 6579 7320 3d20 6d61         keys = ma
-00004bd0: 7070 696e 672e 7661 6c75 6573 2829 0d0a  pping.values()..
-00004be0: 2020 2020 2020 2020 2020 2020 0d0a 2020              ..  
-00004bf0: 2020 2020 2020 4074 7261 6e73 6c61 7465        @translate
-00004c00: 5f63 6f6e 6669 6728 6d61 7070 696e 6729  _config(mapping)
-00004c10: 0d0a 2020 2020 2020 2020 4065 7874 7261  ..        @extra
-00004c20: 6374 5f63 6861 6e6e 656c 7328 6d61 7070  ct_channels(mapp
-00004c30: 696e 6729 0d0a 2020 2020 2020 2020 6465  ing)..        de
-00004c40: 6620 6765 7428 7365 6c66 2c20 2a6b 6579  f get(self, *key
-00004c50: 7329 3a0d 0a20 2020 2020 2020 2020 2020  s):..           
-00004c60: 2072 6574 7572 6e20 7365 6c66 2e67 6574   return self.get
-00004c70: 282a 6b65 7973 290d 0a0d 0a20 2020 2020  (*keys)....     
-00004c80: 2020 2064 6620 3d20 6765 7428 7365 6c66     df = get(self
-00004c90: 2c20 2a6b 6579 7329 0d0a 2020 2020 2020  , *keys)..      
-00004ca0: 2020 0d0a 2020 2020 2020 2020 666f 7220    ..        for 
-00004cb0: 6b2c 2076 2069 6e20 6466 2e69 7465 6d73  k, v in df.items
-00004cc0: 2829 3a0d 0a20 2020 2020 2020 2020 2020  ():..           
-00004cd0: 2073 656c 662e 6466 5b6b 5d20 3d20 760d   self.df[k] = v.
-00004ce0: 0a20 2020 2020 2020 2020 2020 200d 0a20  .            .. 
-00004cf0: 2020 2020 2020 2072 6574 7572 6e20 6466         return df
-00004d00: 0d0a 2020 2020 0d0a 0d0a 2020 2020 6465  ..    ....    de
-00004d10: 6620 7265 6c6f 6164 2873 656c 6629 3a0d  f reload(self):.
-00004d20: 0a20 2020 2020 2020 2022 2222 0d0a 2020  .        """..  
-00004d30: 2020 2020 2020 5265 6c6f 6164 7320 7468        Reloads th
-00004d40: 6520 6461 7461 2062 7920 6465 6c65 7469  e data by deleti
-00004d50: 6e67 2074 6865 2065 7869 7374 696e 6720  ng the existing 
-00004d60: 6461 7461 6672 616d 6520 616e 6420 7265  dataframe and re
-00004d70: 7475 726e 696e 6720 7468 6520 696e 7374  turning the inst
-00004d80: 616e 6365 2e0d 0a0d 0a20 2020 2020 2020  ance.....       
-00004d90: 2052 6574 7572 6e73 3a0d 0a20 2020 2020   Returns:..     
-00004da0: 2020 2020 2020 2073 656c 663a 2054 6865         self: The
-00004db0: 2069 6e73 7461 6e63 6520 6f66 2074 6865   instance of the
-00004dc0: 2044 6174 6149 6e74 6572 6661 6365 2063   DataInterface c
-00004dd0: 6c61 7373 2e0d 0a20 2020 2020 2020 2022  lass...        "
-00004de0: 2222 0d0a 2020 2020 2020 2020 6966 2068  ""..        if h
-00004df0: 6173 6174 7472 2873 656c 662c 2027 5f64  asattr(self, '_d
-00004e00: 6627 293a 0d0a 2020 2020 2020 2020 2020  f'):..          
-00004e10: 2020 6465 6c20 7365 6c66 2e5f 6466 0d0a    del self._df..
-00004e20: 2020 2020 2020 2020 7265 7475 726e 2073          return s
-00004e30: 656c 660d 0a20 2020 0d0a 2020 2020 6465  elf..   ..    de
-00004e40: 6620 6d65 7267 6528 7365 6c66 2c20 6f62  f merge(self, ob
-00004e50: 6a30 2c20 7265 7365 745f 696e 6465 783d  j0, reset_index=
-00004e60: 4661 6c73 6529 3a0d 0a20 2020 2020 2020  False):..       
-00004e70: 2022 2222 0d0a 2020 2020 2020 2020 4d65   """..        Me
-00004e80: 7267 6573 2074 6865 2063 6f6c 756d 6e73  rges the columns
-00004e90: 206f 6620 616e 6f74 6865 7220 6f62 6a65   of another obje
-00004ea0: 6374 2069 6e74 6f20 7468 6520 6375 7272  ct into the curr
-00004eb0: 656e 7420 6f62 6a65 6374 2e0d 0a0d 0a20  ent object..... 
-00004ec0: 2020 2020 2020 2050 6172 616d 6574 6572         Parameter
-00004ed0: 733a 0d0a 2020 2020 2020 2020 2d20 6f62  s:..        - ob
-00004ee0: 6a30 3a20 416e 6f74 6865 7220 6f62 6a65  j0: Another obje
-00004ef0: 6374 2074 6f20 6d65 7267 6520 7769 7468  ct to merge with
-00004f00: 2e0d 0a0d 0a20 2020 2020 2020 2052 6574  .....        Ret
-00004f10: 7572 6e73 3a0d 0a20 2020 2020 2020 202d  urns:..        -
-00004f20: 2073 656c 663a 2054 6865 206d 6572 6765   self: The merge
-00004f30: 6420 6f62 6a65 6374 2e0d 0a20 2020 2020  d object...     
-00004f40: 2020 2022 2222 0d0a 2020 2020 2020 2020     """..        
-00004f50: 6b65 7973 203d 206f 626a 302e 6466 2e63  keys = obj0.df.c
-00004f60: 6f6c 756d 6e73 2e64 6966 6665 7265 6e63  olumns.differenc
-00004f70: 6528 7365 6c66 2e64 662e 636f 6c75 6d6e  e(self.df.column
-00004f80: 7329 0d0a 2020 2020 2020 2020 0d0a 2020  s)..        ..  
-00004f90: 2020 2020 2020 6966 206c 656e 286b 6579        if len(key
-00004fa0: 7329 3a0d 0a20 2020 2020 2020 2020 2020  s):..           
-00004fb0: 2069 6620 7265 7365 745f 696e 6465 783a   if reset_index:
-00004fc0: 0d0a 2020 2020 2020 2020 2020 2020 2020  ..              
-00004fd0: 2020 7365 6c66 2e72 6573 6574 5f69 6e64    self.reset_ind
-00004fe0: 6578 2829 0d0a 2020 2020 2020 2020 2020  ex()..          
-00004ff0: 2020 2020 2020 6f62 6a30 2e72 6573 6574        obj0.reset
-00005000: 5f69 6e64 6578 2829 0d0a 2020 2020 2020  _index()..      
-00005010: 2020 2020 2020 2020 2020 0d0a 2020 2020            ..    
-00005020: 2020 2020 2020 2020 7365 6c66 2e5f 6466          self._df
-00005030: 5b6b 6579 735d 203d 206f 626a 305b 6b65  [keys] = obj0[ke
-00005040: 7973 5d0d 0a20 2020 2020 2020 2020 2020  ys]..           
-00005050: 2020 2020 2020 2020 200d 0a20 2020 2020           ..     
-00005060: 2020 2072 6574 7572 6e20 7365 6c66 0d0a     return self..
-00005070: 2020 2020 0d0a 2020 2020 6465 6620 7371      ..    def sq
-00005080: 7565 657a 6528 7365 6c66 2c20 2a6b 6579  ueeze(self, *key
-00005090: 7329 3a0d 0a20 2020 2020 2020 2022 2222  s):..        """
-000050a0: 0d0a 2020 2020 2020 2020 5365 6c65 6374  ..        Select
-000050b0: 7320 616e 6420 7265 7475 726e 7320 6120  s and returns a 
-000050c0: 6e65 7720 4461 7461 4672 616d 6520 636f  new DataFrame co
-000050d0: 6e74 6169 6e69 6e67 206f 6e6c 7920 7468  ntaining only th
-000050e0: 6520 7370 6563 6966 6965 6420 636f 6c75  e specified colu
-000050f0: 6d6e 732e 0d0a 0d0a 2020 2020 2020 2020  mns.....        
-00005100: 5061 7261 6d65 7465 7273 3a0d 0a20 2020  Parameters:..   
-00005110: 2020 2020 202a 6b65 7973 3a20 5661 7269       *keys: Vari
-00005120: 6162 6c65 206c 656e 6774 6820 6172 6775  able length argu
-00005130: 6d65 6e74 2072 6570 7265 7365 6e74 696e  ment representin
-00005140: 6720 7468 6520 636f 6c75 6d6e 206e 616d  g the column nam
-00005150: 6573 2074 6f20 6265 2073 656c 6563 7465  es to be selecte
-00005160: 642e 0d0a 0d0a 2020 2020 2020 2020 5265  d.....        Re
-00005170: 7475 726e 733a 0d0a 2020 2020 2020 2020  turns:..        
-00005180: 7365 6c66 3a20 5265 7475 726e 7320 7468  self: Returns th
-00005190: 6520 6d6f 6469 6669 6564 2044 6174 6149  e modified DataI
-000051a0: 6e74 6572 6661 6365 206f 626a 6563 7420  nterface object 
-000051b0: 7769 7468 2074 6865 206e 6577 2044 6174  with the new Dat
-000051c0: 6146 7261 6d65 2e0d 0a0d 0a20 2020 2020  aFrame.....     
-000051d0: 2020 2052 6169 7365 733a 0d0a 2020 2020     Raises:..    
-000051e0: 2020 2020 4b65 7945 7272 6f72 3a20 4966      KeyError: If
-000051f0: 2061 6e79 206f 6620 7468 6520 7370 6563   any of the spec
-00005200: 6966 6965 6420 636f 6c75 6d6e 206e 616d  ified column nam
-00005210: 6573 2061 7265 206e 6f74 2066 6f75 6e64  es are not found
-00005220: 2069 6e20 7468 6520 4461 7461 4672 616d   in the DataFram
-00005230: 652c 2069 7420 7261 6973 6573 2061 204b  e, it raises a K
-00005240: 6579 4572 726f 722e 0d0a 2020 2020 2020  eyError...      
-00005250: 2020 2222 220d 0a20 2020 2020 2020 2074    """..        t
-00005260: 7279 3a0d 0a20 2020 2020 2020 2020 2020  ry:..           
-00005270: 2073 656c 662e 5f64 6620 3d20 7365 6c66   self._df = self
-00005280: 2e64 665b 6c69 7374 286b 6579 7329 5d0d  .df[list(keys)].
-00005290: 0a20 2020 2020 2020 2020 2020 200d 0a20  .            .. 
-000052a0: 2020 2020 2020 2065 7863 6570 7420 4b65         except Ke
-000052b0: 7945 7272 6f72 3a0d 0a20 2020 2020 2020  yError:..       
-000052c0: 2020 2020 206e 6577 5f6b 6579 7320 3d20       new_keys = 
-000052d0: 6c69 7374 2873 6574 2873 656c 662e 5f64  list(set(self._d
-000052e0: 662e 636f 6c75 6d6e 7329 2026 2073 6574  f.columns) & set
-000052f0: 286b 6579 7329 290d 0a20 2020 2020 2020  (keys))..       
-00005300: 2020 2020 2073 656c 662e 5f64 6620 3d20       self._df = 
-00005310: 7365 6c66 2e64 665b 6e65 775f 6b65 7973  self.df[new_keys
-00005320: 5d0d 0a20 2020 2020 2020 2020 2020 200d  ]..            .
-00005330: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00005340: 7365 6c66 0d0a 2020 2020 0d0a 2020 2020  self..    ..    
-00005350: 4073 7461 7469 636d 6574 686f 640d 0a20  @staticmethod.. 
-00005360: 2020 2064 6566 2070 6970 656c 696e 6528     def pipeline(
-00005370: 2a66 756e 732c 2069 676e 6f72 655f 6572  *funs, ignore_er
-00005380: 726f 723d 5472 7565 293a 0d0a 2020 2020  ror=True):..    
-00005390: 2020 2020 2222 220d 0a20 2020 2020 2020      """..       
-000053a0: 2045 7865 6375 7465 7320 6120 7365 7269   Executes a seri
-000053b0: 6573 206f 6620 6675 6e63 7469 6f6e 7320  es of functions 
-000053c0: 6f6e 2061 6e20 6f62 6a65 6374 2069 6e20  on an object in 
-000053d0: 6120 7069 7065 6c69 6e65 2066 6173 6869  a pipeline fashi
-000053e0: 6f6e 2e0d 0a0d 0a20 2020 2020 2020 2041  on.....        A
-000053f0: 7267 733a 0d0a 2020 2020 2020 2020 2020  rgs:..          
-00005400: 2020 2a66 756e 733a 2056 6172 6961 626c    *funs: Variabl
-00005410: 6520 6e75 6d62 6572 206f 6620 6675 6e63  e number of func
-00005420: 7469 6f6e 7320 746f 2062 6520 6578 6563  tions to be exec
-00005430: 7574 6564 206f 6e20 7468 6520 6f62 6a65  uted on the obje
-00005440: 6374 2e0d 0a20 2020 2020 2020 2020 2020  ct...           
-00005450: 2069 676e 6f72 655f 6572 726f 7220 2862   ignore_error (b
-00005460: 6f6f 6c2c 206f 7074 696f 6e61 6c29 3a20  ool, optional): 
-00005470: 466c 6167 2074 6f20 696e 6469 6361 7465  Flag to indicate
-00005480: 2077 6865 7468 6572 2074 6f20 6967 6e6f   whether to igno
-00005490: 7265 2065 7272 6f72 7320 7261 6973 6564  re errors raised
-000054a0: 2064 7572 696e 6720 6578 6563 7574 696f   during executio
-000054b0: 6e2e 200d 0a20 2020 2020 2020 2020 2020  n. ..           
-000054c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000054d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000054e0: 2044 6566 6175 6c74 7320 746f 2054 7275   Defaults to Tru
-000054f0: 652e 0d0a 0d0a 2020 2020 2020 2020 5261  e.....        Ra
-00005500: 6973 6573 3a0d 0a20 2020 2020 2020 2020  ises:..         
-00005510: 2020 2045 7863 6570 7469 6f6e 3a20 4966     Exception: If
-00005520: 2069 676e 6f72 655f 6572 726f 7220 6973   ignore_error is
-00005530: 2046 616c 7365 2061 6e64 2061 6e20 6572   False and an er
-00005540: 726f 7220 6973 2072 6169 7365 6420 6475  ror is raised du
-00005550: 7269 6e67 2065 7865 6375 7469 6f6e 2e0d  ring execution..
-00005560: 0a0d 0a20 2020 2020 2020 2052 6574 7572  ...        Retur
-00005570: 6e73 3a0d 0a20 2020 2020 2020 2020 2020  ns:..           
-00005580: 204e 6f6e 650d 0a20 2020 2020 2020 2022   None..        "
-00005590: 2222 0d0a 2020 2020 2020 2020 6966 206e  ""..        if n
-000055a0: 6f74 2061 6c6c 2868 6173 6174 7472 2866  ot all(hasattr(f
-000055b0: 756e 2c20 275f 5f63 616c 6c5f 5f27 2920  un, '__call__') 
-000055c0: 666f 7220 6675 6e20 696e 2066 756e 7329  for fun in funs)
-000055d0: 3a0d 0a20 2020 2020 2020 2020 2020 2072  :..            r
-000055e0: 6169 7365 2056 616c 7565 4572 726f 7228  aise ValueError(
-000055f0: 2749 6e70 7574 2076 616c 7565 7320 6d75  'Input values mu
-00005600: 7374 2062 6520 6361 6c6c 6162 6c65 2e27  st be callable.'
-00005610: 290d 0a20 2020 2020 2020 200d 0a20 2020  )..        ..   
-00005620: 2020 2020 2064 6566 2077 7261 7070 6572       def wrapper
-00005630: 286f 626a 293a 0d0a 2020 2020 2020 2020  (obj):..        
-00005640: 2020 2020 666f 7220 6675 6e20 696e 2066      for fun in f
-00005650: 756e 733a 0d0a 2020 2020 2020 2020 2020  uns:..          
-00005660: 2020 2020 2020 7472 793a 0d0a 2020 2020        try:..    
-00005670: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005680: 7969 656c 6420 6675 6e28 6f62 6a29 0d0a  yield fun(obj)..
-00005690: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000056a0: 6578 6365 7074 2045 7863 6570 7469 6f6e  except Exception
-000056b0: 2061 7320 6572 723a 0d0a 2020 2020 2020   as err:..      
-000056c0: 2020 2020 2020 2020 2020 2020 2020 6966                if
-000056d0: 2069 676e 6f72 655f 6572 726f 723a 0d0a   ignore_error:..
-000056e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000056f0: 2020 2020 2020 2020 6572 726e 616d 6520          errname 
-00005700: 3d20 6572 722e 5f5f 636c 6173 735f 5f2e  = err.__class__.
-00005710: 5f5f 6e61 6d65 5f5f 0d0a 2020 2020 2020  __name__..      
-00005720: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005730: 2020 7462 203d 2074 7261 6365 6261 636b    tb = traceback
-00005740: 2e66 6f72 6d61 745f 6578 6328 6c69 6d69  .format_exc(limi
-00005750: 743d 302c 2063 6861 696e 3d46 616c 7365  t=0, chain=False
-00005760: 290d 0a20 2020 2020 2020 2020 2020 2020  )..             
-00005770: 2020 2020 2020 2020 2020 2077 6172 6e69             warni
-00005780: 6e67 732e 7761 726e 2866 2745 7863 6570  ngs.warn(f'Excep
-00005790: 7469 6f6e 2022 7b65 7272 6e61 6d65 7d22  tion "{errname}"
-000057a0: 2069 7320 7261 6973 6564 2077 6869 6c65   is raised while
-000057b0: 2070 726f 6365 7373 696e 6720 227b 6f62   processing "{ob
-000057c0: 6a2e 6e61 6d65 7d22 3a20 227b 7462 7d22  j.name}": "{tb}"
-000057d0: 2729 0d0a 2020 2020 2020 2020 2020 2020  ')..            
-000057e0: 2020 2020 2020 2020 656c 7365 3a0d 0a20          else:.. 
-000057f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005800: 2020 2020 2020 2072 6169 7365 0d0a 2020         raise..  
-00005810: 2020 2020 2020 7265 7475 726e 2077 7261        return wra
-00005820: 7070 6572 0d0a 0d0a 2020 2020 0d0a 2020  pper....    ..  
-00005830: 2020 6465 6620 7265 6e61 6d65 2873 656c    def rename(sel
-00005840: 662c 202a 2a6b 7761 7267 7329 3a0d 0a20  f, **kwargs):.. 
-00005850: 2020 2020 2020 2022 2222 0d0a 2020 2020         """..    
-00005860: 2020 2020 5265 6e61 6d65 7320 7468 6520      Renames the 
-00005870: 636f 6c75 6d6e 7320 6f66 2074 6865 2044  columns of the D
-00005880: 6174 6146 7261 6d65 2075 7369 6e67 2074  ataFrame using t
-00005890: 6865 2070 726f 7669 6465 6420 6b65 792d  he provided key-
-000058a0: 7661 6c75 6520 7061 6972 732e 0d0a 0d0a  value pairs.....
-000058b0: 2020 2020 2020 2020 4172 6773 3a0d 0a20          Args:.. 
-000058c0: 2020 2020 2020 2020 2020 202a 2a6b 7761             **kwa
-000058d0: 7267 733a 204b 6579 2d76 616c 7565 2070  rgs: Key-value p
-000058e0: 6169 7273 2077 6865 7265 2074 6865 206b  airs where the k
-000058f0: 6579 2072 6570 7265 7365 6e74 7320 7468  ey represents th
-00005900: 6520 6375 7272 656e 7420 636f 6c75 6d6e  e current column
-00005910: 206e 616d 6520 616e 6420 7468 6520 7661   name and the va
-00005920: 6c75 6520 7265 7072 6573 656e 7473 2074  lue represents t
-00005930: 6865 206e 6577 2063 6f6c 756d 6e20 6e61  he new column na
-00005940: 6d65 2e0d 0a0d 0a20 2020 2020 2020 2052  me.....        R
-00005950: 6574 7572 6e73 3a0d 0a20 2020 2020 2020  eturns:..       
-00005960: 2020 2020 2054 6865 206d 6f64 6966 6965       The modifie
-00005970: 6420 4461 7461 4672 616d 6520 6f62 6a65  d DataFrame obje
-00005980: 6374 2e0d 0a0d 0a20 2020 2020 2020 2045  ct.....        E
-00005990: 7861 6d70 6c65 3a0d 0a20 2020 2020 2020  xample:..       
-000059a0: 2020 2020 2064 662e 7265 6e61 6d65 2863       df.rename(c
-000059b0: 6f6c 756d 6e31 3d27 6e65 775f 636f 6c75  olumn1='new_colu
-000059c0: 6d6e 3127 2c20 636f 6c75 6d6e 323d 276e  mn1', column2='n
-000059d0: 6577 5f63 6f6c 756d 6e32 2729 0d0a 0d0a  ew_column2')....
-000059e0: 2020 2020 2020 2020 2222 220d 0a20 2020          """..   
-000059f0: 2020 2020 206b 6579 6d61 7020 3d20 6b77       keymap = kw
-00005a00: 6172 6773 0d0a 0d0a 2020 2020 2020 2020  args....        
-00005a10: 4074 7261 6e73 6c61 7465 5f63 6f6e 6669  @translate_confi
-00005a20: 6728 6b65 796d 6170 290d 0a20 2020 2020  g(keymap)..     
-00005a30: 2020 2064 6566 2067 6574 2873 656c 6629     def get(self)
-00005a40: 3a0d 0a20 2020 2020 2020 2020 2020 2072  :..            r
-00005a50: 6574 7572 6e20 7365 6c66 2e5f 6466 0d0a  eturn self._df..
-00005a60: 0d0a 2020 2020 2020 2020 6765 7428 7365  ..        get(se
-00005a70: 6c66 290d 0a0d 0a20 2020 2020 2020 2072  lf)....        r
-00005a80: 6574 7572 6e20 7365 6c66 0d0a 2020 2020  eturn self..    
-00005a90: 0d0a 2020 2020 6465 6620 7265 7361 6d70  ..    def resamp
-00005aa0: 6c65 2873 656c 662c 206e 6577 5f69 6e64  le(self, new_ind
-00005ab0: 6578 3d4e 6f6e 6529 3a0d 0a20 2020 2020  ex=None):..     
-00005ac0: 2020 2022 2222 0d0a 2020 2020 2020 2020     """..        
-00005ad0: 5265 7475 726e 2061 206e 6577 2044 6174  Return a new Dat
-00005ae0: 6146 7261 6d65 2077 6974 6820 616c 6c20  aFrame with all 
-00005af0: 636f 6c75 6d6e 7320 7661 6c75 6573 2069  columns values i
-00005b00: 6e74 6572 706f 6c61 7465 640d 0a20 2020  nterpolated..   
-00005b10: 2020 2020 2074 6f20 7468 6520 6e65 775f       to the new_
-00005b20: 696e 6465 7820 7661 6c75 6573 2e0d 0a0d  index values....
-00005b30: 0a20 2020 2020 2020 2050 6172 616d 6574  .        Paramet
-00005b40: 6572 733a 0d0a 2020 2020 2020 2020 2d20  ers:..        - 
-00005b50: 6e65 775f 696e 6465 7820 2861 7272 6179  new_index (array
-00005b60: 2d6c 696b 652c 206f 7074 696f 6e61 6c29  -like, optional)
-00005b70: 3a20 5468 6520 6e65 7720 696e 6465 7820  : The new index 
-00005b80: 7661 6c75 6573 2074 6f20 696e 7465 7270  values to interp
-00005b90: 6f6c 6174 6520 7468 6520 636f 6c75 6d6e  olate the column
-00005ba0: 7320 746f 2e0d 0a20 2020 2020 2020 2020  s to...         
-00005bb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005bc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005bd0: 2020 2049 6620 6e6f 7420 7072 6f76 6964     If not provid
-00005be0: 6564 2c20 7468 6520 6f72 6967 696e 616c  ed, the original
-00005bf0: 2044 6174 6146 7261 6d65 2069 7320 7265   DataFrame is re
-00005c00: 7475 726e 6564 2e0d 0a0d 0a20 2020 2020  turned.....     
-00005c10: 2020 2052 6574 7572 6e73 3a0d 0a20 2020     Returns:..   
-00005c20: 2020 2020 202d 206e 6577 5f6f 626a 2028       - new_obj (
-00005c30: 4441 5441 5f4f 424a 4543 5429 3a20 4120  DATA_OBJECT): A 
-00005c40: 6e65 7720 696e 7374 616e 6365 206f 6620  new instance of 
-00005c50: 7468 6520 4441 5441 5f4f 424a 4543 5420  the DATA_OBJECT 
-00005c60: 636c 6173 7320 7769 7468 2074 6865 2072  class with the r
-00005c70: 6573 616d 706c 6564 2044 6174 6146 7261  esampled DataFra
-00005c80: 6d65 2e0d 0a20 2020 2020 2020 2022 2222  me...        """
-00005c90: 0d0a 2020 2020 2020 2020 6672 6f6d 2064  ..        from d
-00005ca0: 6174 6173 7572 6665 7220 696d 706f 7274  atasurfer import
-00005cb0: 2044 4154 415f 4f42 4a45 4354 0d0a 2020   DATA_OBJECT..  
-00005cc0: 2020 2020 2020 0d0a 2020 2020 2020 2020        ..        
-00005cd0: 6966 206e 6577 5f69 6e64 6578 2069 7320  if new_index is 
-00005ce0: 6e6f 7420 4e6f 6e65 3a0d 0a20 2020 2020  not None:..     
-00005cf0: 2020 2020 2020 206e 6577 5f69 6e64 6578         new_index
-00005d00: 203d 206e 702e 6173 6172 7261 7928 6e65   = np.asarray(ne
-00005d10: 775f 696e 6465 7829 0d0a 0d0a 2020 2020  w_index)....    
-00005d20: 2020 2020 2020 2020 6966 206e 6577 5f69          if new_i
-00005d30: 6e64 6578 2e73 697a 6520 3d3d 2031 3a0d  ndex.size == 1:.
-00005d40: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
-00005d50: 2069 6478 203d 2073 656c 662e 6466 2e69   idx = self.df.i
-00005d60: 6e64 6578 0d0a 2020 2020 2020 2020 2020  ndex..          
-00005d70: 2020 2020 2020 6e65 775f 696e 6465 7820        new_index 
-00005d80: 3d20 6e70 2e61 7261 6e67 6528 6d69 6e28  = np.arange(min(
-00005d90: 6964 7829 2c20 6d61 7828 6964 7829 2b6e  idx), max(idx)+n
-00005da0: 6577 5f69 6e64 6578 2c20 6e65 775f 696e  ew_index, new_in
-00005db0: 6465 7829 0d0a 0d0a 2020 2020 2020 2020  dex)....        
-00005dc0: 2020 2020 6466 5f6f 7574 203d 2070 642e      df_out = pd.
-00005dd0: 4461 7461 4672 616d 6528 696e 6465 783d  DataFrame(index=
-00005de0: 6e65 775f 696e 6465 7829 0d0a 2020 2020  new_index)..    
-00005df0: 2020 2020 2020 2020 6466 5f6f 7574 2e69          df_out.i
-00005e00: 6e64 6578 2e6e 616d 6520 3d20 7365 6c66  ndex.name = self
-00005e10: 2e64 662e 696e 6465 782e 6e61 6d65 0d0a  .df.index.name..
-00005e20: 0d0a 2020 2020 2020 2020 2020 2020 666f  ..            fo
-00005e30: 7220 636f 6c6e 616d 652c 2063 6f6c 2069  r colname, col i
-00005e40: 6e20 7365 6c66 2e64 662e 6974 656d 7328  n self.df.items(
-00005e50: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
-00005e60: 2020 2020 7472 793a 0d0a 2020 2020 2020      try:..      
-00005e70: 2020 2020 2020 2020 2020 2020 2020 636f                co
-00005e80: 6c20 3d20 636f 6c2e 6173 7479 7065 2866  l = col.astype(f
-00005e90: 6c6f 6174 290d 0a20 2020 2020 2020 2020  loat)..         
-00005ea0: 2020 2020 2020 2020 2020 2064 665f 6f75             df_ou
-00005eb0: 745b 636f 6c6e 616d 655d 203d 206e 702e  t[colname] = np.
-00005ec0: 696e 7465 7270 286e 6577 5f69 6e64 6578  interp(new_index
-00005ed0: 2c20 7365 6c66 2e64 662e 696e 6465 782c  , self.df.index,
-00005ee0: 2063 6f6c 290d 0a20 2020 2020 2020 2020   col)..         
-00005ef0: 2020 2020 2020 2065 7863 6570 7420 2854         except (T
-00005f00: 7970 6545 7272 6f72 2c20 5661 6c75 6545  ypeError, ValueE
-00005f10: 7272 6f72 293a 0d0a 2020 2020 2020 2020  rror):..        
-00005f20: 2020 2020 2020 2020 2020 2020 7761 726e              warn
-00005f30: 696e 6773 2e77 6172 6e28 6627 227b 636f  ings.warn(f'"{co
-00005f40: 6c6e 616d 657d 2220 6361 6e20 6e6f 7420  lname}" can not 
-00005f50: 6265 2072 6573 616d 706c 6564 2e27 290d  be resampled.').
-00005f60: 0a20 2020 2020 2020 2065 6c73 653a 0d0a  .        else:..
-00005f70: 2020 2020 2020 2020 2020 2020 6466 5f6f              df_o
-00005f80: 7574 203d 2073 656c 662e 6466 0d0a 0d0a  ut = self.df....
-00005f90: 2020 2020 2020 2020 6e65 775f 6f62 6a20          new_obj 
-00005fa0: 3d20 4441 5441 5f4f 424a 4543 5428 7061  = DATA_OBJECT(pa
-00005fb0: 7468 3d73 7472 2873 656c 662e 7061 7468  th=str(self.path
-00005fc0: 292c 2063 6f6e 6669 673d 7365 6c66 2e63  ), config=self.c
-00005fd0: 6f6e 6669 672c 0d0a 2020 2020 2020 2020  onfig,..        
-00005fe0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00005ff0: 2020 2020 2020 6e61 6d65 3d73 656c 662e        name=self.
-00006000: 6e61 6d65 2c0d 0a20 2020 2020 2020 2020  name,..         
-00006010: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006020: 2020 2020 2063 6f6d 6d65 6e74 3d73 656c       comment=sel
-00006030: 662e 636f 6d6d 656e 742c 2064 663d 6466  f.comment, df=df
-00006040: 5f6f 7574 290d 0a0d 0a20 2020 2020 2020  _out)....       
-00006050: 2072 6574 7572 6e20 6e65 775f 6f62 6a0d   return new_obj.
-00006060: 0a20 2020 200d 0a20 2020 2064 6566 2066  .    ..    def f
-00006070: 696c 6c5f 6d69 7373 696e 675f 6b65 7973  ill_missing_keys
-00006080: 2873 656c 662c 2063 6f6e 6669 673d 4e6f  (self, config=No
-00006090: 6e65 293a 0d0a 2020 2020 2020 2020 2222  ne):..        ""
-000060a0: 220d 0a20 2020 2020 2020 2046 696c 6c73  "..        Fills
-000060b0: 2069 6e20 6d69 7373 696e 6720 6b65 7973   in missing keys
-000060c0: 2069 6e20 7468 6520 636f 6e66 6967 7572   in the configur
-000060d0: 6174 696f 6e20 6469 6374 696f 6e61 7279  ation dictionary
-000060e0: 2e0d 0a0d 0a20 2020 2020 2020 2041 7267  .....        Arg
-000060f0: 733a 0d0a 2020 2020 2020 2020 2020 2020  s:..            
-00006100: 636f 6e66 6967 2028 6469 6374 2c20 6f70  config (dict, op
-00006110: 7469 6f6e 616c 293a 2054 6865 2063 6f6e  tional): The con
-00006120: 6669 6775 7261 7469 6f6e 2064 6963 7469  figuration dicti
-00006130: 6f6e 6172 7920 746f 2066 696c 6c20 696e  onary to fill in
-00006140: 206d 6973 7369 6e67 206b 6579 7320 666f   missing keys fo
-00006150: 722e 0d0a 2020 2020 2020 2020 2020 2020  r...            
-00006160: 2020 2020 4966 206e 6f74 2070 726f 7669      If not provi
-00006170: 6465 642c 2074 6865 206d 6574 686f 6420  ded, the method 
-00006180: 7769 6c6c 2075 7365 2074 6865 2064 6566  will use the def
-00006190: 6175 6c74 2063 6f6e 6669 6775 7261 7469  ault configurati
-000061a0: 6f6e 2e0d 0a0d 0a20 2020 2020 2020 2052  on.....        R
-000061b0: 6574 7572 6e73 3a0d 0a20 2020 2020 2020  eturns:..       
-000061c0: 2020 2020 2064 6963 743a 2054 6865 2075       dict: The u
-000061d0: 7064 6174 6564 2063 6f6e 6669 6775 7261  pdated configura
-000061e0: 7469 6f6e 2064 6963 7469 6f6e 6172 7920  tion dictionary 
-000061f0: 7769 7468 206d 6973 7369 6e67 206b 6579  with missing key
-00006200: 7320 6669 6c6c 6564 2069 6e2e 0d0a 2020  s filled in...  
-00006210: 2020 2020 2020 2222 220d 0a20 2020 2020        """..     
-00006220: 2020 2066 726f 6d20 6461 7461 7375 7266     from datasurf
-00006230: 6572 2e64 6174 6170 6f6f 6c20 696d 706f  er.datapool impo
-00006240: 7274 2063 6f6d 6269 6e65 5f63 6f6e 6669  rt combine_confi
-00006250: 6773 0d0a 2020 2020 2020 2020 636f 6e66  gs..        conf
-00006260: 6967 203d 2063 6f6e 6669 6720 6f72 2073  ig = config or s
-00006270: 656c 662e 636f 6e66 6967 0d0a 2020 2020  elf.config..    
-00006280: 2020 2020 2020 2020 2020 2020 0d0a 2020              ..  
-00006290: 2020 2020 2020 636f 6e66 6967 203d 2063        config = c
-000062a0: 6f6d 6269 6e65 5f63 6f6e 6669 6773 2870  ombine_configs(p
-000062b0: 6172 7365 5f63 6f6e 6669 6728 636f 6e66  arse_config(conf
-000062c0: 6967 2929 0d0a 0d0a 2020 2020 2020 2020  ig))....        
-000062d0: 6d69 7373 696e 675f 6b65 7973 203d 205b  missing_keys = [
-000062e0: 6b20 666f 7220 6b20 696e 2063 6f6e 6669  k for k in confi
-000062f0: 6720 6966 206b 206e 6f74 2069 6e20 7365  g if k not in se
-00006300: 6c66 2e64 662e 636f 6c75 6d6e 735d 0d0a  lf.df.columns]..
-00006310: 0d0a 2020 2020 2020 2020 666f 7220 6d6b  ..        for mk
-00006320: 2069 6e20 6d69 7373 696e 675f 6b65 7973   in missing_keys
-00006330: 3a20 2020 2020 2020 200d 0a20 2020 2020  :        ..     
-00006340: 2020 2020 2020 2073 6967 7320 3d20 636f         sigs = co
-00006350: 6e66 6967 5b6d 6b5d 0d0a 2020 2020 2020  nfig[mk]..      
-00006360: 2020 2020 2020 666f 7220 7369 6720 696e        for sig in
-00006370: 2073 6967 733a 0d0a 2020 2020 2020 2020   sigs:..        
-00006380: 2020 2020 2020 2020 666f 7220 6b2c 2076          for k, v
-00006390: 7320 696e 2063 6f6e 6669 672e 6974 656d  s in config.item
-000063a0: 7328 293a 0d0a 2020 2020 2020 2020 2020  s():..          
-000063b0: 2020 2020 2020 2020 2020 0d0a 2020 2020            ..    
-000063c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000063d0: 6966 2073 6967 2069 6e20 7673 2061 6e64  if sig in vs and
-000063e0: 206b 2069 6e20 7365 6c66 2e64 662e 636f   k in self.df.co
-000063f0: 6c75 6d6e 733a 0d0a 2020 2020 2020 2020  lumns:..        
-00006400: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006410: 7365 6c66 2e64 665b 6d6b 5d20 3d20 7365  self.df[mk] = se
-00006420: 6c66 2e64 665b 6b5d 0d0a 2020 2020 2020  lf.df[k]..      
-00006430: 2020 2020 2020 0d0a 2020 2020 2020 2020        ..        
-00006440: 7265 7475 726e 2073 656c 660d 0a20 2020  return self..   
-00006450: 200d 0a20 2020 2064 6566 2074 6f5f 6e75   ..    def to_nu
-00006460: 6d70 7928 7365 6c66 293a 0d0a 2020 2020  mpy(self):..    
-00006470: 2020 2020 2222 220d 0a20 2020 2020 2020      """..       
-00006480: 2043 6f6e 7665 7274 7320 7468 6520 6461   Converts the da
-00006490: 7461 2074 6f20 6120 4e75 6d50 7920 6172  ta to a NumPy ar
-000064a0: 7261 792e 0d0a 0d0a 2020 2020 2020 2020  ray.....        
-000064b0: 5265 7475 726e 733a 0d0a 2020 2020 2020  Returns:..      
-000064c0: 2020 2020 2020 6e75 6d70 792e 6e64 6172        numpy.ndar
-000064d0: 7261 793a 2054 6865 2064 6174 6120 6173  ray: The data as
-000064e0: 2061 204e 756d 5079 2061 7272 6179 2e0d   a NumPy array..
-000064f0: 0a20 2020 2020 2020 2022 2222 0d0a 2020  .        """..  
-00006500: 2020 2020 2020 7265 7475 726e 2073 656c        return sel
-00006510: 662e 7265 7361 6d70 6c65 2829 0d0a 2020  f.resample()..  
-00006520: 2020 2020 2020 0d0a 2020 2020 6465 6620        ..    def 
-00006530: 746f 5f64 6963 7428 7365 6c66 293a 0d0a  to_dict(self):..
-00006540: 2020 2020 2020 2020 2222 220d 0a20 2020          """..   
-00006550: 2020 2020 2043 6f6e 7665 7274 7320 7468       Converts th
-00006560: 6520 6461 7461 2069 6e74 6572 6661 6365  e data interface
-00006570: 206f 626a 6563 7420 746f 2061 2064 6963   object to a dic
-00006580: 7469 6f6e 6172 792e 0d0a 0d0a 2020 2020  tionary.....    
-00006590: 2020 2020 5265 7475 726e 733a 0d0a 2020      Returns:..  
-000065a0: 2020 2020 2020 2020 2020 6469 6374 3a20            dict: 
-000065b0: 4120 6469 6374 696f 6e61 7279 2072 6570  A dictionary rep
-000065c0: 7265 7365 6e74 6174 696f 6e20 6f66 2074  resentation of t
-000065d0: 6865 2064 6174 6120 696e 7465 7266 6163  he data interfac
-000065e0: 6520 6f62 6a65 6374 2e0d 0a20 2020 2020  e object...     
-000065f0: 2020 2022 2222 0d0a 2020 2020 2020 2020     """..        
-00006600: 6f75 7420 3d20 6469 6374 2829 0d0a 2020  out = dict()..  
-00006610: 2020 2020 2020 0d0a 2020 2020 2020 2020        ..        
-00006620: 6f75 745b 2770 6174 6827 5d20 3d20 7374  out['path'] = st
-00006630: 7228 7365 6c66 2e70 6174 6829 0d0a 2020  r(self.path)..  
-00006640: 2020 2020 2020 6f75 745b 2763 6f6e 6669        out['confi
-00006650: 6727 5d20 3d20 7365 6c66 2e63 6f6e 6669  g'] = self.confi
-00006660: 670d 0a20 2020 2020 2020 206f 7574 5b27  g..        out['
-00006670: 636f 6d6d 656e 7427 5d20 3d20 7365 6c66  comment'] = self
-00006680: 2e63 6f6d 6d65 6e74 2020 0d0a 2020 2020  .comment  ..    
-00006690: 2020 2020 6f75 745b 276e 616d 6527 5d20      out['name'] 
-000066a0: 3d20 7365 6c66 2e6e 616d 650d 0a20 2020  = self.name..   
-000066b0: 2020 2020 206f 7574 5b27 6466 275d 203d       out['df'] =
-000066c0: 2073 656c 662e 6466 2e74 6f5f 6e75 6d70   self.df.to_nump
-000066d0: 7928 290d 0a20 2020 2020 2020 206f 7574  y()..        out
-000066e0: 5b27 696e 6465 7827 5d20 3d20 7365 6c66  ['index'] = self
-000066f0: 2e64 662e 696e 6465 780d 0a20 2020 2020  .df.index..     
-00006700: 2020 206f 7574 5b27 636f 6c75 6d6e 7327     out['columns'
-00006710: 5d20 3d20 7365 6c66 2e64 662e 636f 6c75  ] = self.df.colu
-00006720: 6d6e 730d 0a20 2020 2020 2020 200d 0a20  mns..        .. 
-00006730: 2020 2020 2020 2072 6574 7572 6e20 6f75         return ou
-00006740: 740d 0a20 2020 200d 0a20 2020 2064 6566  t..    ..    def
-00006750: 2074 6f5f 6373 7628 7365 6c66 2c20 6e61   to_csv(self, na
-00006760: 6d65 3d4e 6f6e 652c 206f 7665 7277 7269  me=None, overwri
-00006770: 7465 3d54 7275 6529 3a0d 0a20 2020 2020  te=True):..     
-00006780: 2020 2022 2222 0d0a 2020 2020 2020 2020     """..        
-00006790: 4578 706f 7274 2074 6865 2044 6174 6146  Export the DataF
-000067a0: 7261 6d65 2074 6f20 6120 4353 5620 6669  rame to a CSV fi
-000067b0: 6c65 2e0d 0a0d 0a20 2020 2020 2020 2041  le.....        A
-000067c0: 7267 733a 0d0a 2020 2020 2020 2020 2020  rgs:..          
-000067d0: 2020 6e61 6d65 2028 7374 722c 206f 7074    name (str, opt
-000067e0: 696f 6e61 6c29 3a20 5468 6520 6e61 6d65  ional): The name
-000067f0: 206f 6620 7468 6520 4353 5620 6669 6c65   of the CSV file
-00006800: 2e20 4966 206e 6f74 2070 726f 7669 6465  . If not provide
-00006810: 642c 2074 6865 206e 616d 6520 7769 6c6c  d, the name will
-00006820: 2062 6520 6765 6e65 7261 7465 6420 6261   be generated ba
-00006830: 7365 6420 6f6e 2074 6865 206f 626a 6563  sed on the objec
-00006840: 7427 7320 6e61 6d65 2e20 4465 6661 756c  t's name. Defaul
-00006850: 7473 2074 6f20 4e6f 6e65 2e0d 0a20 2020  ts to None...   
-00006860: 2020 2020 2020 2020 206f 7665 7277 7269           overwri
-00006870: 7465 2028 626f 6f6c 2c20 6f70 7469 6f6e  te (bool, option
-00006880: 616c 293a 2057 6865 7468 6572 2074 6f20  al): Whether to 
-00006890: 6f76 6572 7772 6974 6520 616e 2065 7869  overwrite an exi
-000068a0: 7374 696e 6720 6669 6c65 2077 6974 6820  sting file with 
-000068b0: 7468 6520 7361 6d65 206e 616d 652e 2044  the same name. D
-000068c0: 6566 6175 6c74 7320 746f 2054 7275 652e  efaults to True.
-000068d0: 0d0a 0d0a 2020 2020 2020 2020 5265 7475  ....        Retu
-000068e0: 726e 733a 0d0a 2020 2020 2020 2020 2020  rns:..          
-000068f0: 2020 7365 6c66 3a20 5468 6520 6375 7272    self: The curr
-00006900: 656e 7420 696e 7374 616e 6365 206f 6620  ent instance of 
-00006910: 7468 6520 4461 7461 496e 7465 7266 6163  the DataInterfac
-00006920: 6520 6f62 6a65 6374 2e0d 0a20 2020 2020  e object...     
-00006930: 2020 2022 2222 0d0a 2020 2020 2020 2020     """..        
-00006940: 6966 206e 616d 6520 6973 204e 6f6e 653a  if name is None:
-00006950: 0d0a 2020 2020 2020 2020 2020 2020 6e61  ..            na
-00006960: 6d65 203d 2073 656c 662e 6e61 6d65 202b  me = self.name +
-00006970: 2027 2e63 7376 270d 0a20 2020 2020 2020   '.csv'..       
-00006980: 2020 2020 200d 0a20 2020 2020 2020 2069       ..        i
-00006990: 6620 6f76 6572 7772 6974 6520 6f72 206e  f overwrite or n
-000069a0: 6f74 2050 6174 6828 6e61 6d65 292e 6973  ot Path(name).is
-000069b0: 5f66 696c 6528 293a 0d0a 2020 2020 2020  _file():..      
-000069c0: 2020 2020 2020 7365 6c66 2e64 662e 746f        self.df.to
-000069d0: 5f63 7376 286e 616d 6529 0d0a 2020 2020  _csv(name)..    
-000069e0: 2020 2020 0d0a 2020 2020 2020 2020 7265      ..        re
-000069f0: 7475 726e 2073 656c 660d 0a0d 0a20 2020  turn self....   
-00006a00: 2064 6566 2074 6f5f 6578 6365 6c28 7365   def to_excel(se
-00006a10: 6c66 2c20 6e61 6d65 3d4e 6f6e 652c 206f  lf, name=None, o
-00006a20: 7665 7277 7269 7465 3d54 7275 6529 3a0d  verwrite=True):.
-00006a30: 0a20 2020 2020 2020 2022 2222 0d0a 2020  .        """..  
-00006a40: 2020 2020 2020 4578 706f 7274 2074 6865        Export the
-00006a50: 2044 6174 6146 7261 6d65 2074 6f20 616e   DataFrame to an
-00006a60: 2045 7863 656c 2066 696c 652e 0d0a 0d0a   Excel file.....
-00006a70: 2020 2020 2020 2020 4172 6773 3a0d 0a20          Args:.. 
-00006a80: 2020 2020 2020 2020 2020 206e 616d 6520             name 
-00006a90: 2873 7472 2c20 6f70 7469 6f6e 616c 293a  (str, optional):
-00006aa0: 2054 6865 206e 616d 6520 6f66 2074 6865   The name of the
-00006ab0: 2045 7863 656c 2066 696c 652e 2049 6620   Excel file. If 
-00006ac0: 6e6f 7420 7072 6f76 6964 6564 2c20 7468  not provided, th
-00006ad0: 6520 6e61 6d65 2077 696c 6c20 6265 2067  e name will be g
-00006ae0: 656e 6572 6174 6564 2062 6173 6564 206f  enerated based o
-00006af0: 6e20 7468 6520 6f62 6a65 6374 2773 206e  n the object's n
-00006b00: 616d 652e 2044 6566 6175 6c74 7320 746f  ame. Defaults to
-00006b10: 204e 6f6e 652e 0d0a 2020 2020 2020 2020   None...        
-00006b20: 2020 2020 6f76 6572 7772 6974 6520 2862      overwrite (b
-00006b30: 6f6f 6c2c 206f 7074 696f 6e61 6c29 3a20  ool, optional): 
-00006b40: 5768 6574 6865 7220 746f 206f 7665 7277  Whether to overw
-00006b50: 7269 7465 2074 6865 2066 696c 6520 6966  rite the file if
-00006b60: 2069 7420 616c 7265 6164 7920 6578 6973   it already exis
-00006b70: 7473 2e20 4465 6661 756c 7473 2074 6f20  ts. Defaults to 
-00006b80: 5472 7565 2e0d 0a0d 0a20 2020 2020 2020  True.....       
-00006b90: 2052 6574 7572 6e73 3a0d 0a20 2020 2020   Returns:..     
-00006ba0: 2020 2020 2020 2073 656c 663a 2054 6865         self: The
-00006bb0: 2063 7572 7265 6e74 2069 6e73 7461 6e63   current instanc
-00006bc0: 6520 6f66 2074 6865 2044 6174 6149 6e74  e of the DataInt
-00006bd0: 6572 6661 6365 206f 626a 6563 742e 0d0a  erface object...
-00006be0: 2020 2020 2020 2020 2222 220d 0a20 2020          """..   
-00006bf0: 2020 2020 2069 6620 6e61 6d65 2069 7320       if name is 
-00006c00: 4e6f 6e65 3a0d 0a20 2020 2020 2020 2020  None:..         
-00006c10: 2020 206e 616d 6520 3d20 7365 6c66 2e6e     name = self.n
-00006c20: 616d 6520 2b20 272e 786c 7378 270d 0a20  ame + '.xlsx'.. 
-00006c30: 2020 2020 2020 200d 0a20 2020 2020 2020         ..       
-00006c40: 2069 6620 6f76 6572 7772 6974 6520 6f72   if overwrite or
-00006c50: 206e 6f74 2050 6174 6828 6e61 6d65 292e   not Path(name).
-00006c60: 6973 5f66 696c 6528 293a 0d0a 2020 2020  is_file():..    
-00006c70: 2020 2020 2020 2020 7365 6c66 2e64 662e          self.df.
-00006c80: 746f 5f65 7863 656c 286e 616d 6529 0d0a  to_excel(name)..
-00006c90: 2020 2020 2020 2020 0d0a 2020 2020 2020          ..      
-00006ca0: 2020 7265 7475 726e 2073 656c 660d 0a20    return self.. 
-00006cb0: 2020 200d 0a20 2020 2064 6566 2073 6176     ..    def sav
-00006cc0: 6528 7365 6c66 2c20 6e61 6d65 2c20 6f76  e(self, name, ov
-00006cd0: 6572 7772 6974 653d 5472 7565 293a 0d0a  erwrite=True):..
-00006ce0: 2020 2020 2020 2020 0d0a 2020 2020 2020          ..      
-00006cf0: 2020 6966 206f 7665 7277 7269 7465 206f    if overwrite o
-00006d00: 7220 6e6f 7420 5061 7468 286e 616d 6529  r not Path(name)
-00006d10: 2e69 735f 6669 6c65 2829 3a0d 0a20 2020  .is_file():..   
-00006d20: 2020 2020 2020 2020 200d 0a20 2020 2020           ..     
-00006d30: 2020 2020 2020 2066 726f 6d20 6461 7461         from data
-00006d40: 7375 7266 6572 2069 6d70 6f72 7420 4441  surfer import DA
-00006d50: 5441 5f4f 424a 4543 540d 0a20 2020 2020  TA_OBJECT..     
-00006d60: 2020 2020 2020 200d 0a20 2020 2020 2020         ..       
-00006d70: 2020 2020 2064 6f62 6a20 3d20 4441 5441       dobj = DATA
-00006d80: 5f4f 424a 4543 5428 7061 7468 3d73 656c  _OBJECT(path=sel
-00006d90: 662e 7061 7468 2c20 636f 6e66 6967 3d73  f.path, config=s
-00006da0: 656c 662e 636f 6e66 6967 2c20 6e61 6d65  elf.config, name
-00006db0: 3d73 656c 662e 6e61 6d65 2c20 0d0a 2020  =self.name, ..  
-00006dc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006dd0: 2020 2020 2020 2020 2063 6f6d 6d65 6e74           comment
-00006de0: 3d73 656c 662e 636f 6d6d 656e 742c 2064  =self.comment, d
-00006df0: 663d 7365 6c66 2e64 6629 0d0a 2020 2020  f=self.df)..    
-00006e00: 2020 2020 2020 2020 646f 626a 2e73 6176          dobj.sav
-00006e10: 6528 6e61 6d65 290d 0a20 2020 2020 2020  e(name)..       
-00006e20: 200d 0a20 2020 2020 2020 2072 6574 7572   ..        retur
-00006e30: 6e20 7365 6c66 0d0a 2020 2020 0d0a 2020  n self..    ..  
-00006e40: 2020 6465 6620 636c 6561 6e28 7365 6c66    def clean(self
-00006e50: 293a 0d0a 2020 2020 2020 2020 2222 220d  ):..        """.
-00006e60: 0a20 2020 2020 2020 2043 6c65 616e 7320  .        Cleans 
-00006e70: 7468 6520 6461 7461 2062 7920 6465 6c65  the data by dele
-00006e80: 7469 6e67 2074 6865 2069 6e74 6572 6e61  ting the interna
-00006e90: 6c20 4461 7461 4672 616d 6520 6f62 6a65  l DataFrame obje
-00006ea0: 6374 2e0d 0a20 2020 2020 2020 200d 0a20  ct...        .. 
-00006eb0: 2020 2020 2020 2052 6574 7572 6e73 3a0d         Returns:.
-00006ec0: 0a20 2020 2020 2020 2020 2020 2073 656c  .            sel
-00006ed0: 663a 2054 6865 2044 6174 6149 6e74 6572  f: The DataInter
-00006ee0: 6661 6365 206f 626a 6563 7420 6166 7465  face object afte
-00006ef0: 7220 636c 6561 6e69 6e67 2e0d 0a20 2020  r cleaning...   
-00006f00: 2020 2020 2022 2222 0d0a 2020 2020 2020       """..      
-00006f10: 2020 6966 2068 6173 6174 7472 2873 656c    if hasattr(sel
-00006f20: 662c 2027 5f64 6627 293a 0d0a 2020 2020  f, '_df'):..    
-00006f30: 2020 2020 2020 2020 6465 6c20 7365 6c66          del self
-00006f40: 2e5f 6466 0d0a 2020 2020 2020 2020 7265  ._df..        re
-00006f50: 7475 726e 2073 656c 660d 0a20 2020 2020  turn self..     
-00006f60: 2020 2020 2020 2020 2020 200d 0a20 2020             ..   
-00006f70: 2064 6566 2063 6c6f 7365 2873 656c 662c   def close(self,
-00006f80: 2063 6c65 616e 3d54 7275 6529 3a0d 0a20   clean=True):.. 
-00006f90: 2020 2020 2020 2022 2222 0d0a 2020 2020         """..    
-00006fa0: 2020 2020 436c 6f73 6573 2074 6865 2066      Closes the f
-00006fb0: 696c 6520 6861 6e64 6c65 7220 616e 6420  ile handler and 
-00006fc0: 7065 7266 6f72 6d73 206f 7074 696f 6e61  performs optiona
-00006fd0: 6c20 636c 6561 6e75 702e 0d0a 0d0a 2020  l cleanup.....  
-00006fe0: 2020 2020 2020 4172 6773 3a0d 0a20 2020        Args:..   
-00006ff0: 2020 2020 2020 2020 2063 6c65 616e 2028           clean (
-00007000: 626f 6f6c 2c20 6f70 7469 6f6e 616c 293a  bool, optional):
-00007010: 2046 6c61 6720 696e 6469 6361 7469 6e67   Flag indicating
-00007020: 2077 6865 7468 6572 2074 6f20 7065 7266   whether to perf
-00007030: 6f72 6d20 636c 6561 6e75 702e 2044 6566  orm cleanup. Def
-00007040: 6175 6c74 7320 746f 2054 7275 652e 0d0a  aults to True...
-00007050: 2020 2020 2020 2020 2222 220d 0a20 2020          """..   
-00007060: 2020 2020 2069 6620 6861 7361 7474 7228       if hasattr(
-00007070: 7365 6c66 2c20 275f 6668 616e 646c 6572  self, '_fhandler
-00007080: 2729 2061 6e64 2068 6173 6174 7472 2873  ') and hasattr(s
-00007090: 656c 662e 5f66 6861 6e64 6c65 722c 2027  elf._fhandler, '
-000070a0: 636c 6f73 6527 293a 0d0a 2020 2020 2020  close'):..      
-000070b0: 2020 2020 2020 7365 6c66 2e5f 6668 616e        self._fhan
-000070c0: 646c 6572 2e63 6c6f 7365 2829 0d0a 2020  dler.close()..  
-000070d0: 2020 2020 2020 2020 2020 6465 6c20 7365            del se
-000070e0: 6c66 2e5f 6668 616e 646c 6572 0d0a 0d0a  lf._fhandler....
-000070f0: 2020 2020 2020 2020 6966 2063 6c65 616e          if clean
-00007100: 3a0d 0a20 2020 2020 2020 2020 2020 2073  :..            s
-00007110: 656c 662e 636c 6561 6e28 290d 0a20 2020  elf.clean()..   
-00007120: 0d0a 2020 2020 4070 726f 7065 7274 790d  ..    @property.
-00007130: 0a20 2020 2064 6566 2070 6c6f 7428 7365  .    def plot(se
-00007140: 6c66 293a 0d0a 2020 2020 2020 2020 2222  lf):..        ""
-00007150: 220d 0a20 2020 2020 2020 2047 656e 6572  "..        Gener
-00007160: 6174 6520 6120 7374 6174 6973 7469 6361  ate a statistica
-00007170: 6c20 706c 6f74 2075 7369 6e67 2074 6865  l plot using the
-00007180: 2053 7461 745f 506c 6f74 7320 636c 6173   Stat_Plots clas
-00007190: 732e 0d0a 0d0a 2020 2020 2020 2020 5265  s.....        Re
-000071a0: 7475 726e 733a 0d0a 2020 2020 2020 2020  turns:..        
-000071b0: 2020 2020 5374 6174 5f50 6c6f 7473 3a20      Stat_Plots: 
-000071c0: 416e 2069 6e73 7461 6e63 6520 6f66 2074  An instance of t
-000071d0: 6865 2053 7461 745f 506c 6f74 7320 636c  he Stat_Plots cl
-000071e0: 6173 732e 0d0a 2020 2020 2020 2020 2222  ass...        ""
-000071f0: 220d 0a20 2020 2020 2020 2066 726f 6d20  "..        from 
-00007200: 6461 7461 7375 7266 6572 2e6c 6962 5f70  datasurfer.lib_p
-00007210: 6c6f 7473 2069 6d70 6f72 7420 506c 6f74  lots import Plot
-00007220: 730d 0a20 2020 2020 2020 200d 0a20 2020  s..        ..   
-00007230: 2020 2020 2072 6574 7572 6e20 506c 6f74       return Plot
-00007240: 7328 7365 6c66 290d 0a20 2020 200d 0a20  s(self)..    .. 
-00007250: 2020 2040 7072 6f70 6572 7479 0d0a 2020     @property..  
-00007260: 2020 6465 6620 7374 6174 7328 7365 6c66    def stats(self
-00007270: 293a 0d0a 2020 2020 2020 2020 2222 220d  ):..        """.
-00007280: 0a20 2020 2020 2020 2047 656e 6572 6174  .        Generat
-00007290: 6520 7374 6174 6973 7469 6361 6c20 7375  e statistical su
-000072a0: 6d6d 6172 6965 7320 666f 7220 7468 6520  mmaries for the 
-000072b0: 6461 7461 706f 6f6c 206f 626a 6563 7473  datapool objects
-000072c0: 2e0d 0a0d 0a20 2020 2020 2020 2052 6574  .....        Ret
-000072d0: 7572 6e73 3a0d 0a20 2020 2020 2020 2020  urns:..         
-000072e0: 2020 2053 7461 7473 3a20 416e 2069 6e73     Stats: An ins
-000072f0: 7461 6e63 6520 6f66 2074 6865 2053 7461  tance of the Sta
-00007300: 7473 2063 6c61 7373 2e0d 0a20 2020 2020  ts class...     
-00007310: 2020 2022 2222 0d0a 2020 2020 2020 2020     """..        
-00007320: 6672 6f6d 2064 6174 6173 7572 6665 722e  from datasurfer.
-00007330: 6c69 625f 7374 6174 7320 696d 706f 7274  lib_stats import
-00007340: 2053 7461 7473 0d0a 2020 2020 2020 2020   Stats..        
-00007350: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
-00007360: 2053 7461 7473 2873 656c 6629 0d0a 2320   Stats(self)..# 
-00007370: 2525 0d0a                                %%..
```

## datasurfer/lib_objects/amedata_object.py

```diff
@@ -1,28 +1,29 @@
 import re
 import numpy as np
 import pandas as pd
-from datasurfer.lib_objects import DataInterface
+from datasurfer.datainterface import DataInterface
 from functools import reduce
-#%% AMEDATA_OBJECT
+#%% AMEDataObject
 
-class AMEDATA_OBJECT(DataInterface):
+class AMEDataObject(DataInterface):
     """ 
     A class reads AMESim tables.
 
     Attributes:
         fhandler (list): The lines of the file represented by the object.
         ndim (int): The number of dimensions of the data.
         shape (list): The shape of the data.
         headidx (int): The index of the first non-header line in the file.
         axispoints (list): The axis points of the data.
         data1D (ndarray): The 1D data.
         data (ndarray): The reshaped data.
     """
-
+    exts = ['.data']
+    
     @property
     def fhandler(self):
         """
         Property that returns the lines of the file represented by the object.
 
         Returns:
             list: The lines of the file.
```

## datasurfer/lib_objects/amegp_object.py

```diff
@@ -1,17 +1,17 @@
 #%% Import Libraries
 
 import re
 import pandas as pd
 from pathlib import Path
-from datasurfer.lib_objects import DataInterface
+from datasurfer.datainterface import DataInterface
 
 
 #%% AMEGP_OJBECT
-class AMEGP_OBJECT(DataInterface):
+class AMEGPObject(DataInterface):
     """
     Represents an object for handling AMEGP data.
 
     Args:
         path (str): The path to the data file.
         config (dict): Configuration settings for the object.
         name (str): The name of the object.
@@ -22,29 +22,30 @@
         config (dict): Configuration settings for the object.
         name (str): The name of the object.
         comment (str): Additional comment for the object.
         df (pd.DataFrame): The data stored in a pandas DataFrame.
 
     Methods:
         __init__(self, path=None, config=None, name=None, comment=None):
-            Initializes a new instance of the AMEGP_OBJECT class.
+            Initializes a new instance of the AMEGPObject class.
         __setitem__(self, name, value):
             Sets the value of a specific item in the object.
         get_df(self):
             Retrieves the data as a transposed DataFrame.
         set_value(self, name, value):
             Sets the value of a specific item in the DataFrame.
         save(self, name=None):
             Saves the object's data to a file.
 
     """
-
+    exts = ['.gp']
+    
     def __init__(self, path=None, config=None, name=None, comment=None):
         """
-        Initializes a new instance of the AMEGP_OBJECT class.
+        Initializes a new instance of the AMEGPObject class.
 
         Args:
             path (str): The path to the data file.
             config (dict): Configuration settings for the object.
             name (str): The name of the object.
             comment (str): Additional comment for the object.
 
@@ -82,29 +83,29 @@
         Sets the value of a specific item in the DataFrame.
 
         Args:
             name (str): The name of the item.
             value: The value to be set.
 
         Returns:
-            self: The updated AMEGP_OBJECT instance.
+            self: The updated AMEGPObject instance.
 
         """
         self.df.at['VALUE', name] = value
         return self
     
     def save(self, name=None):
         """
         Saves the object's data to a file.
 
         Args:
             name (str, optional): The name of the file to save the data to. If not provided, the original file will be overwritten.
 
         Returns:
-            self: The AMEGP_OBJECT instance.
+            self: The AMEGPObject instance.
 
         """
         name = name if name is not None else self.path
         
         with open(self.path, 'r') as fobj:
             lines = fobj.readlines()
```

## datasurfer/lib_objects/ameres_object.py

```diff
@@ -3,21 +3,21 @@
 
 import re
 import pandas as pd
 import numpy as np
 
 from pathlib import Path
 
-from datasurfer.lib_objects import DataInterface 
+from datasurfer.datainterface import DataInterface 
 from datasurfer.datautils import translate_config, extract_channels
 
 
 
 #%% AMERES_OJBECT
-class AMERES_OBJECT(DataInterface):
+class AMEResObject(DataInterface):
     """
     Represents an object for handling AMERES data.
 
     Args:
         path (str): The path to the AMERES data file.
         config (dict): Configuration parameters for data extraction.
         name (str): The name of the AMERES object.
@@ -33,14 +33,15 @@
         get_df: Retrieves a DataFrame containing the specified data channels.
         get: Retrieves the specified data channels or time values from the AMERES data.
         get_results: Retrieves the raw data from the AMERES data file.
         keys: Retrieves the keys (data channels) of the AMERES data.
         search_channel: Searches for data channels that match a given pattern.
     """
 
+    exts = ['.results']
 
     def __init__(self, path=None, config=None, name=None, comment=None):
         
         if name is None:
             
             name = Path(path).stem[:-1]
         
@@ -226,11 +227,19 @@
         else:
             
             res = list(self.df.keys())
         
         return res   
     
     def search_channel(self, patt):
-        
+        """
+        Searches for channels in the `self.channels` list that match the given pattern.
+
+        Parameters:
+        patt (str): The pattern to search for.
+
+        Returns:
+        list: A list of channels that match the given pattern.
+        """
         r = re.compile(patt)
         
         return list(filter(r.match, self.channels))
```

## datasurfer/lib_objects/asammdf_object.py

```diff
@@ -3,36 +3,37 @@
 import pandas as pd
 import numpy as np
 import warnings
 import asammdf
 from asammdf import set_global_option    
 set_global_option("raise_on_multiple_occurrences", False) 
 from xml.etree.ElementTree import fromstring
-from datasurfer.lib_objects import DataInterface
+from datasurfer.datainterface import DataInterface
 from datasurfer.datautils import translate_config, extract_channels
 
-#%% ASAMMDF_OBJECT
-class ASAMMDF_OBJECT(DataInterface):
+#%% ASAMmdfObject
+class ASAMmdfObject(DataInterface):
     """
     Represents an ASAM MDF object.
 
     Args:
         path (str): The path to the MDF file.
         config (dict, optional): The configuration dictionary. Defaults to None.
         sampling (float, optional): The sampling rate. Defaults to 0.1.
         name (str, optional): The name of the object. Defaults to None.
         comment (str, optional): The comment for the object. Defaults to None.
         autoclose (bool, optional): Whether to automatically close the object. Defaults to False.
     """
   
+    exts = ['.mf4']
     
     def __init__(self, path, config=None, sampling=0.1, name=None, 
                  comment=None, autoclose=False):
         """
-        Initializes a new instance of the ASAMMDF_OBJECT class.
+        Initializes a new instance of the ASAMmdfObject class.
 
         Args:
             path (str): The path to the MDF file.
             config (dict, optional): The configuration dictionary. Defaults to None.
             sampling (float, optional): The sampling rate. Defaults to 0.1.
             name (str, optional): The name of the object. Defaults to None.
             comment (str, optional): The comment for the object. Defaults to None.
@@ -44,15 +45,15 @@
         self.autoclose = autoclose
 
     def __enter__(self):
         """
         Enters the context manager.
 
         Returns:
-            ASAMMDF_OBJECT: The current instance.
+            ASAMmdfObject: The current instance.
         """
         return self
     
     def __exit__(self, exc_type, exc_value, exc_traceback):
         """
         Exits the context manager.
 
@@ -142,17 +143,17 @@
             warnings.warn('Time axis may have deviation due to missing configuration.')
             n = 0
             while 1:
                 df = self.get_channels(self.channels[n])
                 if len(df):
                     break
                 n = n + 1
-            t = df.index
+            t = df['time']
         else:
-            t = self.df.index
+            t = self.df['time']
         return np.asarray(t)
     
     @property
     def df(self):
         """
         Gets the DataFrame of the object.
 
@@ -160,14 +161,15 @@
             pandas.DataFrame: The DataFrame.
         """
         if not hasattr(self, '_df'):
             if self.config is None:
                 self._df = pd.DataFrame()
             else:
                 self._df = self.get_df()
+                
         return self._df
     
     @property
     def fhandler(self):
         """
         Gets the MDF file handler.
 
@@ -201,29 +203,32 @@
         Returns:
             pandas.DataFrame: The DataFrame containing the channels.
         """
         df = self.fhandler.to_dataframe(channels=channels, 
                                     raster=self.sampling,
                                     time_from_zero=True)
         df.index.name = 'time'
+        df.reset_index(inplace=True)
         return df 
     
     def keys(self):
         """
         Gets the keys of the object.
 
         Returns:
             list: The keys of the object.
         """
-        if not len(self.df):
+        if not hasattr(self, '_df') or len(self._df) == 0:
             res = self.channels
         else:
             res = list(self.df.keys())
-        return res   
+        return res
     
+    list_signals = keys       
+       
     def get_df(self, close=None):
         """
         Gets the DataFrame of the object.
 
         Args:
             close (bool, optional): Whether to close the object after getting the DataFrame. Defaults to None.
```

## datasurfer/lib_objects/finance_object.py

```diff
@@ -1,30 +1,30 @@
 import pandas as pd
 from datasurfer.datautils import translate_config
-from datasurfer.lib_objects import PANDAS_OBJECT
+from datasurfer.lib_objects.pandas_object import PandasObject
 
 #%%
 
-class FINANCE_OBJECT(PANDAS_OBJECT):
+class FinanceObject(PandasObject):
     """
     A class representing a finance object.
     
     Attributes:
         path (str): The path to the finance object.
         config (dict): The configuration settings for the finance object.
         name (str): The name of the finance object.
         comment (str): Any additional comments about the finance object.
         df (pandas.DataFrame): The data stored in the finance object.
         time_format (str): The format of the time values in the finance object.
     """
-    
+    exts = ['.csv', '.xlsx', '.xls']
     def __init__(self, path=None, config=None, name=None, comment=None, 
                  df=None, time_format='%Y%m%d'):
         """
-        Initializes a new instance of the FINANCE_OBJECT class.
+        Initializes a new instance of the FinanceObject class.
         
         Args:
             path (str, optional): The path to the finance object. Defaults to None.
             config (dict, optional): The configuration settings for the finance object. Defaults to None.
             name (str, optional): The name of the finance object. Defaults to None.
             comment (str, optional): Any additional comments about the finance object. Defaults to None.
             df (pandas.DataFrame, optional): The data stored in the finance object. Defaults to None.
```

## datasurfer/lib_objects/json_object.py

```diff
@@ -1,15 +1,15 @@
 
 import json
 import pandas as pd
-from datasurfer.lib_objects import DataInterface
+from datasurfer.datainterface import DataInterface
 from datasurfer.datautils import translate_config
 
 #%%
-class JSON_OBJECT(DataInterface):
+class JSONObject(DataInterface):
     """
     Represents a JSON object.
 
     Args:
         path (str): The path to the JSON file.
         config (dict): Configuration options for the JSON object.
         name (str): The name of the JSON object.
@@ -17,26 +17,28 @@
 
     Attributes:
         path (str): The path to the JSON file.
         config (dict): Configuration options for the JSON object.
         name (str): The name of the JSON object.
         comment (str): Additional comments about the JSON object.
     """
-
+    exts = ['.json']
     def __init__(self, path=None, config=None, name=None, comment=None):
         super().__init__(path, config=config, name=name, comment=comment)
         
     @translate_config()
     def get_df(self):
         """
         Returns a pandas DataFrame representation of the JSON object.
 
         Returns:
             pandas.DataFrame: The DataFrame representation of the JSON object.
         """
-        dat = json.load(open(self.path, 'r'))
-        df = pd.DataFrame(dat).transpose()
-        return df
+        
+        with open(self.path, 'r') as fobj:
+            dat = json.load(fobj)
+            df = pd.DataFrame(dat).transpose()
+            return df
         
 if __name__ == '__main__':
     
     pass
```

## datasurfer/lib_objects/matlab_object.py

```diff
@@ -1,15 +1,16 @@
 #%% Import Libraries
 import pandas as pd
 import numpy as np
-from datasurfer.lib_objects import DataInterface
+import warnings
+from datasurfer.datainterface import DataInterface
 
 #%% MATLAB_OJBECT
 
-class MATLAB_OBJECT(DataInterface):
+class MatlabObject(DataInterface):
     """
     Represents a MATLAB object that can be loaded from a file.
 
     Args:
         path (str): The path to the MATLAB file.
         config (dict, optional): Configuration parameters for the object. Defaults to None.
         key (str, optional): The key to access the desired data in the MATLAB file. Defaults to None.
@@ -24,15 +25,15 @@
         fhandler (numpy.ndarray): The loaded data from the MATLAB file.
         t (numpy.ndarray): The time values associated with the data.
 
     Methods:
         get_df(): Returns a pandas DataFrame containing the loaded data.
 
     """
-
+    exts = ['.mat']
     def __init__(self, path, config=None, key=None, name=None, comment=None, **kwargs):
         super().__init__(path, config, comment=comment, name=name)
         self.matkey = key
 
     @property
     def fhandler(self):
         """
@@ -91,13 +92,13 @@
 
         for key, value in dat.items():
             try:
                 df[key] = value
             except ValueError:
                 if len(value) == 1:
                     df[key] = value[0]
-                else:
-                    raise ValueError(f'Can not convert "{key}" to DataFrame')
+                else:                   
+                    warnings.warn(f'Can not convert "{key}" to DataFrame')
 
         return df
     
 # %%
```

## datasurfer/lib_objects/mdf_object.py

```diff
@@ -1,19 +1,19 @@
 #%% Import Libraries
 
-
+import re
 import pandas as pd
 import numpy as np
 import warnings
 import mdfreader
-from datasurfer.lib_objects import DataInterface
+from datasurfer.datainterface import DataInterface
 from datasurfer.datautils import translate_config, extract_channels
 
-#%% MDF_OBJECT
-class MDF_OBJECT(DataInterface):
+#%% MDFObject
+class MDFObject(DataInterface):
     """
     Represents an MDF object that provides access to MDF file data.
 
     Args:
         path (str): The path to the MDF file.
         config (dict, optional): Configuration dictionary specifying the channels to extract. Defaults to None.
         sampling (float, optional): The sampling rate for resampling the data. Defaults to 0.1.
@@ -24,15 +24,15 @@
         sampling (float): The sampling rate for resampling the data.
         fhandler: The MDF file handler.
         info: Information about the MDF file.
         comment: The comment associated with the MDF object.
         channels: The list of available channels in the MDF file.
         t: The time axis of the data.
     """
-
+    exts = ['.mf4']
     def __init__(self, path, config=None, sampling=0.1, name=None, comment=None):
         super().__init__(path, config, comment=comment, name=name)
         self.sampling = sampling
 
     @property
     def fhandler(self):
         """
@@ -93,32 +93,33 @@
         Returns:
             ndarray: The time axis.
         """
         if self.config is None:
             warnings.warn('Time axis may have deviation due to missing configuration.')
         if not len(self.df):
             df = self.get_channels(self.channels[0])
-            t = df.index
+            t = df['time']
         else:
-            t = self.df.index
+            t = self.df['time']
         return np.asarray(t)
 
     def keys(self):
         """
         Returns the list of keys.
 
         Returns:
             list: The list of keys.
         """
-        if not len(self.df):
+        if not hasattr(self, '_df') or len(self._df) == 0:
             res = self.channels
         else:
             res = list(self.df.keys())
         return res
-
+    list_signals = keys
+    
     def search_channel(self, patt):
         """
         Searches for channels that match the given pattern.
 
         Args:
             patt (str): The pattern to search for.
 
@@ -155,15 +156,18 @@
         for chn in channels:
             try:
                 res = get(chn)
                 outs.append(res)
             except ValueError:
                 raise
                 warnings.warn(f'Channel "{chn}" not found.')
-        return pd.concat(outs, axis=1)
+        df = pd.concat(outs, axis=1)
+        df.index.name = 'time'
+        df.reset_index(inplace=True)
+        return df
 
     def get_df(self):
         """
         Returns the DataFrame representation of the MDF object.
 
         Returns:
             DataFrame: The DataFrame representation of the MDF object.
```

## datasurfer/lib_objects/pandas_object.py

```diff
@@ -1,44 +1,50 @@
 
 import numpy as np
 import pandas as pd
-from datasurfer.lib_objects import DataInterface
+
+from datasurfer import DataPool
+from datasurfer.datainterface import DataInterface
 from datasurfer.datautils import translate_config
 
 
 #%%
-class PANDAS_OBJECT(DataInterface):
+class PandasObject(DataInterface):
     """
     A class representing a Pandas object.
 
     Attributes:
         dict_fun (dict): A dictionary mapping file extensions to Pandas read functions.
     """
 
     dict_fun = {
         '.csv':  pd.read_csv,
         '.xlsx': pd.read_excel,
         '.xls':  pd.read_excel,        
     }
     
+    exts = ['.xlsx', '.csv', '.xls']
+    
     def __init__(self, path=None, config=None, name=None, comment=None, **kwargs):
         """
-        Initializes a new instance of the PANDAS_OBJECT class.
+        Initializes a new instance of the PandasObject class.
 
         Args:
             path (str): The path to the data file.
             config (dict): A dictionary containing configuration options.
             name (str): The name of the object.
             comment (str): A comment or description for the object.
         """
         super().__init__(path, config=config, name=name, comment=comment)
         self.kwargs = kwargs
         
-        if self.path.suffix.lower() in ('.xlsx', '.xls'):
+        if self.path and self.path.suffix.lower() in ('.xlsx', '.xls'):
             self.sheet_names = pd.ExcelFile(self.path).sheet_names
+            
+
         
     @property   
     def t(self):
         """
         Returns the index of the DataFrame as a NumPy array.
         """
         return np.asarray(self.df.index)
@@ -52,10 +58,76 @@
             DataFrame: The loaded data as a Pandas DataFrame.
         """
         fun = self.__class__.dict_fun[self.path.suffix.lower()]
        
         kwargs = dict(index_col=0)  
         kwargs.update(self.kwargs)        
         df = fun(self.path, **self.kwargs)
+            
+        return df
+    
+    @staticmethod
+    def from_other(other):
+        
+        assert isinstance(other, DataInterface)
+        dat = other.to_dict()
+        df = pd.DataFrame(dat['df'], index=dat['index'], columns=dat['columns'])
+        obj = PandasObject(path=dat['path'],
+                    config=dat['config'],
+                    comment=dat['comment'],
+                    name=dat['name'],)
+        obj._df = df
+
+        return obj 
+    
+
+
+#%%
+class FinanceObject(PandasObject):
+    """
+    A class representing a finance object.
+    
+    Attributes:
+        path (str): The path to the finance object.
+        config (dict): The configuration settings for the finance object.
+        name (str): The name of the finance object.
+        comment (str): Any additional comments about the finance object.
+        df (pandas.DataFrame): The data stored in the finance object.
+        time_format (str): The format of the time values in the finance object.
+    """
+    exts = ['.csv', '.xlsx', '.xls']
+    def __init__(self, path=None, config=None, name=None, comment=None, time_format='%Y%m%d'):
+        """
+        Initializes a new instance of the FinanceObject class.
+        
+        Args:
+            path (str, optional): The path to the finance object. Defaults to None.
+            config (dict, optional): The configuration settings for the finance object. Defaults to None.
+            name (str, optional): The name of the finance object. Defaults to None.
+            comment (str, optional): Any additional comments about the finance object. Defaults to None.
+            df (pandas.DataFrame, optional): The data stored in the finance object. Defaults to None.
+            time_format (str, optional): The format of the time values in the finance object. Defaults to '%Y%m%d'.
+        """
+        
+        super().__init__(path, config=config, name=name, comment=comment)
+        self.time_format = time_format
+    
+    @translate_config()
+    def get_df(self):
+        """
+        Retrieves the data stored in the finance object.
         
+        Returns:
+            pandas.DataFrame: The data stored in the finance object.
+        """
+        
+        fun = self.__class__.dict_fun[self.path.suffix.lower()]
+                
+        df = fun(self.path)
+                
+        cols_dat = df.columns[df.columns.str.contains('date')]
+               
+        for c in cols_dat:
+            
+            df[c] = pd.to_datetime(df[c], format=self.time_format)
         
         return df
```

## datasurfer/lib_objects/xkf_object.py

```diff
@@ -56,15 +56,15 @@
         
         X, Y = np.meshgrid(x, y)
         
         return X, Y
     
     def getZ(self, key, **kwargs):
         
-        from datasurfer.lib_stats.interp_methods import interp_linearND 
+        from datasurfer.lib_signals.interp_methods import interp_linearND 
         
         X = self.df[[self.key_speed, self.key_torque]].values
         z = self.df[key].values.ravel()
          
         f = interp_linearND(X, z, **kwargs)
         
         XX, YY = self.getXY()
```

## datasurfer/lib_plots/__init__.py

```diff
@@ -4,39 +4,58 @@
 from collections import abc
 from functools import wraps
 from datasurfer.lib_plots.plot_collection import plot_histogram, plot_dendrogram, plot_parallel_coordinate
 from datasurfer.lib_plots.plot_utils import parallel_coordis, get_histo_bins
 from datasurfer.datautils import parse_data
 
 figparams = {'figsize': (8, 6), 
-             'dpi': 120,}
+             'dpi': 105,}
 
 def set_ax(ax):
     
     ax.minorticks_on()
     ax.set_axisbelow(True)
     ax.grid(which='major', ls='--')
     ax.grid(which='minor', ls=':')
     
     return ax
     
 axisfunc = set_ax
 
 def define_ax(func):
-    
+    """
+    A decorator function that defines an axis for plotting.
+
+    Parameters:
+    - func: The function to be decorated.
+
+    Returns:
+    - The decorated function.
+
+    Usage:
+    - Use this decorator to define an axis for plotting in functions that require an axis.
+    - If an axis is not provided as a keyword argument, a new axis will be created using plt.subplots().
+
+    Example:
+    @define_ax
+    def plot_data(self, *keys, ax=None, **kwargs):
+        # Function implementation
+    """
+
     @wraps(func)
-    def wrapper(self, *keys, **kwargs): 
+    def wrapper(self, *args, **kwargs): 
           
         ax = kwargs.pop('ax', None)
         setax = kwargs.pop('setax', False)
         
         if not ax:
             _, ax = plt.subplots(**figparams)        
         
-        ax = func(self, *keys, ax=ax, **kwargs)
+        ax = func(self, *args, ax=ax, **kwargs)
+        
         if setax:
             axisfunc(ax)
         
         return ax
     return wrapper
     
 
@@ -46,39 +65,345 @@
     """
     A class for generating statistical plots.
     
     Parameters:
     - dp: A pandas DataFrame containing the data.
     """
     
-    def __init__(self, dp=None):
+    def __init__(self, db=None):
         """
         Initialize the Stat_Plots object.
         
         Parameters:
         - dp: A pandas DataFrame containing the data.
         """
-        self.dp = dp
+        self.db = db
+        
+    def __getattr__(self, name: str):
+        """
+        Retrieve the value of an attribute dynamically.
+
+        This method is called when an attribute is accessed that doesn't exist
+        in the current object. It attempts to retrieve the attribute from the
+        underlying database object and returns it.
+
+        Parameters:
+        - name (str): The name of the attribute to retrieve.
+
+        Returns:
+        - Any: The value of the attribute.
+
+        Raises:
+        - AttributeError: If the attribute doesn't exist in the current object
+                            or the underlying database object.
+        """
+        try:
+            return self.__getattribute__(name)
+        
+        except AttributeError:
+            
+            raise
+                       
         
-    def __call__(self, key, **kwargs):
+    def __call__(self, **kwargs):
         """
         Call the `line` method with the given key and keyword arguments.
 
         Parameters:
         - key: The key to identify the line.
         - **kwargs: Additional keyword arguments to pass to the `line` method.
 
         Returns:
         - The result of the `line` method.
 
         """
-        return self.line(key, **kwargs)
+
+        return self.set_params(**kwargs)
+
+    
+    @property
+    def pandas(self):
+        
+        """
+        Further information at https://pandas.pydata.org/docs/reference/plotting.html
+        
+        
+        """
+        
+        __all__ = [
+            'area',
+            'bar',
+            'barh',
+            'box',
+            'density',
+            'hexbin',
+            'hist',
+            'kde',
+            'line',
+            'pie',
+            'scatter'
+        ]
+               
+        class wrapper(object):           
+            def __init__(self, db):
+                self.db = db
+                       
+            def __getattr__(self, name):
+                
+                assert name in __all__, f'"{name}" is not a valid pandas plotting method. Please choose from {__all__}'
+                
+                def foo(*args, **kwargs):
+                    @define_ax
+                    @parse_data(add_labels=True)
+                    def boo(self, *args, **kwargs):                       
+                        labels = kwargs.pop('labels', None)
+                        ax = kwargs.pop('ax', None)
+                        if labels:
+                            df = pd.DataFrame(dict(zip(labels, args)))
+                            out = getattr(df.plot, name)(ax=ax, **kwargs)
+                        else:
+                            raise ValueError('Keys or dataframe must be provided')                        
+                        return out
+                    return boo(self, *args, **kwargs)  
+                
+                foo.__name__ = name     
+              
+                return foo  
+                      
+        return wrapper(self.db)
     
+    @property
+    def seaborn(self):
+        """
+        A method that provides a wrapper for seaborn plotting functions.
+
+        Returns:
+            wrapper: An instance of the wrapper class that allows access to seaborn plotting functions.
+        """
+        import seaborn as sns
+        __all__ = [
+            'clustermap',
+            'jointplot',
+            'pairplot',
+            'swarmplot',
+            'violinplot',
+            'heatmap',
+            'scatterplot',
+            'lineplot',
+            'boxplot',
+            'kdeplot',
+            'lmplot',
+            'relplot',
+            'catplot',
+            'barplot',
+            'countplot',
+            'pointplot',
+            'stripplot',
+            'pairplot',
+            'FacetGrid',
+            'PairGrid',
+        ]
+        
+        class wrapper(object):           
+            def __init__(self, db):
+                self.db = db 
+            
+            def set_theme(self, style='darkgrid', **kwargs):
+                sns.set_theme(style=style, **kwargs)
+                return self
+                
+            def __getattr__(self, name):
+                
+                assert name in __all__, f'"{name}" is not a valid pandas plotting method. Please choose from {__all__}'
+                def foo(*args, **kwargs):
+                    @parse_data(add_labels=True)
+                    def boo(self, *args, **kwargs):                       
+                        labels = kwargs.pop('labels', None)
+
+                        if labels:
+                            df = pd.DataFrame(dict(zip(labels, args)))
+                        else:
+                            df = kwargs.pop('data')
+                            
+                        out = getattr(sns, name)(data=df, **kwargs)  
+                        # else:
+                        #     raise ValueError('Keys or dataframe must be provided')                        
+                        return out
+                    return boo(self, *args, **kwargs)  
+                
+                foo.__name__ = name     
+              
+                return foo  
+                      
+        return wrapper(self.db)    
+    
+    @property
+    def plotly(self):
+        
+        """
+        Example:
+        df = pd.DataFrame([y, yhat, time], index=['y', 'yhat', 'time']).T
+
+        obj.plot.plotly.line(df, x='time', y=['y', 'yhat'], height=400, width=600)
+        """
+        
+        import plotly.express as px
+        import plotly.graph_objects as go
+        
+        __all__ =  [
+                    'scatter',
+                    'line',
+                    'bar',
+                    'histogram',
+                    'box',
+                    'violin',
+                    'density_contour',
+                    'density_heatmap',
+                    'density_mapbox',
+                    'density_violin',   
+                    'scatter_3d',
+                    'line_3d',
+                    'scatter_polar',
+                    'line_polar',
+                    'bar_polar',
+                    'scatter_ternary',
+                    'line_ternary',
+                    'scatter_geo',
+                    'line_geo',
+                    'scatter_mapbox',
+                    'line_mapbox',
+                    'scatter_matrix',
+                    'parallel_coordinates',
+                     ]
+        class wrapper(object):           
+            def __init__(self, db):
+                self.db = db 
+               
+            def __getattr__(self, name):
+                
+                assert name in __all__, f'"{name}" is not a valid pandas plotting method. Please choose from {__all__}'
+                def foo(*args, **kwargs):
+                    @parse_data(add_labels=True)
+                    def boo(self, *args, **kwargs):                       
+                        labels = kwargs.pop('labels', None)
+
+                        if labels:
+                            df = pd.DataFrame(dict(zip(labels, args)))
+                            fig = getattr(px, name)(df, **kwargs)  
+
+                        else:
+                            raise ValueError('Keys or dataframe must be provided')                        
+                        return fig
+                    return boo(self, *args, **kwargs)  
+                
+                foo.__name__ = name     
+              
+                return foo  
+                      
+        return wrapper(self.db) 
+    
+    @property
+    def bokeh(self):
+        """
+        Homepage:
+        https://docs.bokeh.org/en/2.4.1/index.html
+        Notebooks:
+        https://github.com/bokeh/bokeh-notebooks.git
+        Demos:
+        https://demo.bokeh.org/
+        
+        Example:
+        fig = obj.plot.bokeh(theme='dark_minimal', output_nb=True)
+        fig.figure(height=400, width=600, x_axis_label='x')
+        fig.line('time', keys[2], legend_label=keys[2], color='red')
+        fig.line('time', keys[3], legend_label=keys[3])
+        fig.scatter('time', keys[0], line_color='yellow', legend_label=keys[0])
+        fig.p.legend.location = "bottom_left"
+        fig.p.legend.label_text_font_size = '8pt'
+        fig.p.legend.click_policy = "hide"
+
+        fig.show()
+        
+        Post html to notebook:
+        from IPython.core.display import HTML
+        HTML('test.html')
+        
+        """
+
+        import bokeh.plotting as bp
+        import bokeh.io as bio
+        import bokeh.layouts as bl
+                
+        class wrapper(object):         
+              
+            def __init__(self, db):
+                self.db = db 
+                
+            def __call__(self, **kwargs):
+                                    
+                if kwargs.pop('output_nb', False):
+                    from bokeh.io import output_notebook
+                    output_notebook()
+                if kwargs.get('theme', None):
+                    from bokeh.io import curdoc
+                    curdoc().theme = kwargs.pop('theme')
+                return self
+           
+            def figure(self, **kwargs):
+                
+                self.ax = bp.figure(**kwargs)
+                return self
+            
+            def show(self, layout=None):
+                if layout is None:
+                    bp.show(self.ax)
+                else:
+                    bio.show(layout)
+                    
+                return self
+            
+            def layout(self, *axs, layout):
+
+                
+                axs = [ax.ax for ax in axs]
+                
+                return getattr(bl, layout)(*axs)
+                
+            
+            def save(self, path):
+                from bokeh.plotting import output_file, save
+                
+                output_file(filename=path, title="Static HTML file")
+                save(self.ax)
+                return self
+                          
+            def __getattr__(self, name):
+                
+                def foo(*args, **kwargs):                   
+                    @parse_data(add_labels=True)
+                    def boo(self, *args, **kwargs): 
+                                              
+                        labels = kwargs.pop('labels', None)  
+                        if not isinstance(self.ax, bp.Figure):
+                            self.figure()
+                            
+                        obj = getattr(self.ax, name)(*args, **kwargs)
+                                              
+                        return self
+                    
+                    return boo(self, *args, **kwargs)  
+                
+                foo.__name__ = name     
+              
+                return foo  
+                      
+        return wrapper(self.db)         
+                              
     
-    def set_figparam(self, **kwargs):
+    def set_params(self, **kwargs):
         """
         Set the figure parameters for the plots.
         
         Parameters:
         - **kwargs: The keyword arguments to be passed to the matplotlib figure function.
         """
         global figparams
@@ -92,17 +417,31 @@
         Parameters:
         - func: The function to be used for formatting the axes of the plots.
         """
         assert callable(func), 'func must be a callable function'
         global axisfunc
         axisfunc = func
         return self
+    
+    @define_ax
+    def gca(self, ax=None, setax=False, **kwargs):
+        """
+        Get the axis for plotting.
+        
+        Parameters:
+        - ax: The matplotlib Axes object to plot on. If None, a new figure and axes will be created.
+        
+        Returns:
+        - ax: The matplotlib Axes object to plot on.
+        """
+        self.set_params(**kwargs)
+        return ax
         
     @define_ax   
-    @parse_data
+    @parse_data(add_labels=True)
     def histogram(self, *keys, ax=None, bins=None, **kwargs):
         """
         Generate a histogram plot.
         
         Parameters:
         - keys: The column names of the data to plot. If keys are strings, the corresponding columns will be used. 
                 If keys are arrays, the arrays will be used directly.
@@ -112,26 +451,26 @@
                 If bins is a sequence, it defines the bin edges, including the rightmost edge.
         - **kwargs: Additional keyword arguments to be passed to the plot_histogram function.
         
         Returns:
         - ax: The matplotlib Axes object containing the histogram plot.
         """
         if all(isinstance(key, str) for key in keys):
-            data = self.dp[keys].dropna().to_numpy().T
+            data = self.db[keys].dropna().to_numpy().T
         else:
             data = keys
 
         
         if ax is None:           
             _, ax = plt.subplots()
             
             
         if bins is None:
-            # bins = np.linspace(np.min(data), np.max(data), 10)
             bins = get_histo_bins(data)
+            
         elif isinstance(bins, (abc.Sequence, np.ndarray)):
             bins = np.asarray(bins)
         
         elif isinstance(bins, int):
             bins = np.linspace(np.min(data), np.max(data), bins) 
               
         else:
@@ -139,78 +478,82 @@
 
         
         plot_histogram(ax, keys, bins, **kwargs)
                
         return ax
     
     @define_ax
-    @parse_data
-    def scatter(self, *keys, ax=None, setax=True, **kwargs):
+    @parse_data('x', 'y', 'c', 's', add_labels=True, label_keys=['x', 'y'])
+    def scatter(self, x, y, ax=None, **kwargs):
         """
         Create a scatter plot.
 
         Parameters:
         - keys: The data to be plotted. Must contain 2-4 elements.
         - ax: The matplotlib Axes object to plot on. If not provided, a new figure and axes will be created.
         - setax: A boolean indicating whether to set the x and y axis labels. Default is True.
         - labels: A list of labels for the x and y axis. If provided, the x and y axis labels will be set accordingly.
         - kwargs: Additional keyword arguments to be passed to the scatter function.
 
         Returns:
         - ax: The matplotlib Axes object containing the scatter plot.
         """
         labels = kwargs.pop('labels', None) 
+
+
+        ax.scatter(x, y, **kwargs)
+
         
-        if len(keys) == 2:
-            ax.scatter(keys[0], keys[1], **kwargs)
-        elif len(keys) == 3:
-            ax.scatter(keys[0], keys[1], c=keys[2], **kwargs)   
-        elif len(keys) == 4:
-            ax.scatter(keys[0], keys[1], c=keys[2], s=keys[3], **kwargs)    
-        else:
-            raise ValueError('keys must contain 2-4 elements')
-        
-        if labels:
+        if labels and len(labels) == 2:
             ax.set_xlabel(labels[0])   
             ax.set_ylabel(labels[1])
         
         return ax
     
     @define_ax
-    @parse_data
+    @parse_data('x', add_labels=True)
     def line(self, *keys, ax=None, **kwargs):
         """
         Plot a line graph.
 
         Parameters:
         - keys: Tuple of two elements representing the x and y values.
         - ax: Optional matplotlib Axes object to plot on.
         - labels: Optional tuple of x and y axis labels.
 
         Returns:
         - ax: The matplotlib Axes object with the line graph plotted.
         """
+        #assert len(keys) > 0, 'keys must contain at least one element'
+        
         labels = kwargs.pop('labels', None)
+        x = kwargs.pop('x', None)
+        
+        func = lambda x, y, label=None: (ax.plot(x, y, label=label, **kwargs) if x is not None 
+                                                else ax.plot(y, label=label, **kwargs))
+         
         if len(keys) == 1:
-            ax.plot(keys[0], **kwargs)  
+            if labels is not None:
+                func(x, keys[0], labels[0])
+            else:   
+                func(x, keys[0])
+            
             if labels:
                 ax.set_ylabel(labels[0]) 
-        elif len(keys) == 2:
-            ax.plot(keys[0], keys[1], **kwargs) 
-            if labels:
-                ax.set_xlabel(labels[0])   
-                ax.set_ylabel(labels[1])           
-        else:
-            raise ValueError('keys must contain 2 elements')
-        
        
+        elif len(keys) > 1 :
+            for idx, key in enumerate(keys):
+                if labels is not None:
+                    func(x, key, labels[idx])
+                else:   
+                    func(x, key)       
         return ax
      
     @define_ax
-    @parse_data
+    @parse_data(add_labels=True)
     def dendrogram(self, *keys, ax=None, **kwargs):
         """
         Generate a dendrogram plot.
 
         Parameters:
             *keys: Variable length argument list of keys.
             ax: Optional matplotlib Axes object to plot on.
@@ -221,15 +564,15 @@
         """
         labels = kwargs.pop('labels')
         df = pd.DataFrame(dict(zip(labels, keys)))        
         plot_dendrogram(ax, df.dropna(), **kwargs)       
         return ax
     
     @define_ax
-    @parse_data
+    @parse_data(add_labels=True)
     def parallel_coordinate(self, *keys, ax=None, **kwargs):
         """
         Plots a parallel coordinate plot based on the given keys.
 
         Parameters:
             *keys: The keys used to create the parallel coordinate plot.
             ax (optional): The matplotlib Axes object to plot on.
@@ -243,15 +586,15 @@
         default = dict(facecolor='none', lw=0.3, alpha=0.5, edgecolor='g')
         default.update(kwargs)        
         plot_parallel_coordinate(host=ax, df=df.dropna(), **default)
         
         return ax
     
     @define_ax
-    @parse_data
+    @parse_data(add_labels=True)
     def parallel_coordis(self, *keys, **kwargs):
         """
         Generate a parallel coordinates plot using the given keys as dimensions.
 
         Parameters:
         - keys: The keys to be used as dimensions for the parallel coordinates plot.
         - kwargs: Additional keyword arguments to be passed to the `parallel_coordis` function.
@@ -285,15 +628,15 @@
         Returns:
             ax: The matplotlib Axes object containing the heatmap plot.
         """
         import seaborn as sns
 
         cmap = kwargs.pop('cmap', sns.diverging_palette(230, 20, as_cmap=True))
 
-        corr = self.dp.stats.corr(*keys)
+        corr = self.db.signals.corr(*keys)
 
         default = dict(annot=True, cmap=cmap, cbar=False, vmin=-1, vmax=1)
 
         default.update(kwargs)
 
         sns.heatmap(corr, ax=ax, **default)
         ax.set_aspect('equal')
@@ -309,42 +652,59 @@
             text (str): The text to generate the word cloud from. If not provided, it will use the comments from the data provider.
             ax (matplotlib.axes.Axes, optional): The matplotlib axes to plot the word cloud on. If not provided, a new figure will be created.
             **kwargs: Additional keyword arguments to customize the word cloud.
 
         Returns:
             matplotlib.axes.Axes: The matplotlib axes containing the word cloud plot.
         """
+
         from datasurfer.lib_plots.plot_collection import plot_wordcloud
 
-        if text is None:
-            text = ' '.join([txt for txt in self.dp.comments().values.tolist() if isinstance(txt, str)])
+        if text is None and hasattr(self.db, 'comments'):
+            text = ' '.join([txt for txt in self.db.comments().values.tolist() if isinstance(txt, str)])
+        else:
+            raise ValueError("Expect text input for word cloud.")
 
         for r in remove:
             text = text.replace(r, ' ')
             
         ax = plot_wordcloud(ax=ax, text=text, **kwargs)
 
         return ax
     
     @define_ax
-    @parse_data
+    @parse_data(add_labels=True)
     def kde(self, *keys, ax=None, **kwargs):
+        """
+        Plot the kernel density estimate (KDE) for the given keys.
+
+        Parameters:
+        *keys : array-like
+            The keys for which the KDE will be computed and plotted.
+        ax : matplotlib.axes.Axes, optional
+            The axes on which the KDE plot will be drawn. If not provided, a new figure and axes will be created.
+        **kwargs : dict
+            Additional keyword arguments to customize the KDE plot.
+
+        Returns:
+        ax : matplotlib.axes.Axes
+            The axes on which the KDE plot is drawn.
+
+        """
+        from datasurfer.lib_signals.distrib_methods import get_kde
 
-        from datasurfer.lib_stats.distrib_methods import get_kde
         lbls = kwargs.pop('labels', [None]*len(keys))
         num = kwargs.pop('count', 100)
         pltkws = kwargs.pop('plot_kws', {})
-        
+
         for key, lbl in zip(keys, lbls):
-            
             kde = get_kde(key, **kwargs)
             x = np.linspace(np.min(key), np.max(key), num)
             ax.plot(x, kde(x), label=lbl, **pltkws)
 
-        
         return ax
         
     
     
        
 if __name__ == '__main__':
```

## datasurfer/lib_plots/plot_collection.py

```diff
@@ -196,36 +196,15 @@
         host.add_patch(patch)
     #host.legend(legend_handles, iris.target_names,
                 #loc='lower center', bbox_to_anchor=(0.5, -0.18),
                 #ncol=len(iris.target_names), fancybox=True, shadow=True)
     #plt.tight_layout()
     return axes
 
-#%%
-def arghisto(data, bins):
-    """
-    Compute the histogram of the input data based on the given bins.
 
-    Parameters:
-    data (ndarray): Input data array.
-    bins (ndarray): Bins for computing the histogram.
-
-    Returns:
-    list: List of arrays containing the indices of data points falling into each bin.
-    """
-    out = []
-    dat = data.ravel()
-       
-    for idx in range(0, len(bins)-1):
-        if idx == 0:
-            out.append(np.where((bins[idx]<=dat) & (bins[idx+1]>=dat))[0])
-        else:
-            out.append(np.where((bins[idx]<dat) & (bins[idx+1]>=dat))[0])
-        
-    return out
 
 #%%
 def plot_xybar(ax, data, bins, width=None, labels=None, title=None, xlabel=None, 
               ylabel=None, yfun=None, pct=True, colors=None, rebuildx=False):
     """
     Plot a bar chart with multiple bars for each x value.
 
@@ -767,15 +746,16 @@
     x = np.asarray(ax.get_xticks())
     xloc = (x[:-1] + x[1:]) / 2
     ax.set_xticks(xloc)
     
     ax.set_xticklabels(list('abcde'))
     ax.legend()
     """
- 
+                    
+    from datasurfer.lib_signals.distrib_methods import arghisto  
 
     
     n = len(data)
     x = np.asarray(bins)
     
     plot_kwargs = plot_kwargs or {} 
     
@@ -806,15 +786,16 @@
             arr2d = [np.asarray(d) for d in dat]
         
         for arr1d in arr2d:
             
             if arr1d.size == len(bins) - 1:            
                 y = arr1d
                 
-            else:               
+            else:
+                # y = np.array([len(index) for index in arghisto(arr1d, bins=bins)], dtype=int)               
                 y, _ = np.histogram(arr1d, bins)
                 
             if yfun:
                 y = yfun(y)
                 
             if colors:     
                 
@@ -857,16 +838,15 @@
                     bs = ax.barh(xloc, y, height=width, left=bttm, color=color, **plot_kwargs)
             
             if stacked:
                 bottom[idx0, :] = bottom[idx0, :] + y
             else:
                 
                 bottom[idx0, :] = np.max(np.vstack((bottom[idx0, :], y)), axis=0)
-                
-                
+                                
             count += 1
 
     if pct:
         sums = np.abs(bottom).sum(axis=1, keepdims=True)
         pcs  = np.abs(bottom) / sums * 100
         
 
@@ -1207,14 +1187,167 @@
     Plot a word cloud on the given axes.
 
     Parameters:
     - ax (matplotlib.axes.Axes): The axes on which to plot the word cloud.
     - text (str): The text to generate the word cloud from.
     - **kwargs: Additional keyword arguments to customize the word cloud appearance.
 
+
+                kwargs
+                ----------
+                font_path : string
+                    Font path to the font that will be used (OTF or TTF).
+                    Defaults to DroidSansMono path on a Linux machine. If you are on
+                    another OS or don't have this font, you need to adjust this path.
+
+                width : int (default=400)
+                    Width of the canvas.
+
+                height : int (default=200)
+                    Height of the canvas.
+
+                prefer_horizontal : float (default=0.90)
+                    The ratio of times to try horizontal fitting as opposed to vertical.
+                    If prefer_horizontal < 1, the algorithm will try rotating the word
+                    if it doesn't fit. (There is currently no built-in way to get only
+                    vertical words.)
+
+                mask : nd-array or None (default=None)
+                    If not None, gives a binary mask on where to draw words. If mask is not
+                    None, width and height will be ignored and the shape of mask will be
+                    used instead. All white (#FF or #FFFFFF) entries will be considerd
+                    "masked out" while other entries will be free to draw on. [This
+                    changed in the most recent version!]
+
+                contour_width: float (default=0)
+                    If mask is not None and contour_width > 0, draw the mask contour.
+
+                contour_color: color value (default="black")
+                    Mask contour color.
+
+                scale : float (default=1)
+                    Scaling between computation and drawing. For large word-cloud images,
+                    using scale instead of larger canvas size is significantly faster, but
+                    might lead to a coarser fit for the words.
+
+                min_font_size : int (default=4)
+                    Smallest font size to use. Will stop when there is no more room in this
+                    size.
+
+                font_step : int (default=1)
+                    Step size for the font. font_step > 1 might speed up computation but
+                    give a worse fit.
+
+                max_words : number (default=200)
+                    The maximum number of words.
+
+                stopwords : set of strings or None
+                    The words that will be eliminated. If None, the build-in STOPWORDS
+                    list will be used. Ignored if using generate_from_frequencies.
+
+                background_color : color value (default="black")
+                    Background color for the word cloud image.
+
+                max_font_size : int or None (default=None)
+                    Maximum font size for the largest word. If None, height of the image is
+                    used.
+
+                mode : string (default="RGB")
+                    Transparent background will be generated when mode is "RGBA" and
+                    background_color is None.
+
+                relative_scaling : float (default='auto')
+                    Importance of relative word frequencies for font-size.  With
+                    relative_scaling=0, only word-ranks are considered.  With
+                    relative_scaling=1, a word that is twice as frequent will have twice
+                    the size.  If you want to consider the word frequencies and not only
+                    their rank, relative_scaling around .5 often looks good.
+                    If 'auto' it will be set to 0.5 unless repeat is true, in which
+                    case it will be set to 0.
+
+                    .. versionchanged: 2.0
+                        Default is now 'auto'.
+
+                color_func : callable, default=None
+                    Callable with parameters word, font_size, position, orientation,
+                    font_path, random_state that returns a PIL color for each word.
+                    Overwrites "colormap".
+                    See colormap for specifying a matplotlib colormap instead.
+                    To create a word cloud with a single color, use
+                    ``color_func=lambda *args, **kwargs: "white"``.
+                    The single color can also be specified using RGB code. For example
+                    ``color_func=lambda *args, **kwargs: (255,0,0)`` sets color to red.
+
+                regexp : string or None (optional)
+                    Regular expression to split the input text into tokens in process_text.
+                    If None is specified, ``r"\w[\w']+"`` is used. Ignored if using
+                    generate_from_frequencies.
+
+                collocations : bool, default=True
+                    Whether to include collocations (bigrams) of two words. Ignored if using
+                    generate_from_frequencies.
+
+
+                    .. versionadded: 2.0
+
+                colormap : string or matplotlib colormap, default="viridis"
+                    Matplotlib colormap to randomly draw colors from for each word.
+                    Ignored if "color_func" is specified.
+
+                    .. versionadded: 2.0
+
+                normalize_plurals : bool, default=True
+                    Whether to remove trailing 's' from words. If True and a word
+                    appears with and without a trailing 's', the one with trailing 's'
+                    is removed and its counts are added to the version without
+                    trailing 's' -- unless the word ends with 'ss'. Ignored if using
+                    generate_from_frequencies.
+
+                repeat : bool, default=False
+                    Whether to repeat words and phrases until max_words or min_font_size
+                    is reached.
+
+                include_numbers : bool, default=False
+                    Whether to include numbers as phrases or not.
+
+                min_word_length : int, default=0
+                    Minimum number of letters a word must have to be included.
+
+                collocation_threshold: int, default=30
+                    Bigrams must have a Dunning likelihood collocation score greater than this
+                    parameter to be counted as bigrams. Default of 30 is arbitrary.
+
+                    See Manning, C.D., Manning, C.D. and Schütze, H., 1999. Foundations of
+                    Statistical Natural Language Processing. MIT press, p. 162
+                    https://nlp.stanford.edu/fsnlp/promo/colloc.pdf#page=22
+
+                Attributes
+                ----------
+                ``words_`` : dict of string to float
+                    Word tokens with associated frequency.
+
+                    .. versionchanged: 2.0
+                        ``words_`` is now a dictionary
+
+                ``layout_`` : list of tuples ((string, float), int, (int, int), int, color))
+                    Encodes the fitted word cloud. For each word, it encodes the string,
+                    normalized frequency, font size, position, orientation, and color.
+                    The frequencies are normalized by the most commonly occurring word.
+                    The color is in the format of 'rgb(R, G, B).'
+
+                Notes
+                -----
+                Larger canvases make the code significantly slower. If you need a
+                large word cloud, try a lower canvas size, and set the scale parameter.
+
+                The algorithm might give more weight to the ranking of the words
+                than their actual frequencies, depending on the ``max_font_size`` and the
+                scaling heuristic.
+
+
     Returns:
     - matplotlib.axes.Axes: The axes with the word cloud plotted.
     """
     from wordcloud import WordCloud
     
     default = dict(background_color='black', colormap='viridis', height=600, width=1000,
                    contour_width=2, contour_color='steelblue')
```

### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

## datasurfer/lib_plots/plot_utils.py

```diff
@@ -6,14 +6,63 @@
 import matplotlib.pyplot as plt
 import matplotlib.tri as tri 
 
 from matplotlib.collections import LineCollection
 
 
 #%%
+def adjust_axis_offset(ax, offset=1.2, which='right', color=None):
+    """
+    Adjusts the offset of the specified axis spine.
+
+    Parameters:
+    ax (matplotlib.axes.Axes): The axes object to adjust.
+    offset (float): The offset value to set for the spine position. Default is 1.2.
+    which (str): The spine to adjust. Can be 'left', 'right', 'top', or 'bottom'. Default is 'right'.
+
+    Returns:
+    matplotlib.axes.Axes: The modified axes object.
+    """
+    
+    axis = ax.spines[which]
+    axis.set_position(('axes', offset))
+    
+    if color:
+        axis.set_color(color)
+        
+    
+    return ax
+
+
+#%%
+def set_axis_color(ax, axis='both', color='black'):
+    """
+    Sets the color of the specified axis or axes.
+
+    Parameters:
+    ax (matplotlib.axes.Axes): The axes object to adjust.
+    axis (str): The axis or axes to adjust. Can be 'x', 'y', or 'both'. Default is 'both'.
+    color (str): The color to set for the axis or axes. Default is 'black'.
+
+    Returns:
+    matplotlib.axes.Axes: The modified axes object.
+    """
+    
+    if axis in ('x', 'both'):
+        ax.xaxis.label.set_color(color)
+        ax.tick_params(axis='x', colors=color)
+        
+    if axis in ('y', 'both'):
+        ax.yaxis.label.set_color(color)
+        ax.tick_params(axis='y', colors=color)
+        
+    return ax
+    
+
+#%%
 def get_histo_bins(arr, num=10, decimals=0, base=None, maxi=None):
     
     arr = np.asarray(arr).ravel()
     
     ptp = arr.ptp()
     
     assert ptp > 0, 'Data has no range'
```

## datasurfer/lib_stats/__init__.py

```diff
@@ -1,312 +0,0 @@
-00000000: 696d 706f 7274 2070 616e 6461 7320 6173  import pandas as
-00000010: 2070 640d 0a69 6d70 6f72 7420 6e75 6d70   pd..import nump
-00000020: 7920 6173 206e 700d 0a66 726f 6d20 6461  y as np..from da
-00000030: 7461 7375 7266 6572 2e64 6174 6175 7469  tasurfer.datauti
-00000040: 6c73 2069 6d70 6f72 7420 6172 6768 6973  ls import arghis
-00000050: 746f 2c20 7061 7273 655f 6461 7461 2c20  to, parse_data, 
-00000060: 7368 6f77 5f70 6f6f 6c5f 7072 6f67 7265  show_pool_progre
-00000070: 7373 0d0a 0d0a 2325 250d 0a0d 0a63 6c61  ss....#%%....cla
-00000080: 7373 2053 7461 7473 286f 626a 6563 7429  ss Stats(object)
-00000090: 3a0d 0a20 2020 2022 2222 0d0a 2020 2020  :..    """..    
-000000a0: 4120 636c 6173 7320 666f 7220 7065 7266  A class for perf
-000000b0: 6f72 6d69 6e67 2073 7461 7469 7374 6963  orming statistic
-000000c0: 616c 2063 6f6d 7075 7461 7469 6f6e 732e  al computations.
-000000d0: 0d0a 0d0a 2020 2020 4174 7472 6962 7574  ....    Attribut
-000000e0: 6573 3a0d 0a20 2020 2064 703a 2054 6865  es:..    dp: The
-000000f0: 2064 6174 6120 6f62 6a65 6374 2e0d 0a0d   data object....
-00000100: 0a20 2020 2022 2222 0d0a 0d0a 2020 2020  .    """....    
-00000110: 6465 6620 5f5f 696e 6974 5f5f 2873 656c  def __init__(sel
-00000120: 662c 2064 7029 202d 3e20 4e6f 6e65 3a0d  f, dp) -> None:.
-00000130: 0a20 2020 2020 2020 2073 656c 662e 6470  .        self.dp
-00000140: 203d 2064 700d 0a20 2020 2020 2020 200d   = dp..        .
-00000150: 0a20 2020 2064 6566 205f 5f63 616c 6c5f  .    def __call_
-00000160: 5f28 7365 6c66 2c20 2a6b 6579 732c 202a  _(self, *keys, *
-00000170: 2a6b 7761 7267 7329 3a0d 0a20 2020 2020  *kwargs):..     
-00000180: 2020 200d 0a20 2020 2020 2020 2072 6574     ..        ret
-00000190: 7572 6e20 7365 6c66 2e64 705b 6b65 7973  urn self.dp[keys
-000001a0: 5d2e 6465 7363 7269 6265 282a 2a6b 7761  ].describe(**kwa
-000001b0: 7267 7329 0d0a 0d0a 2020 2020 4070 6172  rgs)....    @par
-000001c0: 7365 5f64 6174 610d 0a20 2020 2064 6566  se_data..    def
-000001d0: 2061 7267 6869 7374 6f28 7365 6c66 2c20   arghisto(self, 
-000001e0: 7661 6c2c 202a 2c20 6269 6e73 2c20 2a2a  val, *, bins, **
-000001f0: 6b77 6172 6773 293a 0d0a 2020 2020 2020  kwargs):..      
-00000200: 2020 2222 220d 0a20 2020 2020 2020 2043    """..        C
-00000210: 6f6d 7075 7465 2074 6865 2068 6973 746f  ompute the histo
-00000220: 6772 616d 206f 6620 6120 6769 7665 6e20  gram of a given 
-00000230: 7661 6c75 652e 0d0a 0d0a 2020 2020 2020  value.....      
-00000240: 2020 5061 7261 6d65 7465 7273 3a0d 0a20    Parameters:.. 
-00000250: 2020 2020 2020 2076 616c 2028 6172 7261         val (arra
-00000260: 792d 6c69 6b65 293a 2054 6865 2069 6e70  y-like): The inp
-00000270: 7574 2076 616c 7565 732e 0d0a 2020 2020  ut values...    
-00000280: 2020 2020 6269 6e73 2028 696e 7429 3a20      bins (int): 
-00000290: 5468 6520 6e75 6d62 6572 206f 6620 6269  The number of bi
-000002a0: 6e73 2074 6f20 7573 6520 666f 7220 7468  ns to use for th
-000002b0: 6520 6869 7374 6f67 7261 6d2e 0d0a 0d0a  e histogram.....
-000002c0: 2020 2020 2020 2020 5265 7475 726e 733a          Returns:
-000002d0: 0d0a 2020 2020 2020 2020 6e75 6d70 792e  ..        numpy.
-000002e0: 6e64 6172 7261 793a 2054 6865 2063 6f6d  ndarray: The com
-000002f0: 7075 7465 6420 6869 7374 6f67 7261 6d2e  puted histogram.
-00000300: 0d0a 0d0a 2020 2020 2020 2020 2222 220d  ....        """.
-00000310: 0a20 2020 2020 2020 2072 6574 7572 6e20  .        return 
-00000320: 6172 6768 6973 746f 2876 616c 2c20 6269  arghisto(val, bi
-00000330: 6e73 290d 0a20 2020 200d 0a20 2020 2040  ns)..    ..    @
-00000340: 7061 7273 655f 6461 7461 0d0a 2020 2020  parse_data..    
-00000350: 6465 6620 6b64 6528 7365 6c66 2c20 6b65  def kde(self, ke
-00000360: 792c 202a 2a6b 7761 7267 7329 3a0d 0a20  y, **kwargs):.. 
-00000370: 2020 2020 2020 2022 2222 0d0a 2020 2020         """..    
-00000380: 2020 2020 4361 6c63 756c 6174 6520 7468      Calculate th
-00000390: 6520 6b65 726e 656c 2064 656e 7369 7479  e kernel density
-000003a0: 2065 7374 696d 6174 6520 284b 4445 2920   estimate (KDE) 
-000003b0: 666f 7220 6120 6769 7665 6e20 6b65 792e  for a given key.
-000003c0: 0d0a 0d0a 2020 2020 2020 2020 5061 7261  ....        Para
-000003d0: 6d65 7465 7273 3a0d 0a20 2020 2020 2020  meters:..       
-000003e0: 202d 206b 6579 3a20 5468 6520 6b65 7920   - key: The key 
-000003f0: 666f 7220 7768 6963 6820 746f 2063 616c  for which to cal
-00000400: 6375 6c61 7465 2074 6865 204b 4445 2e0d  culate the KDE..
-00000410: 0a20 2020 2020 2020 202d 202a 2a6b 7761  .        - **kwa
-00000420: 7267 733a 2041 6464 6974 696f 6e61 6c20  rgs: Additional 
-00000430: 6b65 7977 6f72 6420 6172 6775 6d65 6e74  keyword argument
-00000440: 7320 746f 2062 6520 7061 7373 6564 2074  s to be passed t
-00000450: 6f20 7468 6520 6067 6574 5f6b 6465 6020  o the `get_kde` 
-00000460: 6675 6e63 7469 6f6e 2e0d 0a0d 0a20 2020  function.....   
-00000470: 2020 2020 2052 6574 7572 6e73 3a0d 0a20       Returns:.. 
-00000480: 2020 2020 2020 202d 2054 6865 206b 6572         - The ker
-00000490: 6e65 6c20 6465 6e73 6974 7920 6573 7469  nel density esti
-000004a0: 6d61 7465 2066 6f72 2074 6865 2067 6976  mate for the giv
-000004b0: 656e 206b 6579 2e0d 0a0d 0a20 2020 2020  en key.....     
-000004c0: 2020 2022 2222 0d0a 2020 2020 2020 2020     """..        
-000004d0: 6672 6f6d 2064 6174 6173 7572 6665 722e  from datasurfer.
-000004e0: 6c69 625f 7374 6174 732e 6469 7374 7269  lib_stats.distri
-000004f0: 625f 6d65 7468 6f64 7320 696d 706f 7274  b_methods import
-00000500: 2067 6574 5f6b 6465 0d0a 0d0a 2020 2020   get_kde....    
-00000510: 2020 2020 6b77 6172 6773 2e70 6f70 2827      kwargs.pop('
-00000520: 6c61 6265 6c73 272c 204e 6f6e 6529 0d0a  labels', None)..
-00000530: 0d0a 2020 2020 2020 2020 7265 7475 726e  ..        return
-00000540: 2067 6574 5f6b 6465 286b 6579 2c20 2a2a   get_kde(key, **
-00000550: 6b77 6172 6773 290d 0a20 2020 200d 0a20  kwargs)..    .. 
-00000560: 2020 2064 6566 2063 6f72 7228 7365 6c66     def corr(self
-00000570: 2c20 2a6b 6579 732c 202a 2a6b 7761 7267  , *keys, **kwarg
-00000580: 7329 3a0d 0a20 2020 2020 2020 2022 2222  s):..        """
-00000590: 0d0a 2020 2020 2020 2020 436f 6d70 7574  ..        Comput
-000005a0: 6520 7468 6520 636f 7272 656c 6174 696f  e the correlatio
-000005b0: 6e20 6265 7477 6565 6e20 7477 6f20 6f72  n between two or
-000005c0: 206d 6f72 6520 6b65 7973 2069 6e20 7468   more keys in th
-000005d0: 6520 6461 7461 7365 742e 0d0a 0d0a 2020  e dataset.....  
-000005e0: 2020 2020 2020 5061 7261 6d65 7465 7273        Parameters
-000005f0: 3a0d 0a20 2020 2020 2020 202d 206b 6579  :..        - key
-00000600: 733a 2054 776f 206f 7220 6d6f 7265 206b  s: Two or more k
-00000610: 6579 7320 746f 2063 6f6d 7075 7465 2074  eys to compute t
-00000620: 6865 2063 6f72 7265 6c61 7469 6f6e 2066  he correlation f
-00000630: 6f72 2e0d 0a20 2020 2020 2020 202d 206b  or...        - k
-00000640: 7761 7267 733a 2041 6464 6974 696f 6e61  wargs: Additiona
-00000650: 6c20 6b65 7977 6f72 6420 6172 6775 6d65  l keyword argume
-00000660: 6e74 7320 746f 2062 6520 7061 7373 6564  nts to be passed
-00000670: 2074 6f20 7468 6520 6063 6f72 7260 206d   to the `corr` m
-00000680: 6574 686f 642e 0d0a 0d0a 2020 2020 2020  ethod.....      
-00000690: 2020 5265 7475 726e 733a 0d0a 2020 2020    Returns:..    
-000006a0: 2020 2020 2d20 5468 6520 636f 7272 656c      - The correl
-000006b0: 6174 696f 6e20 6d61 7472 6978 2062 6574  ation matrix bet
-000006c0: 7765 656e 2074 6865 2073 7065 6369 6669  ween the specifi
-000006d0: 6564 206b 6579 732e 0d0a 0d0a 2020 2020  ed keys.....    
-000006e0: 2020 2020 5261 6973 6573 3a0d 0a20 2020      Raises:..   
-000006f0: 2020 2020 202d 2041 7373 6572 7469 6f6e       - Assertion
-00000700: 4572 726f 723a 2049 6620 6c65 7373 2074  Error: If less t
-00000710: 6861 6e20 7477 6f20 6b65 7973 2061 7265  han two keys are
-00000720: 2070 726f 7669 6465 642e 0d0a 0d0a 2020   provided.....  
-00000730: 2020 2020 2020 4578 616d 706c 6520 7573        Example us
-00000740: 6167 653a 0d0a 2020 2020 2020 2020 3e3e  age:..        >>
-00000750: 3e20 6461 7461 7365 742e 636f 7272 2827  > dataset.corr('
-00000760: 6b65 7931 272c 2027 6b65 7932 272c 206d  key1', 'key2', m
-00000770: 6574 686f 643d 2770 6561 7273 6f6e 2729  ethod='pearson')
-00000780: 0d0a 2020 2020 2020 2020 2222 220d 0a20  ..        """.. 
-00000790: 2020 2020 2020 2061 7373 6572 7420 6c65         assert le
-000007a0: 6e28 6b65 7973 2920 3e3d 2032 2c20 2741  n(keys) >= 2, 'A
-000007b0: 7420 6c65 6173 7420 7477 6f20 6b65 7973  t least two keys
-000007c0: 2061 7265 2072 6571 7569 7265 6420 666f   are required fo
-000007d0: 7220 636f 7272 656c 6174 696f 6e20 636f  r correlation co
-000007e0: 6d70 7574 6174 696f 6e2e 270d 0a20 2020  mputation.'..   
-000007f0: 2020 2020 2072 6574 7572 6e20 7365 6c66       return self
-00000800: 2e64 705b 6b65 7973 5d2e 636f 7272 282a  .dp[keys].corr(*
-00000810: 2a6b 7761 7267 7329 0d0a 2020 2020 0d0a  *kwargs)..    ..
-00000820: 2020 2020 4070 6172 7365 5f64 6174 610d      @parse_data.
-00000830: 0a20 2020 2064 6566 2069 6e74 6572 705f  .    def interp_
-00000840: 6c69 6e65 6172 2873 656c 662c 202a 7661  linear(self, *va
-00000850: 6c73 2c20 2a2a 6b77 6172 6773 293a 0d0a  ls, **kwargs):..
-00000860: 2020 2020 2020 2020 2222 220d 0a20 2020          """..   
-00000870: 2020 2020 2050 6572 666f 726d 206c 696e       Perform lin
-00000880: 6561 7220 696e 7465 7270 6f6c 6174 696f  ear interpolatio
-00000890: 6e20 696e 204e 2d64 696d 656e 7369 6f6e  n in N-dimension
-000008a0: 616c 2073 7061 6365 2e0d 0a0d 0a20 2020  al space.....   
-000008b0: 2020 2020 2050 6172 616d 6574 6572 733a       Parameters:
-000008c0: 0d0a 2020 2020 2020 2020 2a76 616c 733a  ..        *vals:
-000008d0: 2074 7570 6c65 0d0a 2020 2020 2020 2020   tuple..        
-000008e0: 2020 2020 5475 706c 6520 6f66 204e 2061      Tuple of N a
-000008f0: 7272 6179 7320 7265 7072 6573 656e 7469  rrays representi
-00000900: 6e67 2074 6865 2063 6f6f 7264 696e 6174  ng the coordinat
-00000910: 6573 206f 6620 7468 6520 706f 696e 7473  es of the points
-00000920: 2074 6f20 6265 2069 6e74 6572 706f 6c61   to be interpola
-00000930: 7465 642e 0d0a 2020 2020 2020 2020 2020  ted...          
-00000940: 2020 5468 6520 6c61 7374 2061 7272 6179    The last array
-00000950: 2069 6e20 7468 6520 7475 706c 6520 7265   in the tuple re
-00000960: 7072 6573 656e 7473 2074 6865 2076 616c  presents the val
-00000970: 7565 7320 6174 2074 6865 2067 6976 656e  ues at the given
-00000980: 2063 6f6f 7264 696e 6174 6573 2e0d 0a20   coordinates... 
-00000990: 2020 2020 2020 202a 2a6b 7761 7267 733a         **kwargs:
-000009a0: 2064 6963 742c 206f 7074 696f 6e61 6c0d   dict, optional.
-000009b0: 0a20 2020 2020 2020 2020 2020 2041 6464  .            Add
-000009c0: 6974 696f 6e61 6c20 6b65 7977 6f72 6420  itional keyword 
-000009d0: 6172 6775 6d65 6e74 7320 746f 2062 6520  arguments to be 
-000009e0: 7061 7373 6564 2074 6f20 7468 6520 696e  passed to the in
-000009f0: 7465 7270 6f6c 6174 696f 6e20 6d65 7468  terpolation meth
-00000a00: 6f64 2e0d 0a0d 0a20 2020 2020 2020 2052  od.....        R
-00000a10: 6574 7572 6e73 3a0d 0a20 2020 2020 2020  eturns:..       
-00000a20: 2066 3a20 6f62 6a65 6374 0d0a 2020 2020   f: object..    
-00000a30: 2020 2020 2020 2020 5468 6520 696e 7465          The inte
-00000a40: 7270 6f6c 6174 6564 2066 756e 6374 696f  rpolated functio
-00000a50: 6e2e 0d0a 0d0a 2020 2020 2020 2020 5261  n.....        Ra
-00000a60: 6973 6573 3a0d 0a20 2020 2020 2020 2041  ises:..        A
-00000a70: 7373 6572 7469 6f6e 4572 726f 723a 2049  ssertionError: I
-00000a80: 6620 6c65 7373 2074 6861 6e20 7468 7265  f less than thre
-00000a90: 6520 6b65 7973 2061 7265 2070 726f 7669  e keys are provi
-00000aa0: 6465 6420 666f 7220 696e 7465 7270 6f6c  ded for interpol
-00000ab0: 6174 696f 6e2e 0d0a 0d0a 2020 2020 2020  ation.....      
-00000ac0: 2020 4578 616d 706c 653a 0d0a 2020 2020    Example:..    
-00000ad0: 2020 2020 3e3e 3e20 7820 3d20 5b31 2c20      >>> x = [1, 
-00000ae0: 322c 2033 5d0d 0a20 2020 2020 2020 203e  2, 3]..        >
-00000af0: 3e3e 2079 203d 205b 342c 2035 2c20 365d  >> y = [4, 5, 6]
-00000b00: 0d0a 2020 2020 2020 2020 3e3e 3e20 7a20  ..        >>> z 
-00000b10: 3d20 5b37 2c20 382c 2039 5d0d 0a20 2020  = [7, 8, 9]..   
-00000b20: 2020 2020 203e 3e3e 2076 616c 7320 3d20       >>> vals = 
-00000b30: 2878 2c20 792c 207a 290d 0a20 2020 2020  (x, y, z)..     
-00000b40: 2020 203e 3e3e 2069 6e74 6572 705f 6c69     >>> interp_li
-00000b50: 6e65 6172 4e44 282a 7661 6c73 290d 0a20  nearND(*vals).. 
-00000b60: 2020 2020 2020 203c 696e 7465 7270 6f6c         <interpol
-00000b70: 6174 6564 2066 756e 6374 696f 6e20 6f62  ated function ob
-00000b80: 6a65 6374 3e0d 0a20 2020 2020 2020 2022  ject>..        "
-00000b90: 2222 0d0a 2020 2020 2020 2020 6672 6f6d  ""..        from
-00000ba0: 2064 6174 6173 7572 6665 722e 6c69 625f   datasurfer.lib_
-00000bb0: 7374 6174 732e 696e 7465 7270 5f6d 6574  stats.interp_met
-00000bc0: 686f 6473 2069 6d70 6f72 7420 696e 7465  hods import inte
-00000bd0: 7270 5f6c 696e 6561 7231 442c 2069 6e74  rp_linear1D, int
-00000be0: 6572 705f 6c69 6e65 6172 4e44 0d0a 0d0a  erp_linearND....
-00000bf0: 2020 2020 2020 2020 6173 7365 7274 206c          assert l
-00000c00: 656e 2876 616c 7329 203e 3d20 322c 2027  en(vals) >= 2, '
-00000c10: 4174 206c 6561 7374 2074 776f 2069 6e70  At least two inp
-00000c20: 7574 7320 6172 6520 7265 7175 6972 6564  uts are required
-00000c30: 2066 6f72 2069 6e74 6572 706f 6c61 7469   for interpolati
-00000c40: 6f6e 2e27 0d0a 0d0a 2020 2020 2020 2020  on.'....        
-00000c50: 6b77 6172 6773 2e70 6f70 2827 6c61 6265  kwargs.pop('labe
-00000c60: 6c73 272c 204e 6f6e 6529 0d0a 2020 2020  ls', None)..    
-00000c70: 2020 2020 0d0a 2020 2020 2020 2020 6966      ..        if
-00000c80: 206c 656e 2876 616c 7329 203d 3d20 323a   len(vals) == 2:
-00000c90: 0d0a 2020 2020 2020 2020 2020 2020 782c  ..            x,
-00000ca0: 2079 203d 2076 616c 730d 0a20 2020 2020   y = vals..     
-00000cb0: 2020 2020 2020 2066 203d 2069 6e74 6572         f = inter
-00000cc0: 705f 6c69 6e65 6172 3144 2878 2c20 792c  p_linear1D(x, y,
-00000cd0: 202a 2a6b 7761 7267 7329 0d0a 2020 2020   **kwargs)..    
-00000ce0: 2020 2020 656c 7365 3a0d 0a20 2020 2020      else:..     
-00000cf0: 2020 2020 2020 2058 203d 206e 702e 7673         X = np.vs
-00000d00: 7461 636b 2876 616c 735b 3a2d 315d 292e  tack(vals[:-1]).
-00000d10: 540d 0a20 2020 2020 2020 2020 2020 2079  T..            y
-00000d20: 203d 206e 702e 6174 6c65 6173 745f 3264   = np.atleast_2d
-00000d30: 2876 616c 735b 2d31 5d2e 7261 7665 6c28  (vals[-1].ravel(
-00000d40: 2929 2e54 0d0a 0d0a 2020 2020 2020 2020  )).T....        
-00000d50: 2020 2020 6620 3d20 696e 7465 7270 5f6c      f = interp_l
-00000d60: 696e 6561 724e 4428 582c 2079 2c20 2a2a  inearND(X, y, **
-00000d70: 6b77 6172 6773 290d 0a0d 0a20 2020 2020  kwargs)....     
-00000d80: 2020 2072 6574 7572 6e20 660d 0a20 2020     return f..   
-00000d90: 200d 0a20 2020 2040 7061 7273 655f 6461   ..    @parse_da
-00000da0: 7461 0d0a 2020 2020 6465 6620 6669 745f  ta..    def fit_
-00000db0: 6375 7276 6528 7365 6c66 2c20 2a76 616c  curve(self, *val
-00000dc0: 732c 2066 3d4e 6f6e 652c 202a 2a6b 7761  s, f=None, **kwa
-00000dd0: 7267 7329 3a0d 0a20 2020 2020 2020 200d  rgs):..        .
-00000de0: 0a20 2020 2020 2020 2066 726f 6d20 6461  .        from da
-00000df0: 7461 7375 7266 6572 2e6c 6962 5f73 7461  tasurfer.lib_sta
-00000e00: 7473 2e69 6e74 6572 705f 6d65 7468 6f64  ts.interp_method
-00000e10: 7320 696d 706f 7274 2066 6974 5f63 7572  s import fit_cur
-00000e20: 7665 0d0a 2020 2020 2020 2020 0d0a 2020  ve..        ..  
-00000e30: 2020 2020 2020 6173 7365 7274 206c 656e        assert len
-00000e40: 2876 616c 7329 203d 3d20 322c 2027 4f6e  (vals) == 2, 'On
-00000e50: 6c79 2074 776f 2069 6e70 7574 7320 6172  ly two inputs ar
-00000e60: 6520 7265 7175 6972 6564 2066 6f72 2063  e required for c
-00000e70: 7572 7665 2066 6974 7469 6e67 2e27 0d0a  urve fitting.'..
-00000e80: 2020 2020 2020 2020 0d0a 2020 2020 2020          ..      
-00000e90: 2020 6b77 6172 6773 2e70 6f70 2827 6c61    kwargs.pop('la
-00000ea0: 6265 6c73 272c 204e 6f6e 6529 0d0a 2020  bels', None)..  
-00000eb0: 2020 2020 2020 0d0a 2020 2020 2020 2020        ..        
-00000ec0: 6966 2066 2069 7320 4e6f 6e65 3a0d 0a20  if f is None:.. 
-00000ed0: 2020 2020 2020 2020 2020 2066 203d 206c             f = l
-00000ee0: 616d 6264 6120 782c 2061 2c20 623a 2061  ambda x, a, b: a
-00000ef0: 2a78 202b 2062 0d0a 2020 2020 2020 2020  *x + b..        
-00000f00: 2020 2020 0d0a 2020 2020 2020 2020 7265      ..        re
-00000f10: 7475 726e 2066 6974 5f63 7572 7665 2866  turn fit_curve(f
-00000f20: 2c20 2a76 616c 732c 202a 2a6b 7761 7267  , *vals, **kwarg
-00000f30: 7329 0d0a 2020 2020 2020 2020 0d0a 2020  s)..        ..  
-00000f40: 2020 4070 6172 7365 5f64 6174 610d 0a20    @parse_data.. 
-00000f50: 2020 2064 6566 2070 6f6c 7966 6974 2873     def polyfit(s
-00000f60: 656c 662c 202a 7661 6c73 2c20 6465 6772  elf, *vals, degr
-00000f70: 6565 3d31 2c20 2a2a 6b77 6172 6773 293a  ee=1, **kwargs):
-00000f80: 0d0a 2020 2020 2020 2020 0d0a 2020 2020  ..        ..    
-00000f90: 2020 2020 0d0a 2020 2020 2020 2020 6173      ..        as
-00000fa0: 7365 7274 206c 656e 2876 616c 7329 203d  sert len(vals) =
-00000fb0: 3d20 322c 2027 4f6e 6c79 2074 776f 2069  = 2, 'Only two i
-00000fc0: 6e70 7574 7320 6172 6520 7265 7175 6972  nputs are requir
-00000fd0: 6564 2066 6f72 2063 7572 7665 2066 6974  ed for curve fit
-00000fe0: 7469 6e67 2e27 0d0a 2020 2020 2020 2020  ting.'..        
-00000ff0: 0d0a 2020 2020 2020 2020 6b77 6172 6773  ..        kwargs
-00001000: 2e70 6f70 2827 6c61 6265 6c73 272c 204e  .pop('labels', N
-00001010: 6f6e 6529 0d0a 2020 2020 2020 2020 0d0a  one)..        ..
-00001020: 2020 2020 2020 2020 7265 7475 726e 206e          return n
-00001030: 702e 706f 6c79 3164 286e 702e 706f 6c79  p.poly1d(np.poly
-00001040: 6669 7428 2a76 616c 732c 2064 6567 7265  fit(*vals, degre
-00001050: 652c 202a 2a6b 7761 7267 7329 290d 0a20  e, **kwargs)).. 
-00001060: 2020 2020 2020 2020 2020 200d 0a20 2020             ..   
-00001070: 2064 6566 2063 6469 7374 2873 656c 662c   def cdist(self,
-00001080: 2064 662c 2061 7869 733d 302c 2070 6261   df, axis=0, pba
-00001090: 723d 5472 7565 293a 0d0a 2020 2020 2020  r=True):..      
-000010a0: 2020 0d0a 2020 2020 2020 2020 6672 6f6d    ..        from
-000010b0: 2073 6369 7079 2e73 7061 7469 616c 2069   scipy.spatial i
-000010c0: 6d70 6f72 7420 6469 7374 616e 6365 0d0a  mport distance..
-000010d0: 2020 2020 2020 2020 0d0a 2020 2020 2020          ..      
-000010e0: 2020 5842 203d 206e 702e 6174 6c65 6173    XB = np.atleas
-000010f0: 745f 3264 2864 662e 7661 6c75 6573 290d  t_2d(df.values).
-00001100: 0a20 2020 2020 2020 206b 6579 7320 3d20  .        keys = 
-00001110: 6466 2e63 6f6c 756d 6e73 0d0a 2020 2020  df.columns..    
-00001120: 2020 2020 0d0a 2020 2020 2020 2020 4073      ..        @s
-00001130: 686f 775f 706f 6f6c 5f70 726f 6772 6573  how_pool_progres
-00001140: 7328 2743 6163 756c 6174 696e 6727 2c20  s('Caculating', 
-00001150: 7368 6f77 3d70 6261 7229 0d0a 2020 2020  show=pbar)..    
-00001160: 2020 2020 6465 6620 6765 7428 7365 6c66      def get(self
-00001170: 293a 0d0a 2020 2020 2020 2020 2020 2020  ):..            
-00001180: 666f 7220 6f62 6a20 696e 2073 656c 662e  for obj in self.
-00001190: 6f62 6a73 3a0d 0a20 2020 2020 2020 2020  objs:..         
-000011a0: 2020 2020 2020 2074 7279 3a0d 0a20 2020         try:..   
-000011b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000011c0: 2058 4120 3d20 6f62 6a5b 6b65 7973 5d2e   XA = obj[keys].
-000011d0: 7661 6c75 6573 0d0a 2020 2020 2020 2020  values..        
-000011e0: 2020 2020 2020 2020 2020 2020 6469 7374              dist
-000011f0: 203d 2064 6973 7461 6e63 652e 6364 6973   = distance.cdis
-00001200: 7428 5841 2c20 5842 292e 6d69 6e28 6178  t(XA, XB).min(ax
-00001210: 6973 3d61 7869 7329 0d0a 2020 2020 2020  is=axis)..      
-00001220: 2020 2020 2020 2020 2020 2020 2020 7969                yi
-00001230: 656c 6420 6f62 6a2e 6e61 6d65 2c20 6469  eld obj.name, di
-00001240: 7374 0d0a 2020 2020 2020 2020 2020 2020  st..            
-00001250: 2020 2020 6578 6365 7074 2028 4b65 7945      except (KeyE
-00001260: 7272 6f72 2c20 5275 6e74 696d 6545 7272  rror, RuntimeErr
-00001270: 6f72 293a 0d0a 2020 2020 2020 2020 2020  or):..          
-00001280: 2020 2020 2020 2020 2020 7969 656c 640d            yield.
-00001290: 0a20 2020 2020 2020 200d 0a20 2020 2020  .        ..     
-000012a0: 2020 2072 6573 203d 2064 6963 7428 7820     res = dict(x 
-000012b0: 666f 7220 7820 696e 2067 6574 2873 656c  for x in get(sel
-000012c0: 662e 6470 2920 6966 2078 290d 0a20 2020  f.dp) if x)..   
-000012d0: 2020 2020 200d 0a20 2020 2020 2020 2072       ..        r
-000012e0: 6574 7572 6e20 7064 2e44 6174 6146 7261  eturn pd.DataFra
-000012f0: 6d65 2e66 726f 6d5f 6469 6374 2872 6573  me.from_dict(res
-00001300: 2c20 6f72 6965 6e74 3d27 696e 6465 7827  , orient='index'
-00001310: 292e 7472 616e 7370 6f73 6528 290d 0a20  ).transpose().. 
-00001320: 2020 2020 2020 200d 0a20 2020 2020 2020         ..       
-00001330: 2020 2020 200d 0a20 2020 2020 2020 2020       ..         
-00001340: 2020 200d 0a20 2020 2020 2020 2020 2020     ..           
-00001350: 200d 0a20 2020 2020 2020 200d 0a20 0d0a   ..        .. ..
-00001360: 2020 2020 2020 2020 0d0a 2020 2020 0d0a          ..    ..
-00001370: 2320 2525 0d0a                           # %%..
```

## Comparing `datasurfer-1.0.9.dist-info/LICENSE` & `datasurfer-1.1.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `datasurfer-1.0.9.dist-info/METADATA` & `datasurfer-1.1.dist-info/METADATA`

 * *Files 13% similar despite different names*

```diff
@@ -1,53 +1,60 @@
-Metadata-Version: 2.1
-Name: datasurfer
-Version: 1.0.9
-Summary: A Python package for data processing
-Home-page: https://github.com/yuw1si/datasurfer
-Author: Wei Yu
-Author-email: wei.yu2@de.bosch.com
-License: MIT license
-Keywords: datasurfer
-Classifier: Development Status :: 2 - Pre-Alpha
-Classifier: Intended Audience :: Developers
-Classifier: License :: OSI Approved :: MIT License
-Classifier: Natural Language :: English
-Classifier: Programming Language :: Python :: 3
-Classifier: Programming Language :: Python :: 3.6
-Classifier: Programming Language :: Python :: 3.7
-Classifier: Programming Language :: Python :: 3.8
-Requires-Python: >=3.6
-License-File: LICENSE
-License-File: AUTHORS.rst
-
-# Datasurfer 
-is a solution designed to effortlessly read various file formats and seamlessly convert them into structured dataframes. This tool is engineered to streamline the data processing workflow, providing unparalleled flexibility and efficiency.
-Key Features:
-
-    Universal File Compatibility:
-    Datastructure supports a wide array of file formats, including CSV, Excel, Matlab and more. No matter the source of your data, this software ensures compatibility for a hassle-free integration.
-
-    Intelligent File Parsing:
-    The software employs intelligent parsing algorithms to interpret and extract data from diverse file structures. Whether the data is tabular, nested, or semi-structured, DataFlex Pro adapts to the nuances of each format with precision.
-
-    Dataframe Transformation:
-    DataFlex Pro converts the parsed data into versatile dataframes, providing a structured and organized representation. This enables users to easily manipulate, analyze, and visualize the data with popular data science libraries.
-
-    Customizable Output Options:
-    Tailor the output of your data according to your needs. DataFlex Pro allows users to export dataframes to various destinations, including databases, cloud storage, and popular data analysis tools. This ensures seamless integration with your existing data ecosystem.
-
-    Data Cleaning:
-    The software includes robust data cleaning features to identify and rectify inconsistencies, missing values, and anomalies during the conversion process. This ensures that the resulting dataframes are accurate and reliable for downstream analysis.
-
-    Batch Processing:
-    Streamline your data conversion tasks by utilizing DataFlex Pro's batch processing capabilities. Process multiple files concurrently, saving time and resources.
-
-
-
-=======
-History
-=======
-
-0.1.0 (2023-12-12)
-------------------
-
-* First release on PyPI.
+Metadata-Version: 2.1
+Name: datasurfer
+Version: 1.1
+Summary: A Python package for data processing
+Home-page: https://github.com/yuw1si/datasurfer
+Author: Wei Yu
+Author-email: yuwei2005@gmail.com
+License: MIT license
+Keywords: datasurfer
+Platform: UNKNOWN
+Classifier: Development Status :: 2 - Pre-Alpha
+Classifier: Intended Audience :: Developers
+Classifier: License :: OSI Approved :: MIT License
+Classifier: Natural Language :: English
+Classifier: Programming Language :: Python :: 3
+Classifier: Programming Language :: Python :: 3.6
+Classifier: Programming Language :: Python :: 3.7
+Classifier: Programming Language :: Python :: 3.8
+Requires-Python: >=3.6
+License-File: LICENSE
+License-File: AUTHORS.rst
+
+# Datasurfer 
+is a solution designed to effortlessly read various file formats and seamlessly convert them into structured dataframes. This tool is engineered to streamline the data processing workflow, providing unparalleled flexibility and efficiency.
+Key Features:
+
+    Universal File Compatibility:
+    Datastructure supports a wide array of file formats, including CSV, Excel, Matlab and more. No matter the source of your data, this software ensures compatibility for a hassle-free integration.
+
+    Intelligent File Parsing:
+    The software employs intelligent parsing algorithms to interpret and extract data from diverse file structures. Whether the data is tabular, nested, or semi-structured, DataFlex Pro adapts to the nuances of each format with precision.
+
+    Dataframe Transformation:
+    DataFlex Pro converts the parsed data into versatile dataframes, providing a structured and organized representation. This enables users to easily manipulate, analyze, and visualize the data with popular data science libraries.
+
+    Customizable Output Options:
+    Tailor the output of your data according to your needs. DataFlex Pro allows users to export dataframes to various destinations, including databases, cloud storage, and popular data analysis tools. This ensures seamless integration with your existing data ecosystem.
+
+    Data Cleaning:
+    The software includes robust data cleaning features to identify and rectify inconsistencies, missing values, and anomalies during the conversion process. This ensures that the resulting dataframes are accurate and reliable for downstream analysis.
+
+    Batch Processing:
+    Streamline your data conversion tasks by utilizing DataFlex Pro's batch processing capabilities. Process multiple files concurrently, saving time and resources.
+
+
+
+=======
+History
+=======
+
+0.1.0 (2023-12-12)
+------------------
+
+* First release on PyPI.
+
+1.0.9 (2024-04-04)
+------------------
+
+* Release data lake and data pool
+
```

## Comparing `datasurfer-1.0.9.dist-info/RECORD` & `datasurfer-1.1.dist-info/RECORD`

 * *Files 26% similar despite different names*

```diff
@@ -13,38 +13,53 @@
 datastructure/lib_objects/data_object.py,sha256=mb5Noi9M-_RUARhzHhqsm9u40eX4GavOp53JguFHPvk,3021
 datastructure/lib_objects/finance_object.py,sha256=0DkfNPoBgaX4_H3E3Fru8gKqKcLsjwlD2-GKnsvTfvw,2211
 datastructure/lib_objects/matlab_object.py,sha256=YgdumVb8s3POb_frQGaXdCQO_gftKQ3EWp6ia-JJ3EU,2862
 datastructure/lib_objects/mdf_object.py,sha256=ENAv1y-1gOrFICz63a5KQ7sBTbP9t-Gdn4lELWKqmAE,6114
 datastructure/lib_objects/pandas_object.py,sha256=YoBAjfqa9eJoemr-fdFNrjsdw7igwOQuQmkXkbfqTFY,1624
 datasurfer/Plot_Collections.py,sha256=Y5Q4RgWdtbVkGZDe8n5zWN6VK5Morny1xUPJPpLIcIA,40406
 datasurfer/Plot_IDIADA.py,sha256=kJI_5tHpNnXwOg0h6FetAcatnR1I4rLMwIIVtCLsBTY,27117
-datasurfer/__init__.py,sha256=88Exe2wfVCMo_R5vfyKcpv-XB9YtB6eVkHkoo51L53Q,306
-datasurfer/datainterface.py,sha256=Qb3MAB5en6gs6L_rZbWwqDEgczCuciAQGQfp3ncDOnA,33171
-datasurfer/datalake.py,sha256=Dr_PBo_Ae11WHiQ5vjAituhLHRo0cuaQ9tSliWIBm6M,16163
-datasurfer/datapool.py,sha256=RhCnEhh6IEnI-54NWymBJsNOe8-MVjjodZ4qvcVh_A8,51607
-datasurfer/datautils.py,sha256=CmmkY9hs4teHjb7NbQ1ud_9cfJXmrFFg8kSy8XWgQYk,15464
-datasurfer/lib_mlearn/__init__.py,sha256=bGvhxdTI4AboMBxm9gxTJ8FOtpwHjfuLUggh-4-DAHY,2453
-datasurfer/lib_mlearn/preproc.py,sha256=RxJGqReWU1yfjuDQrsRIMrimxUPkGmnBrEl5nRcLorY,227
-datasurfer/lib_objects/__init__.py,sha256=Gg7SBIWOqloVOZCNRtyJZlsW1_qZXVaOSzByt6VVv2g,29556
-datasurfer/lib_objects/amedata_object.py,sha256=viQXMre_ZMGwMDYpxavjoTjaaRKcSkI2wSYHbI9EKac,5503
-datasurfer/lib_objects/amegp_object.py,sha256=nK7Khwj8It9afWI28H1PIq_5UTkcfgUEQZifojoZgnU,4037
-datasurfer/lib_objects/ameres_object.py,sha256=mVxEJVh0UVli6GQmKNGSFKvwlGNQZCzDxnDjlHOl7ew,7723
-datasurfer/lib_objects/asammdf_object.py,sha256=nGzkJMv-Lb-pI9qxLarNUCARy-oG2nMyeEkaweJTpB8,8510
+datasurfer/__init__.py,sha256=i-8-W6X-xf-U7j5ZBEdLBb1ub4-uiks7Zmw5zUTG-Nk,5456
+datasurfer/datainterface.py,sha256=wXny82zlACy8ilBIY0KnU7-wy4RO3yswbMf2lcWqFHk,35899
+datasurfer/datalake.py,sha256=4_eFVsy7H4SdXAbS5Rfv5EzkEFIbRButhO8TnwUmMc0,18028
+datasurfer/datapool.py,sha256=L-54DdSwB0N8St4Qo3TybP5mQCHNHPMuqvSlvbh5ZZI,63805
+datasurfer/datautils.py,sha256=e5VXHW59Qpj2JJFzXs6_g4RSebPkWRgHo2iJ1H-Hxmc,16710
+datasurfer/lib_dlearn/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+datasurfer/lib_mlearn/__init__.py,sha256=257Nhlo7t-nfmp4DB9jY0k7cW48Y98X3gdiTrp5bRz4,4391
+datasurfer/lib_mlearn/clustering.py,sha256=JJlBgFdl43oaXxQdni7JY2jTWkanivmwKh3nQEAlX6M,1866
+datasurfer/lib_mlearn/preproc.py,sha256=vHc1DPqm1x7RmcMdGe2jSFG9wykSDN7RomJdTh9lhQA,220
+datasurfer/lib_objects/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+datasurfer/lib_objects/amedata_object.py,sha256=OYa9Cber4FgFoQMs44V2iAOTdbjEnmx7EQALsxdAqn8,5529
+datasurfer/lib_objects/amegp_object.py,sha256=Hcs6rcGG00Il3pSzWNOQIF91ZHvzPONye-BI0BgczJo,4058
+datasurfer/lib_objects/ameres_object.py,sha256=ZFri-ESibNWhrkGW7KIbutcaZFEY9NdaTBJmlHxfxGQ,8009
+datasurfer/lib_objects/asammdf_object.py,sha256=84U81aRYbOCPY3il6NafLk0ORjxs3AaFCGzJ_nkA_aw,8657
 datasurfer/lib_objects/data_object.py,sha256=VCbmeZdb-rh6dhTjPNiSYoFeuXX4udc-bLB3CDh6iKg,3028
-datasurfer/lib_objects/finance_object.py,sha256=7i3WD-MDoVAc2OllROMboza3cVQlqi3IOgeRInGiyTc,2229
-datasurfer/lib_objects/json_object.py,sha256=EShRMAjmX3cgKjofBJkccM7hUA0K1iu7BCfc0uUQtis,1292
-datasurfer/lib_objects/matlab_object.py,sha256=BwJ8_krbYwYDefD8uWSgATpMb3QDlzkS-C1J1jsrxy4,3188
-datasurfer/lib_objects/mdf_object.py,sha256=5xpIlcT6xDPMOec7b_Gopqq450NipbtO8OTNmC4n2GE,6040
-datasurfer/lib_objects/pandas_object.py,sha256=5HoBq3brkv7hdRpzmrpiwJ9jXszaB_ntRhgmTy70lNg,1852
-datasurfer/lib_objects/xkf_object.py,sha256=5eJQ8ItZLfEvgO26mkJClr9_i3FWH9kuUfmEUlwiGHQ,2426
-datasurfer/lib_plots/__init__.py,sha256=cs33mmfak2guDPuwpq6BjRJuDPqNsZKYst1opMO_T-Q,11502
-datasurfer/lib_plots/plot_collection.py,sha256=OBdsPA7Ptte6q8Z8DoZ8Ie_DgWvCjOlGv40-SZNnBgw,40380
-datasurfer/lib_plots/plot_utils.py,sha256=6KhKpXX2gvp4k1VaLu9U-cktZ_Azi7b8IBItYVLPNCA,41548
-datasurfer/lib_stats/__init__.py,sha256=9EChxWc8KVpEHumvUmmocbSSxp74c9WPHA5sJ9uJJZc,4982
+datasurfer/lib_objects/femke_object.py,sha256=Ta5e6JFpDqi_FsyWA7htZYui9r_nevdbHlYx7FzBHxs,2831
+datasurfer/lib_objects/finance_object.py,sha256=RYPMLnmWJFWevFXO82BIT0if30I6KpgaB4KlZeC-6fQ,2271
+datasurfer/lib_objects/json_object.py,sha256=Qp7dIQMCwvHizMBJUyKLskEuCp6XnzSVJnFSCz77R44,1363
+datasurfer/lib_objects/matlab_object.py,sha256=T2vswBGvY1C7J_RFbW1VM31pVXOKHfSu5OIR62mkuiA,3241
+datasurfer/lib_objects/mdf_object.py,sha256=_q7_hoo9_yuU3clRoUiUujTgZxoUYRseHt_pbpFoolw,6218
+datasurfer/lib_objects/multisheet_object.py,sha256=ofnmR9ECFQOaWj2u6emd2wAtk34Cel_2nemvLz-Hvlk,1004
+datasurfer/lib_objects/numpy_object.py,sha256=EaXpaoTcE5HeTGAMOma5_AtbUuxbZQD6P2ECX99ZB7c,3629
+datasurfer/lib_objects/pandas_object.py,sha256=CKdTpoAXOs9HomoNPUZS_V3Rn1n_cCfrQTEEOrMiSUQ,4515
+datasurfer/lib_objects/pdf_object.py,sha256=TrsK2T0C8jRQ1jI16cYGXo26ZMUfgKY8kt8e5yL603U,984
+datasurfer/lib_objects/string_object.py,sha256=8VKRl1es6wzb4s--rMFre3WGlLUI6IRWuGXTi7UH_6A,5357
+datasurfer/lib_objects/xkf_object.py,sha256=YLalBBPqPOq4JJavZ3biyVx_sl-gBwhYP6Ehiboeasg,2428
+datasurfer/lib_plots/__init__.py,sha256=z8QkejaDTNVIeSqxP_wa_iCZyMJ6uvTCJ1Xdy9DbXrs,23773
+datasurfer/lib_plots/plot_collection.py,sha256=PNiqnTfprZ6_zkBmOlfvpXAyHo2XcFExFvW0DJYNu-M,47643
+datasurfer/lib_plots/plot_utils.py,sha256=rPvwXfR-9KRW2op0mfzwfcf67nVHaosWsmD84mcwg9c,42922
+datasurfer/lib_poolobjects/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
+datasurfer/lib_poolobjects/multisheet_object.py,sha256=dTgKxaxkfSza9Ied8St6Z1WUTXMKikuQVSIl9kz5Hl4,1007
+datasurfer/lib_signals/__init__.py,sha256=oQamTqTeVFzd04oevnPNIbwAMMkptxjTPOcXGs1liaE,6998
+datasurfer/lib_signals/distrib_methods.py,sha256=YSYWvbkpWYkLDWEcQwvVxH65lVokJoJtKfuQV9zqm1k,3056
+datasurfer/lib_signals/filter_methods.py,sha256=RYS1VuXYfmJoOcWfto_SgqB5j2rIJ7Q7dXMS3Pta2-I,277
+datasurfer/lib_signals/interp_methods.py,sha256=-iGuf_sc2tB_k3wJgSHptPBpE9wWaOXSXHPBrGTOhzY,1900
+datasurfer/lib_stats/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 datasurfer/lib_stats/distrib_methods.py,sha256=VO3n_CnhxfnEPFOyonLX3XcAkbyhX-jnUwUXSWhJIRg,667
 datasurfer/lib_stats/interp_methods.py,sha256=uQOE5vixLn8Ifmqq7dDiyt-zLTIHJeM54rtNteX5GCw,1955
-datasurfer-1.0.9.dist-info/AUTHORS.rst,sha256=J_0aYn4esxraQ7_QjD_zsE4jKxW_jT-eyHsFfkckGB4,164
-datasurfer-1.0.9.dist-info/LICENSE,sha256=kv5c-cVFsGGcBOhI8EXem_QLS5QWzY4cys8HKdKVmkY,1530
-datasurfer-1.0.9.dist-info/METADATA,sha256=Llc8cxKQ_gHAiqDH22Xp8bVaonD5zfM8wvLWPQUWqeA,2636
-datasurfer-1.0.9.dist-info/WHEEL,sha256=iYlv5fX357PQyRT2o6tw1bN-YcKFFHKqB_LwHO5wP-g,110
-datasurfer-1.0.9.dist-info/top_level.txt,sha256=Q4FtCvJzAL3PPM_4zc_L-GkozI100aBxRK35CQQ44WQ,11
-datasurfer-1.0.9.dist-info/RECORD,,
+datasurfer/util_config/__init__.py,sha256=AixBFQsN6wxruu68aDXi9NJGSr_cBBicJuhMhRHjbws,12865
+datasurfer/util_multiproc/__init__.py,sha256=jm2-oLwzobAbG0mEUrffgBb9eE-vxnoVjN6YouNYtJw,7628
+datasurfer-1.1.dist-info/AUTHORS.rst,sha256=J_0aYn4esxraQ7_QjD_zsE4jKxW_jT-eyHsFfkckGB4,164
+datasurfer-1.1.dist-info/LICENSE,sha256=kv5c-cVFsGGcBOhI8EXem_QLS5QWzY4cys8HKdKVmkY,1530
+datasurfer-1.1.dist-info/METADATA,sha256=aRPQYW-pZ-NxYFmM7SB7p_ptzbv_kuKSOjDaoW5mla4,2673
+datasurfer-1.1.dist-info/WHEEL,sha256=WzZ8cwjh8l0jtULNjYq1Hpr-WCqCRgPr--TX4P5I1Wo,110
+datasurfer-1.1.dist-info/top_level.txt,sha256=Q4FtCvJzAL3PPM_4zc_L-GkozI100aBxRK35CQQ44WQ,11
+datasurfer-1.1.dist-info/RECORD,,
```

